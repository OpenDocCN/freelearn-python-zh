- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Scaling Your Code
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规模化你的代码
- en: Now that we know how to interact with network devices, we should start thinking
    about building a solution that scales. But why do we need to scale our code? You
    might be thinking that the answer is obvious and it is just because it will allow
    your solution to grow easily as your network grows. But scaling is not just about
    going up but scaling down too. So, scaling your code means that you are going
    to build a solution that can follow demand easily, saving resources when not required
    and using more when required.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何与网络设备交互，我们应该开始考虑构建一个可扩展的解决方案。但我们为什么需要扩展我们的代码呢？你可能认为答案很明显，那就是因为它将允许你的解决方案随着网络的增长而轻松增长。但扩展不仅仅是关于向上扩展，还包括向下扩展。因此，扩展你的代码意味着你将构建一个能够轻松跟随需求的解决方案，在不需要时节省资源，在需要时使用更多资源。
- en: You should consider adding scaling capabilities adding scaling capabilities
    to your network automation solution before writing the code. It should be planned
    during design time and then executed during development time. The scaling capabilities
    have to be one of the requirements for building your solution. It also should
    be a clear milestone during implementation and testing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写代码之前，你应该考虑在你的网络自动化解决方案中添加扩展功能。它应该在设计时间规划，并在开发时间执行。扩展功能必须是构建解决方案的要求之一。它还应该在实施和测试期间成为一个明确的里程碑。
- en: In this chapter, we are going to check some techniques used today to scale your
    code up and down effectively. This will allow your solution to adapt easily to
    follow network growth and, if necessary, easily scale down to save resources.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将检查一些今天用来有效扩展和缩小代码的技术。这将使你的解决方案能够轻松适应网络增长，并在必要时轻松缩小规模以节省资源。
- en: 'We are going to cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中涵盖以下主题：
- en: Dealing with multitasking, threads, and coroutines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理多任务、线程和协程
- en: Adding schedulers and job dispatchers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加调度器和作业分配器
- en: Using microservices and containers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用微服务和容器
- en: By the end of this chapter, you should have enough information to choose the
    best scaling solution for your code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该有足够的信息来为你的代码选择最佳的扩展解决方案。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The source code described in this chapter is stored in the GitHub repository
    at [https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08](https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中描述的源代码存储在GitHub仓库[https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08](https://github.com/PacktPublishing/Network-Programming-and-Automation-Essentials/tree/main/Chapter08)。
- en: Dealing with multitasking, threads, and coroutines
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理多任务、线程和协程
- en: Multitasking, as the name suggests, is the capability of doing several tasks
    at the same time. In computers, a task is also known as a job or a process and
    there are different techniques for running tasks at the same time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务，正如其名所示，是指同时执行多个任务的能力。在计算机中，任务也被称为作业或进程，并且有不同技术在同时运行任务。
- en: The capability to run code at the same time allows your system to scale up and
    down whenever necessary. If you have to communicate with more network devices,
    just run more code in parallel; if you need fewer devices, just run less code.
    That will enable your system to scale up and down.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同时运行代码的能力允许你的系统在必要时进行扩展和缩小。如果你需要与更多的网络设备通信，只需并行运行更多的代码；如果你需要较少的设备，只需运行较少的代码。这将使你的系统能够进行扩展和缩小。
- en: But running code in parallel will have an impact on the available machine resources,
    and some of these resources will be limited by how your code is consuming them.
    For instance, if your code is using the network interface to download files, and
    running one single line of code is already consuming 50 Mbps of the network interface
    (which is 50% of the 100 Mbps interface), it is not advised to run multiple lines
    of code in parallel to increase the speed, as the limitation is on the network
    interface and not in the CPU.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但是并行运行代码将对可用的机器资源产生影响，其中一些资源将受到你的代码如何消耗它们的影响而受限。例如，如果你的代码正在使用网络接口下载文件，并且运行一行代码就已经消耗了网络接口的50
    Mbps（即100 Mbps接口的50%），那么不建议并行运行多行代码以增加速度，因为限制在于网络接口，而不是CPU。
- en: Other factors are also important to be considered when running code in parallel,
    that is, the other shared resources besides the network, such as the CPU, disk,
    and memory. In some cases, bottlenecks in the disk might cause more limitations
    for code parallelism than the CPU, especially using disks mounted over the network.
    In other cases, a large program consuming lots of memory would block the execution
    of any other program running in parallel because of a lack of free memory. Therefore,
    the resources that your process will touch and how they interact will have an
    impact on how much parallelism is possible.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行运行代码时，还需要考虑其他因素，即除了网络之外的共享资源，例如 CPU、磁盘和内存。在某些情况下，磁盘的瓶颈可能会对代码并行性造成比 CPU 更多的限制，尤其是在使用通过网络挂载的磁盘时。在其他情况下，一个消耗大量内存的大程序可能会因为缺乏可用内存而阻塞任何其他并行运行的程序。因此，你的进程将接触到的资源以及它们之间的交互将影响并行化的程度。
- en: One thing we should clarify here is the term **I/O**, which is an acronym for
    computer **input/output**. I/O is used to designate any communication between
    the CPU of the machine and the external world, such as accessing the disk, writing
    to memory, or sending data to the network. If your code requires lots of external
    access and it is, most of the time, waiting to receive a response from external
    communication, we normally say the code is **I/O bound**. An example of slow I/O
    can be found when accessing remote networks and, in some cases, remote disks.
    On the other hand, if your code requires more CPU computation than I/O, we normally
    say the code is **CPU bound**. Most network automation systems will be I/O bound
    because of network device access.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们需要明确一点，即术语 **I/O**，它是计算机 **输入/输出** 的缩写。I/O 用于指定机器的 CPU 与外部世界之间的任何通信，例如访问磁盘、写入内存或将数据发送到网络。如果你的代码需要大量的外部访问，并且大多数时间都在等待外部通信的响应，我们通常说代码是
    **I/O 密集型**。当访问远程网络和在某些情况下远程磁盘时，可以找到慢速 I/O 的例子。另一方面，如果你的代码需要的 CPU 计算比 I/O 更多，我们通常说代码是
    **CPU 密集型**。大多数网络自动化系统将是 I/O 密集型的，因为网络设备访问。
- en: Let’s now investigate a few techniques to run code at the same time in Go and
    Python.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨一些在 Go 和 Python 中同时运行代码的技术。
- en: Multiprocessing
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多进程
- en: In computers, when a program is loaded in memory to run, it’s called a process.
    The program can be either a script or a binary file, but it is normally represented
    by one single file. This file will be loaded into memory and it is seen by the
    operating system as a process. The capability of running multiple processes at
    the same time is called multiprocessing, and it is normally managed by the operating
    system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机中，当一个程序被加载到内存中运行时，它被称为进程。程序可以是脚本或二进制文件，但通常由一个单独的文件表示。这个文件将被加载到内存中，并且操作系统将其视为一个进程。同时运行多个进程的能力称为多进程，这通常由操作系统管理。
- en: The number of CPUs of the hardware where the processes are running is irrelevant
    to the multiprocessing capability. The operating system is responsible for allocating
    the CPU time for all processes that are in memory and ready to run. However, as
    the number of CPUs, speed of the CPU, and memory are limited, the number of processes
    that can run at the same time will also be limited. Normally, it depends on the
    size of the process and how much CPU it consumes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 运行进程的硬件的 CPU 数量与多进程能力无关。操作系统负责为所有已加载到内存中并准备运行的进程分配 CPU 时间。然而，由于 CPU 数量、CPU 速度和内存有限，可以同时运行的进程数量也将有限。通常，这取决于进程的大小以及它消耗的
    CPU 资源。
- en: In most computer languages, multiprocessing is implemented using the `fork()`
    system call implemented by the operating system to create a complete copy of the
    currently running process.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数计算机语言中，多进程是通过操作系统实现的 `fork()` 系统调用来创建当前运行进程的完整副本来实现的。
- en: Let’s investigate how we can use multiprocessing in Go and Python.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们研究一下如何在 Go 和 Python 中使用多进程。
- en: Multiprocessing in Python
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 中的多进程
- en: In Python, multiprocessing is accomplished by the standard library called `multiprocessing`.
    Full documentation on Python `multiprocessing` can be found at [docs.python.org/3/library/multiprocessing](http://docs.python.org/3/library/multiprocessing).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，多进程是通过标准库 `multiprocessing` 实现的。Python `multiprocessing` 的完整文档可以在
    [docs.python.org/3/library/multiprocessing](http://docs.python.org/3/library/multiprocessing)
    找到。
- en: In the first example, we are going to use the operating system program called
    `ping` to target one network node. Then, we are going to make it parallel for
    multiple targets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个示例中，我们将使用操作系统的程序`ping`来针对一个网络节点。然后，我们将使其对多个目标并行化。
- en: 'The following is an example for one target network node:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个针对单个目标网络节点的示例：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It is important to note that calling `ping` from Python is not efficient. It
    will cause more overhead because Python will have to invoke an external program
    that resides in the filesystem. In order to make the example more efficient, we
    need to use the ICMP `echo request` and receive an ICMP `echo reply` from the
    Python network sockets, instead of invoking an external program such as `ping`.
    One solution is to use the Python third-party library called `pythonping` ([https://pypi.org/project/pythonping/](https://pypi.org/project/pythonping/)).
    But there is one caveat: the `ping` program has `setuid` to allow ICMP packets
    to be sent by a non-privileged user. Thus, in order to run with `pythonping`,
    you need admin/root privileges (accomplished in Linux using `sudo`).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，从Python调用`ping`效率不高。它将导致更多的开销，因为Python将不得不调用一个位于文件系统中的外部程序。为了使示例更高效，我们需要使用ICMP的`echo
    request`并从Python网络套接字接收ICMP的`echo reply`，而不是调用外部程序，如`ping`。一个解决方案是使用名为`pythonping`的Python第三方库([https://pypi.org/project/pythonping/](https://pypi.org/project/pythonping/))。但有一个注意事项：`ping`程序被设置为`setuid`，允许非特权用户发送ICMP数据包。因此，为了使用`pythonping`运行，你需要管理员/根权限（在Linux中使用`sudo`完成）。
- en: 'The following is the same example using `pythonping` for one target network
    node:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用`pythonping`针对单个目标网络节点的相同示例：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Running this program should generate the following output:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此程序应该会生成以下输出：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you want to send ICMP requests to multiple targets, you will have to send
    them sequentially one after the other. However, a better solution would be to
    run them in parallel using the `multiprocessing` Python library. The following
    is an example of four targets using `multiprocessing`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要向多个目标发送ICMP请求，你必须一个接一个地顺序发送。然而，一个更好的解决方案是使用`multiprocessing` Python库并行运行它们。以下是一个使用`multiprocessing`的四个目标的示例：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you run the preceding program, you should get an output similar to the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行先前的程序，你应该得到类似于以下输出的结果：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that the response of each target does not depend on the response of others.
    Therefore, the output should always be in order from low latency to high latency.
    In the preceding example, `google.com` finished first, showing a latency of just
    45.31 ms.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个目标的响应不依赖于其他目标的响应。因此，输出应该始终按从低延迟到高延迟的顺序排列。在先前的示例中，`google.com`首先完成，显示延迟仅为45.31毫秒。
- en: Important note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is important to call `multiprocessing` inside the `main()` function, or a
    function that is called from `main()`. Also, make sure `main()` can be safely
    imported by a Python interpreter (use `__name__` ). You can find more details
    on why at [https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming](https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`函数或从`main()`函数调用的函数中调用`multiprocessing`是很重要的。同时，确保`main()`可以被Python解释器安全导入（使用`__name__`）。你可以在[https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming](https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming)找到更多关于为什么需要这样做的细节。
- en: Python has additional methods to invoke code parallelism besides the preceding
    example using `Process()`, called `multiprocessing.Pool()` and `multiprocessing.Queue()`.
    The `Pool()` class is used to instantiate a pool of workers that can do a job
    without the need to communicate with each other. The `Queue()` class is used when
    communication between processes is required. More on that can be found at [https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除了先前的使用`Process()`的示例之外，Python还有其他方法可以调用代码并行性，称为`multiprocessing.Pool()`和`multiprocessing.Queue()`。`Pool()`类用于实例化一个工作池，它可以执行工作而无需相互通信。当需要进程间通信时使用`Queue()`类。更多关于这方面的信息可以在[https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html)找到。
- en: Let’s see how we can use multiprocessing in Go.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在Go语言中使用多进程。
- en: Multiprocessing in Go
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Go语言中的多进程
- en: To create processes from a program, you need to create a copy of the data of
    the current running program to a new process. That is what Python’s `multiprocessing`
    does. However, Go implements parallelism very differently. Go was designed to
    work with routines similar to coroutines, they are called goroutines, which manage
    parallelism at runtime. As goroutines are much more efficient, there is no need
    to implement multiprocessing natively in Go.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要从程序中创建进程，你需要将当前运行程序的数据复制到一个新进程中。这就是Python的`multiprocessing`所做的事情。然而，Go实现并行化的方式非常不同。Go被设计成与协程类似的工作方式，它们被称为goroutines，它们在运行时管理并行性。由于goroutines效率更高，因此不需要在Go中原生实现多进程。
- en: Note that using the `exec` library, by calling `exec.Command()` and then `Cmd.Start()`
    and `Cmd.Wait()`, will allow you to create multiple processes at the same time,
    but it is a call to the operating system to execute an external program. Therefore,
    it is not considered native multiprocessing and is not efficient.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用`exec`库，通过调用`exec.Command()`然后`Cmd.Start()`和`Cmd.Wait()`，可以同时创建多个进程，但这是对操作系统的调用以执行外部程序。因此，它不被视为原生多进程，并且效率不高。
- en: For these reasons, we don’t have an example of multi-processing in Go.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，我们在Go中没有多进程的示例。
- en: Let’s see now how we do multithreading.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们是如何进行多线程的。
- en: Multithreading
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多线程
- en: In computer languages, a thread is a smaller part of a process, which can have
    one or multiple threads. The memory is shared between the threads in the same
    process, in contrast with a process that does not share memory with another process.
    Therefore, a thread is known as a lightweight process because it requires less
    memory, and communication between threads within a process is faster. In consequence,
    spawning new threads is much faster in comparison with new processes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机语言中，线程是进程的一个较小部分，它可以有一个或多个线程。在同一个进程中的线程之间共享内存，与不与其他进程共享内存的进程相对。因此，线程被称为轻量级进程，因为它需要的内存更少，并且进程内线程之间的通信更快。因此，与创建新进程相比，创建新线程要快得多。
- en: A CPU with multithreading capability is a CPU that has the ability to run multiple
    threads in a single core by providing instruction-level parallelism or thread-level
    parallelism. This capability is also known as **Simultaneous** **Multithreading**
    (**SMT**).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 具有多线程能力的CPU是能够通过提供指令级并行性或线程级并行性，在单个核心中运行多个线程的CPU。这种能力也被称为**同时** **多线程** (**SMT**)。
- en: One example of SMT is the Intel CPU i9-10900K, which has 10 cores and the capability
    to run 2 threads at the same time per core, which allows up to 20 simultaneous
    threads. Intel has created a trademark name for SMT, which they call **hyper-threading**.
    Normally, AMD and Intel x86 CPU architectures can run up to two threads per core.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: SMT的一个例子是Intel CPU i9-10900K，它有10个核心，每个核心可以同时运行2个线程，这允许最多20个同时线程。Intel为SMT创建了一个商标名称，他们称之为**超线程**。通常，AMD和Intel
    x86 CPU架构每个核心可以运行多达两个线程。
- en: In contrast, the Oracle SPARC M8 processor has 32 cores that can run 8 threads
    each, allowing a staggering number of 256 simultaneous threads. More on this amazing
    CPU can be found at [https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf](https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，Oracle SPARC M8处理器有32个核心，每个核心可以运行8个线程，允许惊人的256个同时线程。更多关于这个惊人的CPU的信息可以在[https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf](https://www.oracle.com/us/products/servers-storage/sparc-m8-processor-ds-3864282.pdf)找到。
- en: But for the CPU to perform its best using threads, two other requirements are
    necessary, an operating system that allows CPU-level multithreading and a computer
    language that allows the creation of simultaneous threads.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但要使CPU通过线程发挥最佳性能，还需要两个其他要求，一个是允许CPU级多线程的操作系统，以及一个允许创建同时线程的计算机语言。
- en: Let’s see how we can use multithreading in Python.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何在Python中使用多线程。
- en: Multithreading in Python
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python中的多线程
- en: Multithreading is the Achilles’ heel of Python. The main reason is that the
    Python interpreter called CPython (discussed in [*Chapter 6*](B18165_06.xhtml#_idTextAnchor166))
    uses a **Global Interpreter Lock** (**GIL**) to make it thread-safe. This has
    a consequence of not allowing Python code to run multiple threads at the same
    time in a multithread CPU. GIL also adds overhead and using multithreading might
    cause the program to run slower in comparison with multiprocessing when more CPU
    work is required.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程是Python的阿喀琉斯之踵。主要原因在于Python解释器CPython（在第6章中讨论）使用全局解释器锁（GIL）来确保线程安全。这导致的结果是在多线程CPU上不允许Python代码同时运行多个线程。GIL还增加了开销，并且当需要更多的CPU工作时，使用多线程可能比使用多进程慢。
- en: Therefore, in Python, multithreading is not recommended for programs that are
    CPU bound. For network and other I/O-bound programs, multithreading might be faster
    to spawn and easier to communicate with and save runtime memory. But it is important
    to note that only one thread will run at a time using the CPython interpreter,
    so if you require true parallelism, use the `multiprocessing` library instead.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在Python中，对于CPU密集型的程序，不建议使用多线程。对于网络和其他I/O密集型的程序，多线程可能更快地启动，更容易通信，并且可以节省运行时内存。但需要注意的是，使用CPython解释器时，一次只能运行一个线程，所以如果你需要真正的并行性，请使用`multiprocessing`库。
- en: 'In Python, the standard library offers multithreading by using the library
    called `threading`. So, let’s create one example using multithreading in Python
    by taking the same targets for ICMP tests used in the code example in the previous
    section. The following is the same example using ICMP but using threading:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，标准库通过使用名为`threading`的库提供了多线程功能。因此，让我们通过使用与上一节代码示例中相同的ICMP测试目标，在Python中创建一个使用多线程的示例。以下是一个使用ICMP但使用线程的相同示例：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of running the preceding program will look as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前一个程序的输出将如下所示：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, the output is quite similar using the `threading` and `multiprocessing`
    libraries, but which one runs faster?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，使用`threading`和`multiprocessing`库的输出相当相似，但哪一个运行得更快？
- en: Let’s now run a test program to compare the speed of using `threading` and `multiprocessing`
    for the ICMP tests. The source code of this program is included in the GitHub
    repository for this chapter. The name of the program is `performance-thread-process-example.py`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们运行一个测试程序来比较使用`threading`和`multiprocessing`进行ICMP测试的速度。这个程序的源代码包含在本章的GitHub仓库中。程序的名字是`performance-thread-process-example.py`。
- en: 'Here is the output of this program running for 10, 20, 50, and 100 ICMP probes:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个程序运行10、20、50和100个ICMP探测的结果：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As shown in the preceding output, running multithreading in Python for a certain
    number of threads might be faster. However, as we get close to the number 50,
    it becomes less effective and runs much slower. It is important to notice that
    this will depend on where you are running your code. The Python interpreter running
    on Windows is different from in Linux or even in macOS, but the general idea is
    the same: more threads mean more overhead for the GIL.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的输出所示，在Python中运行多线程对于一定数量的线程来说可能更快。然而，当我们接近数字50时，它变得不那么有效，运行速度也大大减慢。重要的是要注意，这取决于你运行代码的位置。在Windows上运行的Python解释器与Linux或macOS上的不同，但总体思路是相同的：更多的线程意味着GIL（全局解释器锁）有更多的开销。
- en: The recommendation is not to use Python multithreading unless you are spawning
    a small number of threads and are not CPU bound.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 建议除非你正在启动少量线程并且不是CPU密集型的，否则不要使用Python多线程。
- en: Important note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Because of the CPython GIL, it is not possible to run parallel threads in Python.
    Therefore, if your program is CPU bound and requires CPU parallelism, the way
    to go is to use the `multiprocessing` library instead of the `threading` library.
    More details can be found at [docs.python.org/3/library/threading](http://docs.python.org/3/library/threading).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CPython GIL的存在，Python中无法运行并行线程。因此，如果你的程序是CPU密集型的并且需要CPU并行性，那么应该使用`multiprocessing`库而不是`threading`库。更多详情可以在[docs.python.org/3/library/threading](http://docs.python.org/3/library/threading)中找到。
- en: But if you still want to use Python with multithreading, there are other Python
    interpreters that might provide some capability. One example is `threading` module.
    With PyPy-STM, it is possible for simultaneous threads to run, but you will have
    to use the `transaction` module, specifically the `TransactionQueue` class. More
    on multithreading using PyPy-STM can be found at [doc.pypy.org/en/latest/stm.html#user-guide](http://doc.pypy.org/en/latest/stm.html#user-guide).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你仍然想使用Python进行多线程，还有一些其他Python解释器可能提供一些功能。一个例子是`threading`模块。使用PyPy-STM，可以同时运行线程，但你将不得不使用`transaction`模块，特别是`TransactionQueue`类。有关使用PyPy-STM进行多线程的更多信息，请参阅[doc.pypy.org/en/latest/stm.html#user-guide](http://doc.pypy.org/en/latest/stm.html#user-guide)。
- en: Now, let’s see how we can do multithreading in Go.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在Go中实现多线程。
- en: Multithreading in Go
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Go中的多线程
- en: Writing code that scales in Go does not require the creation of threads or processes.
    Go implements parallelism very efficiently using goroutines, which are presented
    as threads to the operating system by the Go runtime. Goroutines will be explained
    in more detail in the following section, which talks about coroutines.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中编写可扩展的代码不需要创建线程或进程。Go通过goroutines实现了并行性，goroutines被Go运行时作为线程呈现给操作系统。Goroutines将在下一节中更详细地解释，该节将讨论协程。
- en: We will also see how we can run multiple lines of code at the same time using
    coroutines.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将看到如何使用协程同时运行多行代码。
- en: Coroutines
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协程
- en: The term *coroutine* was coined back in 1958 by Melvin Conway and Joel Erdwinn.
    Then, the idea was officially introduced in a paper published in the *ACM* magazine
    in 1963.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*协程*最早在1958年由Melvin Conway和Joel Erdwinn提出。然后，这个想法在1963年发表在*ACM*杂志上的一篇论文中被正式介绍。
- en: Despite being very old, the adoption of the term came later with some modern
    computer languages. Coroutines are essentially code that can be suspended. The
    concept is like a thread (in multithreading), because it is a small part of the
    code, and has local variables and its own stack. But the main difference between
    threads and coroutines in a multitasking system is threads can run in parallel
    and coroutines are collaborative. Some like to describe the difference as the
    same as between task concurrency and task parallelism.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个术语非常古老，但它的采用是在一些现代计算机语言中后来的事情。协程本质上是可以挂起的代码。这个概念类似于线程（在多线程中），因为它是一小部分代码，有自己的局部变量和栈。但多任务系统中线程和协程的主要区别在于线程可以并行运行，而协程是协作的。有些人喜欢将这种区别描述为任务并发和任务并行之间的区别。
- en: 'Here is the definition taken from *Oracle Multithreaded* *Programming Guide*:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是来自*Oracle Multithreaded Programming Guide*的定义：
- en: '*In a multithreaded process on a single processor, the processor can switch
    execution resources between threads, resulting in concurrent execution. Concurrency
    indicates that more than one thread is making progress, but the threads are not
    actually running simultaneously. The switching between threads happens quickly
    enough that the threads might appear to run simultaneously. In the same multithreaded
    process in a shared-memory multiprocessor environment, each thread in the process
    can run concurrently on a separate processor, resulting in parallel execution,
    which is true* *simultaneous execution.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*在单处理器上的多线程进程中，处理器可以在线程之间切换执行资源，从而实现并发执行。并发表示多个线程正在取得进展，但实际上线程并不是同时运行的。线程之间的切换发生得足够快，以至于线程可能看起来是同时运行的。在共享内存的多处理器环境中的相同多线程进程中，进程中的每个线程都可以在不同的处理器上并发运行，从而实现并行执行，这是真正的*同时执行*。*'
- en: The source can be found at [https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html](https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码可以在[https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html](https://docs.oracle.com/cd/E36784_01/html/E36868/mtintro-6.html)找到。
- en: So, let’s now check how we can use coroutines in Python and then in Go.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，现在让我们来看看如何在Python和Go中使用协程。
- en: Adding coroutines in Python
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Python中添加协程
- en: Python has recently added coroutines to the standard library. They are part
    of the module called `asyncio`. Because of that, you won’t find this capability
    for older versions of Python; you need at least Python version 3.7.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Python最近将协程添加到标准库中。它们是名为`asyncio`的模块的一部分。因此，你不会在Python的旧版本中找到这种功能；你需要至少Python版本3.7。
- en: But when do we use coroutines in Python? The best fit is when you require lots
    of parallel tasks that are I/O bound, such as a network. For CPU-bound applications,
    it is always recommended to use `multiprocessing` instead.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们何时在Python中使用协程呢？最适合的情况是需要大量I/O绑定的并行任务，例如网络。对于CPU密集型应用程序，始终建议使用`multiprocessing`。
- en: In comparison to `threading`, `asyncio` is more useful for our network automation
    work, because it is I/O bound and scales up more than using `threading`. In addition,
    it is even lighter than threads and processes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与`threading`相比，`asyncio`对我们的网络自动化工作更有用，因为它与I/O绑定，并且比使用`threading`扩展得更好。此外，它甚至比线程和进程更轻量。
- en: 'Let’s then create the same ICMP probe test using coroutines in Python. The
    following is an example of the code for the same network targets used in previous
    examples (you can find this code in `Chapter08/Python/asyncio-example.py` in the
    GitHub repo of the book):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们使用Python中的协程创建相同的ICMP探测测试。以下是在之前示例中使用的相同网络目标的代码示例（你可以在本书的GitHub仓库中的`Chapter08/Python/asyncio-example.py`找到此代码）：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Running the preceding program example will generate the following output:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的程序示例将生成以下输出：
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that now, the first ping reply to be printed is not actually the one that
    has the least latency, which shows the program is running sequentially, following
    the order of the `TARGETS` variable in the loop. That means the `asyncio` coroutines
    are not being suspended to allow others to run when they are blocked. Therefore,
    this is not a good example of using coroutines if we want to scale up. This is
    because the library used in the example is `pythonping`, which is not `asyncio`
    compatible and is not suspending the coroutine when it is waiting for the network
    ICMP response.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在打印出的第一个ping回复实际上并不是延迟最低的那个，这表明程序是顺序运行的，遵循循环中`TARGETS`变量的顺序。这意味着当协程被阻塞时，并没有挂起以允许其他协程运行。因此，如果我们想要扩展，这不是一个很好的使用协程的例子。这是因为示例中使用的库是`pythonping`，它不是`asyncio`兼容的，并且在等待网络ICMP响应时不会挂起协程。
- en: We added this example to show how bad it is to use `asyncio` with coroutines
    that have code that is incompatible with `asyncio`. To fix this issue, let’s now
    use a third-party library for the ICMP probe that is compatible with `asyncio`,
    which is called `aioping`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加这个例子是为了展示使用与`asyncio`不兼容的代码的协程是多么糟糕。为了解决这个问题，现在让我们使用一个与`asyncio`兼容的第三方库来进行ICMP探测，这个库叫做`aioping`。
- en: 'The following code only shows the change on the import to add `aioping` instead
    of `pythonping` and the change on the `myping()` function, where we added an `await`
    statement before the `ping()`function. The other difference is that `aioping`
    works with the exception called `TimeoutError` to detect a non-response of an
    ICMP request:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码仅显示了导入更改，将`pythonping`替换为`aioping`，以及`myping()`函数的更改，我们在`ping()`函数前添加了一个`await`语句。另一个区别是`aioping`使用异常`TimeoutError`来检测ICMP请求的非响应：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The complete program with the fixes shown previously can be found in the GitHub
    repository of this book at `Chapter08/Python/asyncio-example-fixed.py`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 之前显示的修复后的完整程序可以在本书的GitHub仓库中找到，位于`Chapter08/Python/asyncio-example-fixed.py`。
- en: 'If you run this code now with the fix, it should show something like the following
    output:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在运行这个代码并修复了它，它应该会显示类似以下输出：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that, now, the output is based on how fast the targets answer the ICMP
    request and the output does not follow the `TARGETS` list order like in the previous
    example.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在，输出是基于目标响应ICMP请求的速度，输出不遵循之前示例中的`TARGETS`列表顺序。
- en: The important difference in the preceding code is the usage of `await` before
    `ping`, which indicates to the Python `asyncio` module that the coroutine may
    stop and allow another coroutine to run.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 之前代码中的重要区别是在`ping`之前使用`await`，这向Python `asyncio`模块指示协程可能会停止并允许另一个协程运行。
- en: 'Now, you may be wondering whether you could, instead of using the new library,
    `aioping`, just add `await` to the previous example in front of the `ping` statement
    in the `pythonping` library. But that will not work and will generate the following
    exception:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能想知道，你是否可以在不使用新库`aioping`的情况下，只需在`pythonping`库中的`ping`语句前添加`await`。但这是不会工作的，并会生成以下异常：
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: That is because the `pythonping` library is not compatible with the `asyncio`
    module.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为`pythonping`库与`asyncio`模块不兼容。
- en: Use `asyncio` whenever you need to have lots of tasks running because it is
    very cheap to use coroutines as a task, much faster and lighter than processes
    and threads. However, it requires that your application be I/O bound to take advantage
    of the concurrency of the coroutines. Access to network devices is a good example
    of a slow I/O-bound application and may be a perfect fit for our network automation
    cases.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要运行大量任务时，请使用`asyncio`，因为将协程用作任务非常便宜，比进程和线程更快更轻量。然而，要利用协程的并发性，你的应用程序必须是I/O密集型的。访问网络设备就是一个慢速I/O密集型应用程序的例子，可能非常适合我们的网络自动化案例。
- en: Important note
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: To allow efficient use of coroutines in Python, you have to make sure that the
    coroutine is suspending execution when there is a wait in I/O (such as a network)
    to allow other coroutines to run. This is normally indicated by the `asyncio`
    statement called `await`. Indeed, using the third-party library in your coroutine
    needs to be compatible with `asyncio`. As the `asyncio` module is quite new, there
    are not many third-party libraries that are compatible with `asyncio`. Without
    this compatibility, your code will run coroutines sequentially instead of concurrently,
    and using `asyncio` will not be a good idea.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Python中高效使用协程，你必须确保当I/O（如网络）等待时，协程会挂起执行，以便其他协程可以运行。这通常通过名为`await`的`asyncio`语句来指示。确实，在你的协程中使用第三方库需要与`asyncio`兼容。由于`asyncio`模块相当新，与`asyncio`兼容的第三方库并不多。如果没有这种兼容性，你的代码将顺序而不是并发地运行协程，使用`asyncio`将不是一个好主意。
- en: Let’s see how coroutines can be used in Go.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看协程在Go语言中的应用。
- en: Coroutines in Go
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Go中的协程
- en: The Go language is special and shines best when it requires code to scale up
    with performance, and that is accomplished in Go using goroutines.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Go语言很特别，在需要代码与性能一起扩展时表现得最好，而在Go中，这是通过goroutine实现的。
- en: Goroutines are not the same as coroutines, because they can run like threads
    in parallel. But they are not like threads either, because they are much smaller
    (starting with only 8 KB for Go version 1.4) and use channels for communication.
    This may be confusing at first, but I promise you that goroutines are not difficult
    to understand and use. Indeed, they are easier to understand and use compared
    to coroutines in Python.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Goroutine与协程不同，因为它们可以像线程一样并行运行。但它们也不像线程，因为它们更小（从Go版本1.4开始，仅占用8 KB）并且使用通道进行通信。这可能会让人一开始感到困惑，但我向你保证，goroutine并不难理解和使用。实际上，与Python中的协程相比，它们更容易理解和使用。
- en: Since Go version 1.14, goroutines are implemented using asynchronously preemptible
    scheduling. That means the tasks are no longer in the control of the developer
    and are entirely managed by Go’s runtime (you can find details at [https://go.dev/doc/go1.14#runtime](https://go.dev/doc/go1.14#runtime)).
    Go’s runtime is responsible for presenting to the operating system the threads
    that are going to run, which can run simultaneously in some cases.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 自Go版本1.14以来，goroutine是通过异步可抢占式调度实现的。这意味着任务不再受开发者的控制，而是完全由Go的运行时管理（你可以在[https://go.dev/doc/go1.14#runtime](https://go.dev/doc/go1.14#runtime)找到详细信息)。Go的运行时负责向操作系统展示将要运行的线程，在某些情况下，这些线程可以同时运行。
- en: Go’s runtime is responsible for creating and destroying the threads that correspond
    to a goroutine. These operations would be much heavier when implemented by the
    operating system using a native multithreading language, but in Go, they are light
    as Go’s runtime maintains a pool of threads for the goroutines. The fact that
    Go’s runtime controls the mapping between goroutines and threads makes the operating
    system completely unaware of goroutines.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Go的运行时负责创建和销毁与goroutine对应的线程。当使用原生多线程语言由操作系统实现时，这些操作会更重，但在Go中，它们很轻，因为Go的运行时维护了一个线程池供goroutine使用。Go的运行时控制goroutine和线程之间的映射，使得操作系统完全不知道goroutine的存在。
- en: In summary, Go doesn’t use coroutines, but instead uses goroutines, which are
    not the same and are more like a blend between coroutines and threads, with better
    performance than the two.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Go不使用协程，而是使用goroutine，它们与协程不同，更像是协程和线程的结合，性能优于两者。
- en: 'Let’s now go through a simple example of an ICMP probe using goroutines:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过一个使用goroutine的简单ICMP探测示例来了解一下：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If you run this program, it should output something like the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个程序，它应该输出类似以下内容：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To use a goroutine, you just need to add `go` in front of the function you want
    to call as a goroutine. The `go` statement indicates that the function can be
    executed in the background with its own stack and variables. The program then
    executes the line after the `go` statement and continues the flow normally without
    waiting for anything to return from the goroutine. As the ICMP probe request takes
    a few milliseconds to receive an ICMP response, the program will exit before it
    can print anything by the goroutines. Therefore, we need to add a sleep time of
    3 seconds before finishing the program to make sure all the goroutines that send
    ICMP requests have received and printed the results. Otherwise, you won’t be able
    to see any output, because the program will end before the goroutines finish printing
    the results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用goroutine，你只需要在你想作为goroutine调用的函数前加上`go`。`go`语句表示该函数可以在后台执行，拥有自己的栈和变量。然后程序执行`go`语句之后的行，并正常继续流程，不需要等待goroutine返回任何内容。由于ICMP探测请求需要几毫秒来接收ICMP响应，程序会在goroutine打印任何内容之前退出。因此，我们需要在程序结束前添加3秒的睡眠时间，以确保所有发送ICMP请求的goroutine都已经接收并打印了结果。否则，你将看不到任何输出，因为程序会在goroutine完成打印结果之前结束。
- en: 'If you want to wait until the goroutines end, Go has mechanisms to communicate
    and wait until they end. One simple one is using `sync.WaitGroup`. Let’s now rewrite
    our previous example, removing the sleep time and adding `WaitGroup` to wait for
    the goroutines to finish. The following is the same example that waits until all
    goroutines end:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要等待goroutines结束，Go有机制来进行通信并等待它们结束。其中一个简单的方法是使用`sync.WaitGroup`。现在让我们重写之前的例子，移除睡眠时间并添加`WaitGroup`来等待goroutines完成。以下是一个等待所有goroutines结束的相同例子：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you run the preceding code, it should end faster than the previous one because
    it does not sleep for 3 seconds; it only waits until all goroutines end, which
    should be less than half a second.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行前面的代码，它应该比之前的代码结束得更快，因为它不需要等待3秒；它只等待所有goroutines结束，这应该不到半秒。
- en: To allow `sync.WaitGroup` to work, you have to set a value to it at the beginning
    using `Add()`. In the preceding example, it adds `4`, which is the number of goroutines
    that will run. Then, you pass the pointer of the variable to each goroutine function
    (`&wg`), which will be marked as `Done()` as the function ends using `defer` (explained
    in [*Chapter 7*](B18165_07.xhtml#_idTextAnchor183)).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要允许`sync.WaitGroup`工作，你必须在开始时使用`Add()`给它设置一个值。在前面的例子中，它添加了`4`，这是将要运行的goroutine数量。然后，你将变量的指针传递给每个goroutine函数（`&wg`），该函数将使用`defer`（在[*第7章*](B18165_07.xhtml#_idTextAnchor183)中解释）标记为`Done()`。
- en: In the preceding example, we did not generate any communication between the
    goroutines, as they use the terminal to print. We only passed a pointer to the
    workgroup variable, called `wg`. If you want to communicate between goroutines,
    you can do that by using `channel`, which can be unidirectional or bidirectional.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们没有在goroutines之间生成任何通信，因为它们使用终端进行打印。我们只传递了工作组变量的指针，称为`wg`。如果你想goroutines之间进行通信，你可以通过使用`channel`来实现，它可以是单向的或双向的。
- en: 'More on goroutines can be found at the following links:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于goroutines的信息可以在以下链接中找到：
- en: '*Google I/O 2012 - Go Concurrency* *Patterns*: [https://www.youtube.com/watch?v=f6kdp27TYZs](https://www.youtube.com/watch?v=f6kdp27TYZs)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google I/O 2012 - Go并发* *模式*：[https://www.youtube.com/watch?v=f6kdp27TYZs](https://www.youtube.com/watch?v=f6kdp27TYZs)'
- en: '*Google I/O 2013 – Advanced Go Concurrency* *Patterns*: [https://www.youtube.com/watch?v=QDDwwePbDtw](https://www.youtube.com/watch?v=QDDwwePbDtw)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google I/O 2013 – 高级Go并发* *模式*：[https://www.youtube.com/watch?v=QDDwwePbDtw](https://www.youtube.com/watch?v=QDDwwePbDtw)'
- en: More documentation on Goroutines can be found at [go.dev/doc/effective_go#concurrency](http://go.dev/doc/effective_go#concurrency)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于Goroutines的文档可以在[go.dev/doc/effective_go#concurrency](http://go.dev/doc/effective_go#concurrency)找到
- en: 'Before going to the next section, let’s summarize how we scale up in Python
    and Go. In Python, to make the right choice, use *Figure 8**.1*:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一节之前，让我们总结一下如何在Python和Go中进行扩展。在Python中，为了做出正确的选择，使用*图8**.1*：
- en: '![Figure 8.1 – Python decision-making for scaling your code](img/B18165_08_001.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – Python代码扩展的决策](img/B18165_08_001.jpg)'
- en: Figure 8.1 – Python decision-making for scaling your code
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – Python代码扩展的决策
- en: The diagram in *Figure 8**.1* shows which Python library to use when scaling
    your code. If CPU bound, use `multiprocessing`. If you have too many connections
    with slow I/O, use `asyncio`, and if the number of connections is small, use `threading`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.1*中的图示显示了在扩展你的代码时应该使用哪个Python库。如果你是CPU密集型的，使用`multiprocessing`。如果你有太多慢速I/O的连接，使用`asyncio`，如果连接数量较少，使用`threading`。'
- en: For Go, there is only one option, which is a goroutine. Easy answer!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Go语言来说，只有一个选项，那就是goroutine。简单明了的答案！
- en: Let’s now check how we can scale the system using schedulers and dispatchers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来检查如何使用调度器和派发器来扩展系统。
- en: Adding schedulers and job dispatchers
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加调度器和任务派发器
- en: A scheduler is a system that selects a job for running, where a **job** can
    be understood as a program or part of code that requires running. A dispatcher,
    on the other hand, is the system that takes the job and places it in the execution
    queue of a machine. They are complementary, and in some cases, they are treated
    as the same system. So, for the purpose of this section, we are going to talk
    about some systems that can do both scheduling and dispatching jobs.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器是一个选择要运行的任务的系统，其中**任务**可以理解为需要运行的一个程序或代码的一部分。另一方面，派发器是接收任务并将其放入机器执行队列的系统。它们是互补的，在某些情况下，它们被视为同一个系统。因此，为了本节的目的，我们将讨论一些可以同时进行调度和派发任务的系统。
- en: The main objective of using systems that can schedule and dispatch jobs is to
    gain scale by adding machines that can run more jobs in parallel. It is kind of
    similar to a single program using multiprocessing but with the difference that
    the new processes are being executed on another machine.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用能够调度和派发任务的系统的主要目标是通过对能够并行运行更多任务的机器进行添加来获得规模。这有点类似于单个程序使用多进程，但不同之处在于新进程是在另一台机器上执行的。
- en: You could do lots of work to improve the performance of your program, but in
    the end, you will be bound by the machine’s limitations, and if your application
    is CPU bound, it will be limited by the number of cores, the number of concurrent
    threads, and the speed of the CPU used. You could work hard to improve the performance
    of your code, but to grow more, the only solution is to add more CPU hardware,
    which can be accomplished by adding machines. The group of machines that are dedicated
    to running jobs for schedulers and dispatchers is normally called a **cluster**.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做一些工作来提高你程序的性能，但最终，你将受到机器限制的束缚，如果你的应用程序是CPU密集型的，它将受到核心数量、并发线程数量和所用CPU速度的限制。你可以努力提高代码的性能，但为了进一步增长，唯一的解决方案是添加更多的CPU硬件，这可以通过添加机器来实现。专门用于为调度器和派发器运行任务的机器组通常被称为**集群**。
- en: A cluster of machines that are ready to run jobs in parallel can be installed
    locally or can be installed in separate locations. The distance between the machines
    in a cluster adds latency to the communication between the machines and delays
    data synchronization. Quick synchronization between machines may or may not be
    relevant, depending on how fast the results are required and how they need to
    be combined if they depend on each other in time. Quicker results might require
    a local cluster. A more relaxed time frame for getting results would allow clusters
    to be located further apart.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 一组准备并行运行任务的机器可以本地安装，也可以在单独的位置安装。集群中机器之间的距离会增加机器间通信的延迟，并延迟数据同步。快速同步机器可能或可能不相关，这取决于所需结果的快慢以及它们在时间上的依赖性。如果需要更快的结果，可能需要一个本地集群。如果对结果的时间框架较为宽松，集群可以位于更远的位置。
- en: Let’s now discuss how we can use a classical scheduler and dispatcher.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论如何使用经典的调度器和派发器。
- en: Using classical schedulers and dispatchers
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用经典的调度器和派发器
- en: The classical scheduler and dispatcher would be any system that takes one job,
    deploys it to a machine in the cluster, and executes it. In a classical case,
    the job is just a program that is ready to run on a machine. The program can be
    written in any language; however, there are differences in how the installation
    would be compared between Python and Go.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的调度器和派发器可以是任何一种系统，它接受一个任务，将其部署到集群中的某台机器上，并执行它。在经典的情况下，任务只是一个准备在机器上运行的程序。程序可以用任何语言编写；然而，Python和Go在安装方式上的差异是存在的。
- en: Let’s investigate what the differences are between using a cluster ready to
    run Python scripts and ready to run Go-compiled code.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调查一下使用准备运行Python脚本的集群和准备运行Go编译代码的集群之间的区别。
- en: Considerations for using Go and Python
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Go和Python的注意事项
- en: If the program was written in Python, it is required that all machines in the
    cluster have the Python interpreter version that is compatible with the Python
    code. For instance, if code was written for Python 3.10, the CPython interpreter
    to be installed must be at least version 3.10\. Another important point here is
    that all third-party libraries used in the Python script will also have to be
    installed on all machines. The version of each third-party library must be compatible
    with the Python script, as newer versions of a particular third-party library
    might break the execution of your code. You might need to maintain a table somewhere
    containing the versions of each third-party library used to avoid wrong machine
    updates. In conclusion, using Python complicates your cluster installation, management,
    and updates a lot.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序是用 Python 编写的，集群中的所有机器都必须安装与 Python 代码兼容的 Python 解释器版本。例如，如果代码是为 Python
    3.10 编写的，则要安装的 CPython 解释器版本必须至少为 3.10。另一个重要的点是，Python 脚本中使用的所有第三方库也必须安装到所有机器上。每个第三方库的版本必须与
    Python 脚本兼容，因为特定第三方库的新版本可能会破坏你代码的执行。你可能需要在某处维护一个包含每个第三方库版本的表格，以避免错误的机器更新。总之，使用
    Python 使得你的集群安装、管理和更新变得非常复杂。
- en: On the other hand, using the Go language is much simpler for deploying in a
    cluster. You just need to compile the Go program to the same CPU architecture
    that the code will run. All third-party libraries used will be added to the compiled
    code. The versions of each third-party library used in your program will be controlled
    automatically by your local development environment with the `go.sum` and `go.mod`
    files. In summary, you don’t need to install an interpreter on the machines and
    don’t need to worry about installing or updating any third-party libraries, which
    is much simpler.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用 Go 语言在集群中部署要简单得多。你只需将 Go 程序编译成代码将要运行的相同 CPU 架构。所有使用的第三方库都将添加到编译后的代码中。你程序中使用的每个第三方库的版本将由你的本地开发环境通过
    `go.sum` 和 `go.mod` 文件自动控制。总之，你不需要在机器上安装解释器，也不需要担心安装或更新任何第三方库，这要简单得多。
- en: Let’s now see a few examples of a scheduler and dispatcher for a cluster of
    machines.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一些机器集群的调度器和派发器的例子。
- en: Using Nomad
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Nomad
- en: Nomad is an implementation for job scheduling that was built using Go and is
    supported by a company called HashiCorp ([https://www.nomadproject.io/](https://www.nomadproject.io/)).
    Nomad is also very popular for scheduling and launching Docker containers in a
    cluster of machines, as we are going to see in the next section.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Nomad 是一个使用 Go 语言编写的作业调度程序实现，由名为 HashiCorp 的公司支持（[https://www.nomadproject.io/](https://www.nomadproject.io/)）。Nomad
    在机器集群中进行调度和启动 Docker 容器方面也非常受欢迎，我们将在下一节中看到这一点。
- en: With Nomad, you are able to define a job by writing a configuration file that
    describes the job and how you want to run it. The job description can be written
    in any formatted file, such as YAML or TOML, but the default supported format
    is **HCL**. Once you have the job description completed, it is then translated
    to JSON, which will be used on the Nomad API (more details can be found at [https://developer.hashicorp.com/nomad/docs/job-specification](https://developer.hashicorp.com/nomad/docs/job-specification)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Nomad，你可以通过编写一个描述作业及其运行方式的配置文件来定义一个作业。作业描述可以编写为任何格式化的文件，例如 YAML 或 TOML，但默认支持的格式是
    **HCL**。一旦完成作业描述，它就会被转换为 JSON 格式，这将用于 Nomad API（更多详情请参阅 [https://developer.hashicorp.com/nomad/docs/job-specification](https://developer.hashicorp.com/nomad/docs/job-specification))。
- en: Nomad supports several task drivers, which allows you to schedule different
    kinds of programs. If you are using a Go-compiled program, you will have to use
    the `Fork/Exec` driver (further details are available at [https://developer.hashicorp.com/nomad/docs/drivers/exec](https://developer.hashicorp.com/nomad/docs/drivers/exec)).
    Using the `Fork/Exec` driver, you can execute any program, including Python scripts,
    but with the caveat of having all third-party libraries and the Python interpreter
    previously installed on all machines of the cluster, which is not managed by Nomad
    and must be done on your own separately.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Nomad 支持多种任务驱动程序，这允许你调度不同类型的程序。如果你使用的是 Go 编译程序，你必须使用 `Fork/Exec` 驱动程序（更多详情请参阅
    [https://developer.hashicorp.com/nomad/docs/drivers/exec](https://developer.hashicorp.com/nomad/docs/drivers/exec))。使用
    `Fork/Exec` 驱动程序，你可以执行任何程序，包括 Python 脚本，但前提是在集群的所有机器上预先安装了所有第三方库和 Python 解释器，这不由
    Nomad 管理，必须由你自己单独完成。
- en: 'The following is an example of a job specification for an ICMP probe program:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 ICMP 探测程序的作业规范示例：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note that the preceding program example is called `icmp-probe` and would have
    to accept the operating system environment variable as input. In our example,
    the variable is called `TARGETS`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面的程序示例名为 `icmp-probe`，必须接受操作系统环境变量作为输入。在我们的示例中，该变量名为 `TARGETS`。
- en: Once you have defined your job, you can dispatch it by issuing the `nomad job
    dispatch <job-description-file>` command (more details can be found at [developer.hashicorp.com/nomad/docs/commands/job/dispatch](http://developer.hashicorp.com/nomad/docs/commands/job/dispatch)).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您定义了作业，您可以通过发出 `nomad job dispatch <job-description-file>` 命令来调度它（更多详情请见 [developer.hashicorp.com/nomad/docs/commands/job/dispatch](http://developer.hashicorp.com/nomad/docs/commands/job/dispatch)）。
- en: Let’s now check how we could use another popular scheduler.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来检查我们如何使用另一个流行的调度器。
- en: Using Cronsun
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Cronsun
- en: Cronsun is another scheduler and dispatcher that works in a similar way to the
    popular Unix cron but for multiple machines. The goal of Cronsun is to be easy
    and simple for managing jobs on lots of machines. It is developed in the Go language
    but can also launch jobs in any language by invoking a shell on the remote machine,
    such as in the Nomad `Fork/Exec` driver (more details can be found at [https://github.com/shunfei/cronsun](https://github.com/shunfei/cronsun)).
    It also has a graphical interface that allows easy visualization of the running
    jobs. Cronsun was built and designed based on another Go third-party package,
    called `robfig/cron` ([https://github.com/robfig/cron](https://github.com/robfig/cron)).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Cronsun 是另一个调度器和分配器，它的工作方式与流行的 Unix cron 类似，但适用于多台机器。Cronsun 的目标是使管理大量机器上的作业变得简单和直观。它是用
    Go 语言开发的，但也可以通过在远程机器上调用 shell 来启动任何语言的作业，例如在 Nomad 的 `Fork/Exec` 驱动程序中（更多详情请见
    [https://github.com/shunfei/cronsun](https://github.com/shunfei/cronsun)）。它还提供了一个图形界面，可以轻松可视化正在运行的作业。Cronsun
    是基于另一个名为 `robfig/cron` 的 Go 第三方包构建和设计的（更多详情请见 [https://github.com/robfig/cron](https://github.com/robfig/cron)）。
- en: Using Cronsun, you will be able to launch several jobs on multiple machines,
    but there is no machine cluster management like in Nomad. Another important point
    is Cronsun does not work with Linux containers, so it purely focuses on executing
    Unix shell programs in the remote machine by doing process forking.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Cronsun，您将能够在多台机器上启动多个作业，但没有像 Nomad 那样的机器集群管理。另一个重要点是 Cronsun 不与 Linux 容器一起工作，因此它纯粹专注于通过进程分叉在远程机器上执行
    Unix shell 程序。
- en: Let’s now look at a more complex scheduler.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个更复杂的调度器。
- en: Using DolphinScheduler
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 DolphinScheduler
- en: DolphinScheduler is a complete system for scheduling and dispatching jobs that
    is supported by the Apache Software Foundation. It has many more features compared
    to Nomad and Cronsun, with workflow capabilities that allow a job to wait for
    input from another job before executing. It also has a graphical interface that
    helps to visualize running jobs and dependencies (more details can be found at
    [https://dolphinscheduler.apache.org/](https://dolphinscheduler.apache.org/)).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: DolphinScheduler 是一个由 Apache 软件基金会支持的完整作业调度和分配系统。与 Nomad 和 Cronsun 相比，它具有更多功能，具有工作流功能，允许作业在执行前等待来自另一个作业的输入。它还提供了一个图形界面，有助于可视化正在运行的作业和依赖关系（更多详情请见
    [https://dolphinscheduler.apache.org/](https://dolphinscheduler.apache.org/)）。
- en: Although DolphinScheduler is primarily written in Java, it can dispatch jobs
    in Python and Go. It is much more complex and has many capabilities that might
    not be necessary for your requirements to scale up.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 DolphinScheduler 主要用 Java 编写，但它可以在 Python 和 Go 中调度作业。它更加复杂，具有许多可能对您的扩展需求不是必需的功能。
- en: There are several other job schedulers and dispatchers that you could use, but
    some of them are used for specific languages, such as Quartz.NET, used for .NET
    applications ([https://www.quartz-scheduler.net/](https://www.quartz-scheduler.net/)),
    and Bree, used for Node.js applications ([https://github.com/breejs/bree](https://github.com/breejs/bree)).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种其他作业调度器和分配器可供使用，但其中一些是为特定语言设计的，例如用于 .NET 应用程序的 Quartz.NET ([https://www.quartz-scheduler.net/](https://www.quartz-scheduler.net/))
    和用于 Node.js 应用程序的 Bree ([https://github.com/breejs/bree](https://github.com/breejs/bree)）。
- en: Let’s see now how we can use big data schedulers and dispatchers for carrying
    out computation at scale in network automation.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何使用大数据调度器和分配器在网络自动化中进行大规模计算。
- en: Working with big data
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与大数据一起工作
- en: There are specific applications that require lots of CPU for data processing.
    These applications require a system that allows running code with very specialized
    algorithms focused on data analysis. These are normally referred to as systems
    and applications for **big data**.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些特定的应用需要大量的CPU进行数据处理。这些应用需要一个允许运行专注于数据分析的非常专业算法的系统的系统。这些通常被称为**大数据**系统和应用。
- en: Big data is a collection of datasets that are too large to be analyzed on just
    one computer. It is a field that is dominated by data scientists, data engineers,
    and artificial intelligence engineers. The reason is that they normally analyze
    a lot of data to extract information, and their work requires a system that scales
    up a lot in terms of CPU processing. Such scale can only be achieved by using
    systems that can schedule and dispatch jobs over many computers in a cluster.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据是数据集的集合，太大以至于无法仅在一台计算机上进行分析。这是一个由数据科学家、数据工程师和人工智能工程师主导的领域。原因是他们通常分析大量数据以提取信息，并且他们的工作需要一个在CPU处理方面大量扩展的系统。这种规模只能通过使用可以在集群中的多台计算机上调度和分配任务的系统来实现。
- en: The algorithm model used for big data is called **MapReduce**. A MapReduce programming
    model is used to implement analysis on large datasets using an algorithm that
    runs on several machines in a cluster. Originally, the term MapReduce was related
    to a Google product, but now it is a term used for programs that deal with big
    data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 用于大数据的算法模型称为**MapReduce**。使用在集群中的多台机器上运行的算法对大型数据集进行分析的MapReduce编程模型被用来实现分析。最初，MapReduce术语与谷歌产品相关，但现在它是一个用于处理大数据的程序术语。
- en: 'The original paper published by Jeffrey Dean and Sanjay Ghemawat called *MapReduce:
    Simplified Data Processing on Large Clusters* is a good reference and good reading
    to dive deeper into the subject. The paper is public and can be downloaded from
    the Google Research page at [https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 由Jeffrey Dean和Sanjay Ghemawat发表的原始论文《*MapReduce：在大型集群上的简化数据处理*》是深入了解该主题的好参考和好读物。该论文是公开的，可以从谷歌研究页面[https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)下载。
- en: Let’s see how we can use big data in our network automation.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何在网络自动化中使用大数据。
- en: Big data and network automation
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大数据和网络自动化
- en: Big data is used in network automation to help with traffic engineering and
    optimization. MapReduce is used to calculate better traffic paths over a combination
    of traffic demands and routing paths. Traffic demands are collected and stored
    using the IP source and IP destination, then MapReduce is used to calculate a
    traffic demand matrix. For this work, routing and traffic information is collected
    from all network devices using BGP, SNMP, and a flow-based collection such as
    `sflow`, `ipfix`, or `netflow`. The data collected is normally big and real-time
    results are required to allow for proper network optimization and traffic engineering
    on time.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据在网络自动化中用于帮助进行流量工程和优化。MapReduce用于计算基于流量需求和路由路径组合的更好流量路径。流量需求通过IP源和IP目的地址收集和存储，然后使用MapReduce计算流量需求矩阵。对于这项工作，使用BGP、SNMP和基于流的收集（如`sflow`、`ipfix`或`netflow`）从所有网络设备收集路由和流量信息。收集的数据通常是大量的，需要实时结果以允许及时进行适当的网络优化和流量工程。
- en: One example would be the collection of IP data flow from the transit routers
    and peering routers (discussed in [*Chapter 1*](B18165_01.xhtml#_idTextAnchor015)).
    This flow information would then be analyzed in conjunction with the routing information
    obtained from the routers. Then, a better routing policy can be applied in real
    time to select better external paths or network interfaces that are less congested.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子就是从转接路由器和对等路由器（在第[*第一章*](B18165_01.xhtml#_idTextAnchor015)中讨论）收集的IP数据流。然后，将这些流信息与从路由器获取的路由信息一起分析。然后，可以实时应用更好的路由策略，以选择更少拥堵的外部路径或网络接口。
- en: Let’s now investigate some popular systems that can be used for big data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来调查一些可以用于大数据的流行系统。
- en: Using systems for big data
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用大数据系统
- en: The two most popular open source systems for big data are **Apache Hadoop**
    ([https://hadoop.apache.org/](https://hadoop.apache.org/)) and **Apache Spark**
    ([https://spark.apache.org/](https://spark.apache.org/)). Both systems are supported
    and maintained by the Apache Software Foundation ([https://www.apache.org/](https://www.apache.org/))
    and are used to build large cluster systems to run big data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 两个最受欢迎的大数据开源系统是 **Apache Hadoop**（[https://hadoop.apache.org/](https://hadoop.apache.org/)）和
    **Apache Spark**（[https://spark.apache.org/](https://spark.apache.org/)）。这两个系统都由
    Apache 软件基金会（[https://www.apache.org/](https://www.apache.org/)）支持和维护，用于构建大型集群系统以运行大数据。
- en: The difference between Hadoop and Spark is related to how they perform big data
    analysis. Hadoop is used for batch job scheduling without real-time requirements.
    It uses more disk capacity and the response time is more relaxed, so the cluster
    machines don’t need to be local, and the machines need to have large disks. On
    the other hand, Spark uses more memory and less disk space, the machines need
    to be located closer, and the response time is more predictable, therefore it
    is used for real-time applications.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 和 Spark 之间的区别与它们如何执行大数据分析有关。Hadoop 用于批量作业调度，没有实时需求。它使用更多的磁盘容量，响应时间更宽松，因此集群机器不需要本地化，机器需要有大容量硬盘。另一方面，Spark
    使用更多的内存和更少的磁盘空间，机器需要更靠近，响应时间更可预测，因此它用于实时应用。
- en: For our network automation on traffic analysis, either option can be used, but
    Spark would be preferred for faster and more periodic results. Hadoop would be
    used to generate monthly and daily reports, but not to interact with real-time
    routing policies.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的流量分析网络自动化，可以使用任一选项，但为了获得更快和更规律的结果，Spark 会更受欢迎。Hadoop 将用于生成月度和日报，但不用于与实时路由策略交互。
- en: Let’s now look at a common problem with having your own cluster.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下拥有自己的集群的一个常见问题。
- en: Resource allocation and cloud services
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 资源分配和云服务
- en: One of the problems with using Hadoop and Spark is that you will need to create
    your own cluster of machines. That means installing and maintaining the hardware
    and operating system software. But that is not the main problem. The main problem
    is that resource utilization will vary throughout the day and the year.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Hadoop 和 Spark 的问题之一是，你需要创建自己的机器集群。这意味着安装和维护硬件和操作系统软件。但这不是主要问题。主要问题是资源利用率将在一天和一年中变化。
- en: As an example, imagine you are using a big data system in your company to calculate
    the best path for a particular group of routers during the day. The problem is
    the collected data to be analyzed will change; in busy hours, you will need more
    CPU processing to calculate compared to non-busy hours. The difference can be
    hundreds of CPUs, which will lead to lots of idle CPU hours at the end of the
    month.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一下你正在使用公司的大数据系统来计算白天特定组路由器的最佳路径。问题是待分析收集的数据将发生变化；在繁忙时段，与空闲时段相比，你需要更多的 CPU
    处理能力来计算。差异可能达到数百个 CPU，这将导致月底有大量的空闲 CPU 小时。
- en: How do you solve this issue? By using a cloud-based service provider to allocate
    machines for your cluster. With it, you can add and remove machines during the
    day and throughout the week, allowing growth when needed and releasing computing
    power when not needed. One example is to use AWS’ product called **Elastic MapReduce**
    (**EMR**), which can be used with easy machine allocation for your cluster, scaling
    up and down by software (more details can be found at [https://aws.amazon.com/emr/](https://aws.amazon.com/emr/)).
    Similar services can be obtained from other cloud service providers, such as Google,
    Oracle, or Microsoft.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何解决这个问题？通过使用基于云的服务提供商为你的集群分配机器。有了它，你可以在一天之内和整个星期内添加和删除机器，在需要时增长，在不需要时释放计算能力。一个例子是使用
    AWS 的产品 **Elastic MapReduce**（**EMR**），它可以用于轻松地为你的集群分配机器，通过软件进行扩展和缩减（更多详情请见 [https://aws.amazon.com/emr/](https://aws.amazon.com/emr/)）。其他云服务提供商，如
    Google、Oracle 或 Microsoft，也可以获得类似的服务。
- en: One important point to observe is that big data systems do not allow running
    any program or language, but only code that has the MapReduce concept capabilities.
    So, it is much more specific compared to Nomad or Cronsun, and focuses only on
    data analysis.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要注意的重要点是，大数据系统不允许运行任何程序或语言，但只有具有 MapReduce 概念能力的代码。因此，它比 Nomad 或 Cronsun
    更具体，并且只关注数据分析。
- en: Let’s now check how we can scale using microservices and Linux containers.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来检查如何使用微服务和 Linux 容器进行扩展。
- en: Using microservices and containers
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用微服务和容器
- en: When software is built based on a combination of small, independent services,
    we normally say the software was built using microservices architecture. Microservices
    architecture is a way to develop applications by combining small services that
    might belong or not to the same software development team.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当软件基于小型、独立服务的组合构建时，我们通常说该软件是使用微服务架构构建的。微服务架构是通过组合可能属于或不属于同一软件开发团队的小型服务来开发应用程序的一种方式。
- en: The success of this approach is due to the isolation between each service, which
    is accomplished by using Linux containers (described in [*Chapter 2*](B18165_02.xhtml#_idTextAnchor041)).
    Using Linux containers is a good way to isolate memory, CPU, networks, and disks.
    Each Linux container can’t interact with other Linux containers in the same host
    unless a pre-defined communication channel is established. The communication channels
    of a service have to use well-documented APIs.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的成功归功于每个服务之间的隔离，这是通过使用Linux容器（在第[*第2章*](B18165_02.xhtml#_idTextAnchor041)中描述）实现的。使用Linux容器是隔离内存、CPU、网络和磁盘的好方法。除非建立了预定义的通信通道，否则每个Linux容器都无法与同一主机上的其他Linux容器交互。服务的通信通道必须使用经过良好文档化的API。
- en: The machine that runs microservices is normally called a **container host**
    or just a host. A host can have multiple microservices that may or may not communicate
    with each other. A combination of hosts is called a cluster of container hosts.
    Some orchestration software is able to spawn several copies of a service in one
    host or different hosts. Using microservices architecture is a good way to scale
    your system.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 运行微服务的机器通常被称为**容器主机**或简称**主机**。一个主机可以有多个微服务，这些微服务可能相互通信，也可能不通信。主机的组合称为容器主机集群。一些编排软件能够在单个主机或不同主机上生成服务的多个副本。使用微服务架构是扩展您系统的好方法。
- en: One very popular place to build and publish a microservice is **Docker** ([https://www.docker.com/](https://www.docker.com/)).
    A Docker container is normally referred to as a service that is built using a
    Linux container. A Docker host is where a Docker container can run, and in a similar
    way, a Docker cluster is a group of hosts that can run Docker containers.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和发布微服务的一个非常流行的场所是**Docker** ([https://www.docker.com/](https://www.docker.com/))。Docker容器通常指的是使用Linux容器构建的服务。Docker主机是Docker容器可以运行的地方，同样地，Docker集群是一组可以运行Docker容器的主机。
- en: Let’s see now how we can use Docker containers to scale our code.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何使用Docker容器来扩展我们的代码。
- en: Building a scalable solution by example
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过示例构建可扩展的解决方案
- en: 'Let’s build a solution using microservices architecture by creating our own
    Docker container and then launching it multiple times. Our service has a few requirements,
    as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过创建自己的Docker容器并多次启动它来构建一个使用微服务架构的解决方案。我们的服务有一些要求，如下：
- en: It needs to have an API to accept requests
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要有一个API来接受请求
- en: The API needs to accept a list of targets
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API需要接受目标列表
- en: An ICMP probe will be sent to each target to verify latency concurrently
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将向每个目标发送ICMP探测以并发验证延迟
- en: The API will respond using HTTP plain text
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API将以HTTP纯文本格式响应
- en: Each service can accept up to 1,000 targets
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个服务可以接受多达1,000个目标
- en: The timeout for each ICMP probe must be 2 seconds
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个ICMP探测的超时时间必须为2秒
- en: Based on these requirements, let’s write some code that will be used in our
    service.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些要求，让我们编写一些将在我们的服务中使用的代码。
- en: Writing the service code
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写服务代码
- en: With the previous requirements, let’s write some code in Go to build our service.
    We are going to use the Go third-party package for ICMP that we used before in
    this chapter called `go-ping/ping`, and `sync.WaitGroup` to wait for the goroutines
    to end.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的要求，让我们用Go编写一些代码来构建我们的服务。我们将使用本章之前使用的Go第三方ICMP包`go-ping/ping`，以及`sync.WaitGroup`来等待goroutines结束。
- en: 'Let’s break the code into two blocks. The second block of code is as follows,
    describing the `probeTargets()` and `main()` functions:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将代码分成两个部分。以下是第二个代码块，描述`probeTargets()`和`main()`函数：
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding block represents the last two functions of our service. In the
    `main()` function, we just need to call `http.HandleFunc`, passing the API reference
    used for the `GET` method and the name of the function that will be invoked. Then,
    `http.ListenAndServe` is called using port `9900` to listen for API requests.
    Note that `log.Fatal` is used with `ListenAndServe` because it should never end
    unless it has a problem. The following is an API `GET` client request example:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块代表我们服务的最后两个函数。在`main()`函数中，我们只需要调用`http.HandleFunc`，传递用于`GET`方法的API引用和将被调用的函数名称。然后，使用端口`9900`调用`http.ListenAndServe`以监听API请求。注意，`log.Fatal`与`ListenAndServe`一起使用，因为它不应该在没有问题的情况下结束。以下是一个API
    `GET`客户端请求示例：
- en: '[PRE18]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding API request will call `probeTargets()`, which will run the loop
    invoking the goroutines (called `probe()`) two times, which will send ICMP requests
    to `google.com` and `cisco.com`.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的API请求将调用`probeTargets()`，这将运行循环调用goroutines（称为`probe()`），两次发送ICMP请求到`google.com`和`cisco.com`。
- en: 'Let’s now have a look at the last block of code containing the `probe()` function:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看包含`probe()`函数的最后一段代码：
- en: '[PRE19]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note that the `probe()` function does not return a value, a `log` message, or
    a print message. All messages, including errors, are returned to the HTTP client
    requesting the ICMP probes. To allow the return to the client, we have to use
    the `fmt.Fprintf()` function, passing the reference `w`, which points to an `http.ResponseWriter`
    type.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`probe()`函数不返回任何值、日志消息或打印消息。所有消息，包括错误，都返回给请求ICMP探测的HTTP客户端。为了允许消息返回给客户端，我们必须使用`fmt.Fprintf()`函数，传递引用`w`，它指向一个`http.ResponseWriter`类型。
- en: 'Before we continue with our example, let’s make a modification to our `main()`
    function to allow reading the port number from the operating system environment
    variable. So, the service can be called with different port numbers when being
    invoked, just needing to change the operating system environment variable called
    `PORT`, as shown here:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续示例之前，让我们修改一下`main()`函数，以便从操作系统环境变量中读取端口号。这样，当服务被调用时，可以使用不同的端口号，只需更改名为`PORT`的操作系统环境变量，如下所示：
- en: '[PRE20]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Let’s now build our Docker container using a Dockerfile.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用Dockerfile构建我们的Docker容器。
- en: Building our Docker container
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建我们的Docker容器
- en: To build the Docker container, we are going to use Dockerfile definitions. Then,
    we just need to run `docker build` to create our container. Before you install
    the Docker engine in your environment, check the documentation on how to install
    it at [https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 构建Docker容器时，我们将使用Dockerfile定义。然后，我们只需运行`docker build`来创建我们的容器。在你将Docker引擎安装到你的环境中之前，请检查有关如何安装它的文档，[https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)。
- en: 'The following is the Dockerfile used in our example of an ICMP probe service:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们示例中使用的ICMP探测服务的Dockerfile：
- en: '[PRE21]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To build the Docker container, you just need to run `docker build . –t probe-service`.
    After running the build, you should be able to see the image by using the `docker
    image` command, as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建Docker容器，你只需运行`docker build . –t probe-service`。构建完成后，你应该可以使用`docker image`命令看到镜像，如下所示：
- en: '[PRE22]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The Docker container name is `probe-service` and you can run the service by
    using the following command:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Docker容器的名称是`probe-service`，你可以使用以下命令运行服务：
- en: '[PRE23]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To listen to a different port, you need to set the `PORT` environment variable.
    An example for port `7700` is as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要监听不同的端口，你需要设置`PORT`环境变量。端口`7700`的示例如下：
- en: '[PRE24]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Note that you could map different host ports to port `9900` if you want to
    run multiple services in the same host without changing the port that the container
    listens to. You just need to specify a different port for the host when mapping,
    as in the following example running three services on the same machine:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果你想在同一主机上运行多个服务而不更改容器监听的端口，你可以将不同的主机端口映射到端口`9900`。你只需在映射时指定不同的主机端口，如下例所示，在同一台机器上运行三个服务：
- en: '[PRE25]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Running the preceding three commands will start three services on the host
    ports: `9001`, `9002`, and `9003`. The service inside the container still uses
    port `9900`. To check the services running in a host, use the `docker ps` command,
    as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的三个命令将在主机端口上启动三个服务：`9001`、`9002`和`9003`。容器内的服务仍然使用端口`9900`。要检查主机上运行的服务，请使用`docker
    ps`命令，如下所示：
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The preceding output shows that there are three services running on the host,
    listening to ports `9001`, `9002`, and `9003`. You can access the APIs for each
    of them and probe up to 3,000 targets, 1,000 per service.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出显示，在主机上运行了三个服务，监听端口`9001`、`9002`和`9003`。你可以访问每个服务的API，并对高达3,000个目标进行探测，每个服务1,000个。
- en: Let’s now see how we can automate launching multiple services using Docker Compose.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用Docker Compose自动化启动多个服务。
- en: Scaling up using Docker Compose
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Docker Compose进行扩展
- en: 'Using Docker Compose will help you to add services that will run at the same
    time without needing to invoke the `docker run` command. In our example, we are
    going to use Docker Compose to launch five ICMP probe services. The following
    is the Docker Compose file example in YAML format (described in [*Chapter 4*](B18165_04.xhtml#_idTextAnchor100),):'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker Compose可以帮助你添加同时运行的服务，而无需调用`docker run`命令。在我们的示例中，我们将使用Docker Compose来启动五个ICMP探测服务。以下是一个YAML格式的Docker
    Compose文件示例（在[*第4章*](B18165_04.xhtml#_idTextAnchor100)中描述）：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To run the services, just type `docker compose up –d`, and to stop them, just
    run `docker compose down`. The following is an example of the output of the command:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行服务，只需输入`docker compose up –d`，要停止它们，只需运行`docker compose down`。以下是一个命令输出的示例：
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now, let’s see how we can scale up using multiple machines with a Docker container.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用多个机器和Docker容器进行扩展。
- en: Scaling up with clusters
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用集群进行扩展
- en: To scale even more, you could set up a cluster of Docker host containers. This
    will allow you to launch thousands of services, allowing our ICMP probe service
    to scale to millions of targets. You could build the cluster yourself by managing
    a group of machines and running the services, or you could use a system to do
    all that for you.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步扩展规模，你可以设置一个Docker主机容器的集群。这将允许你启动成千上万的服务，使得我们的ICMP探测服务能够扩展到数百万的目标。你可以通过管理一组机器并运行服务来自己构建集群，或者你可以使用一个系统为你完成所有这些工作。
- en: Let’s now investigate a few systems that are used to manage and launch services
    for a cluster of machines running container services.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们调查一些用于管理和启动运行容器服务的机器集群服务的系统。
- en: Using Docker Swarm
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Docker Swarm
- en: 'With **Docker Swarm**, you are able to launch containers on several machines.
    It is easy to use because it only requires installing Docker. Once you have installed
    it, it is easy to create a Docker Swarm cluster. You just have to run the following
    command:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**Docker Swarm**，你能够在多台机器上启动容器。它很容易使用，因为它只需要安装Docker。一旦安装了它，就很容易创建一个Docker
    Swarm集群。你只需运行以下命令：
- en: '[PRE29]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once you have started the first Docker Swarm host, it will then take the lead
    place, and to add another host, you just need to use the `docker swarm join` command.
    To avoid any host joining the Docker Swarm cluster, a token is used. The preceding
    example starts with `SWMTKN-1`. Note that a host in a Docker Swarm cluster is
    also called a **node**. So, let’s add more nodes to our cluster:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你启动了第一个Docker Swarm主机，它将接管领导位置，要添加另一个主机，你只需使用`docker swarm join`命令。为了避免任何主机加入Docker
    Swarm集群，需要使用一个令牌。前面的示例以`SWMTKN-1`开始。请注意，Docker Swarm集群中的主机也称为**节点**。所以，让我们向我们的集群添加更多节点：
- en: '[PRE30]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, we have four nodes in the cluster, with `host-1` as the leader. You can
    check the status of the cluster nodes by typing the following command:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，集群中有四个节点，`host-1`是领导者。你可以通过输入以下命令来检查集群节点的状态：
- en: '[PRE31]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Once you have your cluster, you can launch a service by running the following
    command:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了集群，你可以通过运行以下命令来启动一个服务：
- en: '[PRE32]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the preceding example, we just launched a Swarm service called `probe` using
    the `probe-service` image, the same image used in previous examples. Note that
    we’ve only launched one replica to later show how easy it is to scale up. Let’s
    check now how the service is installed by running the following command:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们只是使用`probe-service`镜像启动了一个名为`probe`的Swarm服务，与之前的示例中使用的相同镜像。请注意，我们只启动了一个副本，以展示扩展起来的简单性。现在让我们通过运行以下命令来检查服务是如何安装的：
- en: '[PRE33]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s now scale up for 10 probes by running the following command:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过运行以下命令来扩展到10个探测：
- en: '[PRE34]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, if you check the service, it will show 10 replicas, as in the following
    command:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你检查服务，它将显示10个副本，如下面的命令所示：
- en: '[PRE35]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You can also check where each replica is running by running the following command:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过运行以下命令来检查每个副本的运行位置：
- en: '[PRE36]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As you can see in the output of the preceding command, there are 10 probes running
    as replicas on nodes `host-1`, `host-2`, `host-3`, and `host-4`. You can also
    specify where you want the replica to run, among other parameters. In this example,
    we are able to scale up our ICMP probe service to 10,000 targets by using 4 hosts.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前一个命令的输出中看到的，有10个探针作为副本在节点`host-1`、`host-2`、`host-3`和`host-4`上运行。您还可以指定副本运行的位置，以及其他参数。在这个例子中，我们能够通过使用4个主机将我们的ICMP探针服务扩展到10,000个目标。
- en: One important point we missed on these commands was allocating the ports to
    listen for our replicas. As replicas can run in the same host, they can’t use
    the same port. We then need to make sure each replica is assigned with a different
    port number to listen to. A client accessing our `probe-service` cluster needs
    to know the IP addresses of the hosts and the port numbers that are listening
    before connecting for requests.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这些命令中遗漏的一个重要点是分配监听副本的端口。由于副本可以在同一主机上运行，它们不能使用相同的端口。因此，我们需要确保每个副本都被分配了不同的端口号来监听。在连接进行请求之前，访问我们的`probe-service`集群的客户端需要知道主机的IP地址和监听的端口号。
- en: A better and more controlled way to deploy Docker Swarm is to use a YAML configuration
    file like we did when using Docker Compose. More details on the configuration
    file for Docker Swarm can be found at [https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md](https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YAML配置文件部署Docker Swarm是一个更好、更受控的方法，就像我们使用Docker Compose时做的那样。有关Docker Swarm配置文件的更多详细信息可以在[https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md](https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md)找到。
- en: More documentation on Docker Swarm can be found at [https://docs.docker.com/engine/swarm/swarm-mode/](https://docs.docker.com/engine/swarm/swarm-mode/).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于Docker Swarm的文档可以在[https://docs.docker.com/engine/swarm/swarm-mode/](https://docs.docker.com/engine/swarm/swarm-mode/)找到。
- en: Now let’s investigate how to use multiple hosts using Kubernetes.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨如何使用Kubernetes来使用多个主机。
- en: Using Kubernetes
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Kubernetes
- en: Kubernetes is perhaps one of the most popular systems to manage the microservices
    architecture in a cluster. Its popularity is also due to it being backed by the
    **Cloud Native Computing Foundation** ([https://www.cncf.io/](https://www.cncf.io/)),
    which is part of the **Linux Foundation** ([https://www.linuxfoundation.org/](https://www.linuxfoundation.org/)).
    Large companies use Kubernetes, such as Amazon, Google, Apple, Cisco, and Huawei,
    among others.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes可能是管理集群中微服务架构最受欢迎的系统之一。它的流行也得益于它由**云原生计算基金会**（[https://www.cncf.io/](https://www.cncf.io/））支持，该基金会是**Linux基金会**（[https://www.linuxfoundation.org/](https://www.linuxfoundation.org/））的一部分。像亚马逊、谷歌、苹果、思科和华为等大型公司都在使用Kubernetes。
- en: Kubernetes provides many more capabilities than Docker Swarm, such as service
    orchestration, load-balancing, service monitoring, self-healing, and auto-scaling
    by traffic, among other features. Despite the large community and vast capabilities,
    you might not want to use Kubernetes if your requirement is simple and needs to
    scale in large quantities. Kubernetes provides a lot of capabilities that might
    be an overhead to your development. For our `probe-service`, I would not recommend
    using Kubernetes, because it is too complex for our purposes of ICMP probing targets.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了比Docker Swarm更多的功能，例如服务编排、负载均衡、服务监控、自我修复以及通过流量进行自动扩展等。尽管社区庞大且功能强大，但如果您的需求简单且需要大量扩展，您可能不想使用Kubernetes。Kubernetes提供了许多可能对您的开发造成负担的功能。对于我们的`probe-service`，我不建议使用Kubernetes，因为它对我们进行ICMP探针目标的目的来说过于复杂。
- en: You can also use a Docker Compose file to configure Kubernetes, which is done
    by using a service translator such as Kompose ([https://kompose.io/](https://kompose.io/)).
    More details can be found at [https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/](https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用Docker Compose文件来配置Kubernetes，这可以通过使用Kompose（[https://kompose.io/](https://kompose.io/））等服务转换器来完成。更多详细信息可以在[https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/](https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/)找到。
- en: If you want to start using Kubernetes, you can find plenty of examples and documentation
    on the internet. The best place to start is at [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想开始使用Kubernetes，您可以在互联网上找到大量的示例和文档。开始的最佳地方是[https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)。
- en: Let’s now check how we can use another cluster based on Nomad.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看如何使用基于Nomad的另一个集群。
- en: Using Nomad
  id: totrans-265
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Nomad
- en: Nomad is also used to implement Docker clustering ([https://www.nomadproject.io/](https://www.nomadproject.io/)).
    Nomad also has several capabilities that are comparable to Kubernetes, such as
    monitoring, self-healing, and auto-scaling. However, the features list is not
    as long and complete as Kubernetes.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Nomad也被用于实现Docker集群([https://www.nomadproject.io/](https://www.nomadproject.io/))。Nomad还具有与Kubernetes相当的一些功能，例如监控、自我修复和自动扩展。然而，其功能列表并不像Kubernetes那样长且完整。
- en: 'So, why would we use Nomad instead of Kubernetes? There are three main reasons
    that you might want to use Nomad, as listed here:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们会选择使用Nomad而不是Kubernetes呢？这里列出了三个主要的原因，你可能会想使用Nomad：
- en: Simpler to deploy and easy to configure in comparison to Kubernetes.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比Kubernetes，部署更简单，配置也更方便。
- en: Kubernetes can scale up to 5,000 nodes with 300,000 containers. Nomad, on the
    other hand, is able to scale to 10,000 nodes and more than 2 million containers
    ([https://www.javelynn.com/cloud/the-two-million-container-challenge/](https://www.javelynn.com/cloud/the-two-million-container-challenge/)).
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes可以扩展到5,000个节点和300,000个容器。另一方面，Nomad能够扩展到10,000个节点以及超过2百万个容器([https://www.javelynn.com/cloud/the-two-million-container-challenge/](https://www.javelynn.com/cloud/the-two-million-container-challenge/))。
- en: Can support other services besides Linux containers, such as **QEMU** virtual
    machines, Java, Unix processes, and Windows containers.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了Linux容器外，还可以支持其他服务，例如**QEMU**虚拟机、Java、Unix进程和Windows容器。
- en: More documentation on Nomad can be found at [https://developer.hashicorp.com/nomad/docs](https://developer.hashicorp.com/nomad/docs).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Nomad](https://developer.hashicorp.com/nomad/docs)的更多文档可以在[https://developer.hashicorp.com/nomad/docs](https://developer.hashicorp.com/nomad/docs)找到。
- en: Let’s now have a brief look at how to use microservice architectures provided
    by cloud service providers.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在简要地看看如何使用云服务提供商提供的微服务架构。
- en: Using cloud service providers
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用云服务提供商
- en: There are also proprietary solutions that are provided by cloud service providers,
    such as **Azure Container Instances**, **Google Kubernetes Engine** (**GKE**),
    and Amazon **Elastic Container Service** (**ECS**). The advantage of using a cloud
    service provider is you don’t need physical machines in your infrastructure to
    create the cluster. There are also products where you don’t even need to care
    about the cluster and the nodes in it, such as a product from Amazon called AWS
    Fargate. With AWS Fargate, you just need the Docker container published in a Docker
    registry and a service specification without the need to specify the nodes or
    the cluster.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商还提供了一些专有解决方案，例如**Azure容器实例**、**Google Kubernetes Engine**（**GKE**）和**Amazon弹性容器服务**（**ECS**）。使用云服务提供商的优势是你不需要在基础设施中拥有物理机器来创建集群。还有一些产品，你甚至不需要关心集群及其中的节点，例如亚马逊的一个产品叫做AWS
    Fargate。使用AWS Fargate，你只需要在Docker注册表中发布Docker容器和一个服务规范，无需指定节点或集群。
- en: I hope this section has given you a good idea of how to scale your code by using
    Linux containers and host clustering. Microservice architecture is a hot topic
    that has gotten lots of attention from developers and cloud service providers
    in recent years. Several acronyms might be used to describe this technology, but
    we have covered the basics here. You now have enough knowledge to dive even deeper
    into this subject.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这一部分能给你一个很好的想法，了解如何通过使用Linux容器和主机集群来扩展你的代码。微服务架构是近年来开发者和服务提供商都非常关注的热门话题。可能会使用几个缩写来描述这项技术，但在这里我们已经涵盖了基础知识。你现在有足够的知识可以更深入地研究这个主题。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has shown you a good summary of how you can improve and use systems
    to scale your code. We also demonstrated how we can use standard and third-party
    libraries to add capabilities to our code to scale.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向您展示了如何改进和使用系统来扩展你的代码的简要总结。我们还演示了如何使用标准和第三方库来为我们的代码添加功能以实现扩展。
- en: Now, you are probably much more familiar with the technologies that you could
    use to interact with large networks. You are now in a better position to choose
    a language, a library, and a system that will support your network automation
    to scale to handle thousands or even millions of network devices.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能对可以用来与大型网络交互的技术更加熟悉了。你现在处于更好的位置来选择一种语言、一个库和一个系统，这将支持你的网络自动化以扩展处理数千甚至数百万的网络设备。
- en: In the next chapter, we are going to cover how to test your code and your system,
    which will allow you to build solutions for network automation that are less prone
    to failures.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何测试你的代码和系统，这将使你能够构建更少出现故障的网络自动化解决方案。
- en: 'Part 3: Testing, Hands-On, and Going Forward'
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：测试、动手实践和前进
- en: The third part of the book will discuss what has to be considered when building
    a framework for testing your code and how to do so, We will do some real hands-on
    testing and, finally, describe what to do to move forward in the network automation
    realm. We will provide the details on creating a testing framework and do hands-on
    work using an emulated network, which will help to put into practice all the information
    learned in previous parts.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 书的第三部分将讨论在构建测试代码的框架时需要考虑什么，以及如何进行测试，我们将进行一些实际的动手测试，最后描述在网络自动化领域前进时应该做什么。我们将提供创建测试框架的详细信息，并使用模拟网络进行实际操作，这将有助于将之前部分学到的所有信息付诸实践。
- en: 'This part has the following chapters:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 9*](B18165_09.xhtml#_idTextAnchor209), *Network Code Testing Frameworks*'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18165_09.xhtml#_idTextAnchor209), *网络代码测试框架*'
- en: '[*Chapter 10*](B18165_10.xhtml#_idTextAnchor227), *Hands-On and Going Forward*'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18165_10.xhtml#_idTextAnchor227), *动手实践和前进*'
