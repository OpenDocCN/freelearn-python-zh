- en: Chapter 7. Async IO – Multithreading without Threads
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。异步IO - 无需线程的多线程
- en: The previous chapter showed us the basic implementation of synchronous coroutines.
    Whenever you are dealing with external resources, however, synchronous coroutines
    are a bad idea. Just a single stalling remote connection can cause your entire
    process to hang, unless you are using multiprocessing (explained in [Chapter 13](ch13.html
    "Chapter 13. Multiprocessing – When a Single CPU Core Is Not Enough"), *Multiprocessing
    – When a Single CPU Core Is Not Enough*) or asynchronous functions that is.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章向我们展示了同步协程的基本实现。然而，当涉及到外部资源时，同步协程是一个坏主意。只要一个远程连接停顿，整个进程就会挂起，除非你使用了多进程（在[第13章](ch13.html
    "第13章。多进程 - 当单个CPU核心不够用")中有解释，*多进程 - 当单个CPU核心不够用*）或异步函数。
- en: Asynchronous IO makes it possible to access external resources without having
    to worry about slowing down or stalling your application. Instead of actively
    waiting for results, the Python interpreter can simply continue with other tasks
    until it is needed again. This is very similar to the functioning of Node.js and
    AJAX calls in JavaScript. Within Python, we have seen libraries such as `asyncore`,
    `gevent`, and `eventlet` that have made this possible for years. With the introduction
    of the `asyncio` module, however, it has become significantly easier to use.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 异步IO使得可以访问外部资源而无需担心减慢或阻塞应用程序。Python解释器不需要主动等待结果，而是可以简单地继续执行其他任务，直到再次需要。这与Node.js和JavaScript中的AJAX调用的功能非常相似。在Python中，我们已经看到诸如`asyncore`、`gevent`和`eventlet`等库多年来已经实现了这一点。然而，随着`asyncio`模块的引入，使用起来变得更加容易。
- en: This chapter will explain how asynchronous functions can be used in Python (particularly
    3.5 and above) and how code can be restructured in such a way that it still functions
    even though it doesn't follow the standard procedural coding pattern of returning
    values.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释如何在Python（特别是3.5及以上版本）中使用异步函数，以及如何重构代码，使其仍然能够正常运行，即使它不遵循标准的过程式编码模式来返回值。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: 'Functions using:'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下函数：
- en: '`async def`'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`async def`'
- en: '`async for`'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`async for`'
- en: '`async with`'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`async with`'
- en: '`await`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`await`'
- en: Parallel execution
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行执行
- en: Servers
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器
- en: Clients
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端
- en: Eventual results using `Future`
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Future`来获取最终结果
- en: Introducing the asyncio library
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍asyncio库
- en: The `asyncio` library was created to make asynchronous processing much easier
    and results more predictable. It was introduced with the purpose of replacing
    the `asyncore` module, which has been available for a very long time (since Python
    1.5 in fact). The `asyncore` module was never very usable, which prompted the
    creation of the `gevent` and `eventlet` third-party libraries. Both `gevent` and
    `eventlet` make asynchronous programming much easier than `asyncore` ever did,
    but I feel that both have been made largely obsolete with the introduction of
    `asyncio`. Even though I have to admit that `asyncio` still has quite a few rough
    edges, it is in very active development, which makes me think that all the rough
    edges will soon be fixed by either the core Python library or third-party wrappers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`库的创建是为了使异步处理更加容易，并且结果更加可预测。它的目的是取代`asyncore`模块，后者已经可用了很长时间（事实上自Python
    1.5以来）。`asyncore`模块从来没有很好地可用，这促使了`gevent`和`eventlet`第三方库的创建。`gevent`和`eventlet`都比`asyncore`更容易实现异步编程，但我觉得随着`asyncio`的引入，它们已经基本过时了。尽管我不得不承认`asyncio`仍然有一些问题，但它正在积极开发中，这让我认为所有问题很快就会被核心Python库或第三方包解决。'
- en: The `asyncio` library was officially introduced for Python 3.4, but a back port
    for Python 3.3 is available through the Python Package Index. With that in mind,
    while some portions of this chapter will be able to run on Python 3.3, most of
    it has been written with Python 3.5 and the newly introduced `async` and `await`
    keywords in mind.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`库是在Python 3.4中正式引入的，但是可以通过Python包索引为Python 3.3提供后向端口。考虑到这一点，虽然本章的一些部分可以在Python
    3.3上运行，但大部分是以Python 3.5和新引入的`async`和`await`关键字为基础编写的。'
- en: The async and await statements
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步和等待语句
- en: Before we continue with any example, it is important to know how the Python
    3.4 and Python 3.5 code syntaxes relate. Even though the `asyncio` library was
    introduced only in Python 3.4, a large portion of the generic syntax has already
    been replaced in Python 3.5\. Not forcefully, but the easier and therefore recommended
    syntax using `async` and `await` has been introduced.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续任何示例之前，重要的是要了解Python 3.4和Python 3.5代码语法之间的关系。尽管`asyncio`库仅在Python 3.4中引入，但Python
    3.5中已经替换了大部分通用语法。虽然不是强制性的，但更简单，因此推荐使用`async`和`await`的语法已经被引入。
- en: Python 3.4
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 3.4
- en: 'For the traditional Python 3.4 usage, a few things need to be considered:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传统的Python 3.4用法，需要考虑一些事项：
- en: Functions should be declared using the `asyncio.coroutine` decorator
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数应使用`asyncio.coroutine`装饰器声明
- en: Asynchronous results should be fetched using `yield from coroutine()`
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应使用`yield from coroutine()`来获取异步结果
- en: 'Asynchronous loops are not directly supported but can be emulated using `while
    True: yield from coroutine()`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '不直接支持异步循环，但可以使用`while True: yield from coroutine()`来模拟'
- en: 'Here is an example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个例子：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Python 3.5
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 3.5
- en: In Python 3.5, a new syntax was introduced to mark a function as asynchronous.
    Instead of the `asyncio.coroutine` decorator, the `async` keyword can be used.
    Also, instead of the confusing `yield from` syntax, Python now supports the `await`
    statement. The `yield from` statement was slightly confusing because it might
    give someone the idea that a value is being exchanged, which is not always the
    case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.5中，引入了一种新的语法来标记函数为异步的。可以使用`async`关键字来代替`asyncio.coroutine`装饰器。此外，Python现在支持`await`语句，而不是令人困惑的`yield
    from`语法。`yield from`语句稍微令人困惑，因为它可能让人觉得正在交换值，而这并不总是情况。
- en: 'The following is the `async` statement:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`async`语句：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It can be used instead of the decorator:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以代替装饰器：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Within Python 3.5, and most likely in future versions as well, the `coroutine`
    decorator will still be supported, but if backwards compatibility is not an issue,
    I strongly recommend the new syntax.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.5中，以及很可能在未来的版本中，`coroutine`装饰器仍然受到支持，但如果不需要向后兼容性，我强烈推荐使用新的语法。
- en: 'Additionally, instead of the `yield from` statement, we can use the much more
    logical `await` statement. So, the example from the previous paragraph becomes
    as simple as the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用更合乎逻辑的`await`语句，而不是`yield from`语句。因此，前面段落中的示例变得和以下示例一样简单：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `yield from` statement originated from the original coroutines implementation
    in Python and was a logical extension from the `yield` statement used within synchronous
    coroutines. Actually, the `yield from` statement still works and the `await` statement
    is just a wrapper for it, with some added checks. While using `await`, the interpreter
    checks whether the object is an awaitable object, meaning it needs to be one of
    the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`yield from`语句源自Python中原始协程实现，并且是在同步协程中使用的`yield`语句的一个逻辑扩展。实际上，`yield from`语句仍然有效，而`await`语句只是它的一个包装器，增加了一些检查。在使用`await`时，解释器会检查对象是否是可等待对象，这意味着它需要是以下对象之一：'
- en: A native coroutine created with the `async def` statement
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`async def`语句创建的本地协程
- en: A coroutine created with the `asyncio.coroutine` decorator
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`asyncio.coroutine`装饰器创建的协程
- en: An object that implements the `__await__` method
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现`__await__`方法的对象
- en: This check alone makes the `await` statement preferable over the `yield from`
    statement, but I personally think that `await` conveys the meaning of the statement
    much better as well.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个检查本身就使得`await`语句比`yield from`语句更可取，但我个人认为`await`更好地传达了语句的含义。
- en: 'To summarize, to convert to the new syntax, make the following changes:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，要转换为新的语法，进行以下更改：
- en: Functions should be declared using `async def` instead of `def`
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数应该使用`async def`声明，而不是`def`
- en: Asynchronous results should be fetched using `await coroutine()`
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用`await coroutine()`来获取异步结果
- en: Asynchronous loops can be created using `async for ... in ...`
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用`async for ... in ...`创建异步循环
- en: Asynchronous `with` statements can be created using `async with ...`
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用`async with ...`创建异步`with`语句
- en: Choosing between the 3.4 and 3.5 syntax
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在3.4和3.5语法之间进行选择
- en: Unless you really need Python 3.3 or 3.4 support, I would strongly recommend
    the Python 3.5 syntax. The new syntax is clearer and supports more features, such
    as asynchronous `for` loops and `with` statements. Unfortunately, they are not
    fully compatible, so you need to make a choice. Within an `async def` (3.5), we
    cannot use `yield from`, but all we need to do to fix that is replace `yield from`
    with `await`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你真的需要Python 3.3或3.4支持，我强烈推荐使用Python 3.5语法。新的语法更清晰，支持更多功能，比如异步`for`循环和`with`语句。不幸的是，它们并不完全兼容，所以你需要做出选择。在`async
    def`（3.5）中，我们不能使用`yield from`，但我们只需要用`await`替换`yield from`就可以解决这个问题。
- en: A simple example of single-threaded parallel processing
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单线程并行处理的简单示例
- en: 'Parallel processing has many uses: a server taking care of multiple requests
    at the same time, speeding up heavy tasks, waiting for external resources, and
    much more. Generic coroutines can help with handling multiple requests and external
    resources in some cases, but they are still synchronous and therefore limited.
    With `asyncio`, we can transcend the limitations of generic coroutines and easily
    handle stalling resources without having to worry about blocking the main thread.
    Let''s see a quick example of how the code does not stall with multiple parallel
    functions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理有很多用途：服务器同时处理多个请求，加快繁重任务的速度，等待外部资源等等。通用协程在某些情况下可以帮助处理多个请求和外部资源，但它们仍然是同步的，因此受到限制。使用`asyncio`，我们可以超越通用协程的限制，轻松处理阻塞资源，而不必担心阻塞主线程。让我们快速看一下代码如何在多个并行函数中不会阻塞：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Even though we started the sleepers with the order of 1, 3, 2, which sleeps
    for that amount of time, `asyncio.sleep` combined with the `await` statement actually
    tells Python that it should just continue with a task that needs actual processing
    at this time. A regular `time.sleep` would actually stall the Python task, meaning
    they would execute sequentially. This makes it somewhat more obviously transparent
    what these can be used for, as it handles any type of wait, which we can hand
    off to `asyncio` instead of keeping the entire Python thread busy. So, instead
    of `while True: fh.read()`, we can just respond whenever there is new data.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '即使我们按顺序开始了睡眠器，1、3、2，它们会按照相应的时间睡眠，`asyncio.sleep`结合`await`语句实际上告诉Python，它应该继续处理需要实际处理的任务。普通的`time.sleep`实际上会阻塞Python任务，这意味着它们会按顺序执行。这使得它更加透明，可以处理任何类型的等待，我们可以将其交给`asyncio`，而不是让整个Python线程忙碌。因此，我们可以用`while
    True: fh.read()`来代替，只要有新数据就可以立即响应。'
- en: 'Let''s analyze the components used in this example:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下这个例子中使用的组件：
- en: '`asyncio.coroutine`: This decorator enables yielding from `async def` coroutines.
    Unless you are using this syntax, there is no real need for the decorator, but
    it''s a good default if only used as documentation.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio.coroutine`：这个装饰器使得可以从`async def`协程中进行yield。除非你使用这种语法，否则没有真正需要这个装饰器，但如果只用作文档，这是一个很好的默认值。'
- en: '`asyncio.sleep`: This is the asynchronous version of `time.sleep`. The big
    difference between these two is that `time.sleep` will keep the Python process
    busy while it is sleeping, whereas `asyncio.sleep` will allow switching to a different
    task within the event loop. This process is very similar to the workings of task
    switching in most operating systems.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio.sleep`：这是`time.sleep`的异步版本。这两者之间的主要区别是，`time.sleep`在睡眠时会让Python进程保持忙碌，而`asyncio.sleep`允许在事件循环中切换到不同的任务。这个过程与大多数操作系统中的任务切换的工作方式非常相似。'
- en: '`asyncio.get_event_loop`: The default event loop is effectively the `asyncio`
    task switcher; we''ll explain more about these in the next paragraph.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio.get_event_loop`：默认事件循环实际上是`asyncio`任务切换器；我们将在下一段解释更多关于这些的内容。'
- en: '`asyncio.wait`: This is the coroutine for wrapping a sequence of coroutines
    or futures and waiting for the results. The wait time is configurable, as is the
    manner of waiting (first done, all done, or the first exception).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio.wait`：这是用于包装一系列协程或未来并等待结果的协程。等待时间是可配置的，等待方式也是可配置的（首先完成，全部完成，或者第一个异常）。'
- en: 'That should explain the basic workings of the example: the `sleeper` function
    is the asynchronous coroutine, which exits after the given delay. The `wait` function
    waits for all coroutines to finish before exiting, and the `event` loop is used
    for switching between the three coroutines.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该解释了示例的基本工作原理：`sleeper`函数是异步协程，经过给定的延迟后退出。`wait`函数在退出之前等待所有协程完成，`event`循环用于在三个协程之间切换。
- en: Concepts of asyncio
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`asyncio`的概念'
- en: The `asyncio` library has several basic concepts, which have to be explained
    before we venture further into examples and uses. The example shown in the previous
    paragraph actually used most of them, but a little explanation about the how and
    the why might still be useful.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`库有几个基本概念，必须在我们进一步探讨示例和用法之前加以解释。前一段中显示的示例实际上使用了大部分这些概念，但对于如何以及为什么可能仍然有一些解释是有用的。'
- en: The main concepts of `asyncio` are *coroutines* and *event loops*. Within them,
    there are several helper classes available, such as `Streams`, `Futures`, and
    `Processes`. The next few paragraphs will explain the basics so that you can understand
    the implementations in the examples in the later paragraphs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`的主要概念是*协程*和*事件循环*。在其中，还有几个可用的辅助类，如`Streams`、`Futures`和`Processes`。接下来的几段将解释基础知识，以便你能够理解后面段落中的示例中的实现。'
- en: Futures and tasks
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来和任务
- en: The `asyncio.Future` class is essentially a promise of a result; it returns
    the results if they are available, and once it receives results, it will pass
    them along to all the registered callbacks. It maintains a state variable internally,
    which allows an outside party to mark a future as canceled. The API is very similar
    to the `concurrent.futures.Future` class, but since they are not fully compatible,
    make sure you do not confuse the two.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.Future`类本质上是一个结果的承诺；如果结果可用，它会返回结果，并且一旦接收到结果，它将把结果传递给所有注册的回调函数。它在内部维护一个状态变量，允许外部方将未来标记为已取消。API与`concurrent.futures.Future`类非常相似，但由于它们并不完全兼容，所以请确保不要混淆两者。'
- en: The `Future` class by itself is not that convenient to use though, so that is
    where `asyncio.Task` comes in. The `Task` class wraps a coroutine and automatically
    handles the execution, results, and state for you. The coroutine will be executed
    through the given event loop, or the default event loop if none was given.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`Future`类本身并不那么方便使用，这就是`asyncio.Task`发挥作用的地方。`Task`类包装了一个协程，并自动处理执行、结果和状态。协程将通过给定的事件循环执行，或者如果没有给定，则通过默认事件循环执行。'
- en: 'The creation of these classes is not something you need to worry about directly.
    This is because instead of creating the class yourself, the recommended way is
    through either `asyncio.ensure_future` or `loop.create_task`. The former actually
    executes `loop.create_task` internally but it is more convenient if you simply
    want to execute it on the main/default event loop without having to specify it
    first. The usage is simple enough. To create your own future manually, you simply
    tell the event loop to execute `create_task` for you. The following example is
    a bit complicated because of all the setup code but the usage of C should be clear
    enough. The most important aspect to note is that the event loop should be linked
    so that the task knows how/where to run:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类的创建并不是你需要直接担心的事情。这是因为推荐的方式是通过`asyncio.ensure_future`或`loop.create_task`来创建类。前者实际上在内部执行了`loop.create_task`，但如果你只想在主/默认事件循环上执行它而不必事先指定，那么这种方式更方便。使用起来非常简单。要手动创建自己的未来，只需告诉事件循环为你执行`create_task`。下面的示例由于所有的设置代码而有点复杂，但C的使用应该是清楚的。最重要的一点是事件循环应该被链接，以便任务知道如何/在哪里运行：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, a little bit about debugging asynchronous functions. Debugging asynchronous
    functions used to be very difficult if not impossible, as there was no good way
    to see where and how the functions were stalling. Luckily, that has changed. In
    the case of the `Task` class, it is as simple as calling `task.get_stack` or `task.print_stack`
    to see where it is currently. The usage can be as simple as the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，稍微了解一下调试异步函数。调试异步函数曾经非常困难，甚至是不可能的，因为没有好的方法来查看函数在哪里以及如何停滞。幸运的是，情况已经改变。在`Task`类的情况下，只需调用`task.get_stack`或`task.print_stack`就可以看到它当前所在的位置。使用方法可以简单到如下：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Event loops
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件循环
- en: 'The concept of event loops is actually the most important one within `asyncio`.
    You might have suspected that the coroutines themselves are what everything is
    about, but without the event loop, they are useless. Event loops function as task
    switchers, just the way operating systems switch between active tasks on the CPU.
    Even with multicore processors, there is still a need for a main process to tell
    the CPU which tasks have to run and which need to wait/sleep for a while. This
    is exactly what the event loop does: it decides which task to run.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事件循环的概念实际上是`asyncio`中最重要的一个。你可能已经怀疑协程本身就是一切的关键，但没有事件循环，它们就毫无用处。事件循环就像任务切换器一样工作，就像操作系统在CPU上切换活动任务的方式一样。即使有多核处理器，仍然需要一个主进程告诉CPU哪些任务需要运行，哪些需要等待/休眠一段时间。这正是事件循环所做的：它决定要运行哪个任务。
- en: Event loop implementations
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 事件循环实现
- en: 'So far, we have only seen `asyncio.get_event_loop`, which returns the default
    event loop with the default event loop policy. Currently, there are two bundled
    event loop implementations: the `async.SelectorEventLoop` and `async.ProactorEventLoop`
    implementations. Which of the two is available depends on your operating system.
    The latter event loop is available only on Windows machines and uses I/O Completion
    Ports, which is a system that is supposedly faster and more efficient than the
    `Select` implementation of `asyncio.SelectorEventLoop`. This is something to consider
    if performance is an issue. The usage is simple enough, luckily:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看到了`asyncio.get_event_loop`，它返回默认的事件循环和默认的事件循环策略。目前，有两种捆绑的事件循环实现：`async.SelectorEventLoop`和`async.ProactorEventLoop`实现。哪一种可用取决于您的操作系统。后一种事件循环仅在Windows机器上可用，并使用I/O完成端口，这是一个据说比`asyncio.SelectorEventLoop`的`Select`实现更快更高效的系统。如果性能是一个问题，这是需要考虑的事情。幸运的是，使用起来相当简单：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The alternative event loop is based on selectors, which, since Python 3.4,
    are available through the `selectors` module in the core Python installation.
    The `selectors` module was introduced in Python 3.4 to enable easy access to low-level
    asynchronous I/O operations. Basically, it allows you to open and read from many
    files by using I/O multiplexing. Since `asyncio` handles all complexities for
    you, there is generally no need to use the module directly, but the usage is simple
    enough if you need it. Here''s an example of binding a function to the read event
    (`EVENT_READ`) on the standard input. The code will simply wait until one of the
    registered files provides new data:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 备用事件循环基于选择器，自Python 3.4以来，可以通过核心Python安装中的`selectors`模块获得。`selectors`模块是在Python
    3.4中引入的，以便轻松访问低级异步I/O操作。基本上，它允许您通过使用I/O多路复用来打开和读取许多文件。由于`asyncio`为您处理了所有复杂性，通常不需要直接使用该模块，但如果需要，使用起来相当简单。以下是将函数绑定到标准输入的读事件（`EVENT_READ`）的示例。代码将简单地等待，直到其中一个注册的文件提供新数据：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'There are several selectors available, such as the traditional `selectors.SelectSelector`
    (which uses `select.select` internally), but there are also more modern solutions
    such as `selectors.KqueueSelector`, `selectors.EpollSelector`, and `selectors.DevpollSelector`.
    Even though it should select the most efficient selector by default, there are
    cases where the most efficient one is not suitable in some way or another. In
    those cases, the selector event loop allows you to specify a different selector:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种选择器可用，例如传统的`selectors.SelectSelector`（内部使用`select.select`），但也有更现代的解决方案，如`selectors.KqueueSelector`、`selectors.EpollSelector`和`selectors.DevpollSelector`。尽管默认情况下应该选择最有效的选择器，但在某些情况下，最有效的选择器可能不适合。在这些情况下，选择器事件循环允许您指定不同的选择器：
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It should be noted that the differences between these selectors are generally
    too small to notice in most real-world applications. The only situation I have
    come across where such an optimization makes a difference is when building a server
    that has to handle a lot of simultaneous connections. With "a lot," I am referring
    to over 100,000 concurrent connections on a single server, which is a problem
    only a few people on this planet have had to deal with.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，这些选择器之间的差异在大多数实际应用程序中通常太小而难以注意到。我遇到的唯一一种情况是在构建一个必须处理大量同时连接的服务器时，这种优化才会有所不同。当我说“大量”时，我指的是在单个服务器上有超过100,000个并发连接的问题，这只有少数人在这个星球上需要处理。
- en: Event loop policies
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 事件循环策略
- en: 'Event loop policies are objects that create and store the actual event loops
    for you. They have been written with maximum flexibility in mind but are not objects
    that you often need to modify. The only reason I can think of modifying the event
    loop policy is if you want to make specific event loops run on specific processors
    and/or systems, or if you wish to change the default event loop type. Beyond that,
    it offers more flexibility than most people will ever need. Making your own event
    loop (`ProActorEventLoop` in this case) the default is simply possible through
    this code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 事件循环策略是创建和存储实际事件循环的对象。它们被设计为最大灵活性，但通常不需要修改。我能想到的唯一原因修改事件循环策略是如果您想要使特定事件循环在特定处理器和/或系统上运行，或者如果您希望更改默认事件循环类型。除此之外，它提供的灵活性超出了大多数人所需的范围。通过以下代码，使自己的事件循环（在这种情况下是`ProActorEventLoop`）成为默认事件循环是完全可能的：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Event loop usage
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 事件循环使用
- en: So far, we have only seen the `loop.run_until_complete` method. Naturally, there
    are a few others as well. The one you will most likely use most often is `loop.run_forever`.
    This method, as you might expect, keeps running forever, or at least until `loop.stop`
    has been run.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看到了`loop.run_until_complete`方法。当然，还有其他一些方法。你最有可能经常使用的是`loop.run_forever`。这个方法，正如你所期望的那样，会一直运行下去，或者至少直到`loop.stop`被运行。
- en: 'So, assuming we have an event loop running forever now, we need to add tasks
    to it. This is where things get interesting. There are quite a few choices available
    within the default event loops:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，假设我们现在有一个永远运行的事件循环，我们需要向其中添加任务。这就是事情变得有趣的地方。在默认事件循环中有很多选择：
- en: '`call_soon`: Add an item to the end of the (FIFO) queue so that the functions
    will be executed in the order in which they were inserted.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call_soon`：将项目添加到（FIFO）队列的末尾，以便按照插入的顺序执行函数。'
- en: '`call_soon_threadsafe`: This is the same as `call_soon` except for being thread
    safe. The `call_soon` method is not thread safe because thread safety requires
    the usage of the global interpreter lock (GIL), which effectively makes your program
    single threaded at the moment of thread safety. The performance chapter will explain
    this more thoroughly.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call_soon_threadsafe`：这与`call_soon`相同，只是它是线程安全的。`call_soon`方法不是线程安全的，因为线程安全需要使用全局解释器锁（GIL），这在线程安全时会使您的程序变成单线程。性能章节将更彻底地解释这一点。'
- en: '`call_later`: Call the function after the given number of seconds. If two jobs
    would run at the same time, they will run in an undefined order. Note that the
    delay is a minimum. If the event loop is locked/busy, it can run later.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call_later`：在给定的秒数后调用函数。如果两个任务将同时运行，它们将以未定义的顺序运行。请注意，延迟是最小值。如果事件循环被锁定/忙碌，它可能会稍后运行。'
- en: '`call_at`: Call a function at a specific time related to the output of `loop.time`.
    Every integer after `loop.time` adds a second.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call_at`：在与`loop.time`的输出相关的特定时间调用函数。`loop.time`之后的每个整数都会增加一秒。'
- en: 'All of these functions return `asyncio.Handle` objects. These objects allow
    the cancellation of the task through the `handle.cancel` function as long as it
    has not been executed yet. Be careful with canceling from other threads, however,
    as cancellation is not thread safe either. To execute it in a thread-safe way,
    we have to execute the cancellation function as a task as well: `loop.call_soon_threadsafe(handle.cancel)`.
    The following is an example usage:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些函数都返回`asyncio.Handle`对象。只要任务尚未执行，这些对象就允许通过`handle.cancel`函数取消任务。但是要小心取消来自其他线程，因为取消也不是线程安全的。要以线程安全的方式执行它，我们还必须将取消函数作为任务执行：`loop.call_soon_threadsafe(handle.cancel)`。以下是一个示例用法：
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You might be wondering why we are not using the coroutine decorator here. The
    reason is that the loop won''t allow running of coroutines directly. To run a
    coroutine through these call functions, we need to make sure that it is wrapped
    in an `asyncio.Task`. As we have seen in the previous paragraph, this is easy
    enough—luckily:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我们在这里没有使用协程装饰器。原因是循环不允许直接运行协程。要通过这些调用函数运行协程，我们需要确保它被包装在`asyncio.Task`中。正如我们在前一段中看到的那样，这很容易——幸运的是：
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: These call methods might appear slightly different but the internals actually
    boil down to two queues that are implemented through `heapq`. The `loop._scheduled`
    is used for scheduled operations and `loop._ready` is for immediate execution.
    When the `_run_once` method is called (the `run_forever` method wraps this method
    in a `while True` loop), the loop will first try to process all items in the `loop._ready`
    heap with the specific loop implementation (for example, `SelectorEventLoop`).
    Once everything in `loop._ready` is processed, the loop will continue to move
    items from the `loop._scheduled` heap to the `loop._ready` heap if they are due.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些调用方法可能看起来略有不同，但内部实际上都归结为通过`heapq`实现的两个队列。`loop._scheduled`用于计划操作，`loop._ready`用于立即执行。当调用`_run_once`方法（`run_forever`方法在`while
    True`循环中包装了这个方法）时，循环将首先尝试使用特定的循环实现（例如`SelectorEventLoop`）处理`loop._ready`堆中的所有项目。一旦`loop._ready`中的所有项目都被处理，循环将继续将`loop._scheduled`堆中的项目移动到`loop._ready`堆中，如果它们已经到期。
- en: Both `call_soon` and `call_soon_threadsafe` write to the `loop._ready` heap.
    And the `call_later` method is simply a wrapper for `call_at` with the current
    value of `asyncio.time` added to the scheduled time, which writes to the `loop._scheduled`
    heap.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`call_soon`和`call_soon_threadsafe`都写入`loop._ready`堆。而`call_later`方法只是`call_at`的一个包装，其计划时间是当前值加上`asyncio.time`，它写入`loop._scheduled`堆。'
- en: The result of this method of processing is that everything added through the
    `call_soon*` methods will always execute after everything that is added through
    the `call_at`/`call_later` methods.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这种处理方法的结果是，通过`call_soon*`方法添加的所有内容都将始终在通过`call_at`/`call_later`方法添加的所有内容之后执行。
- en: As for the `ensure_futures` function, it will call `loop.create_task` internally
    to wrap the coroutine in a `Task` object, which is, of course, a subclass of a
    `Future` object. If you need to extend the `Task` class for some reason, that
    is easily possible through the `loop.set_task_factory` method.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 至于`ensure_futures`函数，它将在内部调用`loop.create_task`来将协程包装在`Task`对象中，当然，这是`Future`对象的子类。如果出于某种原因需要扩展`Task`类，可以通过`loop.set_task_factory`方法轻松实现。
- en: Depending on the type of event loop, there are actually many other methods for
    creating connections, file handlers, and more. Those will be explained by example
    in later paragraphs, since they have less to do with the event loop and are more
    about programming with coroutines.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据事件循环的类型，实际上有许多其他方法可以创建连接、文件处理程序等。这些将在后面的段落中通过示例进行解释，因为它们与事件循环的关系较小，更多地涉及使用协程进行编程。
- en: Processes
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进程
- en: So far, we have simply executed specifically asynchronous Python functions,
    but some things are a tad more difficult to run asynchronously within Python.
    For example, let's assume we have a long-running external application that we
    wish to run. The `subprocess` module would be the standard approach for running
    external applications, and it works quite well. With a bit of care, one could
    even make sure that these do not block the main thread by polling the output.
    That still requires polling, however. Yet, won't events be better so that we can
    do other things while we are waiting for the results? Luckily, this is easily
    arranged through `asyncio.Process`. Similar to the `Future` and `Task` classes,
    this class is meant to be created through the event loop. In terms of usage, the
    class is very similar to the `subprocess.Popen` class, except that the functions
    have been made asynchronous. This results in the removal of the polling function,
    of course.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只是执行了特定的异步Python函数，但有些事情在Python中异步运行起来会更困难。例如，假设我们有一个长时间运行的外部应用程序需要运行。`subprocess`模块将是运行外部应用程序的标准方法，并且它运行得相当好。通过一些小心，甚至可以确保它们不会通过轮询输出来阻塞主线程。然而，这仍然需要轮询。然而，事件会更好，这样我们在等待结果时可以做其他事情。幸运的是，这很容易通过`asyncio.Process`安排。与`Future`和`Task`类似，这个类是通过事件循环创建的。在使用方面，这个类与`subprocess.Popen`类非常相似，只是函数已经变成了异步的。当然，这会导致轮询函数的消失。
- en: 'First, let''s look at the traditional sequential version:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看传统的顺序版本：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Since everything is executed sequentially, it takes three times the 0.1 seconds
    that the sleep command is sleeping. So, instead of waiting for all of them at
    the same time, let''s run them in parallel this time:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一切都是按顺序执行的，所以等待的时间是休眠命令休眠的0.1秒的三倍。因此，与其同时等待所有这些，这次让我们并行运行它们：
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'While this looks a lot better in terms of runtime, our program structure is
    a bit messy now. We needed two loops, one to start the processes and one to measure
    the finish time. Moreover, we had to move the print statement outside of the function,
    which is generally not desirable either. This time, we will try the `asyncio`
    version:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从运行时间上看这样做要好得多，但我们的程序结构现在有点混乱。我们需要两个循环，一个用于启动进程，另一个用于测量完成时间。此外，我们还必须将打印语句移到函数外部，这通常也是不可取的。这次，我们将尝试`asyncio`版本：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As you can see, it is easy to run multiple applications at the same time this
    way. But that is the easy part; the difficult part with processes is interactive
    input and output. The `asyncio` module has several measures to make it easier,
    but it can still be difficult when actually working with the results. Here''s
    an example of calling the Python interpreter, executing some code, and exiting
    again:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种方式很容易同时运行多个应用程序。但这只是简单的部分；处理进程的难点在于交互式输入和输出。`asyncio`模块有几种措施可以使其更容易，但在实际处理结果时仍然可能会有困难。以下是调用Python解释器、执行一些代码并再次退出的示例：
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The code is simple enough, but there are a few parts of this code that are
    not obvious to us and yet required to function. While the creation of the subprocess
    and the writing code is quite obvious, you might be wondering about the `process.stdin.write_eof()`
    line. The problem here is buffering. To improve performance, most programs will
    buffer input and output by default. In the case of the Python program, the result
    is that unless we send the **end of file** (**eof**), the program will keep waiting
    for more input. An alternative solution would be to close the `stdin` stream or
    somehow communicate with the Python program that we will not send any more input.
    However, it is certainly something to take into consideration. Another option
    is to use `yield` from `process.stdin.drain()`, but that only takes care of the
    sending side of the code; the receiving side might still be waiting for more input.
    Let''s see the output though:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 代码足够简单，但这段代码中有一些对我们来说不明显但却需要的部分。虽然创建子进程和编写代码是相当明显的，但您可能会对`process.stdin.write_eof()`这一行感到疑惑。问题在于缓冲。为了提高性能，大多数程序默认会对输入和输出进行缓冲。在Python程序的情况下，结果是除非我们发送**文件结束**（**eof**），否则程序将继续等待更多的输入。另一种选择是关闭`stdin`流或以某种方式与Python程序通信，告诉它我们不会再发送任何输入。然而，这当然是需要考虑的事情。另一个选择是使用`yield`
    from `process.stdin.drain()`，但那只处理了代码的发送方；接收方可能仍在等待更多的输入。不过，让我们看一下输出：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With this implementation, we still need a loop to get all the results from the
    `stdout` stream. Unfortunately, the `asyncio.StreamReader` (which `process.stdout`
    is) class does not support the `async for` syntax yet. If it did, a simple `async
    for out in process.stdout` would have worked. A simple `yield from process.stdout.read()`
    would have worked as well, but reading per line is generally more convenient to
    use.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种实现方式，我们仍然需要一个循环来从`stdout`流中获取所有的结果。不幸的是，`asyncio.StreamReader`（`process.stdout`所属的类）类尚不支持`async
    for`语法。如果支持的话，一个简单的`async for out in process.stdout`就可以工作了。一个简单的`yield from process.stdout.read()`也可以工作，但通常逐行阅读更方便使用。
- en: If possible, I recommend that you abstain from using `stdin` to send data to
    subprocesses and instead use some network, pipe, or file communication. As we
    will see in the next paragraphs, these are much more convenient to handle.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，我建议您避免使用`stdin`向子进程发送数据，而是使用一些网络、管道或文件通信。正如我们将在下面的段落中看到的，这些更方便处理。
- en: Asynchronous servers and clients
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步服务器和客户端
- en: One of the most common reason for stalling scripts and applications is the usage
    of remote resources. With `asyncio`, at least a large portion of that is easily
    fixable. Fetching multiple remote resources and serving to multiple clients is
    quite a bit easier and more lightweight than it used to be. While both multithreading
    and multiprocessing can be used for these cases as well, `asyncio` is a much lighter
    alternative and it is actually easier to manage. There are two main methods of
    creating clients and servers. The coroutine way is to use `asyncio.open_connection`
    and `asyncio.start_server`. The class-based approach requires you to inherit the
    `asyncio.Protocol` class. While these are essentially the same thing, the workings
    are slightly different.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 导致脚本和应用程序停滞的最常见原因之一是使用远程资源。使用`asyncio`，至少其中的大部分是很容易解决的。获取多个远程资源并为多个客户端提供服务比以前要容易得多，也更轻量级。虽然多线程和多进程也可以用于这些情况，但`asyncio`是一个更轻量级的替代方案，实际上更容易管理。创建客户端和服务器有两种主要方法。协程方式是使用`asyncio.open_connection`和`asyncio.start_server`。基于类的方法要求您继承`asyncio.Protocol`类。虽然它们本质上是相同的，但工作方式略有不同。
- en: Basic echo server
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本回显服务器
- en: 'The basic client and server versions are simple enough to write. The `asyncio`
    module takes care of all the low-level connection handling, leaving us with only
    the requirement of connecting the correct methods. For the server, we need a method
    to handle the incoming connections, and for the client, we need a function to
    create connections. And to illustrate what is happening and at which point in
    time, we will add a dedicated print function that prints both the time since the
    server process was started and the given arguments:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的客户端和服务器版本编写起来相当简单。`asyncio`模块负责所有底层连接处理，我们只需要连接正确的方法。对于服务器，我们需要一个处理传入连接的方法，对于客户端，我们需要一个创建连接的函数。为了说明发生了什么以及在何时发生，我们将添加一个专门的打印函数，打印自服务器进程启动以来的时间和给定的参数：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now we will run the server and two simultaneous clients. Since these run in
    parallel, the server output is a bit strange, of course. Because of that, we synchronize
    the start time from the server to the clients and prefix all print statements
    with the number of seconds since the server was started.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将运行服务器和两个同时的客户端。由于这些是并行运行的，服务器输出当然有点奇怪。因此，我们将从服务器到客户端同步启动时间，并在所有打印语句前加上自服务器启动以来的秒数。
- en: 'The server:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The first client:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个客户端：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The second client:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个客户端：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Since both the input and output have buffers, we need to manually drain the
    input after writing and use `yield from` when reading the output from the other
    party. That is exactly the reason that communication with regular external processes
    is more difficult than network interaction. The standard input for processes is
    more focused towards user input than computer input, which makes it less convenient
    to use.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输入和输出都有缓冲区，我们需要在写入后手动排空输入，并在从对方读取输出时使用`yield from`。这正是与常规外部进程通信更困难的原因。进程的标准输入更侧重于用户输入而不是计算机输入，这使得使用起来不太方便。
- en: Note
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you wish to use `reader.read(BUFFER)` instead of `reader.readline()`, that's
    also possible. Just note that you need to specifically separate the data because
    it might accidently get appended otherwise. All write operations write to the
    same buffer, resulting in one long return stream. On the other hand, trying to
    write without a new line (`\n`) for `reader.readline()` to recognize will cause
    the client to wait forever.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望使用`reader.read(BUFFER)`而不是`reader.readline()`，也是可能的。只是请注意，您需要明确地分隔数据，否则可能会意外地被附加。所有写操作都写入同一个缓冲区，导致一个长的返回流。另一方面，尝试在`reader.readline()`中没有新行(`\n`)的情况下进行写入将导致客户端永远等待。
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how to use asynchronous I/O in Python using `asyncio`.
    For many scenarios, the `asyncio` module is still a bit raw and unfinished, but
    there should not be any obstacles in using it. Creating a fully functional server/client
    setup is still a tad complicated, but the most obvious use of `asyncio` is the
    handling of basic network I/O such as database connections and external resources
    such as websites. Especially, the latter takes only a few lines to implement with
    the use of `asyncio`, removing some very important bottlenecks from your code.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何在Python中使用`asyncio`进行异步I/O。对于许多场景，`asyncio`模块仍然有些原始和未完成，但不应该有任何使用上的障碍。创建一个完全功能的服务器/客户端设置仍然有点复杂，但`asyncio`最明显的用途是处理基本的网络I/O，如数据库连接和外部资源，如网站。特别是后者只需使用`asyncio`就可以实现几行代码，从您的代码中删除一些非常重要的瓶颈。
- en: The point of this chapter is understanding how to tell Python to wait for results
    in the background instead of simply waiting or polling for them as usual. In [Chapter
    13](ch13.html "Chapter 13. Multiprocessing – When a Single CPU Core Is Not Enough"),
    *Multiprocessing – When a Single CPU Core Is Not Enough* you will learn about
    multiprocessing, which is also an option for handling stalling resources. However,
    the goal of multiprocessing is actually to use multiple processors instead of
    handling stalling resources. When it comes to potentially slow external resources,
    I recommend that you always use `asyncio`, if at all possible.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是理解如何告诉Python在后台等待结果，而不是像通常那样简单地等待或轮询结果。在[第13章](ch13.html "第13章。多处理-当单个CPU核心不够用")中，*多处理-当单个CPU核心不够用*，您将了解多处理，这也是处理停滞资源的选项。然而，多处理的目标实际上是使用多个处理器，而不是处理停滞资源。当涉及潜在缓慢的外部资源时，我建议您尽可能使用`asyncio`。
- en: When building utilities based on the `asyncio` library, make sure you search
    for premade libraries to solve your problems, as many of them are currently being
    developed. While writing this chapter, Python 3.5 was not officially out yet,
    so the odds are that a lot more documentation and libraries using the `async/await`
    syntax will pop up soon. To make sure you do not repeat work that others have
    done, search the Internet thoroughly before writing your own code extending on
    `asyncio`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于`asyncio`库构建实用程序时，确保搜索预制库来解决您的问题，因为其中许多目前正在开发中。在撰写本章时，Python 3.5尚未正式发布，因此很可能很快会出现更多使用`async/await`语法的文档和库。为了确保您不重复他人已完成的工作，请在撰写扩展`asyncio`的代码之前彻底搜索互联网。
- en: The next chapter will explain a completely different topic—the construction
    of classes using metaclasses. Regular classes are created using the type class,
    but now we will see how we can extend and modify the default behavior to make
    a class do pretty much anything we want. Metaclasses even make it possible to
    have automatically registering plugins and add features to classes in a very magical
    way—in short, how to customize not just the class instances but the class definitions
    themselves.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将解释一个完全不同的主题-使用元类构建类。常规类是使用type类创建的，但现在我们将看到如何扩展和修改默认行为，使类几乎可以做任何我们想要的事情。元类甚至可以实现自动注册插件，并以非常神奇的方式向类添加功能-简而言之，如何定制不仅类实例而且类定义本身。
