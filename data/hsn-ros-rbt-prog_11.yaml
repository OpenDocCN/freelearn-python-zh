- en: Virtual SLAM and Navigation Using Gazebo
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Gazebo 的虚拟 SLAM 和导航
- en: In this chapter, you will be introduced to the concepts and components of robot
    navigation. Using **SLAM** (short for **Simultaneous Localization and Mapping**)
    techniques, you will be able to execute autonomous navigation with GoPiGo3. This
    chapter deals with advanced topics in simulation. Hence, it is essential that
    you have understood the concepts of the previous chapter, where we gave you the
    basics to interact with a virtual robot in Gazebo.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解机器人导航的概念和组件。通过 **SLAM**（即 **Simultaneous Localization and Mapping**）技术，您将能够使用
    GoPiGo3 执行自主导航。本章涉及模拟的高级主题。因此，您理解前一章中的概念至关重要，在那里我们向您提供了与 Gazebo 中的虚拟机器人交互的基础。
- en: SLAM is a technique used in robotics to explore and map an unknown environment
    while estimating the pose of the robot itself. As it moves all around, it will
    be acquiring structured information of the surroundings by processing the raw
    data coming from its sensors.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: SLAM 是一种在机器人中用于探索和绘制未知环境的同时估计机器人自身位姿的技术。随着它的移动，它将通过处理来自其传感器的原始数据来获取周围环境的结构化信息。
- en: You will explore this concept with a practical approach using the digital twin
    of GoPiGo3, neatly understanding why a SLAM implementation is required for proper
    navigation. The simulation will be run in Gazebo, the ROS native simulation tool
    with a physics engine that offers realistic results.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用 GoPiGo3 的数字孪生以实用的方法探索这个概念，清楚地理解为什么需要 SLAM 实现才能进行适当的导航。模拟将在 Gazebo 中运行，这是
    ROS 原生模拟工具，具有提供逼真结果的物理引擎。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Dynamic simulation using Gazebo
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Gazebo 进行动态模拟
- en: Components in navigation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导航中的组件
- en: Robot perception and SLAM
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人感知和 SLAM
- en: Practicing SLAM and navigation with GoPiGo3
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GoPiGo3 练习 SLAM 和导航
- en: By covering these topics, you will get more familiar with the Gazebo environment.
    You will understand the concepts of navigation and SLAM and how they relate to
    each other. With a very practical approach, you will learn to run SLAM and navigation
    tasks in Gazebo with a virtual model of a robot.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过涵盖这些主题，您将更加熟悉 Gazebo 环境。您将理解导航和 SLAM 的概念以及它们之间的关系。通过非常实用的方法，您将学习在 Gazebo 中使用机器人的虚拟模型运行
    SLAM 和导航任务。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To summarize and clarify the purposes of the steps that we''ll take in this
    chapter dealing with the virtual robot, and in the next chapter regarding the
    physical GoPiGo3, the following list shows all these sensors and actuators we
    are going to work with, as well as the sections of the previous chapters that
    have dealt with each one:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结和阐明本章关于虚拟机器人的步骤以及下一章关于物理 GoPiGo3 的目的，以下列表显示了我们将要使用的所有这些传感器和执行器，以及前几章中处理每个部分的章节：
- en: '**Distance sensor**: In [Chapter 6](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml), *Programming
    in ROS – Commands and Tools*, the *Case study 1: publishing and reading the distance
    sensor*section taught you how to use the distance sensor under ROS with the physical
    robot.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**距离传感器**：在[第 6 章](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml)，*在 ROS 中编程 –
    命令和工具*，*案例研究 1：发布和读取距离传感器*部分教您如何在 ROS 中使用物理机器人使用距离传感器。'
- en: '**Line follower**. See the following list for assembly and unit-testing instructions.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线跟踪器**。请参阅以下列表以获取组装和单元测试说明。'
- en: '**IMU sensor**. See the following list for assembly and unit-testing instructions.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IMU 传感器**。请参阅以下列表以获取组装和单元测试说明。'
- en: '**Pi camera**: In [Chapter 6](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml), *Programming
    in ROS – Commands and Tools*, the *Case Study 1: Publishing and reading the distance
    sensor*section taught you how to use the Pi camera under ROS with the physical
    robot.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pi 相机**：在[第 6 章](0b20bdff-f1dc-42e8-ae83-fc290da31381.xhtml)，*在 ROS 中编程 –
    命令和工具*，*案例研究 1：发布和读取距离传感器*部分教您如何在 ROS 中使用物理机器人使用 Pi 相机。'
- en: '**Drive motors and encoders**: In the previous chapter, the *Case study 3:
    Remote control using the keyboard *section taught you first how to use these items
    in ROS with the physical robot, and then how to implement a differential drive
    controller under the Gazebo simulator in ROS.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**驱动电机和编码器**：在前一章中，*案例研究 3：使用键盘进行遥控*部分首先教您如何在 ROS 中使用物理机器人使用这些项目，然后如何在 Gazebo
    模拟器下实现差分驱动控制器。'
- en: 'For all of these, you have the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有这些，您有以下内容：
- en: Assembly instructions, which can be found in the *Deep dive into the electromechanics*section of
    [Chapter 1](9bb411d1-934c-4497-aad4-7ad770d3783c.xhtml), *Assembling the Robot*
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组装说明，可以在 [第 1 章](9bb411d1-934c-4497-aad4-7ad770d3783c.xhtml) 的 *深入电机械学* 部分、*组装机器人*
    中找到
- en: Unit testing instructions, which can found in the *Unit testing of sensors and
    drives*section of [Chapter 2](7a2b1b82-c666-42df-9f10-9777eabe82df.xhtml), *Unit
    Testing of GoPiGo3*, where the provided software taught you how to deal with unit
    tests using Python
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试说明，可以在 [第 2 章](7a2b1b82-c666-42df-9f10-9777eabe82df.xhtml) 的 *单元测试传感器和驱动*
    部分、*GoPiGo3 单元测试* 中找到，其中提供的软件教您如何使用 Python 进行单元测试
- en: For optimal and easy-to-understand coverage of the topic of SLAM, we will implement
    a 360º-coverage **Laser Distance Sensor** (**LDS**)in the virtual robot. There
    are low-cost versions of this sensor technology, such as **EAI YDLIDAR X4** (available
    at[https://www.aliexpress.com/item/32908156152.html](https://es.aliexpress.com/item/32908156152.html)),
    which is the one we will make use of in the next chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对 SLAM 主题进行最佳且易于理解的覆盖，我们将在虚拟机器人中实现 360° 覆盖的 **激光测距传感器**（**LDS**）。该传感器技术有低成本版本，例如
    **EAI YDLIDAR X4**（可在 [https://www.aliexpress.com/item/32908156152.html](https://es.aliexpress.com/item/32908156152.html)
    购买），这是我们将在下一章中使用的。
- en: 'In this chapter, we will make use of the code located in the `Chapter8_Virtual_SLAM`
    folder at [https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter8_Virtual_SLAM](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter8_Virtual_SLAM).
    Copy its files to the ROS workspace to have them available, and leave the rest
    outside of the `src` folder. This way, you will have a cleaner ROS environment:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用位于 [https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter8_Virtual_SLAM](https://github.com/PacktPublishing/Hands-On-ROS-for-Robotics-Programming/tree/master/Chapter8_Virtual_SLAM)
    的 `Chapter8_Virtual_SLAM` 文件夹中的代码。将其文件复制到 ROS 工作空间以使其可用，并将其余部分放在 `src` 文件夹之外。这样，您将拥有一个更干净的
    ROS 环境：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The code contains two new ROS packages as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码包含以下两个新的 ROS 包：
- en: '`gopigo3_description`, which contains the URDF model plus the SDF (Gazebo tags)
    for a complete, dynamic simulation. This package provides the `gopigo3_rviz.launch` launch
    file to interactively visualize the model in RViz.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gopigo3_description` 包包含 URDF 模型以及用于完整、动态模拟的 SDF（Gazebo 标签）。此包提供了 `gopigo3_rviz.launch`
    启动文件，用于在 RViz 中交互式可视化模型。'
- en: '`virtual_slam` contains the virtual robot simulation itself, plus the launch
    files needed to run SLAM in Gazebo.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`virtual_slam` 包含虚拟机器人模拟本身以及运行 Gazebo 中 SLAM 所需的启动文件。'
- en: 'Then, rebuild the workspace so that it is known to your ROS installation:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，重新构建工作空间，使其为您的 ROS 安装所知：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Check that the packages have been correctly installed by selecting them and
    listing the files:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择它们并列出文件来检查包是否已正确安装：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then you need to make some installation and configuration to run the exercises,
    as follows.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您需要做一些安装和配置才能运行练习，如下所示。
- en: ROS navigation packages
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ROS 导航包
- en: 'The following steps provide the installation instructions for ROS Kinetic,
    the version running in Ubuntu 16.04:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤提供了在 Ubuntu 16.04 上运行的 ROS Kinetic 版本的安装说明：
- en: 'First, let''s prepare your machine with the required ROS packages needed for
    the navigation stack:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们准备您的机器，安装导航堆栈所需的 ROS 包：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In **ROS Kinetic**, you can install `slam_gmapping` from binaries:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **ROS Kinetic** 中，您可以从二进制文件安装 `slam_gmapping`。
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This installs the `gmapping` and `openslam_gmapping` packages. If working with
    ROS Melodic (that is, you are in Ubuntu 18.04):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装 `gmapping` 和 `openslam_gmapping` 包。如果您正在使用 ROS Melodic（即，您在 Ubuntu 18.04
    上）：
- en: 'Install the corresponding versions for Melodic:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Melodic 的相应版本：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And finally the `slam_gmapping` package, that the time of writing is already
    available in its binary version:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后是 `slam_gmapping` 包，在撰写本文时，它已经以二进制版本提供：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ROS master running on the local computer
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地计算机上运行的 ROS 主
- en: 'Since, in this chapter, you will only be using your local machine, you need
    to reconfigure the ROS master URI so that it does not point to the robot but to
    your local computer. Then, open your local `.bashrc` file and comment out the
    line at the end that specifies the URL where the ROS master can be found:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在本章中，您将只使用您的本地计算机，因此您需要重新配置 ROS 主 URI，使其不指向机器人，而是指向您的本地计算机。然后，打开您的本地 `.bashrc`
    文件，注释掉指定 ROS 主可以找到的 URL 的最后一行：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Close all Terminals, open a new one, and check the `ROS_MASTER_URI` variable:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭所有终端，打开一个新的终端，并检查 `ROS_MASTER_URI` 变量：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You should find that the environment variable has reverted to the default server
    (`localhost`) and default port (`11311`). Now, we are ready to switch to the virtual
    robot.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会发现环境变量已恢复到默认服务器（`localhost`）和默认端口（`11311`）。现在，我们准备切换到虚拟机器人。
- en: Dynamic simulation using Gazebo
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Gazebo进行动态模拟
- en: In the previous chapter, you performed a very basic version of navigation, where the
    feedback to the robot about its environment always came from you as a human operator.
    For example, you saw that GoPiGo3 is advancing to an obstacle, so you made it
    turn left or right to avoid it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你执行了一个非常基本的导航版本，其中关于机器人环境的反馈始终来自你作为人类操作员。例如，你看到GoPiGo3正在向一个障碍物前进，所以你让它向左或向右转以避开它。
- en: 'This section takes you one step forward in remote control by providing feedback
    not only from your human vision, but also from robotic sensors. More precisely,
    GoPiGo3 will provide data from the Pi camera and from its distance sensor. The
    goal is that you can teleoperate it more precisely by getting as high-quality
    sensor data as possible. You may be able to guess at least two common scenarios
    in the real world where this kind of manual teleoperation is key for the execution
    of a planned task:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本节通过提供来自你的人类视觉以及机器人传感器的反馈，使你在遥控方面前进了一步。更确切地说，GoPiGo3将提供来自Pi相机和其距离传感器的数据。目标是让你通过获取尽可能高质量的传感器数据来更精确地遥控它。你至少可以猜出在现实世界中至少两种常见的场景，这种手动遥控对于执行计划中的任务至关重要：
- en: '**Surgical robot teleoperation**: Where an expert surgeon can carry out a surgical
    operation without being present in the operating room where the patient is being
    attended to.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手术机器人遥操作**：在这种情况下，专家外科医生可以在患者被照顾的手术室外进行手术操作。'
- en: '**Teleoperated rescue robots**: This used in accidents where human cannot access
    the location on their own, such as a ravine between mountains in the occurrence
    of a flood, or disasters where direct human presence is to be avoided, for example
    in a nuclear disaster where the level of radioactivity is so high that an exposed
    human could absorb a dose of deadly radiation in a few minutes.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遥操作救援机器人**：这在人类无法自行到达的位置的事故中使用，例如洪水发生时山脉之间的峡谷，或者在需要避免直接人类存在的灾难中，例如在放射性水平如此之高以至于暴露的人类在几分钟内就会吸收致命辐射的核灾难中。'
- en: Having these keys in mind, you should understand this section not only as a
    prior learning step before entering into autonomous navigation, but also as a
    motivational introduction to a common way of working with teleoperated robots
    in the real world.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在心中牢记这些关键点，你应该不仅将这一部分视为进入自主导航之前的一个先前的学习步骤，而且还将其视为一种激励性的介绍，介绍一种在现实世界中与遥操作机器人共同工作的常见方式。
- en: Adding sensors to the GoPiGo3 model
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向GoPiGo3模型添加传感器
- en: Up to now, you should have equipped your virtual robot with a differential drive
    controller that provides the capability to convert velocity commands into rotations
    of the left and right wheels. We need to complete the model with some sort of
    perception of the environment. For this, we will add controllers for two common
    sensors, a two-dimensional camera and an LDS. The first corresponds to the Pi
    camera of your physical robot, while the second is the unidirectional distance
    sensor of the GoPiGo3 kit.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经为你的虚拟机器人配备了一个差速驱动控制器，该控制器可以将速度命令转换为左右轮的旋转。我们需要通过某种方式感知环境来完善模型。为此，我们将添加两个常见传感器的控制器，一个二维相机和一个LDS。第一个对应于你物理机器人的Pi相机，而第二个是GoPiGo3套件中的单向距离传感器。
- en: Camera model
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机模型
- en: 'You can add the solid of the camera as usual with `<visual>` tags, but since
    it is a commercial device, you can a get better look by using a realistic three-dimensional
    CAD model supplied by the manufacturer or made by someone else in the open source
    community. The URDF definition is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像往常一样使用`<visual>`标签添加相机的实体，但由于它是一个商业设备，你可以通过使用制造商提供的或开源社区中其他人制作的逼真的三维CAD模型来获得更好的外观。URDF定义如下：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can see two blocks in the preceding snippet: the `<link>` element to specify
    the solid, and the `<joint>` block to attach the camera to the robot chassis.
    Since the camera is rigidly attach to the body, we specify the `type="fixed">` to
    model such a characteristic.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在前面的片段中看到两个块：用于指定实体的`<link>`元素，以及用于将相机连接到机器人底盘的`<joint>`块。由于相机是刚性连接到身体上的，我们指定`type="fixed">`来模拟这种特性。
- en: 'Regarding the `<link>` element, we introduce the `<mesh>` tag to import the
    geometry from a CAD DAE filetype, marked in bold in the preceding snippet. The
    following screenshot shows the CAD model of the camera:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 `<link>` 元素，我们引入了 `<mesh>` 标签来导入来自 CAD DAE 文件类型的几何形状，如前文片段中加粗所示。以下截图显示了相机的
    CAD 模型：
- en: '![](img/9e760d9a-31b7-489b-888f-bdc204d1a3f7.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e760d9a-31b7-489b-888f-bdc204d1a3f7.png)'
- en: 'Then we add the camera technical features using a `<gazebo>` tag:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `<gazebo>` 标签添加相机技术特性：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `<update_rate>` tag specifies that the sensor is read at a frequency of 30
    Hz, that is, it takes 30 images per second. Finally, we add the Gazebo plugin
    that emulates the behavior of the camera. The following snippet is what substitutes
    the commented line that referred to `plugin "camera_controller"`in the preceding
    code block:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`<update_rate>` 标签指定传感器以 30 Hz 的频率读取，即每秒读取 30 张图像。最后，我们添加了模拟相机行为的 Gazebo 插件。以下片段是替换先前代码块中注释行中提到的
    `plugin "camera_controller"` 的内容：'
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The controller for the camera is in the `libgazebo_ros_camera.so` file, so what
    you provide within this block are the technical specifications of the camera you
    are using. Setting `<updateRate>` to `0.0` means that Gazebo should take the refreshment
    rate from the preceding `<sensor>` tag, that is, 30 Hz. As specified (see fields
    in bold letters), camera images will be published in the `/gopigo/camera1/image_raw` topic.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 相机控制器位于 `libgazebo_ros_camera.so` 文件中，因此你在这个块中提供的是你使用的相机的技术规格。将 `<updateRate>`
    设置为 `0.0` 表示 Gazebo 应该从先前的 `<sensor>` 标签中获取刷新率，即 30 Hz。如指定（见粗体字字段），相机图像将在 `/gopigo/camera1/image_raw`
    主题中发布。
- en: 'Launch the ROS visualization tool to check that the model is properly built.
    Since **RViz** only represents its visual features—it does not include any physical
    simulation engine—it is a much lighter environment than Gazebo and you have available
    all the options to check every aspect of the appearance of the model:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 ROS 可视化工具以检查模型是否正确构建。由于 **RViz** 只代表其视觉特征——它不包括任何物理仿真引擎——因此它比 Gazebo 轻得多，你可以使用所有选项来检查模型的每个外观方面：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This launch file is very similar to the one you used in [Chapter 4](742e6846-70e4-4bd4-8576-f3e4f445df3f.xhtml),
    *Creating the Virtual Two-Wheeled ROS Robot*. The following screenshot shows the
    result you should see:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此启动文件与你在第 4 章[创建虚拟两轮 ROS 机器人](742e6846-70e4-4bd4-8576-f3e4f445df3f.xhtml)中使用的启动文件非常相似。以下截图显示了你应该看到的成果：
- en: '![](img/752416bd-2335-4e05-ad11-39114c43716d.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/752416bd-2335-4e05-ad11-39114c43716d.png)'
- en: In the next section, you will do a practical exercise to see how the camera
    works with Gazebo.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将进行一个实际练习，以了解如何使用 Gazebo 来操作相机。
- en: Simulating the camera
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟相机
- en: 'Follow these steps for the simulation:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤进行模拟：
- en: 'Let''s first place the robot in Gazebo the same way we did in the previous
    chapter and enable remote control with the keyboard:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先以与上一章相同的方式将机器人放置在 Gazebo 中，并启用键盘远程控制：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`key_teleop` allows you to remotely control the GoPiGo3 with the arrow keys
    of your keyboard.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`key_teleop` 允许你使用键盘的箭头键远程控制 GoPiGo3。'
- en: 'Now, launch a node from the `image_view` package that comes preinstalled with
    ROS:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从预装在 ROS 中的 `image_view` 包启动一个节点：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We are remapping the `image` topic so that the node takes its data from the
    camera node topic, `/gopigo/camera1/image_raw`. This topic is defined in the preceding snippet
    of the camera controller plugin with the combination of the `<imageTopicName>`
    and
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在重新映射 `image` 主题，以便节点从相机节点主题 `/gopigo/camera1/image_raw` 获取数据。此主题在相机控制器插件的先前片段中定义，结合了
    `<imageTopicName>` 和
- en: '`<cameraInfoTopicName>` tags. Teleoperate the robot with the arrow keys and
    you will see the subjective view in the image window:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`<cameraInfoTopicName>` 标签。使用箭头键远程操作机器人，你将在图像窗口中看到主观视图：'
- en: '![](img/4d34617c-f8e6-4f0f-ae1a-e178edec74d1.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d34617c-f8e6-4f0f-ae1a-e178edec74d1.png)'
- en: The background window corresponds to Gazebo (launched from Terminal `T1`) and
    there you can see the virtual robot looking at the traffic cones. The subjective
    view is shown in the left window (`T2`), provided by the Pi camera image live
    feed using the `image_view` package. Finally, the left-bottom window (`T3`) is
    the one you need to select to be able to move the robot with the arrow keys of
    the keyboard. We have used them to place the robot in front of the traffic cones,
    as shown in the preceding screenshot.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 背景窗口对应于 Gazebo（从终端 `T1` 启动），在那里您可以看到虚拟机器人正在观察交通锥。主观视图显示在左侧窗口（`T2`），由 Pi 相机图像实时流提供，使用
    `image_view` 包。最后，左下角的窗口（`T3`）是您需要选择以能够使用键盘上的箭头键移动机器人的窗口。我们已经使用它们将机器人放置在交通锥前面，如前面的截图所示。
- en: 'At this point, let''s obtain the ROS graph with the well-known command, `rqt_graph`,
    and have a look at how the topic remapping for the image is handled:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，让我们使用众所周知的命令 `rqt_graph` 获取 ROS 图，并查看图像主题重映射是如何处理的：
- en: '![](img/93620544-f345-4af9-8041-866578548eea.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/93620544-f345-4af9-8041-866578548eea.png)'
- en: Thanks to the mapping argument, `image:=/gopigo/camera1/image_raw`, the `image`
    topic of the `image_view` package remains implicit and just the `/gopigo/camera1/image_raw`
    is visible.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢映射参数 `image:=/gopigo/camera1/image_raw`，`image_view` 包的 `image` 主题保持隐式，仅可见
    `/gopigo/camera1/image_raw`。
- en: Are you aware how quick and easy it is to deliver a robot behavior when you
    are using prebuilt ROS modules and your custom robot definition? In the next section,
    we will cover these same steps for the second sensor.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否意识到，当您使用预构建的 ROS 模块和自定义机器人定义时，交付机器人行为是多么快速和简单？在下一节中，我们将为第二个传感器介绍这些相同的步骤。
- en: Distance sensor
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 距离传感器
- en: 'We add the solid model of this sensor under the `<visual>` tag by following
    the same procedure we covered for the camera. The URDF definition is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过遵循我们之前介绍的用于摄像头的相同程序，在 `<visual>` 标签下添加此传感器的实体模型。URDF 定义如下：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see two blocks in the preceding snippet: the `<link>` element to specify
    the solid, and the `<joint>` block to attach the sensor body to the robot chassis.
    Since the distance sensor is rigidly attach to the robot chassis, we specify the `type="fixed">` to
    model this characteristic. The solid model that we are using is shown in the following
    screenshot. In this case, we use a CAD model in STL format and reference it from
    the `<mesh>` tag:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们可以看到两个块：用于指定实体的 `<link>` 元素，以及用于将传感器主体连接到机器人底盘的 `<joint>` 块。由于距离传感器是刚性连接到机器人底盘的，我们指定
    `type="fixed">` 来模拟这一特性。我们使用的实体模型如下截图所示。在这种情况下，我们使用 STL 格式的 CAD 模型，并通过 `<mesh>`
    标签引用它：
- en: '![](img/da1def45-c0f9-4659-9a4a-a0f00ab1e0aa.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/da1def45-c0f9-4659-9a4a-a0f00ab1e0aa.png)'
- en: 'We will base the sensor itself in another solid, since, if you do this with
    the solid in the preceding screenshot, you will see in Gazebo that the distance
    rays are blocked by the solid, and so the sensor will always produce a zero value
    for distance. So, we are going to explain to you a trick with which you can separate
    the solid model of the sensor from the sensing point, located at the origin of
    the link frame:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在另一个实体中基于传感器本身，因为如果您使用前面截图中的实体，您将在 Gazebo 中看到距离射线被实体阻挡，因此传感器将始终产生零距离值。所以，我们将向您解释一个技巧，通过这个技巧您可以分离传感器的实体模型和位于链接框架原点的传感点：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This snippet creates a box of 10 cm x 10 cm and place it in the coordinates
    specified by the `<joint>` tag.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段创建了一个 10 cm x 10 cm 的盒子，并将其放置在 `<joint>` 标签指定的坐标中。
- en: 'Then we add the sensor technical features using a `<gazebo>` tag, which you
    can see refers to the `distance_sensor` link defined in the preceding snippet
    (not `distance_sensor_solid`):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `<gazebo>` 标签添加传感器技术特性，您可以看到它引用了前面代码片段中定义的 `distance_sensor` 链接（不是 `distance_sensor_solid`）：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `<update_rate>` tag specifies that the sensor is read at a frequency of
    10 Hz, and the `<range>` tag sets measured distance values between 10 cm and 3
    m at 1 cm resolution.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`<update_rate>` 标签指定传感器以 10 Hz 的频率读取，而 `<range>` 标签设置测量距离值在 10 cm 到 3 m 之间，分辨率为
    1 cm。'
- en: The `<visualize>**true**</visualize>` tag block allows you to see in Gazebo
    the laser ray of the distance sensor covering the `<range>` limits explained here;
    that is, its detection coverage reaches up to 3 meters.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`<visualize>**true**</visualize>` 标签块允许您在 Gazebo 中看到距离传感器的激光射线覆盖 `<range>`
    标签中解释的极限；也就是说，其检测范围达到 3 米。'
- en: 'Finally, we add the Gazebo plugin that emulates the behavior of the distance
    sensor. The following snippet is what substitutes the commented line referring to `plugin
    "gazebo_ros_ir"`in the preceding code block:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加了模拟距离传感器行为的Gazebo插件。以下片段是替换先前代码块中注释掉的`plugin "gazebo_ros_ir"`行：
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The controller for the distance sensor is in the `libgazebo_ros_range.so` file,
    so what you provide within this block are the technical specifications of the
    sensor you are using. Setting the `<updateRate>` tag to `0.0` means that Gazebo
    should take the refreshment rate from the preceding `<sensor>` tag, that is, 10
    Hz. As specified (see fields in bold letters), range values will be published
    in the `/sensor/ir_front` topic.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 距离传感器的控制器位于`libgazebo_ros_range.so`文件中，因此您在这个块中提供的是您所使用传感器的技术规格。将`<updateRate>`标签设置为`0.0`意味着Gazebo应该从先前的`<sensor>`标签中获取刷新率，即10
    Hz。如指定（请参阅粗体字字段），范围值将在`/sensor/ir_front`主题中发布。
- en: 'Launch the ROS visualization tool to check that the model is properly built.
    Since **RViz** only represents its visual features, it is a much lighter environment
    than Gazebo and you have available all the options to check every aspect of the
    appearance of the model:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 启动ROS可视化工具以检查模型是否正确构建。由于**RViz**仅表示其视觉特征，它比Gazebo轻得多，您有所有选项来检查模型的每个外观方面：
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the following screenshot, you can see the result together with the camera
    that we included earlier:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，您可以一起看到我们之前包括的相机所得到的结果：
- en: '![](img/e9d6f056-2e71-49b1-8202-463f99b4f90f.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e9d6f056-2e71-49b1-8202-463f99b4f90f.png)'
- en: In the next section, you will do a practical exercise to see how it works with
    the distance sensor under Gazebo.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将通过实际练习看到在Gazebo下使用距离传感器的工作方式。
- en: Simulating the distance sensor
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟距离传感器
- en: 'This test includes both the distance sensor and the two-dimensional camera.
    Run the example by using four Terminals, as indicated in the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试包括距离传感器和二维相机。使用以下代码中的四个终端运行示例：
- en: '[PRE20]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following screenshot is a composed view of the result you should obtain:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的屏幕截图是您应该获得的结果的组合视图：
- en: '![](img/a86a6a72-eed5-4b33-931f-f7bc71c827da.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a86a6a72-eed5-4b33-931f-f7bc71c827da.png)'
- en: 'In the preceding screenshot, you can find the following components:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，您可以找到以下组件：
- en: The central window is the Gazebo one, where you can see GoPiGo3, an obstacle,
    and the rays of the distance sensor.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中央窗口是Gazebo窗口，您可以看到GoPiGo3、一个障碍物和距离传感器的射线。
- en: The top-left gray window is the one we need to have selected so that arrow-key
    pushes are received as `/cmd_vel` topic messages for remote control.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶部左边的灰色窗口是我们需要选择的窗口，以便箭头键的推力被接收为远程控制的`/cmd_vel`主题消息。
- en: The bottom-left black window shows in real time the messages transmitted to
    the topic of the distance sensor, that is, `/gopigo/distance_sensor`. The current
    distance to the obstacle is found in the `range` field, with a value of 1.13 m.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 底部左边的黑色窗口实时显示发送到距离传感器主题的消息，即`/gopigo/distance_sensor`。当前到障碍物的距离在`range`字段中找到，值为1.13米。
- en: The right window shows the live view seen by the robot thanks to its two-dimensional camera,
    received in the`/gopigo/camera1/image_raw` topic.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧的窗口显示了机器人通过其二维相机看到的实时视图，该视图通过`/gopigo/camera1/image_raw`主题接收。
- en: You can manually drive from one side of the scene to the other without crashing
    into any of the furniture. You plan—as a human—the optimal trajectory, and execute
    it to bring the robot to the destination goal while avoiding the obstacles. What
    you have done yourself previously is what the robot now has to do itself, performing
    as well as possible. This task is known as **navigation** and is what we are going
    to cover in the next section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以手动驾驶从场景的一侧到另一侧，而不会撞到任何家具。您作为人类规划最优路径，并执行它，将机器人带到目的地目标，同时避开障碍物。您之前所做的是机器人现在必须自己做的，尽可能好地执行。这项任务被称为**导航**，这是我们将在下一节中要讨论的内容。
- en: Components in navigation
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导航组件
- en: Navigation is the movement of a robot from the current position to a target
    location following a planned trajectory. This ability in a robot means that it
    is capable of determining its position at any point along the trajectory, as well
    as to setting up a plan of action given a representation of the environment, such
    as a map. We should also add the ability to avoid dynamic obstacles or others
    that were not present when the map was built for the first time.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 导航是机器人按照计划轨迹从当前位置移动到目标位置的过程。在机器人中，这种能力意味着它能够确定轨迹上的任何位置，以及根据环境表示（如地图）制定行动计划。我们还应该添加避免动态障碍物或第一次构建地图时未存在的其他障碍物的能力。
- en: 'There are four components to consider when building the navigation ability:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建导航能力时，需要考虑四个组成部分：
- en: A map of the environment, preexisting and given to the robot as an input, or
    built by its own means using the sensory data that it collects with its sensors.
    This whole process, that is, data acquisition plus interpretation, constitutes
    what we call the capability of robot perception. One well-known technique that
    takes advantage of robot perception is known as SLAM, as discussed earlier.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境图，预先存在并作为输入提供给机器人，或者通过其自身手段使用其传感器收集的感官数据来构建。这个过程，即数据采集加上解释，构成了我们所说的机器人感知能力。一个利用机器人感知的著名技术被称为SLAM，如前所述。
- en: Real-time pose, understood as the ability of a robot to locate itself in terms
    of position and rotation (together referred to as pose) with respect to a fixed
    frame of reference in the environment. The typical technique in robotics for obtaining
    pose is known as dead reckoning, in which the current pose is estimated relative
    to the previous one plus internal odometry data—coming from the rotary encoders
    of the motors—and IMU sensor data to reduce the error of these calculations. Both
    of them are present in the GoPiGo3.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时姿态，理解为机器人相对于环境中的固定参考系在位置和旋转（统称为姿态）方面的定位能力。在机器人技术中，用于获取姿态的典型技术被称为死 reckoning，其中当前姿态是相对于前一个姿态加上内部里程计数据（来自电机的旋转编码器）和IMU传感器数据来估计的，以减少这些计算的错误。GoPiGo3中都有这两种。
- en: Robot perception, which arises from the combination of sensor data plus its
    interpretation, making the robot aware of the objects and obstacles that are around.
    In the GoPiGo3, the sensors that contribute to perception are the distance sensor,
    the Pi camera, and the LDS.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人感知，源于传感器数据及其解释的结合，使机器人意识到周围的对象和障碍物。在GoPiGo3中，有助于感知的传感器是距离传感器、Pi相机和LDS。
- en: Path planning and execution, which includes the calculation of the optimal path
    and its execution so that the robot can achieve the target location. Since the
    map does not include all the details of the environment and there can be dynamic
    obstacles, the path planning should also be dynamic. Its algorithm will be better
    as it will be able to adapt to the varying conditions in the environment.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径规划和执行，包括计算最佳路径及其执行，以便机器人能够达到目标位置。由于地图不包含环境的所有细节，并且可能存在动态障碍物，因此路径规划也应该是动态的。其算法将越好，因为它将能够适应环境中的变化条件。
- en: Next, we will cover the costmap, a key concept on top of which navigation is
    based.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍成本图，这是导航基础上的一个关键概念。
- en: Costmaps for safe navigation
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全导航的成本图
- en: The costmap for robot navigation arises from the combination of the robot's
    pose, estimated from the odometry data (encoders) and the IMU sensor, the perception
    of objects and obstacles in the environment using the distance sensor and LDS,
    and the **occupancy grid map** (**OGM**) obtained from the SLAM technique.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人导航的成本图源于机器人姿态的结合，该姿态由里程计数据（编码器）和IMU传感器估计，以及使用距离传感器和LDS在环境中感知到的对象和障碍物，以及从SLAM技术获得的**占用栅格地图**（**OGM**）。
- en: These sources of information provide as output a joint measurement of obstacle
    areas, probable collisions, and the movable area for the robot. There is a global
    costmap and a local one. The global one accounts for the navigation path using
    the fixed map obtained through SLAM, while the local version allows the robot
    to deal with the fine-grained details of its immediate environment to move around
    obstacles and avoid collisions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息源提供障碍区域、可能的碰撞和机器人可移动区域的联合测量。存在一个全局成本图和一个局部成本图。全局成本图通过SLAM获得的固定地图来计算导航路径，而局部版本允许机器人处理其即时环境的细粒度细节，以绕过障碍物并避免碰撞。
- en: The costmap, be it local or global, is measured in a range of 8 bits, that is,
    a value from 0 to 255 in each cell of the grid occupancy map. A zero value means
    a free area, and 255 is an occupied area. Values near 255 account for collision
    areas, while intermediate values range from low collision probabilities (0-127) to
    high (128-252).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: costmap，无论是局部还是全局，都是以8位范围为测量单位，即网格占用图中的每个单元格的值从0到255。0值表示空闲区域，而255表示占用区域。接近255的值表示碰撞区域，而中间值从低碰撞概率（0-127）到高（128-252）。
- en: In the next section, we will finally deal with SLAM, the technique that is at
    the core of robot navigation. As a starting point, we will complete the setup
    of the GoPiGo3 perception capability with the integration of an LDS.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将最终处理SLAM，这是机器人导航的核心技术。作为一个起点，我们将通过集成LDS来完成GoPiGo3感知能力的设置。
- en: Robot perception and SLAM
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器人感知和SLAM
- en: The most straightforward way to implement robot navigation in ROS is by using
    an LDS that provides 360° coverage, allowing the robot to be aware of all the
    objects and obstacles around it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在ROS中实现机器人导航最直接的方法是使用提供360°覆盖范围的LDS，使机器人能够感知其周围的所有物体和障碍物。
- en: In the introduction to this chapter, we identified the **EAI YDLIDAR X4 **as
    a low-cost option that can be integrated with our physical robot. That will be
    covered in the next chapter, while in the present one we will develop its virtual
    model to be integrated in Gazebo.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的介绍中，我们确定了**EAI YDLIDAR X4**作为一个低成本选项，可以与我们的物理机器人集成。这将在下一章中介绍，而在本章中，我们将开发其虚拟模型以集成到Gazebo中。
- en: The next subsection extends the virtual GoPiGo3 that we've worked on in this
    chapter to include this very model of LDS. Afterward, we will deploy a quick SLAM
    example to get an overview of what this functionality can provide to robot navigation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个子节扩展了我们本章中工作的虚拟GoPiGo3，以包括这个特定的LDS模型。之后，我们将部署一个快速SLAM示例，以了解该功能可以为机器人导航提供哪些概述。
- en: Adding a Laser Distance Sensor (LDS)
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加激光测距传感器（LDS）
- en: 'The process to add the sensor is similar to what we did for the distance sensor
    in the previous section. Follow these steps to do it:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 添加传感器的过程与我们在上一节中为距离传感器所做的工作类似。按照以下步骤进行操作：
- en: 'We add the solid model of this sensor under the `<visual>` tag by following
    the same procedure we covered for the previous sensors. The URDF definition is
    as follows:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照之前介绍的方法，在`<visual>`标签下添加这个传感器的实体模型。URDF定义如下：
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can see two `<visual>` blocks within the `<link>` element in the preceding snippet:
    `sensor_body` is the LDS itself, and `support` creates the physical interface
    between the sensor and the robot chassis. The solid model that we are using for
    the sensor body is the one shown in the following screenshot, which consists of
    a CAD model in STL format referenced from the `<mesh>` tag:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在前面的片段中的`<link>`元素内看到两个`<visual>`块：`sensor_body`是LDS本身，而`support`创建了传感器和机器人底盘之间的物理接口。我们用于传感器主体的实体模型是以下屏幕截图所示，它由STL格式的CAD模型组成，该模型引用自`<mesh>`标签：
- en: '![](img/47254f3d-453d-4cfe-b185-c5d91356bac0.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/47254f3d-453d-4cfe-b185-c5d91356bac0.png)'
- en: 'Next, we add a `<joint>` element of `<type="fixed">` to attach the sensor assembly
    to the robot chassis:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在机器人底盘上附加传感器组件，添加一个`<joint>`元素，其`<type="fixed">`：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then we add the sensor technical features using a `<gazebo>` tag that you can
    see refers to the `distance_sensor` link defined in the preceding snippet (not `distance_sensor_solid`):'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`<gazebo>`标签添加传感器技术特性，该标签指向前面片段中定义的`distance_sensor`链接（不是`distance_sensor_solid`）：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `<range>` tag sets measured distance values between 12 cm and 10 m, as can
    be found in the technical specification of the EAI YDLIDAR X4\. Pay special attention
    to the `<visualize>true</visualize>` tag, since, with a sensor like this, with
    360º vision, the screen will be filled with rays to show the angle range that
    it covers. It is recommended to set this to `false` once you have visually checked
    that the sensor is working properly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`<range>`标签设置了从12厘米到10米的测量距离值，如EAI YDLIDAR X4的技术规范中所示。请注意`<visualize>true</visualize>`标签，因为对于这种具有360°视场的传感器，屏幕将被射线填满以显示它覆盖的角度范围。建议在视觉检查确认传感器正常工作后将其设置为`false`。'
- en: The `<visualize>true</visualize>` tag block has the same meaning and effect
    for the distance sensor, as explained in the previous section when we built its
    model, in the *Distance sensor* subsection. The only difference is that the LDS
    covers all angles with 360º coverage, tracing as many rays as the number of samples
    specified inside the `<samples>` tag.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`<visualize>true</visualize>` 标签块对于距离传感器具有与之前章节中当我们构建其模型时相同的意义和效果，在 *距离传感器*
    子节中解释过。唯一的区别是，LDS 以 360º 的覆盖范围覆盖所有角度，追踪 `<samples>` 标签内指定的样本数量那么多条射线。'
- en: 'The `<update_rate>` tag specifies that the sensor is read at a frequency of
    5 Hz, but the specification of the LDS is 5,000 Hz. Why don''t we put the actual
    value? This is for CPU usage reasons:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`<update_rate>` 标签指定传感器以 5 Hz 的频率读取，但 LDS 的规格是 5,000 Hz。我们为什么不使用实际值？这是出于 CPU
    使用率的原因：'
- en: Bear in mind that, if we set the reading frequency at its actual physical capability,
    it will take 5,000 samples per second, and each sample is a vector of 720 points.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果我们将其读取频率设置为其实际物理能力，它将每秒读取 5,000 个样本，每个样本是一个包含 720 个点的向量。
- en: Since LDS covers all possible directions, to get 720 rays evenly spaced at 0.5º,
    you have put one more sample, that is, 721, since 0º and 360º are actually the
    same angle.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 LDS 覆盖了所有可能的方向，为了得到 0.5º 均匀分布的 720 条射线，您需要多放一个样本，即 721，因为 0º 和 360º 实际上是同一个角度。
- en: Each point will be characterized by two float values (64 bits), so each sample
    needs 720 x 2 x 64 = 92160 bits = 11 Kb. Since there would be 5,000 samples, we
    would need a bandwidth of 53 Mb/s. That's a huge value to be managed by a Raspberry
    Pi CPU.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点将由两个浮点值（64 位）来表征，因此每个样本需要 720 x 2 x 64 = 92160 位 = 11 Kb。由于会有 5,000 个样本，我们需要
    53 Mb/s 的带宽。这是一个巨大的值，需要由 Raspberry Pi CPU 来管理。
- en: Since the robot will move at low speed, there is no need to have such a high-frequency reading,
    so we can limit it to only 5 Hz, which will have no impact on the robot behavior.
    This will require only 55 Kb/s of bandwidth, 1,000 times lower than what the sensor
    can provide.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器人将以低速移动，没有必要进行如此高频率的读取，因此我们可以将其限制为仅 5 Hz，这对机器人行为没有任何影响。这将只需要 55 Kb/s 的带宽，比传感器可以提供的低
    1,000 倍。
- en: This is a clear example of why you should not directly introduce the specifications
    of sensors within Gazebo, since it can impact the performance of the simulation.
    You need to critically analyze each sensor and decide what parameters to set in
    its virtual controller so that it reproduces the actual behavior well, while not
    unnecessarily overloading the CPU.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个明确的例子，说明了为什么您不应该直接在 Gazebo 中引入传感器的规格，因为它可能会影响模拟的性能。您需要批判性地分析每个传感器，并决定在它的虚拟控制器中设置哪些参数，以便它能很好地重现实际行为，同时不会不必要地过载
    CPU。
- en: 'The next step is to add the Gazebo plugin that emulates the behavior of the
    distance sensor. The following snippet is what substitutes the commented line
    referring to `plugin "gazebo_ros_lds_lfcd_controller"`in the preceding code block:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是添加模拟距离传感器行为的 Gazebo 插件。以下片段是替换前面代码块中注释的行，该行引用 `plugin "gazebo_ros_lds_lfcd_controller"`：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The controller for the distance sensor is in the `libgazebo_ros_laser_range.so`
    file, so what you provide within this block are the technical specifications of
    the sensor for which you want to override the values provided in the `<sensor>`
    tag in the preceding snippet. As specified (see fields in bold letters), the range
    values will be published in the `/gopigo/scan` topic.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 距离传感器的控制器位于 `libgazebo_ros_laser_range.so` 文件中，因此您在这个块中提供的是您想要覆盖前面片段中 `<sensor>`
    标签提供的值的传感器技术规格。如指定（请参阅粗体字母中的字段），范围值将在 `/gopigo/scan` 主题中发布。
- en: 'Finally, launch the ROS visualization tool to check that the model is properly
    built. Since RViz only represents its visual features, it is a much lighter environment
    than Gazebo and you have available all the options to check every aspect of the
    appearance of the model:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，启动 ROS 可视化工具以检查模型是否正确构建。由于 RViz 只代表其视觉特征，它比 Gazebo 轻得多，您有所有选项来检查模型的每个外观方面：
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the following screenshot, you can see the result together with the camera
    that we included earlier:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，您可以一起看到我们之前包括的相机和结果：
- en: '![](img/191d5439-d7ed-4e6e-8f3c-bd7346cdfbfc.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/191d5439-d7ed-4e6e-8f3c-bd7346cdfbfc.png)'
- en: In the next subsection, you will do a practical exercise to see how it works
    the laser distance sensor under Gazebo.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个子节中，您将进行一个实际练习，以了解在 Gazebo 下激光距离传感器是如何工作的。
- en: Simulating the LDS
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟 LDS
- en: 'After including the LDS model in the virtual robot, we can proceed to see how
    it works by running the simulation in Gazebo:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟机器人中包含LDS模型后，我们可以通过在Gazebo中运行模拟来查看它的工作情况：
- en: 'Execute the following commands in separate Terminals to see the sensor in action:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在单独的终端中执行以下命令以查看传感器的工作情况：
- en: '[PRE26]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In `T3`, you will see a large feed of data, since each `LaserScan` message contains
    720 points to cover the 360° view around the sensor.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在`T3`中，你会看到大量数据，因为每个`LaserScan`消息包含720个点来覆盖传感器周围的360°视图。
- en: 'To test this sensor, it is better to use a Python script that makes the robot
    wander in the environment while avoiding the obstacles. To do this, we have implemented
    the following rules in our script:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试这个传感器，最好使用一个Python脚本，使机器人在环境中游荡，同时避开障碍物。为此，我们在脚本中实现了以下规则：
- en: If there is no obstacle, move forward at a reference speed of 0.8 m/s.
  id: totrans-167
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有障碍物，以0.8 m/s的参考速度前进。
- en: If the range provided by the distance sensor is lower than 2 meters, go back
    and rotate counter-clockwise until avoiding the obstacle.
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果距离传感器的范围低于2米，就后退并逆时针旋转，直到避开障碍物。
- en: Since the distance sensor throws unidirectional measurements, we should check
    the measurements from the LDS to find if there are obstacles to the sides, and
    the threshold should be lower than 1.6 meters. If obstacles are detected, go back
    and rotate counter-clockwise faster to avoid the obstacle and not get stuck on
    it.
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于距离传感器提供单向测量，我们应该检查LDS的测量值，以确定是否存在侧面的障碍物，阈值应低于1.6米。如果检测到障碍物，就后退并更快地逆时针旋转，以避开障碍物，并且不要卡在它上面。
- en: This simple algorithm is implemented in the `wanderAround.py` script, and can
    be found under the `./virtual_slam/scripts/wanderAround.py` folder.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的算法在`wanderAround.py`脚本中实现，可以在`./virtual_slam/scripts/wanderAround.py`文件夹下找到。
- en: 'Now, give it a try, and enjoy watching how the GoPiGo3 goes from one side of
    the world to the other while avoiding obstacles. The sequence to run is the following:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，试一试，享受观看GoPiGo3如何从一个世界的一边游荡到另一边，同时避开障碍物。要运行的序列如下：
- en: '[PRE27]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following screenshot shows the robot wandering around:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了机器人四处游荡的情况：
- en: '![](img/75cee70f-3dd8-4cac-b221-d52f1228a2f7.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/75cee70f-3dd8-4cac-b221-d52f1228a2f7.png)'
- en: To finish this section, we will briefly cover the key concepts of the SLAM theory
    so that you know what's under the hood when we proceed in the last section of
    the chapter, covering the practical part of this implementation of robot navigation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这一部分，我们将简要介绍SLAM理论的关键概念，以便在我们进入本章最后部分，即机器人导航实现的实际部分时，你知道底下的情况。
- en: SLAM concepts
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SLAM概念
- en: 'SLAM allows the robot to build a map of the environment using the following
    two sources of information:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: SLAM允许机器人使用以下两种信息来源构建环境地图：
- en: Robot pose estimation, coming from the internal odometry (rotary encoders) and
    IMU sensor data
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人姿态估计，来源于内部里程计（旋转编码器）和IMU传感器数据
- en: Distance to objects, obstacles and walls, coming from distance sensors, the
    LDS in particular
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到物体、障碍物和墙壁的距离，来自距离传感器，特别是LDS
- en: In its most basic version, a map includes two-dimensional information, while
    in more advanced applications using industrial-grade LIDAR sensors, a richer map
    is built using three-dimensional information from LIDAR and/or from three-dimensional
    cameras. For the purpose of our learning path, we will deal with the two-dimensional
    OGM, also very common in ROS projects.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最基本版本中，地图包括二维信息，而在更高级的应用中使用工业级LIDAR传感器时，通过LIDAR和/或三维摄像头提供的三维信息构建了一个更丰富的地图。为了我们学习路径的目的，我们将处理二维OGM，这在ROS项目中也很常见。
- en: Occupancy Grid Map (OGM)
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 占位网格地图（OGM）
- en: 'Take the example of a square room with four static obstacles inside. The following
    diagram shows the map generated using SLAM in ROS (you will later learn how to
    generate it yourself):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个有四个静态障碍物的正方形房间为例。以下图显示了在ROS中使用SLAM生成的地图（你稍后会学习如何自己生成它）：
- en: '![](img/7e521a1a-e44d-40dd-a401-bda67cd033c1.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7e521a1a-e44d-40dd-a401-bda67cd033c1.png)'
- en: 'In such a two-dimensional map, the free areas and occupied areas are drawn
    in different intensities of gray in 8-bit format (0-255 range, as was already
    mentioned earlier when describing the costmaps). Then, the occupancy probability
    for each cell is obtained as the difference between 255 and the intensity value,
    divided by 255\. This means the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样的二维地图中，空闲区域和占用区域以不同的灰度强度（8位格式，0-255范围，如前面在描述成本图时已提到）绘制。然后，每个单元格的占用概率作为255与强度值的差值除以255获得。这意味着以下：
- en: White areas (255 value) give a 0% probability; that is, there is no obstacle
    in them.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 白色区域（255值）表示0%的概率；也就是说，其中没有障碍物。
- en: Black areas (0 value) give a 100% probability; that is, they are occupied.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑色区域（0值）表示100%的概率；也就是说，它们被占用。
- en: 'This probability distribution allows a costmap to be built that helps the robot
    to determine which trajectory to select to achieve the target location. When published
    to ROS, the occupancy probabilities translate into integer values between 0 (0% probability,
    that is, free space) and 100 (100%, that is, occupied space). A value of -1 is
    assigned to unknown areas. Map information is stored using two files:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这种概率分布允许构建一个成本图，帮助机器人确定选择哪个轨迹以达到目标位置。当发布到 ROS 时，占用概率转换为介于0（0%概率，即空闲空间）和100（100%，即占用空间）之间的整数值。未知区域分配值为-1。地图信息使用两个文件存储：
- en: A `.pgm` format file, known as portable graymap format.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.pgm` 格式文件，称为便携式灰度图格式。'
- en: 'A `.yaml` file containing the configuration of the map. See the following example
    of its content:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含地图配置的 `.yaml` 文件。请参阅以下内容的示例：
- en: '[PRE28]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The most interesting parameters are the last two:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的参数是最后两个：
- en: '`occupied_thresh = 0.65` means that a cell is considered as occupied if its
    probability is above 65%.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`occupied_thresh = 0.65` 意味着如果一个单元格的概率超过65%，则被认为是占用的。'
- en: '`free_thresh = 0.196` establishes the threshold value below which the cell
    is considered free, that is, 19.6%.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`free_thresh = 0.196` 确立了以下阈值值，即单元格被认为是空闲的，即19.6%。'
- en: Given the size in pixels of the image, it is straightforward to infer the physical
    dimension of the cells in the map. This value is indicated by the `resolution`
    parameter, that is, 0.01 meter/pixel.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 给定图像的像素大小，可以很容易地推断出地图中单元格的物理尺寸。此值由 `resolution` 参数指示，即 0.01 米/像素。
- en: The SLAM process
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SLAM 过程
- en: 'Building the map using a Gazebo simulation involves employing the following
    workflow:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Gazebo 模拟构建地图涉及采用以下工作流程：
- en: Launch the robot model within a modeled environment.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在建模环境中启动机器人模型。
- en: Launch the mapping ROS package.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动映射 ROS 包。
- en: Launch a special visualization in RViz that lets us see the areas the robot
    is scanning as it moves.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 RViz 中启动一个特殊的可视化，让我们看到机器人移动时扫描的区域。
- en: Teleoperate the robot to make it cover as much as possible of the surface of
    the virtual environment.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 远程操作机器人，使其尽可能覆盖虚拟环境的地表。
- en: Once the exploration is finished, save the map, generating the two files in
    the formats indicated in the preceding section, that is, `.pgm` and `.yaml`.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦探索完成，保存地图，生成前面章节中指明的格式文件，即 `.pgm` 和 `.yaml`。
- en: Having finished this information acquisition phase, we are ready for the robot
    to try and successfully complete a navigation task.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这一信息收集阶段后，我们就可以让机器人尝试并成功完成导航任务。
- en: The navigation process
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导航过程
- en: 'Once your robot has generated a map, it will use it to plan a path to a given
    target destination. The process of executing such a plan is called navigation,
    and involves the following steps:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的机器人生成了一张地图，它将使用它来规划到达指定目标位置的路程。执行此类计划的流程称为导航，涉及以下步骤：
- en: Launch the robot model within the modeled environment. This step is the same
    as the first step in the SLAM process described earlier.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在建模环境中启动机器人模型。这一步骤与前面描述的 SLAM 过程中的第一步相同。
- en: Provide the costmap that the robot built before. Bear in mind that the map is
    a characteristic of the environment, not of the robot. Hence, you can build the
    map with one robot and use the same map in navigation for any other robot you
    put in the same environment.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供机器人之前构建的成本图。请记住，地图是环境的特点，而不是机器人的特点。因此，你可以用一个机器人构建地图，并在任何其他机器人放入相同环境中进行导航时使用相同的地图。
- en: Set up the navigation algorithm. We will use the **Adaptive Monte Carlo Localization**
    (**AMCL**) algorithm, the most common choice for effective navigation. It is out
    of the scope of the book to describe such algorithms, but useful references are
    provided in the further reading section at the end of the chapter.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置导航算法。我们将使用 **自适应蒙特卡洛定位**（**AMCL**）算法，这是有效导航中最常见的选择。本书的范围不包括描述此类算法，但在本章末尾的进一步阅读部分提供了有用的参考资料。
- en: Launch a RViz visualization that will let you visualize the robot in the environment
    and easily mark the target pose (position and orientation) that it should achieve.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 RViz 可视化，这将允许你在环境中可视化机器人，并轻松标记它应达到的目标姿态（位置和方向）。
- en: Let the robot navigate autonomously to the target location. At this point, you
    can relax and enjoy watching how the GoPiGo3 drives to the indicated position
    while avoiding the obstacles and minimizing the distance it has to cover.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让机器人自主导航到目标位置。此时，你可以放松并享受观看 GoPiGo3 如何避开障碍物并尽量减少需要覆盖的距离，到达指定位置的过程。
- en: Should you want the robot to navigate to another location, you just have to
    indicate it in RViz once it has reached the previous target. Now it is time to
    see the preceding two processes—SLAM and navigation—in action. That is the scope
    of the last section of this chapter.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望机器人导航到另一个位置，只需在它到达前一个目标后，在 RViz 中指示即可。现在，是时候看到前两个过程——SLAM 和导航——的实际操作了。这正是本章最后部分的内容范围。
- en: Practising SLAM and navigation with the GoPiGo3
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GoPiGo3 练习 SLAM 和导航
- en: Like it was mentioned at the end of the previous section, we are going to run
    an end-to-end example of SLAM and navigation with GoPiGo3\. The first process
    deals with building a map of the environment using SLAM. Let's retrace the steps
    listed in the preceding section and see how to execute each of them in ROS.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一小节末尾提到的，我们将运行一个使用 GoPiGo3 的 SLAM 和导航的端到端示例。第一个过程是使用 SLAM 构建环境的地图。让我们回顾上一节中列出的步骤，并看看如何在
    ROS 中执行每个步骤。
- en: Exploring the environment to build a map using SLAM
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SLAM 探索环境以构建地图
- en: 'Let''s follow these steps to build the map of a simple Gazebo world called `stage_2.world`:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下步骤构建一个名为 `stage_2.world` 的简单 Gazebo 世界的地图：
- en: 'Launch the robot model within a modeled environment by running the following
    line of code:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码行在建模环境中启动机器人模型：
- en: '[PRE29]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This command launches Gazebo and places the GoPiGo3 model in the middle of
    it, as shown in the following screenshot:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令启动 Gazebo 并将 GoPiGo3 模型放置在其中，如下面的截图所示：
- en: '![](img/1f637221-af4b-4b01-98af-6f5bcfd49e48.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1f637221-af4b-4b01-98af-6f5bcfd49e48.png)'
- en: The environment consists of a square space with four static obstacles. The two-dimensional map
    we used in the *Occupancy Grid Map (OGM)* subsection of the previous section corresponds
    to this Gazebo world, whose filename is `stage_2.world`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 环境由一个包含四个静态障碍物的正方形空间组成。我们在上一节 *占用栅格地图（OGM）* 子节中使用过的二维地图对应于这个 Gazebo 世界，其文件名为
    `stage_2.world`。
- en: You can see that this world is by far simpler than the one we used in the first
    part of the chapter (there is an even simpler environment without the obstacles,
    named `stage_1.world`). We use this to illustrate the navigation concepts with
    a minimal setup for better understanding.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，这个世界的结构远比本章第一部分使用的那个简单（还有一个没有障碍物的更简单环境，名为 `stage_1.world`）。我们使用这个来通过最小设置说明导航概念，以便更好地理解。
- en: It is left as an exercise for the reader to repeat this process with the Gazebo
    world from the first *Dynamic simulation using Gazebo* section. To do so, just
    omit the `world` argument so that it takes the default specified within the launch
    file. The command to execute this simulation is `$ roslaunch virtual_slam gopigo3_world.launch`
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 将重复此过程作为读者的练习，使用第一部分 *使用 Gazebo 的动态模拟* 章节中的 Gazebo 世界。为此，只需省略 `world` 参数，使其采用启动文件中指定的默认值。执行此模拟的命令是
    `$ roslaunch virtual_slam gopigo3_world.launch`
- en: 'Finally, take into account that we can specify any other environment we want
    to use in Gazebo by setting the `world` parameter to the filename of the one selected
    (available worlds are located inside the `./virtual_slam/worlds` folder of the
    code of this chapter):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意，我们可以通过将 `world` 参数设置为所选环境的文件名来指定任何我们想要在 Gazebo 中使用的其他环境（可用世界位于本章代码的 `./virtual_slam/worlds`
    文件夹内）：
- en: '[PRE30]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Launch the SLAM mapping ROS package, including an RViz visualization that superimposes
    the virtual model of the robot with the actual scan data:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动SLAM映射ROS包，包括一个将机器人的虚拟模型与实际扫描数据叠加的RViz可视化：
- en: '[PRE31]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The appearance of the RViz window is shown in the following screenshot, where
    you can see together the virtual robot and the scan data (green points) in real
    time. The light-gray-colored areas are what the robot is actually perceiving with
    its LDS sensor, while the non colored areas (shadow spaces behind the obstacles)
    are not yet known by the GoPiGo3:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的屏幕截图显示了RViz窗口的外观，其中您可以实时看到虚拟机器人和扫描数据（绿色点）。浅灰色区域是机器人实际上通过其LDS传感器感知到的区域，而未着色的区域（障碍物后面的阴影空间）是GoPiGo3尚未了解的：
- en: '![](img/028c1384-3570-4e8f-891a-9e7a56253871.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/028c1384-3570-4e8f-891a-9e7a56253871.png)'
- en: In the next step, we will explore the full environment to build the map.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们将探索整个环境以构建地图。
- en: 'Teleoperate the robot to make it cover as much as possible of the surface of
    the current Gazebo world. Let''s do this as usual with the teleoperation package:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过遥控操作机器人，使其尽可能覆盖当前Gazebo世界的表面。让我们像往常一样使用遥控操作包来做这件事：
- en: '[PRE32]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As you move the robot, the LDS sensor will acquire scan data from the unknown
    areas, and you will receive feedback in the RViz window:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您移动机器人，LDS传感器将从未知区域获取扫描数据，您将在RViz窗口中收到反馈：
- en: '![](img/bf884e89-b642-45b0-9a26-11396d67ef2a.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bf884e89-b642-45b0-9a26-11396d67ef2a.png)'
- en: In the preceding screenshot, you can see that, after wandering in the environment,
    only the bottom-left part is not scanned. Then move the robot to that location,
    and, as soon as you have all the space filled with a homogeneous color (light
    gray), proceed to step 4 in order to save the map.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，您可以看到，在环境中徘徊之后，只有左下角的部分没有被扫描。然后移动机器人到那个位置，一旦所有空间都被同一种颜色（浅灰色）填满，就继续进行第4步以保存地图。
- en: 'Once you''ve finished the exploration, save the map, generating two files of
    the formats indicated in the preceding *SLAM process* subsection, that is, `.pgm` and `.yaml`:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成探索，保存地图，生成前面*SLAM过程*子节中指示的两种格式的两个文件，即，`.pgm`和`.yaml`：
- en: '[PRE33]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You will get two files in the root folder of your workspace: `map_stage_2.pgm`
    and `map_stage_2.yaml`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在工作空间根目录中获得两个文件：`map_stage_2.pgm`和`map_stage_2.yaml`。
- en: The appearance of the generated map is shown in the preceding *Occupancy Grid
    Map (OGM)* subsection.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的地图的外观在前面*占用栅格地图（OGM）*子节中显示。
- en: Provided with the map, we are ready to perform robot navigation with the GoPiGo3.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了地图，我们就可以使用GoPiGo3进行机器人导航了。
- en: Driving along a planned trajectory using navigation
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用导航沿计划轨迹行驶
- en: 'First, close all open Terminals. Then, as in the SLAM process, let''s proceed
    step by step to perform some navigation:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，关闭所有打开的终端。然后，就像在SLAM过程中一样，让我们一步一步地进行一些导航：
- en: 'Launch the robot model within the modeled environment. This step is the same
    as the first step in the SLAM process:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在建模环境中启动机器人模型。这一步与SLAM过程中的第一步相同：
- en: '[PRE34]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Set up the navigation algorithm and launch RViz. We will use AMCL, the most
    common choice for effective navigation. It is out of the scope of the book to
    describe such algorithm, but you are provided with useful references in the* Further
    reading *section at the end of the chapter.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置导航算法并启动RViz。我们将使用AMCL，这是最常用的有效导航选择。本书的范围不包括描述此类算法，但您可以在章节末尾的*进一步阅读*部分找到有用的参考资料。
- en: 'In this step, we also provide the costmap that the robot built before. To do
    this, you just have to reference the `.yaml` map file you created before. Make
    sure that the corresponding `.pgm` file has the same name and is placed in the
    same location. This point is specified in the `roslaunch` command through the
    `map_file` argument:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，我们还提供了机器人之前构建的成本图。为此，您只需参考之前创建的`.yaml`地图文件。确保相应的`.pgm`文件具有相同的名称，并且放置在同一位置。这一点在`roslaunch`命令中通过`map_file`参数指定：
- en: '[PRE35]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The RViz window, shown in the following screenshot, lets you visualize the
    robot in the environment and mark the target pose (position and orientation) that
    it should achieve:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下面的屏幕截图显示了RViz窗口，它让您可视化环境中的机器人并标记它应该达到的目标姿态（位置和方向）：
- en: '![](img/50a5ea86-a012-47f8-b2f8-f2dec49c6eaa.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/50a5ea86-a012-47f8-b2f8-f2dec49c6eaa.png)'
- en: Find the 2D Nav Goal button at the top-right of the RViz window. You will use
    it to mark the target location to which the robot should navigate.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在RViz窗口的右上角找到2D Nav Goal按钮。您将使用它来标记机器人应该导航的目标位置。
- en: First of all, you have to tell the robot that this is the initial pose by pressing
    the **2D Pose Estimate **button. Then, mark it on screen (in this particular case,
    it isn't necessary, since the initial pose is the same as the one the robot had
    when it started to build the map in the preceding subsection).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您必须通过按下**2D 姿态估计**按钮告诉机器人这是初始姿态。然后，在屏幕上标记它（在这个特定情况下，这是不必要的，因为初始姿态与机器人在前一小节开始构建地图时的姿态相同）。
- en: 'Afterward, you can press **2D Nav Goal** button and set the target to the *bottom-left
    corner* by clicking the left mouse button. Release the mouse when the arrow has
    the desired orientation. After releasing, the robot will compute the path to follow
    and start navigating autonomously:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您可以按下**2D 导航目标**按钮，通过点击左鼠标按钮将目标设置为*左下角*。当箭头达到所需方向时释放鼠标。释放后，机器人将计算要遵循的路径并开始自主导航：
- en: '![](img/0bb18a70-d0d2-40ba-8653-1d4807050717.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0bb18a70-d0d2-40ba-8653-1d4807050717.png)'
- en: The preceding screenshot shows the first instant of the navigation plan execution.
    The orientation of the red arrow tells the GoPiGo3 in what direction it should
    stay facing once it has arrived at the target, and the curved line going from
    the robot to the target is the planned path. Since it has a map of the environment
    available, the robot is able to plan a path that avoids the obstacles. Wait a
    few seconds and you will see how the robot reaches the target without any external
    help.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图显示了导航计划执行的第一瞬间。红色箭头的方向告诉GoPiGo3到达目标后应该朝哪个方向保持面对，从机器人到目标的曲线线是计划路径。由于它有环境地图，机器人能够规划一条避开障碍物的路径。等待几秒钟，您将看到机器人如何在没有外部帮助的情况下到达目标。
- en: 'Once the robot has arrived, press the **2D Nav Goal** button again and then
    mark the top-right corner. The following screenshot shows the first instant of
    the execution of the next navigation plan:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦机器人到达，再次按下**2D 导航目标**按钮，然后标记右上角。以下截图显示了下一个导航计划的执行第一瞬间：
- en: '![](img/d094c479-4c53-4f8a-be7b-78af194f3844.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d094c479-4c53-4f8a-be7b-78af194f3844.png)'
- en: You can see the new planned path and how this takes into account the presence
    of obstacles along the way to avoid collisions. The blue square around the robot
    represents the local window for obstacle avoidance planning. This is used by the
    **Dynamic Window Approach** (**DWA**) method, which generates a local path that
    efficiently evades the obstacles. The DWA method performs the calculations taking
    into account the robot's dynamics, in particular, its limited velocity and acceleration.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到新的计划路径以及它是如何考虑沿途障碍物的存在以避免碰撞的。机器人周围的蓝色方块代表障碍物避障规划的局部窗口。这是由**动态窗口方法**（**DWA**）方法使用的，该方法生成一个能够有效避开障碍物的局部路径。DWA方法在考虑机器人的动力学时进行计算，特别是其有限的速度和加速度。
- en: The AMCL algorithm for robot navigation generates the global path to reach the
    target based on the provided map, while the DWA method calculates the local path that
    accounts for the local conditions the robot may find near it. The latter provides
    the capability to deal both with obstacles present in the map, and also dynamic
    ones, such as people crossing the robot's path, for example. The *global path*
    and *local path* combine together to produce *highly autonomous robot navigation*.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人导航的AMCL算法根据提供的地图生成到达目标的全局路径，而DWA方法计算考虑机器人可能在其附近遇到的局部条件的局部路径。后者提供了处理地图中存在的障碍物以及动态障碍物的能力，例如行人穿越机器人的路径。*全局路径*和*局部路径*结合在一起产生*高度自主的机器人导航*。
- en: 'The following screenshot shows the GoPiGo3 in the final instant before reaching
    the goal. Appreciate how, at this point, the DWA window also includes the target:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了GoPiGo3在到达目标前的最后瞬间。欣赏一下，在这个点上，DWA窗口也包含了目标：
- en: '![](img/26c3de76-b819-42f1-a2bc-fd0c6d5d478f.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/26c3de76-b819-42f1-a2bc-fd0c6d5d478f.png)'
- en: 'Finally, you should frame robot navigation within a sequence of tasks that
    the robot has to complete, one after the other, in order to achieve the goal that
    has been set by the user. Taking the examples of the navigation paths that we
    have used already in this chapter for explanation purposes, imagine a scenario
    in which the GoPiGo3 has to pick up an object in location *A* (the left-bottom
    corner) and deliver it to location *B* (the upper-right corner). In this case,
    the sequence of tasks would be as follows:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你应该将机器人导航框架在一系列任务中，这些任务是机器人必须依次完成，以实现用户设定的目标。以本章中用于解释目的的导航路径为例，想象一个场景，其中
    GoPiGo3 必须在位置 *A*（左下角）拾起一个物体，并将其运送到位置 *B*（右上角）。在这种情况下，任务序列如下：
- en: Navigate to location *A*.
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到位置 *A*。
- en: Pick up the piece at location *A*.
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在位置 *A* 拾起物品。
- en: Navigate to location *B*.
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到位置 *B*。
- en: Drop off the piece at location *B*.
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在位置 *B* 放下物品。
- en: Conceptually, it is easy, right? But in this chapter, we have only covered the
    basics to accomplish tasks 1 and 3\. Later, in [Chapter 10](3bf944de-e0f8-4e78-a38b-47796c91185b.xhtml),
    *Applying Machine Learning in Robotics*, you will be given the technical background
    on **object recognition** so that you can also program tasks 2 and 4\. More precisely,
    it will be in the *A methodology to programmatically apply ML in Robotics *section where
    we will provide you with this insight.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，这很容易，对吧？但在本章中，我们只涵盖了完成任务 1 和 3 的基础知识。稍后，在 [第 10 章](3bf944de-e0f8-4e78-a38b-47796c91185b.xhtml)
    “在机器人学中应用机器学习”中，你将获得关于**目标识别**的技术背景，以便你也能编程任务 2 和 4。更确切地说，它将在 *“在机器人学中程序化应用机器学习的方法论”*
    部分提供这一见解。
- en: Summary
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has introduced you to the master task of robot navigation. SLAM
    and navigation are complex matters and active research topics in robotics. So,
    this chapter has given you a taste of how to implement it so that you can quickly
    understand its mechanics without entering into details of the algorithms and the
    mathematics behind.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向你介绍了机器人导航的主要任务。SLAM 和导航是机器人学中的复杂问题，也是活跃的研究课题。因此，本章为你提供了如何实现它的初步了解，以便你能够快速理解其原理，而不必深入了解算法和背后的数学。
- en: We expect to have aroused your curiosity on this topic. Now you are prepared
    to carry out the same task in the real world with the physical GoPiGo3\. In the
    next chapter, you will perform the navigation and SLAM tasks with the physical
    robot.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望已经激起了你对这个主题的好奇心。现在你已准备好在现实世界中用物理 GoPiGo3 执行相同的任务。在下一章中，你将使用物理机器人执行导航和 SLAM
    任务。
- en: Questions
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Where are the sensor specifications included within a Gazebo SDF file?
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传感器规格在 Gazebo SDF 文件中包含在哪里？
- en: A) Outside of a `<gazebo>` tag
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: A) 在 `<gazebo>` 标签外
- en: B) Within a `<joint>` tag
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: B) 在 `<joint>` 标签内
- en: C) Within a `<sensor>` tag
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: C) 在 `<sensor>` 标签内
- en: Regarding the controller specification of a sensor in Gazebo, what is the most
    relevant parameter in terms of CPU usage while running the simulation?
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于在 Gazebo 中传感器控制器的规格，在运行模拟时，哪个参数与 CPU 使用率最相关？
- en: A) The scan distance, because the larger the sensor range is, the more bandwidth
    consumption the CPU performs.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: A) 扫描距离，因为传感器范围越大，CPU 执行的带宽消耗就越多。
- en: B) The angular scan, since the greater the angular resolution, the more bandwidth
    consumption is required to store the readings in the RAM.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: B) 角度扫描，因为角度分辨率越高，存储读取数据在 RAM 中所需的带宽消耗就越大。
- en: C) The maximum sensor frequency, because they are so high in real sensors that
    they easily can overload the CPU.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: C) 传感器的最大频率，因为它们在真实传感器中非常高，很容易超载 CPU。
- en: Where are the sensor mechanical properties included within a Gazebo description
    of the robot?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传感器的机械属性在 Gazebo 机器人描述中包含在哪里？
- en: A) Outside of a `<gazebo>` tag
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: A) 在 `<gazebo>` 标签外
- en: B) Within a `<joint>` tag
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: B) 在 `<joint>` 标签内
- en: C) Within a `<sensor>` tag
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: C) 在 `<sensor>` 标签内
- en: What does the SLAM technique provide to a robot?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SLAM 技术为机器人提供了什么？
- en: A) A method to avoid moving obstacles in the environment
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: A) 避免环境中移动障碍物的方法
- en: B) A method to build a map of the environment
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: B) 建立环境地图的方法
- en: C) A method to avoid static and moving obstacles in the environment
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: C) 避免环境中静态和移动障碍物的方法
- en: How do you operationally specify a navigation goal to a robot?
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何操作性地指定导航目标给机器人？
- en: A) Tell it the target location and orientation
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: A) 告诉它目标位置和方向
- en: B) Set a target location in a two-dimensional map of the environment
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: B) 在环境的二维地图中设置目标位置
- en: C) Mark the borders of the area where the robot is expected to navigate to
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: C) 标记机器人预期导航到的区域边界
- en: Further reading
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To delve deeper into the concepts explained in this chapter, you can check
    out the following references:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解本章中解释的概念，你可以查阅以下参考资料：
- en: Adaptive Monte Carlo Localization (AMCL), at [http://roboticsknowledgebase.com/wiki/state-estimation/adaptive-monte-carlo-localization/](http://roboticsknowledgebase.com/wiki/state-estimation/adaptive-monte-carlo-localization/)
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自适应蒙特卡洛定位（AMCL），见[http://roboticsknowledgebase.com/wiki/state-estimation/adaptive-monte-carlo-localization/](http://roboticsknowledgebase.com/wiki/state-estimation/adaptive-monte-carlo-localization/)
- en: '*Particle Filters in Robotics*, Proceedings of Uncertainty in AI (UAI), Thrun
    S. (2002), at [http://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf](http://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf)'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器人中的粒子滤波*，人工智能不确定性（UAI）会议论文集，Thrun S. (2002)，见[http://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf](http://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf)'
- en: '*SLAM for Dummies*, A Tutorial Approach to Simultaneous Localization and Mapping,
    Riisgaard S, at [http://zyzx.haust.edu.cn/moocresource/data/081503/U/802/pdfs/soren_project.pdf](http://zyzx.haust.edu.cn/moocresource/data/081503/U/802/pdfs/soren_project.pdf)'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SLAM傻瓜指南*，同时定位与建图教程，Riisgaard S，见[http://zyzx.haust.edu.cn/moocresource/data/081503/U/802/pdfs/soren_project.pdf](http://zyzx.haust.edu.cn/moocresource/data/081503/U/802/pdfs/soren_project.pdf)'
- en: '*Robot Perception for Indoor Navigation*, Endres, F. (2015), Albert-Ludwigs-Universitat
    Freiburg, at[ https://d-nb.info/1119716993/34](https://d-nb.info/1119716993/34)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*室内导航中的机器人感知*，Endres, F. (2015)，弗莱堡阿尔伯特-路德维希大学，见[ https://d-nb.info/1119716993/34](https://d-nb.info/1119716993/34)'
