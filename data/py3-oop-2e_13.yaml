- en: Chapter 13. Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章。并发
- en: Concurrency is the art of making a computer do (or appear to do) multiple things
    at once. Historically, this meant inviting the processor to switch between different
    tasks many times per second. In modern systems, it can also literally mean doing
    two or more things simultaneously on separate processor cores.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 并发是让计算机同时做（或看起来同时做）多件事情的艺术。在历史上，这意味着处理器每秒钟要在不同的任务之间切换多次。在现代系统中，它也可以字面意思上同时在不同的处理器核心上执行两个或更多的任务。
- en: 'Concurrency is not inherently an object-oriented topic, but Python''s concurrent
    systems are built on top of the object-oriented constructs we''ve covered throughout
    the book. This chapter will introduce you to the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 并发本质上不是一个面向对象的主题，但Python的并发系统是建立在我们在整本书中介绍的面向对象构造之上的。本章将向您介绍以下主题：
- en: Threads
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程
- en: Multiprocessing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多处理
- en: Futures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来
- en: AsyncIO
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步IO
- en: Concurrency is complicated. The basic concepts are fairly simple, but the bugs
    that can occur are notoriously difficult to track down. However, for many projects,
    concurrency is the only way to get the performance we need. Imagine if a web server
    couldn't respond to a user's request until the previous one was completed! We
    won't be going into all the details of just how hard it is (another full book
    would be required) but we'll see how to do basic concurrency in Python, and some
    of the most common pitfalls to avoid.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 并发是复杂的。基本概念相当简单，但可能发生的错误却极其难以追踪。然而，对于许多项目来说，并发是获得所需性能的唯一途径。想象一下，如果一个Web服务器在前一个请求完成之前无法响应用户的请求！我们不会详细讨论它有多难（需要另一本完整的书），但我们将看到如何在Python中进行基本的并发，以及一些常见的要避免的陷阱。
- en: Threads
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程
- en: Most often, concurrency is created so that work can continue happening while
    the program is waiting for I/O to happen. For example, a server can start processing
    a new network request while it waits for data from a previous request to arrive.
    An interactive program might render an animation or perform a calculation while
    waiting for the user to press a key. Bear in mind that while a person can type
    more than 500 characters per minute, a computer can perform billions of instructions
    per second. Thus, a ton of processing can happen between individual key presses,
    even when typing quickly.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的情况是，通过并发可以让程序在等待I/O时继续进行工作。例如，服务器可以在等待前一个请求的数据到达时开始处理新的网络请求。交互式程序可能在等待用户按键时渲染动画或进行计算。请记住，尽管一个人每分钟可以输入超过500个字符，但计算机每秒可以执行数十亿条指令。因此，即使输入速度很快，也可以在按键之间进行大量处理。
- en: 'It''s theoretically possible to manage all this switching between activities
    within your program, but it would be virtually impossible to get right. Instead,
    we can rely on Python and the operating system to take care of the tricky switching
    part, while we create objects that appear to be running independently, but simultaneously.
    These objects are called **threads**; in Python they have a very simple API. Let''s
    take a look at a basic example:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在理论上，可能会在程序内部管理所有这些活动之间的切换，但要正确地做到这一点几乎是不可能的。相反，我们可以依赖Python和操作系统来处理棘手的切换部分，同时创建看起来是独立运行但同时运行的对象。这些对象称为**线程**；在Python中，它们有一个非常简单的API。让我们看一个基本的例子：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This example runs two threads. Can you see them? Every program has one thread,
    called the main thread. The code that executes from the beginning is happening
    in this thread. The second thread, more obviously, exists as the `InputReader`
    class.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子运行了两个线程。你能看到它们吗？每个程序都有一个线程，称为主线程。从一开始执行的代码都是在这个线程中进行的。第二个线程更明显，存在于`InputReader`类中。
- en: To construct a thread, we must extend the `Thread` class and implement the `run`
    method. Any code inside the `run` method (or that is called from within that method)
    is executed in a separate thread.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个线程，我们必须扩展`Thread`类并实现`run`方法。`run`方法内的任何代码（或在该方法内调用的代码）都将在一个单独的线程中执行。
- en: The new thread doesn't start running until we call the `start()` method on the
    object. In this case, the thread immediately pauses to wait for input from the
    keyboard. In the meantime, the original thread continues executing at the point
    `start` was called. It starts calculating squares inside a `while` loop. The condition
    in the `while` loop checks if the `InputReader` thread has exited its `run` method
    yet; once it does, it outputs some summary information to the screen.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 新线程直到我们在对象上调用`start()`方法时才开始运行。在这种情况下，线程立即暂停等待键盘输入。与此同时，原始线程继续执行`start`被调用的地方。它在`while`循环内开始计算平方。`while`循环中的条件检查`InputReader`线程是否已经退出了它的`run`方法；一旦它退出，就会向屏幕输出一些摘要信息。
- en: 'If we run the example and type the string "hello world", the output looks as
    follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行示例并输入字符串"hello world"，输出如下：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will, of course, calculate more or less squares while typing the string
    as the numbers are related to both our relative typing speeds, and to the processor
    speeds of the computers we are running.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，当我们输入字符串时，计算的平方数会更多或更少，这些数字与我们相对打字速度以及我们运行的计算机的处理器速度有关。
- en: 'A thread only starts running in concurrent mode when we call the `start` method.
    If we want to take out the concurrent call to see how it compares, we can call
    `thread.run()` in the place that we originally called `thread.start()`. The output
    is telling:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当我们调用`start`方法时，线程才以并发模式开始运行。如果我们想要去掉并发调用以查看它的比较，我们可以在原来调用`thread.start()`的地方调用`thread.run()`。输出如下：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this case, the thread never becomes alive and the `while` loop never executes.
    We wasted a lot of CPU power sitting idle while we were typing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，线程永远不会变得活跃，`while`循环也永远不会执行。在我们输入时，浪费了大量的CPU资源。
- en: 'There are a lot of different patterns for using threads effectively. We won''t
    be covering all of them, but we will look at a common one so we can learn about
    the `join` method. Let''s check the current temperature in the capital city of
    every province in Canada:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程有效的方法有很多不同的模式。我们不会覆盖所有这些模式，但我们将看一个常见的模式，以便学习`join`方法。让我们检查加拿大每个省的首府城市的当前温度：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code constructs 10 threads before starting them. Notice how we can override
    the constructor to pass them into the `Thread` object, remembering to call `super`
    to ensure the `Thread` is properly initialized. Pay attention to this: the new
    thread isn''t running yet, so the `__init__` method is still executing from inside
    the main thread. Data we construct in one thread is accessible from other running
    threads.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在启动线程之前构造了10个线程。注意我们如何覆盖构造函数以将它们传递到`Thread`对象中，记得调用`super`以确保`Thread`被正确初始化。请注意：新线程还没有运行，因此`__init__`方法仍然是从主线程内部执行的。我们在一个线程中构造的数据可以从其他运行的线程中访问。
- en: After the 10 threads have been started, we loop over them again, calling the
    `join()` method on each. This method essentially says "wait for the thread to
    complete before doing anything". We call this ten times in sequence; the for loop
    won't exit until all ten threads have completed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动了10个线程之后，我们再次循环遍历它们，对每个线程调用`join()`方法。这个方法基本上是说“在做任何事情之前等待线程完成”。我们按顺序调用这个方法十次；在所有十个线程完成之前，for循环不会退出。
- en: At this point, we can print the temperature that was stored on each thread object.
    Notice once again that we can access data that was constructed within the thread
    from the main thread. In threads, all state is shared by default.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以打印存储在每个线程对象上的温度。再次注意，我们可以从主线程访问在线程内部构造的数据。在线程中，默认情况下所有状态都是共享的。
- en: 'Executing this code on my 100 mbit connection takes about two tenths of a second:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的100兆比特连接上执行这段代码大约需要0.2秒：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If we run this code in a single thread (by changing the `start()` call to `run()`
    and commenting out the `join()` call), it takes closer to 2 seconds because each
    0.2 second request has to complete before the next one begins. This speedup of
    10 times shows just how useful concurrent programming can be.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在单个线程中运行此代码（通过将`start()`调用更改为`run()`并注释掉`join()`调用），那么它需要接近2秒，因为每个0.2秒的请求必须在下一个请求开始之前完成。这种10倍的加速显示了并发编程有多么有用。
- en: The many problems with threads
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程的许多问题
- en: Threads can be useful, especially in other programming languages, but modern
    Python programmers tend to avoid them for several reasons. As we'll see, there
    are other ways to do concurrent programming that are receiving more attention
    from the Python developers. Let's discuss some of these pitfalls before moving
    on to more salient topics.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 线程可以是有用的，特别是在其他编程语言中，但现代Python程序员倾向于避免它们，原因有几个。正如我们将看到的，有其他方法可以进行并发编程，这些方法正在得到Python开发人员的更多关注。在继续讨论更重要的话题之前，让我们先讨论一些这些陷阱。
- en: Shared memory
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 共享内存
- en: The main problem with threads is also their primary advantage. Threads have
    access to all the memory and thus all the variables in the program. This can too
    easily cause inconsistencies in the program state. Have you ever encountered a
    room where a single light has two switches and two different people turn them
    on at the same time? Each person (thread) expects their action to turn the lamp
    (a variable) on, but the resulting value (the lamp is off) is inconsistent with
    those expectations. Now imagine if those two threads were transferring funds between
    bank accounts or managing the cruise control in a vehicle.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的主要问题也是它们的主要优势。线程可以访问程序中的所有内存和变量。这很容易导致程序状态的不一致。你是否遇到过一个房间里有一个灯有两个开关，两个不同的人同时打开它们的情况？每个人（线程）都希望他们的动作打开灯（一个变量），但结果值（灯是关闭的）与这些期望是不一致的。现在想象一下，如果这两个线程正在银行账户之间转账或管理车辆的巡航控制。
- en: The solution to this problem in threaded programming is to "synchronize" access
    to any code that reads or writes a shared variable. There are a few different
    ways to do this, but we won't go into them here so we can focus on more Pythonic
    constructs. The synchronization solution works, but it is way too easy to forget
    to apply it. Worse, bugs due to inappropriate use of synchronization are really
    hard to track down because the order in which threads perform operations is inconsistent.
    We can't easily reproduce the error. Usually, it is safest to force communication
    between threads to happen using a lightweight data structure that already uses
    locks appropriately. Python offers the `queue.Queue` class to do this; it's functionality
    is basically the same as the `multiprocessing.Queue` that we will discuss in the
    next section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程编程中解决这个问题的方法是“同步”访问任何读取或写入共享变量的代码。有几种不同的方法可以做到这一点，但我们不会在这里讨论它们，这样我们就可以专注于更具Python风格的构造。同步解决方案有效，但很容易忘记应用它。更糟糕的是，由于不适当使用同步而导致的错误很难追踪，因为线程执行操作的顺序是不一致的。我们无法轻松地重现错误。通常，最安全的做法是强制线程之间的通信使用已经适当使用锁的轻量级数据结构。Python提供了`queue.Queue`类来实现这一点；它的功能基本上与我们将在下一节讨论的`multiprocessing.Queue`相同。
- en: 'In some cases, these disadvantages might be outweighed by the one advantage
    of allowing shared memory: it''s fast. If multiple threads need access to a huge
    data structure, shared memory can provide that access quickly. However, this advantage
    is usually nullified by the fact that, in Python, it is impossible for two threads
    running on different CPU cores to be performing calculations at exactly the same
    time. This brings us to our second problem with threads.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这些缺点可能被允许共享内存的一个优点所抵消：它很快。如果多个线程需要访问一个巨大的数据结构，共享内存可以快速提供访问。然而，这个优点通常被Python中的一个事实所抵消，即在不同CPU核心上运行的两个线程不可能在完全相同的时间进行计算。这就带我们来到了线程的第二个问题。
- en: The global interpreter lock
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全局解释器锁
- en: 'In order to efficiently manage memory, garbage collection, and calls to machine
    code in libraries, Python has a utility called the **global interpreter lock**,
    or **GIL**. It''s impossible to turn off, and it means that threads are useless
    in Python for one thing that they excel at in other languages: parallel processing.
    The GIL''s primary effect, for our purposes is to prevent any two threads from
    doing work at the exact same time, even if they have work to do. In this case,
    "doing work" means using the CPU, so it''s perfectly ok for multiple threads to
    access the disk or network; the GIL is released as soon as the thread starts to
    wait for something.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地管理内存、垃圾回收和对库中机器代码的调用，Python有一个叫做**全局解释器锁**或**GIL**的实用程序。它是不可能关闭的，这意味着在Python中，线程对于其他语言中它们擅长的一件事情：并行处理是无用的。对于我们的目的来说，GIL的主要影响是防止任何两个线程在完全相同的时间做工作，即使它们有工作要做。在这种情况下，“做工作”意味着使用CPU，因此多个线程访问磁盘或网络是完全可以的；一旦线程开始等待某些东西，GIL就会被释放。
- en: The GIL is quite highly disparaged, mostly by people who don't understand what
    it is or all the benefits it brings to Python. It would definitely be nice if
    our language didn't have this restriction, but the Python reference developers
    have determined that, for now at least, it brings more value than it costs. It
    makes the reference implementation easier to maintain and develop, and during
    the single-core processor days when Python was originally developed, it actually
    made the interpreter faster. The net result of the GIL, however, is that it limits
    the benefits that threads bring us, without alleviating the costs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: GIL受到了相当大的诋毁，主要是因为一些人不理解它是什么，或者它给Python带来的所有好处。如果我们的语言没有这个限制，那肯定会很好，但Python参考开发人员已经确定，至少目前来说，它带来的价值比成本更高。它使参考实现更容易维护和开发，在Python最初开发时是单核处理器的时代，它实际上使解释器更快。然而，GIL的最终结果是它限制了线程给我们带来的好处，而没有减轻成本。
- en: Note
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: While the GIL is a problem in the reference implementation of Python that most
    people use, it has been solved in some of the nonstandard implementations such
    as IronPython and Jython. Unfortunately, at the time of publication, none of these
    support Python 3.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GIL是大多数人使用的Python参考实现中的一个问题，但在一些非标准实现中（如IronPython和Jython）已经解决了这个问题。不幸的是，在出版时，这些都不支持Python
    3。
- en: Thread overhead
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程开销
- en: One final limitation of threads as compared to the asynchronous system we will
    be discussing later is the cost of maintaining the thread. Each thread takes up
    a certain amount of memory (both in the Python process and the operating system
    kernel) to record the state of that thread. Switching between the threads also
    uses a (small) amount of CPU time. This work happens seamlessly without any extra
    coding (we just have to call `start()` and the rest is taken care of), but the
    work still has tohappen somewhere.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们将在后面讨论的异步系统相比，线程的最后一个限制是维护线程的成本。每个线程占用一定量的内存（在Python进程和操作系统内核中），以记录该线程的状态。在线程之间切换也会使用（少量的）CPU时间。这项工作是无缝进行的，无需额外编码（我们只需要调用`start()`，剩下的就会被处理），但这项工作仍然需要在某个地方进行。
- en: This can be alleviated somewhat by structuring our workload so that threads
    can be reused to perform multiple jobs. Python provides a `ThreadPool` feature
    to handle this. It is shipped as part of the multiprocessing library and behaves
    identically to the `ProcessPool`, that we will discuss shortly, so let's defer
    discussion until the next section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构造我们的工作负载，使得线程可以被重用来执行多个任务，这可以在一定程度上缓解。Python提供了一个`ThreadPool`功能来处理这个问题。它作为多进程库的一部分提供，并且与我们将在下一节讨论的`ProcessPool`行为相同，因此让我们推迟讨论到下一节。
- en: Multiprocessing
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程
- en: The multiprocessing API was originally designed to mimic the thread API. However,
    it has evolved and in recent versions of Python 3, it supports more features more
    robustly. The multiprocessing library is designed when CPU-intensive jobs need
    to happen in parallel and multiple cores are available (given that a four core
    Raspberry Pi can currently be purchased for $35, there are usually multiple cores
    available). Multiprocessing is not useful when the processes spend a majority
    of their time waiting on I/O (for example, network, disk, database, or keyboard),
    but they are the way to go for parallel computation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程API最初设计是为了模仿线程API。然而，它已经发展，并且在最近的Python 3版本中，它更加稳健地支持更多功能。多进程库是为了在需要并行进行CPU密集型作业并且有多个核心可用时设计的（鉴于四核的树莓派目前可以以35美元的价格购买，通常有多个核心可用）。多进程在进程大部分时间花在I/O等待上时并不有用（例如网络、磁盘、数据库或键盘），但对于并行计算来说是最佳选择。
- en: The multiprocessing module spins up new operating system processes to do the
    work. On Windows machines, this is a relatively expensive operation; on Linux,
    processes are implemented in the kernel the same way threads are, so the overhead
    is limited to the cost of running separate Python interpreters in each process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程模块会启动新的操作系统进程来执行工作。在Windows机器上，这是一个相对昂贵的操作；在Linux上，进程和线程一样是在内核中实现的，因此开销仅限于在每个进程中运行单独的Python解释器的成本。
- en: 'Let''s try to parallelize a compute-heavy operation using similar constructs
    to those provided by the `threading` API:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用类似于`threading` API提供的构造来并行化一个计算密集型操作：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This example just ties up the CPU for 200 million iterations. You may not consider
    this to be useful work, but it's a cold day and I appreciate the heat my laptop
    generates under such load.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是让CPU进行2亿次迭代。你可能不认为这是有用的工作，但是在寒冷的天气下，我很感激我的笔记本在这样的负载下产生的热量。
- en: The API should be familiar; we implement a subclass of `Process` (instead of
    `Thread`) and implement a `run` method. This method prints out the process ID
    (a unique number the operating system assigns to each process on the machine)
    before doing some intense (if misguided) work.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: API应该是熟悉的；我们实现`Process`的子类（而不是`Thread`）并实现一个`run`方法。这个方法在做一些密集的（如果是误导的）工作之前打印出进程ID（操作系统为机器上的每个进程分配的唯一编号）。
- en: Pay special attention to the `if __name__ == '__main__':` guard around the module
    level code that prevents it to run if the module is being imported, rather than
    run as a program. This is good practice in general, but when using multiprocessing
    on some operating systems, it is essential. Behind the scenes, multiprocessing
    may have to import the module inside the new process in order to execute the `run()`
    method. If we allowed the entire module to execute at that point, it would start
    creating new processes recursively until the operating system ran out of resources.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 特别注意`if __name__ == '__main__':`的保护，它围绕在模块级别的代码周围，防止其在被导入时运行，而不是作为程序运行。这在一般情况下是一个好的做法，但在某些操作系统上使用多进程时，这是必不可少的。在幕后，多进程可能必须在新进程中导入模块以执行`run()`方法。如果我们允许整个模块在那一点上执行，它将开始递归地创建新进程，直到操作系统耗尽资源。
- en: 'We construct one process for each processor core on our machine, then start
    and join each of those processes. On my 2014 era quad-core laptop, the output
    looks like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为机器上的每个处理器核心构建一个进程，然后启动和加入每个进程。在我2014年的四核笔记本上，输出如下：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The first four lines are the process ID that was printed inside each `MuchCPU`
    instance. The last line shows that the 200 million iterations can run in about
    13 seconds on my machine. During that 13 seconds, my process monitor indicated
    that all four of my cores were running at 100 percent.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 前四行是在每个`MuchCPU`实例内打印的进程ID。最后一行显示，2亿次迭代在我的机器上大约需要13秒。在这13秒内，我的进程监视器显示我的四个核心都在以100%的速度运行。
- en: 'If we subclass `threading.Thread` instead of `multiprocessing.Process` in `MuchCPU`,
    the output looks like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在`MuchCPU`中使用`threading.Thread`而不是`multiprocessing.Process`进行子类化，输出如下：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This time, the four threads are running inside the same process and take close
    to three times as long to run. This is the cost of the global interpreter lock;
    in other languages or implementations of Python, the threaded version would run
    at least as fast as the multiprocessing version, We might expect it to be four
    times as long, but remember that many other programs are running on my laptop.
    In the multiprocessing version, these programs also need a share of the four CPUs.
    In the threading version, those programs can use the other three CPUs instead.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，四个线程在同一个进程内运行，需要的时间接近三倍。这是全局解释器锁的成本；在其他语言或Python的其他实现中，线程版本的运行速度至少与多进程版本一样快。我们可能期望它需要四倍的时间，但请记住，我的笔记本上还有许多其他程序在运行。在多进程版本中，这些程序也需要使用四个CPU的一部分。在线程版本中，这些程序可以使用其他三个CPU。
- en: Multiprocessing pools
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多进程池
- en: 'In general, there is no reason to have more processes than there are processors
    on the computer. There are a few reasons for this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，没有理由在计算机上有更多的进程数。这样做有几个原因：
- en: Only `cpu_count()` processes can run simultaneously
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有`cpu_count()`个进程可以同时运行
- en: Each process consumes resources with a full copy of the Python interpreter
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个进程都会消耗资源，拥有完整的Python解释器的副本
- en: Communication between processes is expensive
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程之间的通信是昂贵的
- en: Creating processes takes a nonzero amount of time
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建进程需要一定的时间
- en: Given these constraints, it makes sense to create at most `cpu_count()` processes
    when the program starts and then have them execute tasks as needed. It is not
    difficult to implement a basic series of communicating processes that does this,
    but it can be tricky to debug, test, and get right. Of course, Python being Python,
    we don't have to do all this work because the Python developers have already done
    it for us in the form of multiprocessing pools.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些限制，当程序启动时，最多创建`cpu_count()`个进程，然后让它们根据需要执行任务是有意义的。实现一个基本的通信进程系列并不难，但调试、测试和正确执行可能会有些棘手。当然，由于Python是Python，我们不必做所有这些工作，因为Python开发人员已经在多进程池的形式中为我们做了这些工作。
- en: The primary advantage of pools is that they abstract away the overhead of figuring
    out what code is executing in the main process and which code is running in the
    subprocess. As with the threading API that multiprocessing mimics, it can often
    be hard to remember who is executing what. The pool abstraction restricts the
    number of places that code in different processes interact with each other, making
    it much easier to keep track of.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 池的主要优势在于它们抽象了在主进程中执行的代码和在子进程中执行的代码的开销。与模仿多线程API的多进程一样，很难记住谁在执行什么。池的抽象限制了不同进程中的代码相互交互的位置数量，使得跟踪变得更加容易。
- en: 'Pools also seamlessly hide the process of passing data between processes. Using
    a pool looks much like a function call; you pass data into a function, it is executed
    in another process or processes, and when the work is done, a value is returned.
    It is important to understand that under the hood, a lot of work is being done
    to support this: objects in one process are being pickled and passed into a pipe.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池还可以无缝隐藏进程之间传递数据的过程。使用池看起来很像一个函数调用；你将数据传递给一个函数，它在另一个进程或进程中执行，当工作完成时，会返回一个值。重要的是要理解，在幕后，有很多工作在支持这一点：一个进程中的对象被序列化并传递到管道中。
- en: Another process retrieves data from the pipe and unpickles it. Work is done
    in the subprocess and a result is produced. The result is pickled and passed into
    a pipe. Eventually, the original process unpickles it and returns it.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个进程从管道中检索数据并对其进行反序列化。工作在子进程中完成并产生结果。结果被序列化并传入管道。最终，原始进程对其进行反序列化并返回。
- en: All this pickling and passing data into pipes takes time and memory. Therefore,
    it is ideal to keep the amount and size of data passed into and returned from
    the pool to a minimum, and it is only advantageous to use the pool if a lot of
    processing has to be done on the data in question.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些序列化和将数据传递到管道都需要时间和内存。因此，最好将传入和返回池的数据量和大小保持在最小限度，并且只有在需要对所讨论的数据进行大量处理时才有利于使用池。
- en: 'Armed with this knowledge, the code to make all this machinery work is surprisingly
    simple. Let''s look at the problem of calculating all the prime factors of a list
    of random numbers. This is a common and expensive part of a variety of cryptography
    algorithms (not to mention attacks on those algorithms!). It requires years of
    processing power to crack the extremely large numbers used to secure your bank
    accounts. The following implementation, while readable, is not at all efficient,
    but that''s ok because we want to see it using lots of CPU time:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这些知识后，使所有这些机制工作的代码出人意料地简单。让我们来看看计算一系列随机数的所有质因数的问题。这是各种加密算法（更不用说对这些算法的攻击！）中常见且昂贵的部分。破解用于保护您的银行账户的极大数字需要多年的处理能力。以下的实现虽然可读，但并不高效，但这没关系，因为我们想看到它使用大量的CPU时间：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let's focus on the parallel processing aspects as the brute force recursive
    algorithm for calculating factors is pretty clear. We first construct a multiprocessing
    pool instance. By default, this pool creates a separate process for each of the
    CPU cores in the machine it is running on.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把注意力集中在并行处理方面，因为用于计算因子的蛮力递归算法非常清晰。我们首先构建一个多进程池实例。默认情况下，该池为其运行的机器上的每个CPU核心创建一个单独的进程。
- en: The `map` method accepts a function and an iterable. The pool pickles each of
    the values in the iterable and passes it into an available process, which executes
    the function on it. When that process is finished doing it's work, it pickles
    the resulting list of factors and passes it back to the pool. Once all the pools
    are finished processing work (which could take some time), the results list is
    passed back to the original process, which has been waiting patiently for all
    this work to complete.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`map`方法接受一个函数和一个可迭代对象。池对可迭代对象中的每个值进行pickling，并将其传递给一个可用的进程，该进程对其执行函数。当该进程完成其工作时，它对结果因子的列表进行pickling，并将其传递回池。一旦所有的池都完成了处理工作（这可能需要一些时间），结果列表就会传递回原始进程，该进程一直在耐心地等待所有这些工作的完成。'
- en: It is often more useful to use the similar `map_async` method, which returns
    immediately even though the processes are still working. In that case, the results
    variable would not be a list of values, but a promise to return a list of values
    later by calling `results.get()`. This promise object also has methods like `ready()`,
    and `wait()`, which allow us to check whether all the results are in yet.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常更有用的是使用类似的`map_async`方法，即使进程仍在工作，它也会立即返回。在这种情况下，结果变量不会是一个值的列表，而是通过调用`results.get()`来返回一个值的列表的承诺。这个承诺对象还有`ready()`和`wait()`等方法，允许我们检查是否所有的结果都已经出来了。
- en: Alternatively, if we don't know all the values we want to get results for in
    advance, we can use the `apply_async` method to queue up a single job. If the
    pool has a process that isn't already working, it will start immediately; otherwise,
    it will hold onto the task until there is a free process available.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们事先不知道要获取结果的所有值，我们可以使用`apply_async`方法来排队一个单独的作业。如果池中有一个尚未工作的进程，它将立即启动；否则，它将保留任务，直到有一个可用的进程。
- en: Pools can also be `close`d, which refuses to take any further tasks, but processes
    everything currently in the queue, or `terminate`d, which goes one step further
    and refuses to start any jobs still on the queue, although any jobs currently
    running are still permitted to complete.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 池也可以被`close`，拒绝接受任何进一步的任务，但处理当前队列中的所有任务；或者被`terminate`，进一步拒绝启动队列中仍在进行的任何作业，尽管当前正在运行的作业仍被允许完成。
- en: Queues
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 队列
- en: If we need more control over communication between processes, we can use a `Queue`.
    `Queue` data structures are useful for sending messages from one process into
    one or more other processes. Any picklable object can be sent into a `Queue`,
    but remember that pickling can be a costly operation, so keep such objects small.
    To illustrate queues, let's build a little search engine for text content that
    stores all relevant entries in memory.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要更多控制进程之间的通信，我们可以使用`Queue`。`Queue`数据结构对于将消息从一个进程发送到一个或多个其他进程非常有用。任何可被picklable的对象都可以被发送到`Queue`中，但要记住pickling可能是一个昂贵的操作，所以要保持这些对象小。为了说明队列，让我们构建一个存储所有相关条目的文本内容的小型搜索引擎。
- en: This is not the most sensible way to build a text-based search engine, but I
    have used this pattern to query numerical data that needed to use CPU-intensive
    processes to construct a chart that was then rendered to the user.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是构建基于文本的搜索引擎的最明智的方法，但我已经使用这种模式来查询需要使用CPU密集型进程来构建然后呈现给用户的图表的数值数据。
- en: 'This particular search engine scans all files in the current directory in parallel.
    A process is constructed for each core on the CPU. Each of these is instructed
    to load some of the files into memory. Let''s look at the function that does the
    loading and searching:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的搜索引擎并行扫描当前目录中的所有文件。为CPU上的每个核心构建一个进程。每个进程都被指示将一些文件加载到内存中。让我们来看看执行加载和搜索的函数：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Remember, this function is run in a different process (in fact, it is run in
    `cpucount()` different processes) from the main thread. It is passes a list of
    `path.path` objects and two `multiprocessing.Queue` objects; one for incoming
    queries and one to send outgoing results. These queues have a similar interface
    to the `Queue` class we discussed in [Chapter 6](ch06.html "Chapter 6. Python
    Data Structures"), *Python Data Structures*. However, they are doing extra work
    to pickle the data in the queue and pass it into the subprocess over a pipe. These
    two queues are set up in the main process and passed through the pipes into the
    search function inside the child processes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个函数是在一个不同的进程中运行的（实际上，它是在`cpucount()`个不同的进程中运行的），而不是在主线程中。它传递了一个`path.path`对象的列表和两个`multiprocessing.Queue`对象；一个用于传入查询，一个用于发送输出结果。这些队列具有与我们在[第6章](ch06.html
    "第6章。Python数据结构")中讨论的`Queue`类类似的接口，*Python数据结构*。但是，它们正在额外工作，对队列中的数据进行pickling，并通过管道传递到子进程中。这两个队列在主进程中设置，并通过管道传递到子进程中的搜索函数。
- en: The search code is pretty dumb, both in terms of efficiency and of capabilities;
    it loops over every line stored in memory and puts the matching ones in a list.
    The list is placed on a queue and passed back to the main process.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索代码在效率和功能方面都相当愚蠢；它循环遍历存储在内存中的每一行，并将匹配的行放入列表中。然后将列表放入队列并传回主进程。
- en: 'Let''s look at the main process, which sets up these queues:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看设置这些队列的主要进程：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For easier description, let's assume `cpu_count` is four. Notice how the import
    statements are placed inside the `if` guard? This is a small optimization that
    prevents them from being imported in each subprocess (where they aren't needed)
    on certain operating systems. We list all the paths in the current directory and
    then split the list into four approximately equal parts. We also construct a list
    of four `Queue` objects to send data into each subprocess. Finally, we construct
    a `single` results queue; this is passed into all four of the subprocesses. Each
    of them can put data into the queue and it will be aggregated in the main process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易描述，让我们假设`cpu_count`是四。注意导入语句是如何放置在`if`保护内的？这是一个小优化，可以防止它们在某些操作系统上被导入到每个子进程中（在那里它们是不需要的）。我们列出当前目录中的所有路径，然后将列表分成大约相等的四部分。我们还构建了一个包含四个`Queue`对象的列表，以便将数据发送到每个子进程中。最后，我们构建了一个`single`结果队列；这个队列传递给了所有四个子进程。它们每个都可以将数据放入队列中，并且在主进程中进行聚合。
- en: 'Now let''s look at the code that makes a search actually happen:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看实际进行搜索的代码：
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code performs a single search for `"def"` (because it's a common phrase
    in a directory full of Python files!). In a more production ready system, we would
    probably hook a socket up to this search code. In that case, we'd have to change
    the inter-process protocol so that the message coming back on the return queue
    contained enough information to identify which of many queries the results were
    attached to.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码执行了一次对“def”进行搜索（因为这是一个充满Python文件的目录中的常见短语！）。在一个更适合生产的系统中，我们可能会将一个套接字连接到这个搜索代码。在这种情况下，我们必须改变进程间协议，以便返回队列上的消息包含足够的信息来识别结果附加到哪个查询中的许多查询之一。
- en: This use of queues is actually a local version of what could become a distributed
    system. Imagine if the searches were being sent out to multiple computers and
    then recombined. We won't discuss it here, but the multiprocessing module includes
    a manager class that can take a lot of the boilerplate out of the preceding code.
    There is even a version of the `multiprocessing.Manager` that can manage subprocesses
    on remote systems to construct a rudimentary distributed application. Check the
    Python multiprocessing documentation if you are interested in pursuing this further.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这种使用队列的方式实际上是一个可能成为分布式系统的本地版本。想象一下，如果搜索被发送到多台计算机然后重新组合。我们不会在这里讨论，但多进程模块包括一个管理器类，可以消除前面代码中的大量样板。甚至有一个`multiprocessing.Manager`的版本，可以管理远程系统上的子进程，构建一个基本的分布式应用程序。如果你有兴趣进一步探索，请查看Python多进程文档。
- en: The problems with multiprocessing
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多进程的问题
- en: As threads do, multiprocessing also has problems, some of which we have already
    discussed. There is no best way to do concurrency; this is especially true in
    Python. We always need to examine the parallel problem to figure out which of
    the many available solutions is the best one for that problem. Sometimes, there
    is no best solution.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程一样，多进程也存在一些问题，其中一些我们已经讨论过。并发没有最佳的方式；在Python中尤其如此。我们总是需要检查并行问题，以找出哪种可用的解决方案是最适合该问题的。有时，没有最佳解决方案。
- en: In the case of multiprocessing, the primary drawback is that sharing data between
    processes is very costly. As we have discussed, all communication between processes,
    whether by queues, pipes, or a more implicit mechanism requires pickling the objects.
    Excessive pickling quickly dominates processing time. Multiprocessing works best
    when relatively small objects are passed between processes and a tremendous amount
    of work needs to be done on each one. On the other hand, if no communication between
    processes is required, there may not be any point in using the module at all;
    we can spin up four separate Python processes and use them independently.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在多进程的情况下，主要的缺点是在进程之间共享数据非常昂贵。正如我们所讨论的，所有进程之间的通信，无论是通过队列、管道还是更隐式的机制，都需要对对象进行pickling。过多的pickling很快就会占据处理时间。多进程在相对较小的对象之间传递，并且需要对每个对象进行大量的工作时效果最好。另一方面，如果进程之间不需要通信，也许根本没有必要使用该模块；我们可以启动四个独立的Python进程并独立使用它们。
- en: The other major problem with multiprocessing is that, like threads, it can be
    hard to tell which process a variable or method is being accessed in. In multiprocessing,
    if you access a variable from another process it will usually overwrite the variable
    in the currently running process while the other process keeps the old value.
    This is really confusing to maintain, so don't do it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程的另一个主要问题是，与线程一样，很难确定变量或方法是在哪个进程中被访问的。在多进程中，如果你从另一个进程中访问一个变量，它通常会覆盖当前运行进程中的变量，而另一个进程会保留旧值。这真的很难维护，所以不要这样做。
- en: Futures
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Futures
- en: Let's start looking at a more asynchronous way of doing concurrency. Futures
    wrap either multiprocessing or threading depending on what kind of concurrency
    we need (tending towards I/O versus tending towards CPU). They don't completely
    solve the problem of accidentally altering shared state, but they allow us to
    structure our code such that it is easier to track down when we do so. Futures
    provide distinct boundaries between the different threads or processes. Similar
    to the multiprocessing pool, they are useful for "call and answer" type interactions
    in which processing can happen in another thread and then at some point in the
    future (they are aptly named, after all), you can ask it for the result. It's
    really just a wrapper around multiprocessing pools and thread pools, but it provides
    a cleaner API and encourages nicer code.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始以更多异步的方式进行并发。未来包装了多进程或多线程，取决于我们需要的并发类型（倾向于I/O与倾向于CPU）。它们并不能完全解决意外改变共享状态的问题，但它们允许我们构造我们的代码，使得更容易追踪我们这样做的情况。未来为不同的线程或进程提供了明确的边界。与多进程池类似，它们对于“呼叫和回答”类型的交互非常有用，其中处理可以在另一个线程中进行，然后在将来的某个时候（毕竟，它们的名字很贴切），您可以要求它返回结果。它实际上只是多进程池和线程池的一个包装器，但它提供了一个更清晰的API，并鼓励更好的代码。
- en: A future is an object that basically wraps a function call. That function call
    is run in the background in a thread or process. The future object has methods
    to check if the future has completed and to get the results after it has completed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 未来是一个基本上包装函数调用的对象。该函数调用在后台在一个线程或进程中运行。未来对象有方法来检查未来是否已经完成，并在完成后获取结果。
- en: 'Let''s do another file search example. In the last section, we implemented
    a version of the `unix grep` command. This time, let''s do a simple version of
    the `find` command. The example will search the entire filesystem for paths that
    contain a given string of characters:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再做一个文件搜索的例子。在上一节中，我们实现了`unix grep`命令的一个版本。这一次，让我们做一个`find`命令的简单版本。这个例子将在整个文件系统中搜索包含给定字符的路径：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code consists of a function named `find_files` that is run in a separate
    thread (or process, if we used `ProcessPoolExecutor`). There isn't anything particularly
    special about this function, but note how it does not access any global variables.
    All interaction with the external environment is passed into the function or returned
    from it. This is not a technical requirement, but it is the best way to keep your
    brain inside your skull when programming with futures.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码包括一个名为`find_files`的函数，该函数在一个单独的线程（或进程，如果我们使用`ProcessPoolExecutor`）中运行。这个函数没有什么特别的地方，但请注意它没有访问任何全局变量。与外部环境的所有交互都被传递到函数中或从函数中返回。这不是技术要求，但在使用未来时，这是保持大脑在头脑中的最佳方式。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Accessing outside variables without proper synchronization results in something
    called a **race** condition. For example, imagine two concurrent writes trying
    to increment an integer counter. They start at the same time and both read the
    value as 5\. Then they both increment the value and write back the result as 6\.
    But if two processes are trying to increment a variable, the expected result would
    be that it gets incremented by two, so the result should be 7\. Modern wisdom
    is that the easiest way to avoid doing this is to keep as much state as possible
    private and share them through known-safe constructs, such as queues.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有适当同步的情况下访问外部变量会导致一种称为**竞争**条件的情况。例如，想象两个并发写入尝试增加一个整数计数器。它们同时开始并且都将值读取为5。然后它们都增加了值并将结果写回为6。但是如果两个进程都尝试增加一个变量，预期的结果应该是它增加了两次，所以结果应该是7。现代智慧认为避免这样做的最简单方法是尽可能保持尽可能多的状态私有，并通过已知安全的构造来共享它们，比如队列。
- en: We set up a couple variables before we get started; we'll be searching for all
    files that contain the characters `'.py'` for this example. We have a queue of
    futures that we'll discuss shortly. The `basedir` variable points to the root
    of the filesystem; `'/'` on Unix machines and probably `C:\` on Windows.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们设置了一些变量；在这个例子中，我们将搜索包含字符`'.py'`的所有文件。我们有一个将会讨论的未来队列。`basedir`变量指向文件系统的根目录；在Unix机器上是`'/'`，在Windows上可能是`C:\`。
- en: First, let's have a short course on search theory. This algorithm implements
    breadth first search in parallel. Rather than recursively searching every directory
    using a depth first search, it adds all the subdirectories in the current folder
    to the queue, then all the subdirectories of each of those folders and so on.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们简要介绍一下搜索理论。这个算法实现了并行的广度优先搜索。它不是使用深度优先搜索递归地搜索每个目录，而是将当前文件夹的所有子目录添加到队列中，然后再添加每个文件夹的所有子目录，依此类推。
- en: The meat of the program is known as an event loop. We can construct a `ThreadPoolExecutor`
    as a context manager so that it is automatically cleaned up and its threads closed
    when it is done. It requires a `max_workers` argument to indicate the number of
    threads running at a time; if more than this many jobs are submitted, it queues
    up the rest until a worker thread becomes available. When using `ProcessPoolExecutor`,
    this is normally constrained to the number of CPUs on the machine, but with threads,
    it can be much higher, depending how many are waiting on I/O at a time. Each thread
    takes up a certain amount of memory, so it shouldn't be too high; it doesn't take
    all that many threads before the speed of the disk, rather than number of parallel
    requests, is the bottleneck.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的核心部分称为事件循环。我们可以构建一个`ThreadPoolExecutor`作为上下文管理器，这样当它完成时，它会自动清理并关闭其线程。它需要一个`max_workers`参数来指示同时运行的线程数；如果提交的作业超过这么多，它会排队等待，直到有一个工作线程可用。当使用`ProcessPoolExecutor`时，这通常受限于机器上的CPU数量，但使用线程时，它可以更高，取决于同时等待I/O的数量。每个线程占用一定量的内存，所以它不应该太高；在磁盘的速度而不是并行请求的数量之前，不需要太多的线程成为瓶颈。
- en: Once the executor has been constructed, we submit a job to it using the root
    directory. The `submit()` method immediately returns a `Future` object, which
    promises to give us a result eventually. The future is placed on the queue. The
    loop then repeatedly removes the first future from the queue and inspects it.
    If it is still running, it gets added back to the end of the queue. Otherwise,
    we check if the function raised an exception with a call to `future.exception()`.
    If it did, we just ignore it (it's usually a permission error, although a real
    app would need to be more careful about what the exception was). If we didn't
    check this exception here, it would be raised when we called `result()` and could
    be handled through the normal `try`...`except` mechanism.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行器被构建，我们使用根目录向其提交一个作业。`submit()`方法立即返回一个`Future`对象，该对象承诺最终给我们一个结果。未来被放置在队列中。然后循环从队列中重复删除第一个未来并检查它。如果它仍在运行，它会被添加回队列的末尾。否则，我们检查函数是否通过调用`future.exception()`引发了异常。如果是，我们就忽略它（通常是权限错误，尽管真正的应用程序需要更小心地处理异常是什么）。如果我们没有在这里检查异常，那么当我们调用`result()`时，它将被引发，并且可以通过正常的`try`...`except`机制处理。
- en: Assuming no exception occurred, we can call `result()` to get the return value
    of the function call. Since the function returns a list of subdirectories that
    are not symbolic links (my lazy way of preventing an infinite loop), `result()`
    returns the same thing. These new subdirectories are submitted to the executor
    and the resulting futures are tossed onto the queue to have their contents searched
    in a later iteration.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 假设没有发生异常，我们可以调用`result()`来获取函数调用的返回值。由于该函数返回一个不是符号链接的子目录列表（我懒惰地防止无限循环），`result()`返回相同的结果。这些新的子目录被提交给执行器，并且生成的未来被抛到队列中，在以后的迭代中搜索它们的内容。
- en: So that's all that is required to develop a future-based I/O-bound application.
    Under the hood, it's using the same thread or process APIs we've already discussed,
    but it provides a more understandable interface and makes it easier to see the
    boundaries between concurrently running functions (just don't try to access global
    variables from inside the future!).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是开发基于未来的I/O绑定应用程序所需的全部内容。在底层，它使用了我们已经讨论过的相同的线程或进程API，但它提供了一个更易理解的接口，并且更容易看到并发运行函数之间的边界（只是不要试图从未来中访问全局变量！）。
- en: AsyncIO
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步IO
- en: AsyncIO is the current state of the art in Python concurrent programming. It
    combines the concept of futures and an event loop with the coroutines we discussed
    in [Chapter 9](ch09.html "Chapter 9. The Iterator Pattern"), *The Iterator Pattern*.
    The result is about as elegant and easy to understand as it is possible to get
    when writing concurrent code, though that isn't saying a lot!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 异步IO是Python并发编程的最新技术。它将未来的概念和事件循环与我们在[第9章](ch09.html "第9章. 迭代器模式")中讨论的协程结合起来。结果是写并发代码时尽可能优雅和易于理解，尽管这并不是说很多！
- en: AsyncIO can be used for a few different concurrent tasks, but it was specifically
    designed for network I/O. Most networking applications, especially on the server
    side, spend a lot of time waiting for data to come in from the network. This can
    be solved by handling each client in a separate thread, but threads use up memory
    and other resources. AsyncIO uses coroutines instead of threads.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 异步IO可以用于一些不同的并发任务，但它专门设计用于网络I/O。大多数网络应用程序，特别是在服务器端，花费大量时间等待来自网络的数据。这可以通过在单独的线程中处理每个客户端来解决，但线程会占用内存和其他资源。异步IO使用协程而不是线程。
- en: The library also provides its own event loop, obviating the need for the several
    lines long while loop in the previous example. However, event loops come with
    a cost. When we run code in an async task on the event loop, that code must return
    immediately, blocking neither on I/O nor on long-running calculations. This is
    a minor thing when writing our own code, but it means that any standard library
    or third-party functions that block on I/O have to have non-blocking versions
    created.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 该库还提供了自己的事件循环，消除了前面示例中几行长的while循环的需要。然而，事件循环是有代价的。当我们在事件循环中的异步任务中运行代码时，该代码必须立即返回，既不阻塞I/O，也不阻塞长时间运行的计算。这在编写我们自己的代码时是一个小事情，但这意味着任何标准库或第三方函数在I/O上阻塞时必须创建非阻塞版本。
- en: AsyncIO solves this by creating a set of coroutines that use the `yield from`
    syntax to return control to the event loop immediately. The event loop takes care
    of checking whether the blocking call has completed and performing any subsequent
    tasks, just like we did manually in the previous section.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 异步IO通过创建一组协程来解决这个问题，这些协程使用`yield from`语法立即将控制返回给事件循环。事件循环负责检查阻塞调用是否已经完成，并执行任何后续任务，就像我们在上一节中手动做的那样。
- en: AsyncIO in action
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步IO的实际应用
- en: 'A canonical example of a blocking function is the `time.sleep` call. Let''s
    use the asynchronous version of this call to illustrate the basics of an AsyncIO
    event loop:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的阻塞函数的例子是`time.sleep`调用。让我们使用这个调用的异步版本来说明异步IO事件循环的基础知识：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is a fairly basic example, but it covers several features of AsyncIO programming.
    It is easiest to understand in the order that it executes, which is more or less
    bottom to top.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当基本的例子，但涵盖了异步IO编程的几个特点。最容易理解的顺序是从底部到顶部。
- en: The second last line gets the event loop and instructs it to run a future until
    it is finished. The future in question is named `five_sleepers`. Once that future
    has done its work, the loop will exit and our code will terminate. As asynchronous
    programmers, we don't need to know too much about what happens inside that `run_until_complete`
    call, but be aware that a lot is going on. It's a souped up coroutine version
    of the futures loop we wrote in the previous chapter that knows how to deal with
    iteration, exceptions, function returns, parallel calls, and more.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 倒数第二行获取事件循环并指示它运行一个future直到完成。所讨论的future名为`five_sleepers`。一旦该future完成了它的工作，循环将退出，我们的代码将终止。作为异步程序员，我们不需要太了解`run_until_complete`调用内部发生了什么，但要知道有很多事情正在进行。它是我们在上一章中编写的futures循环的升级版本，它知道如何处理迭代、异常、函数返回、并行调用等。
- en: Now look a little more closely at that `five_sleepers` future. Ignore the decorator
    for a few paragraphs; we'll get back to it. The coroutine first constructs five
    instances of the `random_sleep` future. The resulting futures are wrapped in an
    `asyncio.async` task, which adds them to the loop's task queue so they can execute
    concurrently when control is returned to the event loop.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在更仔细地看一下`five_sleepers` future。在接下来的几段中忽略装饰器；我们会回到它。协程首先构造了五个`random_sleep`
    future的实例。生成的futures被包装在`asyncio.async`任务中，将它们添加到循环的任务队列中，以便在控制权返回到事件循环时可以并发执行。
- en: That control is returned whenever we call `yield from`. In this case, we call
    `yield from asyncio.sleep` to pause execution of this coroutine for two seconds.
    During this break, the event loop executes the tasks that it has queued up; namely
    the five `random_sleep` futures. These coroutines each print a starting message,
    then send control back to the event loop for a specific amount of time. If any
    of the sleep calls inside `random_sleep` are shorter than two seconds, the event
    loop passes control back into the relevant future, which prints its awakening
    message before returning. When the sleep call inside `five_sleepers` wakes up,
    it executes up to the next yield from call, which waits for the remaining `random_sleep`
    tasks to complete. When all the sleep calls have finished executing, the `random_sleep`
    tasks return, which removes them from the event queue. Once all five of those
    are completed, the `asyncio.wait` call and then the `five_sleepers` method also
    return. Finally, since the event queue is now empty, the `run_until_complete`
    call is able to terminate and the program ends.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们调用`yield from`时，控制权就会被返回。在这种情况下，我们调用`yield from asyncio.sleep`来暂停此协程的执行两秒钟。在这段时间内，事件循环执行了它排队的任务；即五个`random_sleep`
    futures。这些协程每个都打印一个开始消息，然后将控制权发送回事件循环，持续一定的时间。如果`random_sleep`中的任何睡眠调用短于两秒，事件循环将控制权传递回相关的future，在返回之前打印它的唤醒消息。当`five_sleepers`中的睡眠调用醒来时，它执行到下一个`yield
    from`调用，等待其余的`random_sleep`任务完成。当所有的睡眠调用都执行完毕时，`random_sleep`任务返回，将它们从事件队列中移除。一旦这五个任务都完成了，`asyncio.wait`调用和`five_sleepers`方法也会返回。最后，由于事件队列现在为空，`run_until_complete`调用能够终止，程序结束。
- en: The `asyncio.coroutine` decorator mostly just documents that this coroutine
    is meant to be used as a future in an event loop. In this case, the program would
    run just fine without the decorator. However, the `asyncio.coroutine` decorator
    can also be used to wrap a normal function (one that doesn't yield) so that it
    can be treated as a future. In this case, the entire function executes before
    returning control to the event loop; the decorator just forces the function to
    fulfill the coroutine API so the event loop knows how to handle it.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.coroutine`装饰器主要是说明这个协程是要在事件循环中作为future使用的。在这种情况下，程序即使没有装饰器也能正常运行。然而，`asyncio.coroutine`装饰器也可以用来包装一个普通函数（不含yield的函数），以便将其视为future。在这种情况下，整个函数在返回控制权给事件循环之前执行；装饰器只是强制函数满足协程API，以便事件循环知道如何处理它。'
- en: Reading an AsyncIO future
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阅读AsyncIO future
- en: An AsyncIO coroutine executes each line in order until it encounters a `yield
    from` statement, at which point it returns control to the event loop. The event
    loop then executes any other tasks that are ready to run, including the one that
    the original coroutine was waiting on. Whenever that child task completes, the
    event loop sends the result back into the coroutine so that it can pick up executing
    until it encounters another `yield from` statement or returns.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO协程按顺序执行每一行，直到遇到`yield from`语句，此时它将控制权返回给事件循环。事件循环然后执行任何其他准备运行的任务，包括原始协程正在等待的任务。每当子任务完成时，事件循环将结果发送回协程，以便它可以继续执行，直到遇到另一个`yield
    from`语句或返回。
- en: This allows us to write code that executes synchronously until we explicitly
    need to wait for something. This removes the nondeterministic behavior of threads,
    so we don't need to worry nearly so much about shared state.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够编写同步执行的代码，直到我们明确需要等待某些东西。这消除了线程的非确定性行为，因此我们不需要太担心共享状态。
- en: Tip
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: It's still a good idea to avoid accessing shared state from inside a coroutine.
    It makes your code much easier to reason about. More importantly, even though
    an ideal world might have all asynchronous execution happen inside coroutines,
    the reality is that some futures are executed behind the scenes inside threads
    or processes. Stick to a "share nothing" philosophy to avoid a ton of difficult
    bugs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然最好避免从协程内部访问共享状态。这样可以使您的代码更容易理解。更重要的是，即使理想的世界可能所有的异步执行都发生在协程内部，现实是一些futures在后台在线程或进程中执行。坚持“不共享”哲学，以避免大量困难的错误。
- en: In addition, AsyncIO allows us to collect logical sections of code together
    inside a single coroutine, even if we are waiting for other work elsewhere. As
    a specific instance, even though the `yield from asyncio.sleep` call in the `random_sleep`
    coroutine is allowing a ton of stuff to happen inside the event loop, the coroutine
    itself looks like it's doing everything in order. This ability to read related
    pieces of asynchronous code without worrying about the machinery that waits for
    tasks to complete is the primary benefit of the AsyncIO module.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AsyncIO允许我们将代码的逻辑部分收集到一个单独的协程中，即使我们在其他地方等待其他工作。作为一个具体的例子，即使`random_sleep`协程中的`yield
    from asyncio.sleep`调用允许事件循环中发生大量的事情，协程本身看起来好像是按顺序完成了所有工作。异步代码的这种相关部分的阅读能力，而不必担心等待任务完成的机制，是AsyncIO模块的主要优势。
- en: AsyncIO for networking
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AsyncIO用于网络
- en: AsyncIO was specifically designed for use with network sockets, so let's implement
    a DNS server. More accurately, let's implement one extremely basic feature of
    a DNS server.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO专门设计用于与网络套接字一起使用，因此让我们实现一个DNS服务器。更准确地说，让我们实现DNS服务器的一个极其基本的功能。
- en: 'The domain name system''s basic purpose is to translate domain names, such
    as www.amazon.com into IP addresses such as 72.21.206.6\. It has to be able to
    perform many types of queries and know how to contact other DNS servers if it
    doesn''t have the answer required. We won''t be implementing any of this, but
    the following example is able to respond directly to a standard DNS query to look
    up IPs for my three most recent employers:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 域名系统的基本目的是将域名（例如www.amazon.com）转换为IP地址（例如72.21.206.6）。它必须能够执行许多类型的查询，并且知道如何在没有所需答案的情况下联系其他DNS服务器。我们不会实现任何这些，但以下示例能够直接响应标准DNS查询以查找我最近三个雇主的IP：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This example sets up a dictionary that dumbly maps a few domains to IPv4 addresses.
    It is followed by two functions that extract information from a binary DNS query
    packet and construct the response. We won't be discussing these; if you want to
    know more about DNS read RFC ("request for comment", the format for defining most
    Internet protocols) 1034 and 1035.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例设置了一个简单地将一些域名映射到IPv4地址的字典。接下来是两个函数，它们从二进制DNS查询数据包中提取信息并构造响应。我们不会讨论这些；如果您想了解更多关于DNS的信息，请阅读RFC（“请求评论”，定义大多数互联网协议的格式）1034和1035。
- en: 'You can test this service by running the following command in another terminal:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在另一个终端中运行以下命令来测试此服务：
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Let's get on with the entrée. AsyncIO networking revolves around the intimately
    linked concepts of transports and protocols. A protocol is a class that has specific
    methods that are called when relevant events happen. Since DNS runs on top of
    **UDP** (**User Datagram Protocol**); we build our protocol class as a subclass
    of `DatagramProtocol`. This class has a variety of events that it can respond
    to; we are specifically interested in the initial connection occurring (solely
    so we can store the transport for future use) and the `datagram_received` event.
    For DNS, each received datagram must be parsed and responded to, at which point
    the interaction is over.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续。 AsyncIO网络围绕传输和协议这两个紧密相关的概念。协议是一个具有特定方法的类，当相关事件发生时会调用这些方法。由于DNS运行在**UDP**（**用户数据报协议**）之上，我们将我们的协议类构建为`DatagramProtocol`的子类。这个类有各种事件可以响应；我们特别关注初始连接的发生（仅仅是为了我们可以存储传输以备将来使用）和`datagram_received`事件。对于DNS，每个接收到的数据报都必须被解析和响应，此时交互就结束了。
- en: So, when a datagram is received, we process the packet, look up the IP, and
    construct a response using the functions we aren't talking about (they're black
    sheep in the family). Then we instruct the underlying transport to send the resulting
    packet back to the requesting client using its `sendto` method.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当接收到数据报时，我们处理数据包，查找IP，并使用我们不讨论的函数构造响应（它们在家族中是黑羊）。然后，我们指示底层传输使用其`sendto`方法将生成的数据包发送回请求的客户端。
- en: The transport essentially represents a communication stream. In this case, it
    abstracts away all the fuss of sending and receiving data on a UDP socket on an
    event loop. There are similar transports for interacting with TCP sockets and
    subprocesses, for example.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 传输本质上代表了一个通信流。在这种情况下，它抽象了在事件循环中的UDP套接字上发送和接收数据的所有麻烦。类似的传输用于与TCP套接字和子进程进行交互，例如。
- en: The UDP transport is constructed by calling the loop's `create_datagram_endpoint`
    coroutine. This constructs the appropriate UDP socket and starts listening on
    it. We pass it the address that the socket needs to listen on, and importantly,
    the protocol class we created so that the transport knows what to call when it
    receives data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: UDP传输是通过调用循环的`create_datagram_endpoint`协程来构造的。这将构造适当的UDP套接字并开始监听它。我们将传递给它套接字需要监听的地址，以及我们创建的协议类，以便传输知道在接收数据时调用什么。
- en: 'Since the process of initializing a socket takes a non-trivial amount of time
    and would block the event loop, the `create_datagram_endpoint` function is a coroutine.
    In our example, we don''t really need to do anything while we wait for this initialization,
    so we wrap the call in `loop.run_until_complete`. The event loop takes care of
    managing the future, and when it''s complete, it returns a tuple of two values:
    the newly initialized transport and the protocol object that was constructed from
    the class we passed in.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由于初始化套接字的过程需要大量时间，并且会阻塞事件循环，`create_datagram_endpoint`函数是一个协程。在我们的示例中，我们在等待此初始化时实际上不需要做任何事情，因此我们将调用包装在`loop.run_until_complete`中。事件循环负责管理未来，当它完成时，它返回两个值的元组：新初始化的传输和从我们传递的类构造的协议对象。
- en: Behind the scenes, the transport has set up a task on the event loop that is
    listening for incoming UDP connections. All we have to do, then, is start the
    event loop running with the call to `loop.run_forever()` so that task can process
    these packets. When the packets arrive, they are processed on the protocol and
    everything just works.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，传输已经在事件循环上设置了一个任务，用于监听传入的UDP连接。那么，我们所要做的就是通过调用`loop.run_forever()`来启动事件循环，以便该任务可以处理这些数据包。当数据包到达时，它们会在协议上进行处理，一切都会正常运行。
- en: The only other major thing to pay attention to is that transports (and, indeed,
    event loops) are supposed to be closed when we are finished with them. In this
    case, the code runs just fine without the two calls to `close()`, but if we were
    constructing transports on the fly (or just doing proper error handling!), we'd
    need to be quite a bit more conscious of it.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的另一件重要的事情是，传输（甚至事件循环）在我们完成它们时应该被关闭。在这种情况下，代码在没有两次调用`close()`的情况下也可以正常运行，但是如果我们正在动态构建传输（或者只是进行适当的错误处理！），我们需要更加注意。
- en: You may have been dismayed to see how much boilerplate is required in setting
    up a protocol class and underlying transport. AsyncIO provides an abstraction
    on top of these two key concepts called streams. We'll see an example of streams
    in the TCP server in the next example.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能对设置协议类和底层传输所需的样板代码感到沮丧。AsyncIO在这两个关键概念之上提供了一个称为streams的抽象。我们将在下一个示例中的TCP服务器中看到streams的示例。
- en: Using executors to wrap blocking code
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用执行器包装阻塞代码
- en: 'AsyncIO provides its own version of the futures library to allow us to run
    code in a separate thread or process when there isn''t an appropriate non-blocking
    call to be made. This essentially allows us to combine threads and processes with
    the asynchronous model. One of the more useful applications of this feature is
    to get the best of both worlds when an application has bursts of I/O-bound and
    CPU-bound activity. The I/O-bound portions can happen in the event-loop while
    the CPU-intensive work can be spun off to a different process. To illustrate this,
    let''s implement "sorting as a service" using AsyncIO:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO提供了自己的版本的futures库，允许我们在没有适当的非阻塞调用时在单独的线程或进程中运行代码。这本质上允许我们将线程和进程与异步模型结合起来。这个特性的更有用的应用之一是在应用程序有I/O密集和CPU密集活动突发时获得最佳效果。I/O密集部分可以在事件循环中进行，而CPU密集型工作可以分配到不同的进程中。为了说明这一点，让我们使用AsyncIO实现“排序作为服务”：
- en: '[PRE16]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This is an example of good code implementing some really stupid ideas. The whole
    idea of sort as a service is pretty ridiculous. Using our own sorting algorithm
    instead of calling Python's `sorted` is even worse. The algorithm we used is called
    gnome sort, or in some cases, "stupid sort". It is a slow sort algorithm implemented
    in pure Python. We defined our own protocol instead of using one of the many perfectly
    suitable application protocols that exist in the wild. Even the idea of using
    multiprocessing for parallelism might be suspect here; we still end up passing
    all the data into and out of the subprocesses. Sometimes, it's important to take
    a step back from the program you are writing and ask yourself if you are trying
    to meet the right goals.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实现一些非常愚蠢想法的好代码示例。将排序作为服务的整个想法相当荒谬。使用我们自己的排序算法而不是调用Python的`sorted`甚至更糟。我们使用的算法称为侏儒排序，或者在某些情况下称为“愚蠢排序”。这是一种在纯Python中实现的缓慢排序算法。我们定义了自己的协议，而不是使用野外存在的许多完全合适的应用程序协议之一。甚至在这里使用多进程进行并行可能是可疑的；我们最终仍然将所有数据传递到子进程中并传出。有时，重要的是要从您正在编写的程序中退后一步，问自己是否正在尝试实现正确的目标。
- en: But let's look at some of the smart features of this design. First, we are passing
    bytes into and out of the subprocess. This is a lot smarter than decoding the
    JSON in the main process. It means the (relatively expensive) decoding can happen
    on a different CPU. Also, pickled JSON strings are generally smaller than pickled
    lists, so less data is passing between processes.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们来看看这种设计的一些智能特性。首先，我们将字节传入并传出子进程。这比在主进程中解码JSON要聪明得多。这意味着（相对昂贵的）解码可以在不同的CPU上进行。此外，被拾取的JSON字符串通常比被拾取的列表小，因此在进程之间传递的数据更少。
- en: Second, the two methods are very linear; it looks like code is being executed
    one line after another. Of course, in AsyncIO, this is an illusion, but we don't
    have to worry about shared memory or concurrency primitives.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，这两种方法非常线性；看起来代码是一行一行地执行的。当然，在AsyncIO中，这只是一种错觉，但我们不必担心共享内存或并发原语。
- en: Streams
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Streams
- en: The previous example should look familiar by now as it has a similar boilerplate
    to other AsyncIO programs. However, there are a few differences. You'll notice
    we called `start_server` instead of `create_server`. This method hooks into AsyncIO's
    streams instead of using the underlying transport/protocol code. Instead of passing
    in a protocol class, we can pass in a normal coroutine, which receives reader
    and writer parameters. These both represent streams of bytes that can be read
    from and written like files or sockets. Second, because this is a TCP server instead
    of UDP, there is some socket cleanup required when the program finishes. This
    cleanup is a blocking call, so we have to run the `wait_closed` coroutine on the
    event loop.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例现在应该看起来很熟悉，因为它与其他AsyncIO程序有相似的样板。但是，有一些区别。您会注意到我们调用了`start_server`而不是`create_server`。这种方法钩入了AsyncIO的streams，而不是使用底层的传输/协议代码。我们可以传入一个普通的协程，而不是传入一个协议类，这个协程接收reader和writer参数。这两者都代表可以像文件或套接字一样读取和写入的字节流。其次，因为这是一个TCP服务器而不是UDP，当程序完成时需要进行一些套接字清理。这个清理是一个阻塞调用，所以我们必须在事件循环上运行`wait_closed`协程。
- en: Streams are fairly simple to understand. Reading is a potentially blocking call
    so we have to call it with `yield from`. Writing doesn't block; it just puts the
    data on a queue, which AsyncIO sends out in the background.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Streams相当容易理解。读取是一个潜在的阻塞调用，因此我们必须使用`yield from`来调用它。写入不会阻塞；它只是将数据放在队列中，AsyncIO会在后台发送出去。
- en: Our code inside the `sort_request` method makes two read requests. First, it
    reads 8 bytes from the wire and converts them to an integer using big endian notation.
    This integer represents the number of bytes of data the client intends to send.
    So in the next call, to `readexactly`, it reads that many bytes. The difference
    between `read` and `readexactly` is that the former will read up to the requested
    number of bytes, while the latter will buffer reads until it receives all of them,
    or until the connection closes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`sort_request`方法中的代码发出了两个读取请求。首先，它从线路上读取8个字节，并使用大端记法将它们转换为整数。这个整数代表客户端打算发送的数据字节数。所以在下一个调用`readexactly`时，它读取了这么多字节。`read`和`readexactly`之间的区别在于前者将读取请求的字节数，而后者将缓冲读取，直到接收到所有字节，或者直到连接关闭。
- en: Executors
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行器
- en: Now let's look at the executor code. We import the exact same `ProcessPoolExecutor`
    that we used in the previous section. Notice that we don't need a special AsyncIO
    version of it. The event loop has a handy `run_in_executor` coroutine that we
    can use to run futures on. By default, the loop runs code in `ThreadPoolExecutor`,
    but we can pass in a different executor if we wish. Or, as we did in this example,
    we can set a different default when we set up the event loop by calling `loop.set_default_executor()`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看执行器代码。我们导入了与上一节中使用的完全相同的`ProcessPoolExecutor`。请注意，我们不需要它的特殊AsyncIO版本。事件循环有一个方便的`run_in_executor`协程，我们可以用它来运行未来。默认情况下，循环在`ThreadPoolExecutor`中运行代码，但如果需要，我们可以传入不同的执行器。或者，就像我们在这个例子中所做的那样，我们可以在设置事件循环时调用`loop.set_default_executor()`来设置不同的默认值。
- en: As you probably recall from the previous section, there is not a lot of boilerplate
    for using futures with an executor. However, when we use them with AsyncIO, there
    is none at all! The coroutine automatically wraps the function call in a future
    and submits it to the executor. Our code blocks until the future completes, while
    the event loop continues processing other connections, tasks, or futures. When
    the future is done, the coroutine wakes up and continues on to write the data
    back to the client.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能还记得上一节所说的，使用执行器与未来的代码并没有太多样板。然而，当我们在AsyncIO中使用它们时，根本没有！协程自动将函数调用包装在未来中，并将其提交给执行器。我们的代码会阻塞，直到未来完成，而事件循环会继续处理其他连接、任务或未来。当未来完成时，协程会唤醒并继续将数据写回客户端。
- en: 'You may be wondering if, instead of running multiple processes inside an event
    loop, it might be better to run multiple event loops in different processes. The
    answer is: "maybe". However, depending on the exact problem space, we are probably
    better off running independent copies of a program with a single event loop than
    to try to coordinate everything with a master multiprocessing process.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会想知道，与其在事件循环中运行多个进程，是否在不同的进程中运行多个事件循环会更好。答案是：“也许”。然而，根据确切的问题空间，我们可能最好是运行程序的独立副本，每个副本都有一个事件循环，而不是试图用主多进程进程协调一切。
- en: We've hit most of the high points of AsyncIO in this section, and the chapter
    has covered many other concurrency primitives. Concurrency is a hard problem to
    solve, and no one solution fits all use cases. The most important part of designing
    a concurrent system is deciding which of the available tools is the correct one
    to use for the problem. We have seen advantages and disadvantages of several concurrent
    systems, and now have some insights into which are the better choices for different
    types of requirements.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经涵盖了AsyncIO的大部分要点，本章还涵盖了许多其他并发原语。并发是一个难题，没有一个解决方案适用于所有用例。设计并发系统最重要的部分是决定使用哪种可用工具来解决问题。我们已经看到了几种并发系统的优缺点，现在对于不同类型的需求，我们有了一些见解，知道哪些是更好的选择。
- en: Case study
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究
- en: To wrap up this chapter, and the book, let's build a basic image compression
    tool. It will take black and white images (with 1 bit per pixel, either on or
    off) and attempt to compress it using a very basic form of compression known as
    run-length encoding. You may find black and white images a bit far-fetched. If
    so, you haven't enjoyed enough hours at [http://xkcd.com](http://xkcd.com)!
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束本章和本书，让我们构建一个基本的图像压缩工具。它将使用黑白图像（每个像素1位，要么打开要么关闭）并尝试使用一种称为行程长度编码的非常基本的压缩形式来压缩它。你可能会觉得黑白图像有点牵强。如果是这样，那么你还没有在[xkcd.com](http://xkcd.com)上享受足够的时间！
- en: I've included some sample black and white BMP images (which are easy to read
    data into and leave a lot of opportunity to improve on file size) with the example
    code for this chapter.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本章的示例代码中包含了一些黑白BMP图像（这些图像很容易读取数据，并且留下了很多改进文件大小的机会）。
- en: We'll be compressing the images using a simple technique called run-length encoding.
    This technique basically takes a sequence of bits and replaces any strings of
    repeated bits with the number of bits that are repeated. For example, the string
    000011000 might be replaced with 04 12 03 to indicate that 4 zeros are followed
    by 2 ones and then 3 more zeroes. To make things a little more interesting, we
    will break each row into 127 bit chunks.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一种称为行程长度编码的简单技术来压缩图像。这种技术基本上是将一系列位替换为重复位的数量。例如，字符串000011000可能被替换为04 12
    03，表示有4个零，然后是2个一，然后是3个零。为了使事情更有趣，我们将每一行分成127位的块。
- en: I didn't pick 127 bits arbitrarily. 127 different values can be encoded into
    7 bits, which means that if a row contains all ones or all zeros, we can store
    it in a single byte; the first bit indicating whether it is a row of 0s or a row
    of 1s, and the remaining 7 bits indicating how many of that bit exists.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不是随意选择了127位。127个不同的值可以编码为7位，这意味着如果一行包含全部1或全部0，我们可以将其存储在一个字节中；第一个位指示它是0的一行还是1的一行，剩下的7位指示该位存在多少个。
- en: Breaking up the image into blocks has another advantage; we can process individual
    blocks in parallel without them depending on each other. However, there's a major
    disadvantage as well; if a run has just a few ones or zeros in it, then it will
    take up `more` space in the compressed file. When we break up long runs into blocks,
    we may end up creating more of these small runs and bloat the size of the file.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像分成块还有另一个优点；我们可以在没有相互依赖的情况下并行处理单个块。然而，也有一个主要缺点；如果一个运行中只有几个1或0，那么它将在压缩文件中占用`更多`的空间。当我们将长运行分成块时，我们可能会创建更多这样的小运行，并使文件的大小膨胀。
- en: When dealing with files, we have to think about the exact layout of the bytes
    in the compressed file. Our file will store two byte little-endian integers at
    the beginning of the file representing the width and height of the completed file.
    Then it will write bytes representing the 127 bit chunks of each row.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理文件时，我们必须考虑压缩文件中字节的确切布局。我们的文件将在文件开头存储两个字节的小端整数，表示完成文件的宽度和高度。然后它将写入表示每行的127位块的字节。
- en: 'Now before we start designing a concurrent system to build such compressed
    images, we should ask a fundamental question: Is this application I/O-bound or
    CPU-bound?'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们开始设计一个并发系统来构建这样的压缩图像之前，我们应该问一个基本问题：这个应用程序是I/O绑定还是CPU绑定？
- en: My answer, honestly, is "I don't know". I'm not sure whether the app will spend
    more time loading data from disk and writing it back or doing the compression
    in memory. I suspect that it is a CPU bound app in principle, but once we start
    passing image strings into subprocesses, we may lose any benefit of parallelism.
    The optimal solution to this problem is probably to write a C or Cython extension,
    but let's see how far we can get in pure Python.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 老实说，我的答案是“我不知道”。我不确定应用程序是更多时间从磁盘加载数据并将其写回，还是在内存中进行压缩。我怀疑原则上这是一个CPU绑定的应用程序，但一旦我们开始将图像字符串传递到子进程中，我们可能会失去并行性的任何好处。解决这个问题的最佳方法可能是编写一个C或Cython扩展，但让我们看看在纯Python中我们能走多远。
- en: 'We''ll build this application using bottom-up design. That way we''ll have
    some building blocks that we can combine into different concurrency patterns to
    see how they compare. Let''s start with the code that compresses a 127-bit chunk
    using run-length encoding:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用自下而上的设计构建此应用程序。这样我们将有一些构建块，可以将它们组合成不同的并发模式，以查看它们的比较。让我们从使用游程编码压缩127位块的代码开始：
- en: '[PRE17]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This code uses the `bitarray` class for manipulating individual zeros and ones.
    It is distributed as a third-party module, which you can install with the command
    `pip install bitarray`. The chunk that is passed into `compress_chunks` is an
    instance of this class (although the example would work just as well with a list
    of Booleans). The primary benefit of the bitarray in this case is that when pickling
    them between processes, they take up an 8th of the space of a list of Booleans
    or a bytestring of 1s and 0s. Therefore, they pickle faster. They are also a bit
    (pun intended) easier to work with than doing a ton of bitwise operations.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用`bitarray`类来操作单个0和1。它作为第三方模块分发，您可以使用`pip install bitarray`命令进行安装。传递给`compress_chunks`的块是这个类的一个实例（尽管示例也可以使用布尔值列表）。在这种情况下，位数组的主要优点是，在进程之间进行pickling时，它们占用布尔值列表或包含1和0的字节字符串的1/8的空间。因此，它们pickle得更快。它们也比进行大量位操作更容易使用。
- en: The method compresses the data using run-length encoding and returns a bytearray
    containing the packed data. Where a bitarray is like a list of ones and zeros,
    a bytearray is like a list of byte objects (each byte, of course, containing 8
    ones or zeros).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法使用游程编码压缩数据，并返回包含打包数据的bytearray。位数组类似于一个由1和0组成的列表，而bytearray类似于一个字节对象的列表（每个字节当然包含8个1或0）。
- en: The algorithm that performs the compression is pretty simple (although I'd like
    to point out that it took me two days to implement and debug it. Simple to understand
    does not necessarily imply easy to write!). It first sets the `last` variable
    to the type of bit in the current run (either `True` or `False`). It then loops
    over the bits, counting each one, until it finds one that is different. When it
    does, it constructs a new byte by making the leftmost bit of the byte (the 128
    position) either a zero or a one, depending on what the `last` variable contained.
    Then it resets the counter and repeats the operation. Once the loop is done, it
    creates one last byte for the last run, and returns the result.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 执行压缩的算法非常简单（尽管我想指出，我花了两天的时间来实现和调试它。简单易懂并不一定意味着容易编写！）。它首先将`last`变量设置为当前运行中的位的类型（`True`或`False`）。然后它循环遍历位，计算每一个，直到找到一个不同的。当找到不同的时，它通过使字节的最左边的位（第128位）为零或一，取决于`last`变量的内容，构造一个新字节。然后它重置计数器并重复操作。一旦循环结束，它为最后一个运行创建一个字节，并返回结果。
- en: 'While we''re creating building blocks, let''s make a function that compresses
    a row of image data:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建构建块的同时，让我们制作一个压缩图像数据行的函数：
- en: '[PRE18]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This function accepts a bitarray named row. It splits it into chunks that are
    each 127 bits wide using a function that we'll define very shortly. Then it compresses
    each of those chunks using the previously defined `compress_chunk`, concatenating
    the results into a `bytearray`, which it returns.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受一个名为row的位数组。它使用一个我们将很快定义的函数将其分成每个127位宽的块。然后它使用先前定义的`compress_chunk`压缩每个块，将结果连接成一个`bytearray`，然后返回。
- en: 'We define `split_bits` as a simple generator:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`split_bits`定义为一个简单的生成器：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, since we aren''t certain yet whether this will run more effectively in
    threads or processes, let''s wrap these functions in a method that runs everything
    in a provided executor:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于我们还不确定这个程序在线程或进程中运行哪种方式更有效，让我们把这些函数封装在一个方法中，该方法在提供的执行器中运行一切：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This example barely needs explaining; it splits the incoming bits into rows
    based on the width of the image using the same `split_bits` function we have already
    defined (hooray for bottom-up design!).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子几乎不需要解释；它根据图像的宽度将传入的位拆分成行，使用我们已经定义的相同的`split_bits`函数（为自下而上的设计欢呼！）。
- en: 'Note that this code will compress any sequence of bits, although it would bloat,
    rather than compress binary data that has frequent changes in bit values. Black
    and white images are definitely good candidates for the compression algorithm
    in question. Let''s now create a function that loads an image file using the third-party
    pillow module, converts it to bits, and compresses it. We can easily switch between
    executors using the venerable comment statement:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这段代码将压缩任何位序列，尽管它会膨胀，而不是压缩具有位值频繁变化的二进制数据。黑白图像绝对是该压缩算法的良好候选。现在让我们创建一个函数，使用第三方pillow模块加载图像文件，将其转换为位，并对其进行压缩。我们可以轻松地在可敬的注释语句中切换执行器。
- en: '[PRE21]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `image.convert()` call changes the image to black and white (one bit) mode,
    while `getdata()` returns an iterator over those values. We pack the results into
    a bitarray so they transfer across the wire more quickly. When we output the compressed
    file, we first write the width and height of the image followed by the compressed
    data, which arrives as a bytearray, which can be written directly to the binary
    file.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`image.convert()`调用将图像更改为黑白（一位）模式，而`getdata()`返回这些值的迭代器。我们将结果打包到位数组中，以便它们可以更快地通过网络传输。当我们输出压缩文件时，我们首先写入图像的宽度和高度，然后是压缩数据，它以字节数组的形式到达，可以直接写入二进制文件。'
- en: Having written all this code, we are finally able to test whether thread pools
    or process pools give us better performance. I created a large (7200 x 5600 pixels)
    black and white image and ran it through both pools. The `ProcessPool` takes about
    7.5 seconds to process the image on my system, while the `ThreadPool` consistently
    takes about 9\. Thus, as we suspected, the cost of pickling bits and bytes back
    and forth between processes is eating almost all the efficiency gains from running
    on multiple processors (though looking at my CPU monitor, it does fully utilize
    all four cores on my machine).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 编写了所有这些代码后，我们终于能够测试线程池或进程池是否能够给我们更好的性能。我创建了一个大型（7200 x 5600像素）的黑白图像，并将其通过两个池。`ProcessPool`在我的系统上大约需要7.5秒来处理图像，而`ThreadPool`始终需要大约9秒。因此，正如我们所怀疑的那样，将位和字节在进程之间来回传递的成本几乎吞噬了在多个处理器上运行的效率收益（尽管从我的CPU监视器来看，它确实充分利用了我的机器上的所有四个核心）。
- en: So it looks like compressing a single image is most effectively done in a separate
    process, but only barely because we are passing so much data back and forth between
    the parent and subprocesses. Multiprocessing is more effective when the amount
    of data passed between processes is quite low.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，看起来压缩单个图像最有效地在单独的进程中完成，但仅仅是因为我们在父进程和子进程之间传递了如此多的数据。当进程之间传递的数据量非常低时，多进程的效果更好。
- en: So let's extend the app to compress all the bitmaps in a directory in parallel.
    The only thing we'll have to pass into the subprocesses are filenames, so we should
    get a speed gain compared to using threads. Also, to be kind of crazy, we'll use
    the existing code to compress individual images. This means we'll be running a
    `ProcessPoolExecutor` inside each subprocess to create even more subprocesses.
    I don't recommend doing this in real life!
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们扩展应用程序以并行压缩目录中的所有位图。我们唯一需要传递给子进程的是文件名，因此与使用线程相比，我们应该获得速度增益。另外，为了有点疯狂，我们将使用现有代码来压缩单个图像。这意味着我们将在每个子进程中运行`ProcessPoolExecutor`来创建更多的子进程。我不建议在现实生活中这样做！
- en: '[PRE22]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This code uses the `compress_image` function we defined previously, but runs
    it in a separate process for each image. It doesn't pass an executor into the
    function, so `compress_image` creates a `ProcessPoolExecutor` once the new process
    has started running.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用我们之前定义的`compress_image`函数，但在每个图像的单独进程中运行它。它没有将执行器传递给函数，因此一旦新进程开始运行，`compress_image`就会创建一个`ProcessPoolExecutor`。
- en: 'Now that we are running executors inside executors, there are four combinations
    of threads and process pools that we can be using to compress images. They each
    have quite different timing profiles:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在执行器内部运行执行器，有四种线程和进程池的组合可以用来压缩图像。它们各自具有非常不同的时间特征：
- en: '|   | Process pool per image | Thread pool per image |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: 每个图像的进程池 | 每个图像的线程池 |
- en: '| --- | --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Process pool per row** | 42 seconds | 53 seconds |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| **每行的进程池** | 42秒 | 53秒 |'
- en: '| **Thread pool per row** | 34 seconds | 64 seconds |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| **每行的线程池** | 34秒 | 64秒 |'
- en: As we might expect, using threads for each image and again using threads for
    each row is the slowest, since the GIL prevents us from doing any work in parallel.
    Given that we were slightly faster when using separate processes for each row
    when we were using a single image, you may be surprised to see that it is faster
    to use a `ThreadPool` feature for rows if we are processing each image in a separate
    process. Take some time to understand why this might be.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所预料的，对每个图像使用线程，再对每行使用线程是最慢的，因为GIL阻止我们并行工作。鉴于当我们对单个图像使用单独的进程时，对每行使用单独的进程时稍微更快，您可能会惊讶地发现，如果我们在单独的进程中处理每个图像，则使用`ThreadPool`功能对行进行处理会更快。花点时间理解为什么会这样。
- en: My machine contains only four processor cores. Each row in each image is being
    processed in a separate pool, which means that all those rows are competing for
    processing power. When there is only one image, we get a (very modest) speedup
    by running each row in parallel. However, when we increase the number of images
    being processed at once, the cost of passing all that row data into and out of
    a subprocess is actively stealing processing time from each of the other images.
    So, if we can process each image on a separate processor, where the only thing
    that has to get pickled into the subprocess pipe is a couple filenames, we get
    a solid speedup.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我的机器只有四个处理器核心。每个图像中的每一行都在一个单独的池中进行处理，这意味着所有这些行都在竞争处理能力。当只有一个图像时，通过并行运行每一行，我们可以获得（非常适度的）加速。然而，当我们增加同时处理的图像数量时，将所有这些行数据传递到子进程中的成本会主动地从其他图像中窃取处理时间。因此，如果我们可以在单独的处理器上处理每个图像，那么只需要将一些文件名pickle到子进程管道中，我们就可以获得很好的加速。
- en: Thus, we see that different workloads require different concurrency paradigms.
    Even if we are just using futures we have to make informed decisions about what
    kind of executor to use.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们看到不同的工作负载需要不同的并发范例。即使我们只是使用futures，我们也必须对要使用的执行器类型做出明智的决定。
- en: Also note that for typically-sized images, the program runs quickly enough that
    it really doesn't matter which concurrency structures we use. In fact, even if
    we didn't use any concurrency at all, we'd probably end up with about the same
    user experience.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，对于通常大小的图像，程序运行速度足够快，以至于使用哪种并发结构并不重要。实际上，即使我们根本不使用并发，最终用户体验也可能差不多。
- en: 'This problem could also have been solved using the threading and/or multiprocessing
    modules directly, though there would have been quite a bit more boilerplate code
    to write. You may be wondering whether or not AsyncIO would be useful here. The
    answer is: "probably not". Most operating systems don''t have a good way to do
    non-blocking reads from the filesystem, so the library ends up wrapping all the
    calls in futures anyway.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题也可以直接使用线程和/或多进程模块来解决，尽管需要编写更多的样板代码。你可能想知道AsyncIO在这里是否有用。答案是：“可能不”。大多数操作系统没有很好的方法来从文件系统进行非阻塞读取，因此该库最终会将所有调用包装在futures中。
- en: 'For completeness, here''s the code that I used to decompress the RLE images
    to confirm that the algorithm was working correctly (indeed, it wasn''t until
    I fixed bugs in both compression and decompression, and I''m still not sure if
    it is perfect. I should have used test-driven development!):'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整起见，这是我用来解压RLE图像以确认算法是否正确运行的代码（事实上，直到我修复了压缩和解压缩中的错误之后，我才确定它是否完美。我应该使用测试驱动开发！）：
- en: '[PRE23]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This code is fairly straightforward. Each run is encoded in a single byte. It
    uses some bitwise math to extract the color of the pixel and the length of the
    run. Then it sets each pixel from that run in the image, incrementing the row
    and column of the next pixel to check at appropriate intervals.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码非常简单。每次运行都被编码为一个字节。它使用一些位运算来提取像素的颜色和运行的长度。然后它在图像中设置每个像素，适当的间隔递增下一个要检查的像素的行和列。
- en: Exercises
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: We've covered several different concurrency paradigms in this chapter and still
    don't have a clear idea of when each one is useful. As we saw in the case study,
    it is often a good idea to prototype a few different strategies before committing
    to one.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了几种不同的并发范例，但仍然不清楚每种范例何时有用。正如我们在案例研究中看到的，通常最好在承诺采用某种范例之前先尝试几种不同的策略。
- en: 'Concurrency in Python 3 is a huge topic and an entire book of this size could
    not cover everything there is to know about it. As your first exercise, I encourage
    you to check out several third-party libraries that may provide additional context:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3中的并发是一个庞大的主题，这样大小的一本书也无法涵盖所有相关知识。作为你的第一个练习，我鼓励你去了解一些第三方库，它们可能提供额外的上下文：
- en: execnet, a library that permits local and remote share-nothing concurrency
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: execnet是一个允许本地和远程共享无状态并发的库
- en: Parallel python, an alternative interpreter that can execute threads in parallel
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parallel python是一种可以并行执行线程的替代解释器
- en: Cython, a python-compatible language that compiles to C and has primitives to
    release the gil and take advantage of fully parallel multi-threading.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cython是一种兼容Python的语言，它编译成C并具有释放GIL和利用完全并行多线程的原语。
- en: PyPy-STM, an experimental implementation of software transactional memory on
    top of the ultra-fast PyPy implementation of the Python interpreter
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyPy-STM是一个在超快PyPy Python解释器上实验性实现的软件事务内存
- en: Gevent
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gevent
- en: If you have used threads in a recent application, take a look at the code and
    see if you can make it more readable and less bug-prone by using futures. Compare
    thread and multiprocessing futures to see if you can gain anything by using multiple
    CPUs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最近在应用程序中使用了线程，请查看代码，看看是否可以通过使用futures使其更易读且更少出错。比较线程和多进程futures，看看是否可以通过使用多个CPU获得任何好处。
- en: Try implementing an AsyncIO service for some basic HTTP requests. You may need
    to look up the structure of an HTTP request on the web; they are fairly simple
    ASCII packets to decipher. If you can get it to the point that a web browser can
    render a simple GET request, you'll have a good understanding of AsyncIO network
    transports and protocols.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试为一些基本的HTTP请求实现一个AsyncIO服务。你可能需要在网上查找HTTP请求的结构；它们是相当简单的ASCII数据包。如果你能让一个网络浏览器呈现一个简单的GET请求，你就会对AsyncIO网络传输和协议有一个很好的理解。
- en: Make sure you understand the race conditions that happen in threads when you
    access shared data. Try to come up with a program that uses multiple threads to
    set shared values in such a way that the data deliberately becomes corrupt or
    invalid.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你理解了在访问共享数据时线程中发生的竞争条件。尝试编写一个程序，使用多个线程以一种使数据故意变得损坏或无效的方式设置共享值。
- en: Remember the link collector we covered for the case study in [Chapter 6](ch06.html
    "Chapter 6. Python Data Structures"), *Python Data Structures*? Can you make it
    run faster by making requests in parallel? Is it better to use raw threads, futures,
    or AsyncIO for this?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.html "第6章 Python数据结构")中，我们介绍了我们在案例研究中涵盖的链接收集器，*Python数据结构*。你能通过并行请求使其运行更快吗？对于这个问题，使用原始线程、futures还是AsyncIO更好？
- en: Try writing the run-length encoding example using threads or multiprocessing
    directly. Do you get any speed gains? Is the code easier or harder to reason about?
    Is there any way to speed up the decompression script by using concurrency or
    parallelism?
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用线程或多进程直接编写运行长度编码示例。你获得了任何速度提升吗？代码更容易还是更难理解？有没有办法通过并发或并行来加快解压缩脚本的速度？
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter ends our exploration of object-oriented programming with a topic
    that isn't very object-oriented. Concurrency is a difficult problem and we've
    only scratched the surface. While the underlying OS abstractions of processes
    and threads do not provide an API that is remotely object-oriented, Python offers
    some really good object-oriented abstractions around them. The threading and multiprocessing
    packages both provide an object-oriented interface to the underlying mechanics.
    Futures are able to encapsulate a lot of the messy details into a single object.
    AsyncIO uses coroutine objects to make our code read as though it runs synchronously,
    while hiding ugly and complicated implementation details behind a very simple
    loop abstraction.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束了我们对面向对象编程的探索，这个主题并不是非常面向对象。并发是一个困难的问题，我们只是触及了表面。虽然进程和线程的底层操作系统抽象并没有提供远程面向对象的API，但Python提供了一些非常好的围绕它们的面向对象抽象。线程和多进程包都提供了对底层机制的面向对象接口。Futures能够将许多混乱的细节封装到一个对象中。AsyncIO使用协程对象使我们的代码看起来像是同步运行，同时隐藏了丑陋和复杂的实现细节，背后是一个非常简单的循环抽象。
- en: Thank you for reading *Python 3 Object-oriented Programming*, *Second Edition*.
    I hope you've enjoyed the ride and are eager to start implementing object-oriented
    software in all your future projects!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读*Python 3面向对象编程*，*第二版*。希望您享受了这段旅程，并渴望开始在未来的所有项目中实现面向对象的软件！
