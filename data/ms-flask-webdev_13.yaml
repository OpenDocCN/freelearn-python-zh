- en: Deploying Flask Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 Flask 应用程序
- en: Now that we have reached the last chapter of the book, and have a fully functioning
    web app made in Flask, the final step in our development cycle is to make the
    app available for the world. There are many different approaches for hosting your
    Flask app, each of them with its own pros and cons. This chapter will cover the
    best solutions and guide you through situations in which you should choose one
    over the other.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经到达了这本书的最后一章，并制作了一个完全功能性的 Flask 网络应用程序，我们开发周期的最后一步是将应用程序提供给全世界。托管您的 Flask
    应用程序有众多不同的方法，每种方法都有其自身的优缺点。本章将涵盖最佳解决方案，并指导您在何种情况下选择一种方法而不是另一种。
- en: 'In this chapter, we will cover the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: A brief introduction to the most commonly used web servers and gateway interfaces
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对最常用的网络服务器和网关接口的简要介绍
- en: How to deploy on various cloud services
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在各种云服务上部署
- en: How to build Docker images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建 Docker 镜像
- en: How to describe services using Docker compose
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Docker Compose 描述服务
- en: How to describe your infrastructure using AWS CloudFormation (IaC)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 AWS CloudFormation (IaC) 描述您的基础设施
- en: How to set up and work with a CI/CD system to easily build, test, review, and
    deploy our application
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设置和使用 CI/CD 系统以轻松构建、测试、审查和部署我们的应用程序
- en: Web servers and gateway interfaces
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络服务器和网关接口
- en: In this section, we will make a quick introduction to the most commonly used
    web servers and **Web Server Gateway Interfaces** (**WSGI**), and their differences
    and configuration. A WSGI is an application-agnostic layer between the web server
    and the python application itself.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将快速介绍最常用的网络服务器和**Web Server Gateway Interfaces**（**WSGI**），以及它们之间的区别和配置。WSGI
    是位于网络服务器和 Python 应用程序本身之间的一种与应用程序无关的层。
- en: Gevent
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gevent
- en: 'The simplest option to get a web server up and running is to use a Python library,
    named `gevent`, to host your application. `Gevent` is a Python library that adds
    an alternative way of doing concurrent programming,called co-routines, outside
    of the Python threading library. Gevent has an interface to run WSGI applications
    that is both simple and has good performance. A simple gevent server can easily
    handle hundreds of concurrent users, which is 99% more than the users of websites
    on the internet will ever have. The downside to this option is that its simplicity
    means a lack of configuration options. There is no way, for example, to add rate
    limiting to the server, or to add HTTPS traffic. This deployment option is purely
    for sites that you don''t expect to receive a huge amount of traffic. Remember
    YAGNI: only upgrade to a different web server if you really need to.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 获取网络服务器运行的最简单选项是使用名为 `gevent` 的 Python 库来托管您的应用程序。`Gevent` 是一个 Python 库，它为 Python
    线程库之外提供了另一种并发编程方式，称为协程。Gevent 提供了一个运行 WSGI 应用程序的接口，它既简单又具有良好性能。一个简单的 gevent 服务器可以轻松处理数百个并发用户，这比互联网上网站的用户多出
    99%。这种选择的缺点是它的简单性意味着缺乏配置选项。例如，无法向服务器添加速率限制或添加 HTTPS 流量。这种部署选项纯粹适用于您不期望接收大量流量的网站。记住
    YAGNI：只有当您真的需要时，才升级到不同的网络服务器。
- en: Co-routines are a bit outside of the scope of this book, but a good explanation
    can be found at [https://en.wikipedia.org/wiki/Coroutine](https://en.wikipedia.org/wiki/Coroutine).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 协程超出了本书的范围，但可以在[https://en.wikipedia.org/wiki/Coroutine](https://en.wikipedia.org/wiki/Coroutine)找到良好的解释。
- en: 'To install `gevent`, we will use `pip` with the following command:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 `gevent`，我们将使用以下命令的 `pip`：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the root of the project directory, in a new file named `gserver.py`, add
    the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目目录的根目录下，在名为 `gserver.py` 的新文件中添加以下内容：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To run the server with supervisor, just change the command value to the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 supervisor 运行服务器，只需将命令值更改为以下内容：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now when you deploy, `gevent` will automatically be installed for you by running
    your `requirements.txt` on every deployment; that is, if you are properly pip
    freezing after every new dependency is added.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当您部署时，`gevent` 将在每次部署时通过运行您的 `requirements.txt` 自动为您安装；也就是说，如果您在添加每个新依赖项后正确地使用
    pip 冻结。
- en: Tornado
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tornado
- en: '**Tornado** is another very simple way to deploy WSGI apps purely with Python.
    Tornado is a web server that is designed to handle thousands of simultaneous connections.
    If your application needs real-time data, Tornado also supports WebSockets for
    continuous, long-lived connections to the server.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**Tornado** 是另一种仅使用 Python 部署 WSGI 应用程序的方法。Tornado 是一个设计用来处理数千个并发连接的网络服务器。如果您的应用程序需要实时数据，Tornado
    还支持 WebSocket 以实现到服务器的持续、长连接。'
- en: Do not use Tornado in production on a Windows server. The Windows version of
    Tornado is not only slower—it is also considered beta-stage quality software.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在Windows服务器上以生产模式使用Tornado。Tornado的Windows版本不仅速度较慢，而且被认为是处于测试阶段的软件。
- en: 'To use Tornado with our application, we will use Tornado''s `WSGIContainer`
    in order to wrap the application object to make it Tornado-compatible. Then, Tornado
    will start to listen on port *80* for requests until the process is terminated.
    In a new file, named `tserver.py`, add the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Tornado与我们的应用程序一起使用，我们将使用Tornado的`WSGIContainer`来包装应用程序对象，使其与Tornado兼容。然后，Tornado将开始监听端口*80*上的请求，直到进程终止。在新的文件`tserver.py`中添加以下内容：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To run the Tornado with supervisor privileges, just change the command value
    to the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要以管理员的权限运行Tornado，只需更改命令值为以下内容：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Nginx and uWSGI
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nginx和uWSGI
- en: 'If you need better performance or more options for customization, the most
    popular way to deploy a Python web application is to use a Nginx web server as
    a frontend for the WSGI-based uWSGI server by using a reverse proxy. A *reverse
    proxy* is a program in networks that retrieves contents for a client from a server,
    as if it returned from the proxy itself. This process is shown in the following
    diagram:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要更好的性能或更多自定义选项，最流行的部署Python网络应用程序的方式是使用Nginx网络服务器作为基于WSGI的uWSGI服务器的代理前端。*反向代理*是一种网络程序，它从服务器获取客户端的内容，就像它从代理本身返回一样。这个过程在以下图中展示：
- en: '![](img/6547d721-3adc-45eb-baa1-850483f73ff3.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6547d721-3adc-45eb-baa1-850483f73ff3.png)'
- en: '**Nginx** and **uWSGI** are used like this, because this way, we get the power
    of the Nginx frontend, while having the customization of uWSGI.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nginx**和**uWSGI**的使用方式是这样的，因为这样我们既获得了Nginx前端的强大功能，又具有uWSGI的定制性。'
- en: '**Nginx** is a very powerful web server that became popular by providing the
    best combination of speed and customization. Nginx is consistently faster than
    other web severs, such as Apache''s httpd, and has native support for WSGI applications.
    It achieves this speed thanks to the developers taking several good architecture
    decisions, as well as not going to try to cover a large amount of use cases, as
    Apache does. The latter point here was a decision taken early on in development
    of Nginx. Having a smaller feature set makes it much easier to maintain and optimize
    the code. From a programmer''s perspective, it is also much easier to configure
    Nginx, as there is no giant default configuration file (`httpd.conf`) that can
    be overridden with `.htaccess` files in each of your project directories.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nginx**是一个非常强大的网络服务器，因其提供了速度和定制的最佳组合而变得流行。Nginx始终比其他网络服务器，如Apache的httpd，要快，并且具有对WSGI应用程序的原生支持。它之所以能够达到这种速度，是因为开发者做出了几个良好的架构决策，并且没有像Apache那样试图覆盖大量用例。后一点是在Nginx开发早期就做出的决定。具有较小的功能集使得维护和优化代码变得更加容易。从程序员的视角来看，配置Nginx也更容易，因为没有巨大的默认配置文件（`httpd.conf`），每个项目目录中都可以用`.htaccess`文件覆盖。'
- en: '**uWSGI** is a web server that supports several different types of server interfaces,
    including WSGI. uWSGI handles the severing of the application content, as well
    as things such as the load balancing of traffic across several different processes
    and threads.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**uWSGI**是一个支持多种不同类型服务器接口的网络服务器，包括WSGI。uWSGI处理应用程序内容的提供，以及诸如在多个不同进程和线程之间进行流量负载均衡等事情。'
- en: 'To install uWSGI, we will use a `pip` command, as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装uWSGI，我们将使用以下`pip`命令：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In order to run our application, uWSGI needs a file with an accessible WSGI
    application. In a file named `wsgi.py` in the top level of the project directory.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行我们的应用程序，uWSGI需要一个包含可访问WSGI应用程序的文件。在项目目录顶层名为`wsgi.py`的文件中。
- en: 'To test uWSGI, we can run it from the **command-line interface** (**CLI**)
    with the following commands:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试uWSGI，我们可以通过以下命令从**命令行界面**（**CLI**）运行它：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are running this on your server, you should be able to access port 8080
    and see your app (if you don't have a firewall, that is).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在自己的服务器上运行此程序，您应该能够访问端口8080并看到您的应用程序（如果您没有防火墙的话）。
- en: What this command does is load the app object from the `wsgi.py` file, and make
    it accessible from `localhost` on port *8080*. It also spawns four different processes
    with two threads each, which are automatically load balanced by a master process.
    This amount of processes is overkill for the vast majority of websites. To start
    off, use a single process with two threads and scale up from there.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令的作用是从 `wsgi.py` 文件中加载 app 对象，并使其在 `localhost` 的端口 *8080* 上可访问。它还启动了四个不同的进程，每个进程有两个线程，这些进程由主进程自动负载均衡。对于绝大多数网站来说，这样的进程数量是过度的。为了开始，使用一个进程和两个线程，然后根据需要扩展。
- en: 'Instead of adding all of the configuration options on the CLI, we can create
    a text file to hold our configuration, which gives us the same benefits for configuration
    that were listed in the *Gevent *section, about supervisor. In the root of the
    project directory, create a file named `uwsgi.ini` and add the following code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不必在 CLI 上添加所有配置选项，可以创建一个文本文件来保存我们的配置，这为我们提供了与 *Gevent* 部分中提到的 supervisor 相同的配置优势。在项目目录的根目录下创建一个名为
    `uwsgi.ini` 的文件，并添加以下代码：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: uWSGI supports hundreds of configuration options, as well as several official
    and unofficial plugins. To leverage the full power of uWSGI, you can explore the
    documentation at [http://uwsgi-docs.readthedocs.org/](http://uwsgi-docs.readthedocs.org/).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI 支持数百个配置选项，以及一些官方和非官方插件。要充分利用 uWSGI 的全部功能，您可以查阅 [http://uwsgi-docs.readthedocs.org/](http://uwsgi-docs.readthedocs.org/)
    上的文档。
- en: 'Let''s now run the server from supervisor:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从 supervisor 运行服务器：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Because we are installing Nginx from the OS's package manager, the OS will handle
    the running of Nginx for us.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是从操作系统的软件包管理器中安装 Nginx，操作系统将为我们处理 Nginx 的运行。
- en: At the time of writing, the Nginx version in the official Debian package manager
    is several years old. To install the most recent version, follow the instructions
    available at [http://wiki.nginx.org/Install](http://wiki.nginx.org/Install).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，官方 Debian 软件包管理器中的 Nginx 版本已经过时好几年。要安装最新版本，请遵循 [http://wiki.nginx.org/Install](http://wiki.nginx.org/Install)
    上提供的说明。
- en: 'Next, we need to create an Nginx configuration file, and then, when we push
    the code, we need to copy the configuration file to the `/etc/nginx/sites-available/`
    directory. In the root of the project directory, create a new file named `nginx.conf`,
    and add the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个 Nginx 配置文件，然后，当我们推送代码时，我们需要将配置文件复制到 `/etc/nginx/sites-available/`
    目录。在项目目录的根目录下创建一个名为 `nginx.conf` 的新文件，并添加以下内容：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: What this configuration file does is tells Nginx to listen for incoming requests
    on port *80*, and forwards all requests to the WSGI application that is listening
    on port *8080*. Also, it makes an exception for any requests for static files,
    and instead sends those requests directly to the file system. Bypassing uWSGI
    for static files gives a great boost to performance, as Nginx is really good at
    serving static files quickly.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置文件的作用是告诉 Nginx 监听端口 *80* 上的传入请求，并将所有请求转发到监听端口 *8080* 的 WSGI 应用程序。此外，它为静态文件请求设置了一个例外，并将这些请求直接发送到文件系统。绕过
    uWSGI 处理静态文件可以极大地提高性能，因为 Nginx 在快速服务静态文件方面非常出色。
- en: Apache and uWSGI
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache 和 uWSGI
- en: 'Using Apache httpd with uWSGI mostly requires the same setup. First off, we
    need an Apache configuration file, so let''s create a new file, named `apache.conf`,
    in the root of our project directory, and add the following code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Apache httpd 与 uWSGI 的设置基本上是相同的。首先，我们需要一个 Apache 配置文件，因此让我们在我们的项目目录根目录下创建一个名为
    `apache.conf` 的新文件，并添加以下代码：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This file simply tells Apache to pass all requests on port *80* to the uWSGI
    web server listening on port *8080*. However, this functionality requires an extra
    Apache plugin from uWSGI, named `mod-proxy-uwsgi`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件仅告知 Apache 将所有端口 *80* 上的请求转发到监听端口 *8080* 的 uWSGI 网络服务器。然而，此功能需要从 uWSGI 获取一个额外的
    Apache 插件，名为 `mod-proxy-uwsgi`。
- en: Next, we will cover several solutions for deploying our application on **Platform
    as a Service** (**PaaS**) and **Infrastructure as a Service** (**IaaS**) utilities.
    You will learn how to create several types of environments and make our example
    Blog application available to the world.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍几种在 **平台即服务**（**PaaS**）和 **基础设施即服务**（**IaaS**）工具上部署我们的应用程序的解决方案。您将学习如何创建几种不同类型的环境，并使我们的示例
    Blog 应用程序对全世界可用。
- en: Deploying on Heroku
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Heroku 上部署
- en: '**Heroku** is the first of the **Platform as a Service** (**PaaS**) providers
    that this chapter will cover. PaaS is a service given to web developers that allows
    them to host their websites on a platform that is controlled and maintained by
    someone else. At the cost of some freedom, you gain assurances that your website
    will automatically scale with the number of users your site has, with no extra
    work on your part. Using PaaS utilities may, however, tend to be more expensive
    than running your own servers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Heroku** 是本章将要介绍的第一个 **平台即服务**（**PaaS**）提供商。PaaS 是一种服务，提供给网络开发者，使他们能够将网站托管在由他人控制和维护的平台之上。以牺牲一些自由为代价，你可以获得保证，你的网站将自动根据网站的用户数量进行扩展，而无需你做额外的工作。然而，使用
    PaaS 工具可能会比运行自己的服务器更昂贵。'
- en: Heroku is a PaaS utility that aims to provide ease of use to web developers
    by hooking into already existing tools, and not requiring any large changes in
    the app. Heroku works by reading a file named `Procfile`, which contains commands
    that your Heroku dyno (basically a virtual machine sitting on a server) will run.
    Before we begin, you will need a Heroku account. If you wish to just experiment,
    there is a free account available.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku 是一种 PaaS 工具，旨在通过挂钩到现有的工具来为网络开发者提供易用性，而不需要应用程序进行任何大的更改。Heroku 通过读取名为 `Procfile`
    的文件来工作，该文件包含你的 Heroku dyno（基本上是位于服务器上的虚拟机）将要运行的命令。在我们开始之前，你需要一个 Heroku 账户。如果你只想进行实验，有一个免费账户可供使用。
- en: 'In the root of the directory, in a new file named `Procfile`, we have the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在目录的根目录下，在名为 `Procfile` 的新文件中，我们有以下内容：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This tells Heroku that we have a process named `web`, which will run the uWSGI
    command and pass the `uwsgi.ini` file. Heroku also needs a file named `runtime.txt`,
    which will tell Heroku what Python runtime you wish to use—at the time of writing,
    the latest Python release is 3.7.0:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉 Heroku 我们有一个名为 `web` 的进程，该进程将运行 uWSGI 命令并传递 `uwsgi.ini` 文件。Heroku 还需要一个名为
    `runtime.txt` 的文件，该文件将告诉 Heroku 你希望使用哪个 Python 运行时——在撰写本文时，最新的 Python 版本是 3.7.0：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Next, make sure that **uwsgi** is present in the `requirements.txt` file.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，确保 **uwsgi** 已存在于 `requirements.txt` 文件中。
- en: 'Finally, we need to make some modifications to the `uwsgi.ini` file that we
    made earlier:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要对之前创建的 `uwsgi.ini` 文件进行一些修改：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We set the port on which uWSGI listens to the environment variable port, because
    Heroku does not directly expose the dyno to the internet. Instead, it has a very
    complicated load balancer and reverse proxy system, so we need to have uWSGI listening
    on the port that Heroku needs us to listen on. Also, we set die-on-term to true,
    so that uWSGI listens for a signal termination event from the OS correctly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 uWSGI 监听的端口设置为环境变量 port，因为 Heroku 并不会直接将 dyno 暴露给互联网。相反，它有一个非常复杂的负载均衡器和反向代理系统，因此我们需要让
    uWSGI 监听 Heroku 需要我们监听的端口。此外，我们还设置了 die-on-term 为 true，以便 uWSGI 能够正确地监听来自操作系统的信号终止事件。
- en: To work with Heroku's command-line tools, we first need to install them, which
    can be done from [https://toolbelt.heroku.com](https://toolbelt.heroku.com).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Heroku 的命令行工具，我们首先需要安装它们，这可以通过 [https://toolbelt.heroku.com](https://toolbelt.heroku.com)
    完成。
- en: 'Next, you need to log in to your account:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要登录到你的账户：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can test our setup to make sure that it will work on Heroku before we deploy
    it, by using the `foreman` command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署之前，我们可以使用 `foreman` 命令测试我们的设置，以确保它将在 Heroku 上正常工作：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `foreman` command simulates the same production environment that Heroku
    uses to run our app. To create the dyno, which will run the application on Heroku''s
    servers, we will use the `create` command. Then, we can push Heroku to the remote
    branch on our Git repository to have Heroku servers automatically pull down our
    changes:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`foreman` 命令模拟了 Heroku 用来运行我们的应用程序的相同生产环境。为了创建将在 Heroku 服务器上运行应用程序的 dyno，我们将使用
    `create` 命令。然后，我们可以将 Heroku 推送到 Git 仓库上的远程分支，以便 Heroku 服务器自动拉取我们的更改：'
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If everything went well, you should now have a working application on your
    new Heroku dyno. You can open a new tab to your new web application with the following
    command:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你现在应该有一个在新的 Heroku dyno 上运行的应用程序。你可以使用以下命令打开新标签页，访问你的新网络应用程序：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To see the app in action in a Heroku deployment, visit [https://mastering-flask.herokuapp.com/](https://mastering-flask.herokuapp.com/).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看在 Heroku 部署中的应用程序运行情况，请访问 [https://mastering-flask.herokuapp.com/](https://mastering-flask.herokuapp.com/).
- en: Using Heroku Postgres
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Heroku Postgres
- en: 'Maintaining a database properly is a full-time job. Thankfully, we can use
    one of Heroku''s built-in features in order to automate this process for us. Heroku
    Postgres offers a database that is maintained and hosted entirely by Heroku. Because
    we are using SQLAlchemy, using Heroku Postgres is trivial. In your dyno''s dashboard,
    there is a link to your Heroku Postgres information. By clicking on it, you will
    be taken to a page similar to the following screenshot:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正确维护数据库是一项全职工作。幸运的是，我们可以使用Heroku的内置功能来自动化这一过程。Heroku Postgres提供了一个由Heroku维护和完全托管的数据库。因为我们使用SQLAlchemy，所以使用Heroku
    Postgres非常简单。在您的dyno仪表板中，有一个链接到您的Heroku Postgres信息。通过点击它，您将进入一个类似于以下截图的页面：
- en: '![](img/d7d77ee8-61c8-46ff-9354-bea69d15beca.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d7d77ee8-61c8-46ff-9354-bea69d15beca.png)'
- en: By clicking on the URL field, you will be given an SQLAlchemy URL, which you
    can copy directly to your production configuration object.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击URL字段，您将获得一个SQLAlchemy URL，您可以直接将其复制到您的生产配置对象中。
- en: Using Celery on Heroku
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Heroku上使用Celery
- en: 'We have our production web server and database set up, but we still need to
    set up Celery. Using one of Heroku''s many plugins, we can host a RabbitMQ instance
    in the cloud, while running the Celery worker on the dyno. The first step is to
    tell Heroku to run your Celery worker in `Procfile`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经设置了生产Web服务器和数据库，但我们仍然需要设置Celery。使用Heroku的众多插件之一，我们可以在云中托管一个RabbitMQ实例，同时在dyno上运行Celery工作进程。第一步是告诉Heroku在`Procfile`中运行您的Celery工作进程：
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, to install the Heroku RabbitMQ plugin with the free plan (the `lemur`
    plan), use the following command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了使用免费计划（`lemur`计划）安装Heroku RabbitMQ插件，请使用以下命令：
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To get the full list of Heroku add-ons, go to [https://elements.heroku.com/addons](https://elements.heroku.com/addons).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取Heroku附加组件的完整列表，请访问[https://elements.heroku.com/addons](https://elements.heroku.com/addons)。
- en: 'At the same location on the dashboard where Heroku Postgres was listed, you
    will now find CloudAMQP:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在仪表板上列出Heroku Postgres的位置，您现在将找到CloudAMQP：
- en: '![](img/a0579d3f-1e34-4b2f-b01d-5b8ebfb9ac06.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a0579d3f-1e34-4b2f-b01d-5b8ebfb9ac06.png)'
- en: 'Clicking on CloudAMQP will also give you a screen with a URL, which you can
    copy and paste into your production configuration:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 点击CloudAMQP也会给您一个带有URL的屏幕，您可以将它复制并粘贴到您的生产配置中：
- en: '![](img/ed113cc9-8bb1-4a24-b6be-0dce512a0284.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ed113cc9-8bb1-4a24-b6be-0dce512a0284.png)'
- en: Deploying on Amazon Web Services
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Amazon Web Services上部署
- en: '**Amazon Web Services** (**AWS**) is a collection of services maintained by
    Amazon, and built on top of the same infrastructure that runs Amazon.com. To deploy
    our Flask code, we will be using Amazon Elastic Beanstalk in this section, while
    the database will be hosted on Amazon''s **Relational Database Service** (**RDS**),
    and our messaging queue for Celery will be hosted on Amazon''s **Simple Queue
    Service** (**SQS**).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**亚马逊网络服务**（**AWS**）是由亚马逊维护的一组服务，建立在运行Amazon.com的相同基础设施之上。在本节中，我们将使用Amazon
    Elastic Beanstalk来部署我们的Flask代码，而数据库将托管在亚马逊的**关系数据库服务**（**RDS**）上，我们的Celery消息队列将托管在亚马逊的**简单队列服务**（**SQS**）上。'
- en: Using Flask on Amazon Elastic Beanstalk
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Amazon Elastic Beanstalk上使用Flask
- en: Elastic Beanstalk is a platform for web applications that offers many powerful
    features for developers, so they don't have to worry about maintaining servers.
    For example, your Elastic Beanstalk application will automatically scale by utilizing
    more and more servers as the number of people using your app at once grows. For
    Python apps, Elastic Beanstalk uses Apache, in combination with `mod_wsgi`, to
    connect to WSGI applications—if your deployment is simple with mid-to-low load,
    there is no extra configuration needed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Beanstalk是一个为Web应用程序提供的平台，它为开发者提供了许多强大的功能，因此他们不必担心维护服务器。例如，随着同时使用您应用程序的人数增加，您的Elastic
    Beanstalk应用程序将自动通过利用更多服务器进行扩展。对于Python应用程序，Elastic Beanstalk使用Apache，结合`mod_wsgi`连接到WSGI应用程序——如果您的部署简单，负载中等或较低，则不需要额外配置。
- en: 'Before we begin, you will need an Amazon.com account to log in to the console.
    Next, you need to install **awscli** and configure it with your credentials—you
    must generate an AWS access key and secret: go to the AWS console, choose IAM
    service, choose your user, then choose the Security Credentials tab, and click
    on the Create access key. Next, we need to install awsebcli to manage Elastic
    Beanstalk from the CLI:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，您需要一个Amazon.com账户来登录控制台。接下来，您需要安装**awscli**并使用您的凭证配置它——您必须生成AWS访问密钥和密钥：前往AWS控制台，选择IAM服务，选择您的用户，然后选择“安全凭证”选项卡，点击“创建访问密钥”。接下来，我们需要安装awsebcli来从命令行管理Elastic
    Beanstalk：
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, from the root directory of our project, we are going to configure the
    CLI and create a new Elastic Beanstalk application:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，从我们项目的根目录开始，我们将配置 CLI 并创建一个新的 Elastic Beanstalk 应用程序：
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Elastic Beanstalk looks for a file named `application.py` in your project directory,
    and it expects to find a WSGI application, named `application`, in that file:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Beanstalk 会查找项目目录中的 `application.py` 文件，并期望在该文件中找到一个名为 `application`
    的 WSGI 应用程序：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, we are going to create a development environment. Each Elastic Beanstalk
    application can contain one or many environments. But as things currently stand,
    our application will fail—we need to tell Elastic Beanstalk how to install Flask-YouTube
    on Python's virtual environment and initialize the database. To do this, we need
    to extend the default setup.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个开发环境。每个 Elastic Beanstalk 应用程序可以包含一个或多个环境。但就目前情况来看，我们的应用程序将会失败——我们需要告诉
    Elastic Beanstalk 如何在 Python 的虚拟环境中安装 Flask-YouTube 并初始化数据库。为此，我们需要扩展默认设置。
- en: 'In the root directory, we need a directory named `.ebextensions`. This is where
    we create a lot of extra configuration and setup scripts. In `.ebextensions`,
    we create two shell scripts that will run in the post-deploy phase. So, in the `.ebextensions/10_post_deploy.config` file,
    add the following code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在根目录下，我们需要一个名为 `.ebextensions` 的目录。这是我们在其中创建大量额外配置和设置脚本的地方。在 `.ebextensions`
    中，我们创建两个将在部署后阶段运行的 shell 脚本。因此，在 `.ebextensions/10_post_deploy.config` 文件中，添加以下代码：
- en: '[PRE23]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Using YAML notation here, we tell Elastic Beanstalk to create two shell scripts
    to install Flask-YouTube and create or migrate the database. The location of these
    files is special—`/opt/elasticbeanstalk/hooks/appdeploy/post` is where we can
    drop scripts to be executed after deploying. These scripts are executed in alphabetic
    order. Also, take note of the following locations:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 YAML 语法，我们告诉 Elastic Beanstalk 创建两个 shell 脚本来安装 Flask-YouTube 并创建或迁移数据库。这些文件的位置是特殊的——`/opt/elasticbeanstalk/hooks/appdeploy/post`
    是我们可以放置在部署后执行的脚本的地方。这些脚本按字母顺序执行。同时，请注意以下位置：
- en: '`/opt/python/current/app`: This is the deploy location of the application.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/current/app`: 这是应用程序的部署位置。'
- en: '`/opt/python/current/env`: This is a file containing defined environment variables
    on Elastic Beanstalk.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/current/env`: 这是一个包含 Elastic Beanstalk 上定义的环境变量的文件。'
- en: '`/opt/python/run/venv`: This is python''s `virtualenv`, and is where Elastic
    Beanstalk installed all our defined dependencies.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/opt/python/run/venv`: 这是指定的 Python 的 `virtualenv`，也是 Elastic Beanstalk 安装所有定义的依赖项的地方。'
- en: 'Now, for our environment creation, run the following commands:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了创建我们的环境，运行以下命令：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, after the environment has finished provisioning the infrastructure
    and deployment, we can check out our application using the following command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在环境完成基础设施和部署配置后，我们可以使用以下命令检查我们的应用程序：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To deploy new versions of our application, we just have to run this command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署我们应用程序的新版本，我们只需运行此命令：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that our development environment uses SQLite, so the database is on a file
    on the web server itself. On each deployment or instance recreation, this database
    is recreated.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的开发环境使用 SQLite，因此数据库位于 Web 服务器上的一个文件中。在每次部署或实例重建时，此数据库都会被重新创建。
- en: Using Amazon RDS
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon RDS
- en: '**Amazon RDS** is a database-hosting platform in the cloud that automatically
    manages several things, such as recovery on node failure, scheduled backups, and
    master/slave setups.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon RDS** 是一个云数据库托管平台，它自动管理多个方面，例如节点故障时的恢复、计划备份和主/从设置。'
- en: To use RDS, go to the Services tab on the AWS console and click on Relational
    Database Service.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 RDS，请转到 AWS 控制台的“服务”选项卡，并点击“关系数据库服务”。
- en: Now, create and configure a new database—make sure that on the Publicly accessible option,
    you choose No. Choose the same VPC as the instances, and register your admin credentials
    carefully. Now, wait a few minutes for the instance creation. After that, choose
    your instance, go to the details configuration, and find the field for the **endpoint**—it
    should look something like `myblog.c7pdwgffmbqdm.eu-central-1.rds.amazonaws.com`.
    Our production configuration uses system environment variables to set up the database
    URI, so we have to configure Elastic Beanstalk to set the `DB_URI` environment
    variable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建并配置一个新的数据库——确保在**公开访问**选项中选择否。选择与实例相同的 VPC，并仔细登记您的管理员凭证。现在，等待几分钟以创建实例。之后，选择您的实例，转到详细配置，并找到**端点**字段——它应该看起来像
    `myblog.c7pdwgffmbqdm.eu-central-1.rds.amazonaws.com`。我们的生产配置使用系统环境变量来设置数据库 URI，因此我们必须配置
    Elastic Beanstalk 以设置 `DB_URI` 环境变量。
- en: 'To use these environment variables, we need to change our blog''s `config.py` file
    to use the actual OS environment variables, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些环境变量，我们需要将博客的 `config.py` 文件更改为使用实际的 OS 环境变量，如下所示：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Make sure your instances can connect to the database. If you chose the security
    group default options and RDS creation, then the wizard will have created a security
    group for you (the default name is '`rds-launch-wizard`'). On EC2, edit this security
    group and open port 3306 to your instances' VPC CIDR.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的实例可以连接到数据库。如果您选择了安全组默认选项和 RDS 创建，那么向导将为您创建一个安全组（默认名称为 '`rds-launch-wizard`'）。在
    EC2 上，编辑此安全组并打开 3306 端口到您的实例的 VPC CIDR。
- en: 'In `.ebextensions`, take a look at the `01_env.config`—this is where we set
    our environment variables:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `.ebextensions` 中查看 `01_env.config`——这是我们设置环境变量的地方：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, let''s create the production environment with the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用以下命令创建生产环境：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Using Celery with Amazon SQS
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Celery 和 Amazon SQS
- en: In order to use Celery on AWS, we need to have our Elastic Beanstalk instance
    run our Celery worker in the background, as well as set up an SQS messaging queue.
    For Celery to support SQS, it needs to install a helper library from `pip`. Once
    more, verify that our `requirements.txt` file contains the **boto3** package.
    Elastic Beanstalk will look at this file and create a virtual environment from
    it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 AWS 上使用 Celery，我们需要让我们的 Elastic Beanstalk 实例在后台运行 Celery 工作进程，并设置 SQS 消息队列。为了使
    Celery 支持 SQS，它需要从 `pip` 安装一个辅助库。再次确认我们的 `requirements.txt` 文件包含 **boto3** 包。Elastic
    Beanstalk 将查看此文件并从中创建一个虚拟环境。
- en: 'Setting up a new messaging queue on SQS is very easy. Go to the Services tab
    and click on Simple Queue Service in the applications tab, then click on **Create
    New Queue**. After a very short configuration screen, you should see a screen
    much like the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SQS 上设置新的消息队列非常简单。转到“服务”选项卡，然后在“应用程序”选项卡中点击“简单队列服务”，然后点击**创建新队列**。在非常简短的配置屏幕后，你应该会看到一个类似于以下屏幕的界面：
- en: '![](img/f22c7501-612e-4e62-b7cc-0f12df21d56a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f22c7501-612e-4e62-b7cc-0f12df21d56a.png)'
- en: Next, we have to give our instances access to the newly created SQS. The easiest
    way to do this is editing the Elastic Beanstalk default instance profile (this
    is not recommended, however—you should create a separate instance profile and
    associate all your instances with it using `.ebextensions` option settings). The
    default IAM instance profile is named [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role).
    Go to IAM service, then roles, then choose the [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role) role.
    Next, click on Add inline policy and follow the wizard to give access to the newly
    created SQS.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须让我们的实例访问新创建的 SQS。最简单的方法是编辑 Elastic Beanstalk 默认实例配置文件（不过这并不推荐——您应该创建一个单独的实例配置文件，并使用
    `.ebextensions` 选项设置将所有实例与其关联）。默认 IAM 实例配置文件名为 [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role)。转到
    IAM 服务，然后选择角色，然后选择 [aws-elasticbeanstalk-ec2-role](https://console.aws.amazon.com/iam/home#/roles/aws-elasticbeanstalk-ec2-role)
    角色。接下来，点击**添加内联策略**并按照向导为新建的 SQS 提供访问权限。
- en: 'Now we have to change our `CELERY_BROKER_URL` to the new URL, which takes the
    following format:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须将我们的 `CELERY_BROKER_URL` 改为新 URL，其格式如下：
- en: '[PRE30]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Change the `AWS_ACCOUNT_ID` value to your AWS account ID.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `AWS_ACCOUNT_ID` 的值更改为您的 AWS 账户 ID。
- en: 'Finally, we need to tell Elastic Beanstalk to run a Celery worker in the background.
    Once more, we can do this in `.ebextensions`. Create a file named `11_celery_start.config`,
    and insert the following code into it:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要告诉Elastic Beanstalk在后台运行Celery工作进程。再一次，我们可以在`.ebextensions`中这样做。创建一个名为`11_celery_start.config`的文件，并将以下代码插入其中：
- en: '[PRE31]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that this kind of Celery worker deployment lives on the web server (which
    is not recommended), and will also scale along with the web servers in line with
    demand. A better option would be to explore the worker feature from Elastic Beanstalk,
    but this would imply a complete rework of the feature, and we'd suffer from subsequent
    vendor lock-in.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种Celery工作部署存在于Web服务器上（这并不推荐），并且会随着Web服务器按需扩展。更好的选择是探索Elastic Beanstalk的工作功能，但这将意味着对功能进行彻底的重构，我们可能会遭受后续的供应商锁定。
- en: Using Docker
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker
- en: Docker is a container-based technology created in 2013 by Docker, Inc. Container
    technology is not new, and has been around for some time on Unix OS, with chroot
    created in 1982, Solaris Zones in 2004, and WPAR available on AIX or OS400 systems
    (although WPAR is more of a virtualization technology than a container). Later,
    two important features were integrated on Linux: **namespaces**, which isolate
    OS function names, and **cgroups**, a collection of processes that are bound by
    configuration and resource limits. These new features gave birth to Linux containers,
    so why use Docker?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是 Docker, Inc. 在 2013 年创建的一种基于容器的技术。容器技术并不新鲜，Unix 操作系统上已经存在一段时间了，1982
    年就有 chroot，2004 年有 Solaris Zones，AIX 或 OS400 系统上也有 WPAR（尽管 WPAR 更像是一种虚拟化技术而不是容器）。后来，Linux
    集成了两个重要的特性：**namespaces**，它隔离了 OS 功能名称，以及 **cgroups**，这是一个受配置和资源限制约束的进程集合。这些新特性催生了
    Linux 容器，那么为什么还要使用 Docker 呢？
- en: Mainly, because Docker made configuration definitions simple. Using a very easy-to-write
    Dockerfile, you can describe how to provision your container and create a new
    image with it. Each Dockerfile line will create a new FS layer using UnionFS,
    which makes changes very quick to apply, and it's equally easy to roll back and
    forward between changes. Also Docker, Inc. created an open image repository, where
    you can find quality images of almost any Linux software available . We have already
    used some of these for Redis and RabbitMQ in [Chapter 9](5672073f-7a18-4865-9800-a2124147042c.xhtml),
    *Creating Asynchronous Tasks with Celery*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 主要是因为Docker使配置定义变得简单。使用非常容易编写的Dockerfile，您可以描述如何配置您的容器并使用它创建一个新的镜像。每个Dockerfile行都会使用UnionFS创建一个新的文件系统层，这使得更改非常快速地应用，并且同样容易回滚和前进到更改。此外，Docker,
    Inc. 创建了一个开放的镜像仓库，您可以在其中找到几乎所有Linux软件的质量镜像。我们已经在[第9章](5672073f-7a18-4865-9800-a2124147042c.xhtml)，*使用Celery创建异步任务*中使用了一些这些镜像。
- en: 'Docker has gained enormous traction and hype. Some of its best features are
    the following:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 已经获得了巨大的关注和炒作。其中一些最好的特性如下：
- en: 'Solving dependency issues from the OS: Since we are packing a thin OS with
    your container image, it is safe to assume that what runs on your laptop will
    run on production as well.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决来自操作系统的依赖问题：由于我们正在将一个薄的操作系统打包到您的容器镜像中，因此可以安全地假设在您的笔记本电脑上运行的内容在生产环境中也能运行。
- en: Containers are very light, and users are able to run multiple containers on
    the same VM or hardware host, which can reduce operations costs and increase efficiency.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器非常轻量，用户可以在同一虚拟机或硬件主机上运行多个容器，这可以降低运营成本并提高效率。
- en: Containers bootstrap very quickly, enabling your infrastructure to scale equally
    quickly, if, for example, you needed to address an increase in workload.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器启动非常快，使您的基础设施能够快速扩展，例如，如果您需要处理工作负载的增加。
- en: Developers can easily share their application with other developers using containers.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者可以轻松地使用容器与其他开发者共享他们的应用程序。
- en: 'Docker supports DevOps principles: developers and operations can and should
    work together on the image and architecture definition, using Dockerfile or Docker
    Compose.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 支持DevOps原则：开发者和运维人员可以在镜像和架构定义上共同工作，使用Dockerfile或Docker Compose。
- en: 'If we consider the differences in features on offer from Docker containers
    versus VMs, let''s remember that containers share the same kernel and normally
    run a single process, while VMs run a fully featured guest OS:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑Docker容器与虚拟机提供的功能差异，让我们记住容器共享相同的内核并且通常运行单个进程，而虚拟机运行一个完整的客户操作系统：
- en: '![](img/5ef2a593-2af8-4fb8-9282-79e7c50ac68a.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ef2a593-2af8-4fb8-9282-79e7c50ac68a.png)'
- en: This architecture makes containers very lightweight and quick to spawn.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构使容器非常轻量且快速启动。
- en: Creating Docker images
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Docker 镜像
- en: Throughout the previous chapters, our Blog application has grown from a simple
    three-tier architecture to a multi-tier one. We now need to address a web server,
    database, cache system, and queue. We are going to define each of these layers
    as Docker containers.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们的 Blog 应用程序已经从简单的三层架构发展到多层架构。我们现在需要处理 web 服务器、数据库、缓存系统和队列。我们将定义每个这些层为
    Docker 容器。
- en: First, let's begin with our web server and Flask application. For this, we will
    be using an Nginx frontend, and a WSGI, called uWSGI, for the backend.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从我们的 web 服务器和 Flask 应用程序开始。为此，我们将使用 Nginx 前端，以及后端使用的 WSGI，称为 uWSGI。
- en: 'A Dockerfile is a text file that contains special instructions with which we
    use to specify our Docker image and how it should be run. The build process is
    going to execute the commands one by one, creating a new layer on each one. Some
    of the most used Dockerfile commands include the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 是一个包含特殊指令的文本文件，我们使用它来指定我们的 Docker 镜像以及如何运行它。构建过程将逐个执行命令，在每个命令上创建一个新的层。一些最常用的
    Dockerfile 命令包括以下内容：
- en: '`FROM`**: **Specifies the base image that our new image is based upon. We can
    start from a really thin OS, such as Alpine, or directly from an RabbitMQ image.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROM`**: **指定我们的新镜像基于的基础镜像。我们可以从一个非常薄的操作系统开始，例如 Alpine，或者直接从 RabbitMQ 镜像开始。'
- en: '`EXPOSE`:Informs Docker that the container listens on a specified network port/protocol.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EXPOSE`: 通知 Docker 容器监听指定的网络端口/协议。'
- en: '`ENV`:Sets environment variables.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ENV`: 设置环境变量。'
- en: '`WORKDIR`: Establishes the base directory for the Dockerfile.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WORKDIR`: 为 Dockerfile 建立基本目录。'
- en: '`RUN`:Runs bash Linux commands on a new layer. This is normally used to install
    additional packages.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RUN`: 在新层上运行 bash Linux 命令。这通常用于安装额外的包。'
- en: '`COPY`:Copies files or directories from local filesystem to the Docker image.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`COPY`: 从本地文件系统复制文件或目录到 Docker 镜像。'
- en: '`CMD`:There can be only one instance of CMD. It specifies how the container
    should be run.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CMD`: 只能有一个 CMD 实例。它指定了如何运行容器。'
- en: '`ENTRYPOINT`: This has the same objective as CMD, but is a script in Docker.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ENTRYPOINT`: 这与 CMD 有相同的目标，但在 Docker 中是一个脚本。'
- en: For a full reference of Dockerfile commands, check out the documentation at [https://docs.docker.com/engine/reference/builder/#usage](https://docs.docker.com/engine/reference/builder/#usage).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Dockerfile 命令的完整参考，请参阅[https://docs.docker.com/engine/reference/builder/#usage](https://docs.docker.com/engine/reference/builder/#usage)文档。
- en: 'Our directory structure for Docker deploy is going to be the following:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为 Docker 部署的目录结构将是以下内容：
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The images we are going to create will be used with Docker Compose (more on
    this later in this chapter), so they will not work on a standalone basis. If you
    don't want to use Docker Compose, very few modification are needed for the images
    to work—you just have to change the `prod.env` file.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要创建的镜像将用于 Docker Compose（本章后面将详细介绍），因此它们不能独立工作。如果您不想使用 Docker Compose，对镜像进行少量修改即可使其工作——您只需更改`prod.env`文件即可。
- en: 'First, let''s create a Dockerfile for our web server. We will use a previous
    image that already contains NGINX and uWSGI, saving us the work to install and
    configure them. Our `Dockerfile_frontend` is the Dockerfile containing the definition
    for creating frontend images:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们为我们的 web 服务器创建一个 Dockerfile。我们将使用一个已经包含 NGINX 和 uWSGI 的先前镜像，这样我们就可以节省安装和配置它们的工作。我们的`Dockerfile_frontend`是包含创建前端镜像定义的
    Dockerfile：
- en: '[PRE33]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: First, in the preceding snippet, we base our image on `uwsgi-nginx:python3.6`,
    which means we are going to use Python 3.6\. Next, we create and set the directory
    where our application will live—this will be in `/srv/app`. Then we copy all our
    local content (myblog code) to the image itself using the `COPY . .`. Next, we
    copy the configuration file for our WSGI, finally configuring the number of workers
    that NGINX will use. At the end, we inform Docker that this image will be listening
    on port 80, using `EXPOSE 80`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在前面的片段中，我们将我们的镜像基于`uwsgi-nginx:python3.6`，这意味着我们将使用 Python 3.6。接下来，我们创建并设置应用程序将驻留的目录——这将是`/srv/app`。然后，我们使用`COPY
    . .`将所有本地内容（myblog 代码）复制到镜像本身。接下来，我们复制 WSGI 的配置文件，最后配置 NGINX 将使用的工人数。最后，我们通知 Docker
    该镜像将在端口 80 上监听，使用`EXPOSE 80`。
- en: 'Next, let''s take a look at our Celery worker Dockerfile:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一下我们的 Celery 工作器 Dockerfile：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This time, our base image is going to be Ubuntu (in particular, a really thin
    Ubuntu version for Docker). We are going to use the **supervisor** Python package
    to monitor and launch our Celery process, so if Celery crashes for some reason,
    supervisor will restart it. So, at the OS level, we are installing the supervisor,
    Python 3, and MySQL client packages. Take a look at the `worker_entrypoint.sh` shell
    script in the preceding code block, where we are doing some interesting things:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们的基础镜像将是 Ubuntu（特别是，一个非常薄的 Ubuntu 版本用于 Docker）。我们将使用 **supervisor** Python
    包来监控和启动我们的 Celery 进程，所以如果 Celery 由于某种原因崩溃，supervisor 将重新启动它。因此，在操作系统级别，我们正在安装
    supervisor、Python 3 和 MySQL 客户端包。看看前面代码块中的 `worker_entrypoint.sh` shell 脚本，我们在那里做一些有趣的事情：
- en: We are waiting for MySQL to become available. When using Docker Compose, we
    can define the order that each task (that is, each Docker container) is launched,
    but we don't have a way to know if the service is already available.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在等待 MySQL 变得可用。当使用 Docker Compose 时，我们可以定义每个任务（即每个 Docker 容器）启动的顺序，但我们没有方法知道服务是否已经可用。
- en: Next, we use the Flask CLI and Alembic to create or migrate our database.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们使用 Flask CLI 和 Alembic 创建或迁移我们的数据库。
- en: Finally, we insert test data to our database (simply because it's nice to have
    for the readers), so that when you launch the app, it's in a workable state with
    some fake post data already present.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将测试数据插入到我们的数据库中（简单来说，对读者来说是个好东西），这样当你启动应用程序时，它已经处于可工作状态，并且已经存在一些假帖子数据。
- en: 'To build and create our images, execute the following Docker commands on the
    shell in the root directory of our project:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建和创建我们的镜像，请在项目根目录的 shell 中执行以下 Docker 命令：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This will create an image named **myblog **with the tag **latest**. As part
    of production best practices, you should tag your images with your project version,
    also using a **git **tag. This way, we can always be sure what code is in which
    images; for example, what changed between `myblog:1.0` and `myblog:1.1`.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为 **myblog** 的镜像，带有 **latest** 标签。作为生产最佳实践的组成部分，你应该使用项目版本给你的镜像打标签，也使用
    **git** 标签。这样，我们总能确保代码在哪个镜像中；例如，`myblog:1.0` 和 `myblog:1.1` 之间有什么变化。
- en: 'Finally, create the Celery worker image with the following command:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用以下命令创建 Celery 工作进程镜像：
- en: '[PRE36]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now that we have our custom images created, we are ready to go to the next section,
    where we are going define our of all infrastructure and link the containers to
    each other.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了自定义镜像，我们可以进入下一节，在那里我们将定义所有基础设施并将容器相互连接。
- en: Docker Compose
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Compose
- en: '**Docker Compose** is a tool for defining our multi-layer application. This
    is where we define all the services needed to run our application, configure them,
    and link them together.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker Compose** 是定义我们多层应用程序的工具。这是我们定义运行应用程序所需的所有服务、配置它们并将它们连接在一起的地方。'
- en: 'Docker Compose is based on YAML files, which is where all the definition happens,
    so let''s dive right into it and take a look at the `deploy/docker/docker-compose.yaml` file:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 基于 YAML 文件，所有定义都发生在这里，所以让我们直接进入它，看看 `deploy/docker/docker-compose.yaml`
    文件：
- en: '[PRE37]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In Docker Compose, we have defined the following services:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Docker Compose 中，我们定义了以下服务：
- en: '**mysql**: This is based on the Docker Hub community image for MySQL 5.7\.
    All the custom configuration happens with environment variables, as defined in
    the `prod.env` file.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mysql**：这是基于 Docker Hub 社区版的 MySQL 5.7 镜像。所有自定义配置都使用环境变量完成，如 `prod.env` 文件中定义的那样。'
- en: '**rmq**: Rabbit MQ is based on the Docker Hub community image, customized by
    us to create user credentials, cookies, and VHOST. This will install the management
    interface as well, which can be accessed on `http://localhost:15672`.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**rmq**：Rabbit MQ 基于我们定制的 Docker Hub 社区镜像，创建用户凭据、cookies 和 VHOST。这将安装管理界面，可以通过
    `http://localhost:15672` 访问。'
- en: '**redis**: This is the Redis service for our cache.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**redis**：这是我们缓存用的 Redis 服务。'
- en: '**worker**: This uses our previously built `myblog_worker` Docker image.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作进程**：这使用我们之前构建的 `myblog_worker` Docker 镜像。'
- en: '**frontend**: This uses our previously built `myblog_worker` Docker image.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前端**：这使用我们之前构建的 `myblog_worker` Docker 镜像。'
- en: This is a very simple composer definition. Note `depends_on`, where we define
    which services depend on other services. So, for example, our frontend service
    is going to depend on the database and Rabbit MQ. The `ports` key is a list of
    exposed ports; in this case, the frontend port 80 is going to be exposed by the
    Docker host on port 80 also. This way, we can access our application on the Docker
    host IP port 80, or by using a load balancer in front of the Docker hosts. On
    your machine with Docker already installed, you can access the application on ` http://localhost`.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的 composer 定义。注意 `depends_on`，其中我们定义了哪些服务依赖于其他服务。例如，我们的前端服务将依赖于数据库和
    Rabbit MQ。`ports` 键是一个公开端口的列表；在这种情况下，前端端口 80 将由 Docker 主机上的端口 80 公开。这样，我们就可以通过
    Docker 主机的 IP 端口 80 或通过在 Docker 主机前面使用负载均衡器来访问我们的应用程序。在已经安装 Docker 的机器上，您可以通过
    `http://localhost` 访问应用程序。
- en: The use of the `prod.env` file is important, because this way, we can define
    different configurations for different environments and still use the same compose
    file. Using the same compose file across environments obeys another Twelve-Factor
    App rule about making the infrastructure components the same across all environments.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `prod.env` 文件非常重要，因为这样我们可以为不同的环境定义不同的配置，同时仍然使用相同的 compose 文件。在环境中使用相同的 compose
    文件遵守了十二要素应用规则中关于使基础设施组件在所有环境中相同的规定。
- en: 'Let''s take a look at the `prod.env` file:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `prod.env` 文件：
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This file environment variables will set actual OS-level environment variables
    so that it's simple to use them on the configuration file for our application.
    This will comply with another of the Twelve-Factor App rules from `https://12factor.net/`.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件环境变量将设置实际的操作系统级别环境变量，以便在应用程序的配置文件中简单使用。这将符合来自 `https://12factor.net/` 的十二要素应用规则之一。
- en: At the top, we set our application environment for production configuration
    using `WEBAPP_ENV=Prod`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部，我们使用 `WEBAPP_ENV=Prod` 设置我们的应用程序生产配置环境。
- en: The `MYSQL_*` variables is where we configure the MySQL 5.7 container. We set
    the root password and an initial database to create (if necessary) a user and
    password for this database.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`MYSQL_*` 变量是我们配置 MySQL 5.7 容器的地方。我们设置了 root 密码，并设置了一个初始数据库来创建（如果需要）为该数据库创建用户和密码。'
- en: It's important to note that the `REDIS_HOST` , `DB_URI`, `CELERY_BROKER_URL` variables
    are using the actual host names that each container will use to communicate with
    the other containers. By default, these are the service names, which makes everything
    pretty simple. So, the frontend container accesses the database using the `db` network
    hostname.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，`REDIS_HOST`、`DB_URI`、`CELERY_BROKER_URL` 这些变量正在使用每个容器实际使用的实际主机名来与其他容器进行通信。默认情况下，这些是服务名称，这使得一切变得相当简单。因此，前端容器使用
    `db` 网络主机名来访问数据库。
- en: 'Finally, let''s start our application:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们开始我们的应用程序：
- en: '[PRE39]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Wait for all the containers to start up, then open your browser and go to `http://localhost`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 等待所有容器启动，然后打开您的浏览器并转到 `http://localhost`。
- en: Deploying Docker containers on AWS
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS 上部署 Docker 容器
- en: To deploy on AWS, we are going to use the **Amazon Elastic Container Service**
    (**ECS**). ECS is a service that provides a scalable cluster for Docker, without
    the need to install any software to orchestrate your containers. It's based on
    **AWS Auto Scaling Groups** (**ASG**), which scale instances up or down with Docker
    installed. This scaling is triggered by monitoring metrics, such as CPU usage
    or network load. ECS also migrates all containers from an instance that, for some
    reason, terminates, or gets its service impaired. ECS thus acts as a cluster.
    After this, the ASG will spawn a new instance to replace the faulty one.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 AWS 上部署，我们将使用 **Amazon Elastic Container Service**（**ECS**）。ECS 是一个为 Docker
    提供可扩展集群的服务，无需安装任何软件来编排您的容器。它基于 **AWS Auto Scaling Groups**（**ASG**），该组使用 Docker
    安装实例进行扩展或缩减。这种扩展是由监控指标触发的，例如 CPU 使用率或网络负载。ECS 还会将所有容器从某个原因终止或服务受损的实例迁移出来。因此，ECS
    充当集群的角色。之后，ASG 将启动一个新实例来替换有故障的实例。
- en: CloudFormation Basics
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CloudFormation 基础
- en: AWS provides many services, each of which has many configuration options. You
    also need to wire these services up. To effectively and reliably create, configure,
    update, or destroy these services, we are going to show you how to use an **IaC**
    (**Infrastructure as code**) technology from AWS, called CloudFormation. **CloudFormation**
    is not a complex technology, but follows the extension of all AWS services and
    configuration options. The details and operation of CloudFormation could be subject
    to a book on its own.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了许多服务，每个服务都有许多配置选项。您还需要将这些服务连接起来。为了有效地和可靠地创建、配置、更新或销毁这些服务，我们将向您展示如何使用AWS的**IaC**（**基础设施即代码**）技术，称为CloudFormation。**CloudFormation**并非复杂的技术，而是遵循所有AWS服务和配置选项的扩展。CloudFormation的详细信息和操作可能需要一本书来专门介绍。
- en: 'CloudFormation is an extended data structure that you write using JSON or YAML.
    I say extended, because it''s possible to use references, functions, and conditions.
    A CloudFormation file is composed of the following sections:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: CloudFormation是一个扩展的数据结构，您可以使用JSON或YAML编写。我说扩展，因为可以使用引用、函数和条件。一个CloudFormation文件由以下部分组成：
- en: '[PRE40]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s take a quick look at the provided CloudFormation file in `./deploy/docker/cfn_myblog.yml`.
    We are going to follow all the CloudFormation sections, one be one. First, let''s
    examine the **Parameters** section:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看提供的CloudFormation文件`./deploy/docker/cfn_myblog.yml`。我们将逐个遵循所有CloudFormation部分。首先，让我们检查**参数**部分：
- en: '[PRE41]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Without going into much detail, in this file, an input parameter is defined
    by a name, and may contain a description, a type, a default value, and rules for
    accepted values. All these values will be referenced later when configuring our
    infrastructure. These values are going to be filled when deploying or updating
    the CloudFormation stack.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入细节，在这个文件中，一个输入参数由一个名称定义，可能包含描述、类型、默认值和接受值的规则。所有这些值将在配置我们的基础设施时被引用。这些值将在部署或更新CloudFormation堆栈时填写。
- en: 'Next, look at the **Mappings** section:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，看看**映射**部分：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is simply a convenient data structure for mapping AWS regions into AMIs.
    An AMI is a base OS image that we are using for our Docker VMs. Each AMI has a
    different identification in each region, so we need to map them out to make our
    stack deployable on any AWS region. On our case, we will be using Amazon ECS-optimized
    Linux.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个方便的数据结构，用于将AWS区域映射到AMI。AMI是我们用于我们的Docker VMs的基础操作系统镜像。每个区域中的AMI都有一个不同的标识符，因此我们需要将它们映射出来，以便我们的堆栈可以在任何AWS区域上部署。在我们的案例中，我们将使用Amazon
    ECS优化的Linux。
- en: 'Now, let''s consider the **Metadata** section:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑**元数据**部分：
- en: '[PRE43]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here, we are declaring an `Interface` to group our parameters. This is just
    to make the parameters display in a nicer way to whomever is going to deploy the
    stack. Remember that the parameters section is a dictionary, and that dictionary
    keys have no order.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们声明了一个`Interface`来分组我们的参数。这只是为了让参数以更美观的方式显示给将要部署堆栈的人。记住，参数部分是一个字典，且该字典的键是无序的。
- en: 'The main, and more important section is **Resources**. We are not going to
    go into full detail on this, rather, we''ll just quickly highlight the main infrastructure
    resources we are going to create and how they are wired. First, for the database,
    we are going to use another AWS service, called **RDS**, and create a MySQL server:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 主要且更为重要的部分是**资源**。我们不会对此进行详细说明，而是快速概述我们将要创建的主要基础设施资源及其连接方式。首先，对于数据库，我们将使用另一个AWS服务，称为**RDS**，并创建一个MySQL服务器：
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Each resource has a type. For RDS, this is `AWS::RDS:DBInstance`. Each type
    has its own specific set of properties. Also, notice how `!Ref` declares values
    that are references from other resources or parameters. `DBUsername` and `DBPassword` are
    parameters, but `DBSubnetGroup` and `DBSecurityGroup` are resources created by
    CloudFormation to set up the network ACL and subnet placement for our database.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 每个资源都有一个类型。对于RDS，这是`AWS::RDS:DBInstance`。每种类型都有自己的特定属性集。注意`!Ref`如何声明来自其他资源或参数的值。"DBUsername"和"DBPassword"是参数，但"DBSubnetGroup"和"DBSecurityGroup"是由CloudFormation创建的资源，用于设置数据库的网络ACL和子网放置。
- en: 'The ECS cluster resource declaration is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ECS集群资源声明如下：
- en: '[PRE45]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: All these definitions belong to the ECS cluster. This cluster can be used to
    provision many different applications, so it would make sense to declare these
    definitions on a separate CloudFormation file, or use nested stacks. To simplify
    the deployment, we will use a single file to create our application. First, we
    create the ECS cluster, and set its name to be a concatenation with the `Environment` and `ApplicationName` parameters. This
    is done using the `!Sub` CloudFormation function.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些定义都属于 ECS 集群。这个集群可以用于部署许多不同的应用程序，因此在这些定义上声明单独的 CloudFormation 文件或使用嵌套堆栈是有意义的。为了简化部署，我们将使用单个文件来创建我们的应用程序。首先，我们创建
    ECS 集群，并设置其名称为 `Environment` 和 `ApplicationName` 参数的连接。这是通过 `!Sub` CloudFormation
    函数完成的。
- en: Next, we declare the **Auto Scaling Group** (**ASG**) for our cluster, and set
    up the way AWS is going to provision each instance that belongs to this ASG. These
    are the `ECSAutoScalingGroup` and `ECSLaunchConfiguration` resources. Finally,
    `ECSRole`, `ECSInstanceProfile`, and `ECSServiceRole` are used to set up the security
    permissions needed for the ECS cluster to fetch Docker images, work with AWS load
    balancers (ELB), S3, and so on. These permissions are the standard used by AWS
    as an example, and can be most certainly be downgraded.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们声明我们集群的 **自动扩展组**（**ASG**），并设置 AWS 将如何为属于此 ASG 的每个实例进行配置。这些是 `ECSAutoScalingGroup`
    和 `ECSLaunchConfiguration` 资源。最后，使用 `ECSRole`、`ECSInstanceProfile` 和 `ECSServiceRole`
    来设置 ECS 集群获取 Docker 镜像、与 AWS 负载均衡器（ELB）、S3 等进行工作所需的安全权限。这些权限是 AWS 作为示例使用的标准，当然也可以降低权限级别。
- en: 'Now, for our application, we are going to define ECS services and ECS task
    definitions. A task definition is where we define one or more container definitions
    that reference the Docker image to use, along with environment variables. Then,
    the ECS service references an ECS task definition, and may tie it up with a load
    balancer and set up deployment configuration options, such as performance limits
    and auto scaling options (yes, the ECS cluster can scale up or down on load shifts,
    but our containers may scale up or down independently as well):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，针对我们的应用，我们将定义 ECS 服务和 ECS 任务定义。任务定义是我们定义一个或多个容器定义的地方，这些定义引用要使用的 Docker 镜像，并包括环境变量。然后，ECS
    服务引用一个 ECS 任务定义，并且可以将其与负载均衡器关联，并设置部署配置选项，例如性能限制和自动扩展选项（是的，ECS 集群可以根据负载变化进行扩展或缩减，但我们的容器也可以独立地进行扩展或缩减）：
- en: '[PRE46]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This is the task definition for our frontend containers. You may notice that
    this is the CloudFormation version of the Docker Compose service that we''ve already
    seen. We declare a name for our container, `Name: "frontend"`, that will later
    be referenced in the load balancers. Next, the image: `!Ref DockerFrontEndImageArn` is
    a reference to an input parameter. This will allow us to easily deploy new versions
    of our blog application. The port mappings for Docker are declared in `PortMappings`.
    This is a list of key values, repeating the keys for `ContainerPort` and `HostPort`.
    The environment is, once again, a list of key values, and here we make the "wiring"
    for DB, RMQ, and Redis from other resources we are creating. For example, here
    is how we use `DB_URI`:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '这是我们的前端容器的任务定义。你可能注意到，这是我们已经看到的 Docker Compose 服务的 CloudFormation 版本。我们为我们的容器声明一个名称，`Name:
    "frontend"`，稍后将在负载均衡器中引用。接下来，image：`!Ref DockerFrontEndImageArn` 是对输入参数的引用。这将使我们能够轻松部署我们博客应用程序的新版本。Docker
    的端口映射在 `PortMappings` 中声明，这是一个键值对的列表，重复了 `ContainerPort` 和 `HostPort` 的键。环境也是一个键值对的列表，在这里我们从我们创建的其他资源中为
    DB、RMQ 和 Redis 进行“连接”。例如，这里是如何使用 `DB_URI` 的：'
- en: '[PRE47]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This `Value` is where we construct the URI for the database, using our already
    known `!Sub` function and a reference for `DBUsername` and `DBPassword`. The `DB.Endpoint.Address` is
    how we can reference the DNS name that AWS created for our newly created MySQL
    server.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `Value` 是我们构建数据库 URI 的地方，使用我们已知的 `!Sub` 函数和 `DBUsername` 以及 `DBPassword`
    的引用。`DB.Endpoint.Address` 是我们如何引用 AWS 为我们新创建的 MySQL 服务器创建的 DNS 名称。
- en: 'In the service definition, we tie our container to an AWS Elastic Load Balancer,
    and make some deployment configuration:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务定义中，我们将我们的容器与 AWS 弹性负载均衡器关联，并做一些部署配置：
- en: '[PRE48]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'First, we declare that this service will run on our newly created ECS cluster,
    using `Cluster: !Ref ECSCluster`. Then, using the `DeploymentConfiguration` and `DesiredCount`,
    we say that this service will start with two containers (for high availability)
    and allow it to scale up and down between 4 and 1\. This obeys the following formulas:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们声明这个服务将在我们新创建的ECS集群上运行，使用`Cluster: !Ref ECSCluster`。然后，使用`DeploymentConfiguration`和`DesiredCount`，我们说明这个服务将以两个容器（为了高可用性）启动，并允许它在4到1之间进行扩展和缩减。这遵循以下公式：'
- en: The maximum number of containers = DesiredCount * (MaximumPercent / 100)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大容器数量 = DesiredCount * (MaximumPercent / 100)
- en: The minimum number of containers = DesiredCount * (MinimumPercent / 100)
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小容器数量 = DesiredCount * (MinimumPercent / 100)
- en: 'So, applying the formulas to our case gives us the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将公式应用于我们的案例，我们得到以下结果：
- en: 4 = 2 * (200/100)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 = 2 * (200/100)
- en: 1 = 2 * (50/100)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 = 2 * (50/100)
- en: With `TaskDefinition: !RefFrontEndTask`, we say that this service uses our previous
    frontend task definition. And finally, with the `LoadBalancers` key property,
    we tie our service with a load balancer. This means that our two newly created
    containers will evenly receive requests from the users, and new containers will
    automatically be registered on the load balancer as they are created, as well.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '通过`TaskDefinition: !RefFrontEndTask`，我们说明这个服务使用我们之前的前端任务定义。最后，通过`LoadBalancers`键属性，我们将我们的服务与负载均衡器绑定。这意味着我们两个新创建的容器将均匀地接收来自用户的请求，并且随着容器的创建，新的容器将自动在负载均衡器上注册。'
- en: 'Finally, let''s look at the load balancer definition:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看负载均衡器定义：
- en: '[PRE49]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This is an AWS classic ELB definition, where we associate the ELB with a network
    security group, which serves more or less like a firewall. This is done with the `SecurityGroups` key
    property. Next, we define in which subnets the ELB is going to serve. Each subnet
    is created in a different AWS availability zone, each of which represent a data
    center in an AWS region (each region contains two or more data centers, or availability
    zones). Then, we define that this ELB is going to be exposed to the internet using `Scheme:
    internet-facing`. For `Listeners`, we say that port 80 of the ELB is mapped to
    port 80 of the Docker host. And finally, we define a health check for the service,
    and the period for which this will occur.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '这是一个AWS经典ELB定义，其中我们将ELB与网络安全组关联，这大致相当于防火墙。这是通过`SecurityGroups`键属性完成的。接下来，我们定义ELB将在哪些子网中提供服务。每个子网都在不同的AWS可用区中创建，每个可用区代表AWS区域中的一个数据中心（每个区域包含两个或多个数据中心，或可用区）。然后，我们定义这个ELB将通过`Scheme:
    internet-facing`暴露给互联网。对于`Listeners`，我们说ELB的80端口映射到Docker主机的80端口。最后，我们定义服务的健康检查，以及这种检查将持续的时间。'
- en: Check out more details on ELB CloudFormation definitions at [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-elb.html)查看ELB
    CloudFormation定义的更多详细信息。
- en: 'We further create the following resources in the `./deploy/docker/cfn_myblog.yml` YAML
    file provided by CloudFormation:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在CloudFormation提供的`./deploy/docker/cfn_myblog.yml` YAML文件中创建了以下资源：
- en: Several security groups for ELBs and Docker hosts
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为ELBs和Docker主机设置几个安全组
- en: Task definition and the respective service for our myblog Celery workers
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们myblog Celery工作者的任务定义和相应的服务
- en: Task definition and the respective service for our RabbitMQ container
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们RabbitMQ容器的任务定义和相应的服务
- en: Task definition and the respective service for our Redis container
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们Redis容器的任务定义和相应的服务
- en: Load balancer for the Redis container
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redis容器的负载均衡器
- en: Load balancer for RabbitMQ
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ的负载均衡器
- en: Using a load balancer for RabbitMQ is a cheap way to get service discovery functionality—it's
    strange to balance load on a single instance, but if the Docker host, located
    where our RabbitMQ is, crashes for some reason, then the RabbitMQ container is
    going to be created on another Docker host, and the application needs to be able
    to find it dynamically.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RabbitMQ的负载均衡器是一种获取服务发现功能的经济方式——在单个实例上平衡负载似乎很奇怪，但如果我们的RabbitMQ所在位置的Docker主机因某种原因崩溃，那么RabbitMQ容器将创建在另一个Docker主机上，并且应用程序需要能够动态地找到它。
- en: Create and update a CloudFormation stack
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和更新一个CloudFormation堆栈
- en: 'We can create and deploy our CloudFormation stack using the console or the
    CLI. To create it using the console, choose the AWS CloudFormation service, and
    then click on the Create Stack button. You will see the following form:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用控制台或CLI创建和部署我们的CloudFormation堆栈。要使用控制台创建，请选择AWS CloudFormation服务，然后点击创建堆栈按钮。你会看到以下表单：
- en: '![](img/462ffb4f-b781-49f1-8851-98dfca713ea6.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/462ffb4f-b781-49f1-8851-98dfca713ea6.png)'
- en: 'Choose the Upload a template to Amazon S3 option, then choose the `deploy/docker/cfn_myblog.yaml`
    file from the provided code, and click Next. Now, we need to fill the stack parameters
    as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 选择“上传模板到Amazon S3”选项，然后从提供的代码中选择`deploy/docker/cfn_myblog.yaml`文件，并点击下一步。现在，我们需要按照以下方式填写堆栈参数：
- en: 'Stack Name: Provide a name to identify this stack; use whatever you want.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Stack Name: 提供一个名称来识别此堆栈；使用你想要的任何名称。'
- en: 'Environment: Choose the environment of this stack for production, staging,
    and development.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Environment: 选择此堆栈的生产、预发布和开发环境。'
- en: 'ApplicationName: Here, use whatever you want to identify the ECS cluster.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ApplicationName: 在这里，使用你想要用来识别ECS集群的任何名称。'
- en: 'VPC: Choose an AWS VPC.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'VPC: 选择一个AWS VPC。'
- en: 'Subnets: From the drop-down menu, choose all the subnets that belong to the
    VPC (if you have public and private subnets, choose only public subnets, remember
    that the ELB''s are internet facing).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Subnets: 从下拉菜单中选择属于VPC的所有子网（如果你有公共和私有子网，请只选择公共子网，记住ELB是面向互联网的）。'
- en: 'ClusterSize: This is the ECS cluster size; leave the default setting of `2`
    here.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ClusterSize: 这是ECS集群的大小；在这里保留默认设置`2`。'
- en: 'InstanceType: This is the AWS instance type for the Docker hosts.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'InstanceType: 这是Docker主机使用的AWS实例类型。'
- en: 'KeyName: This is the AWS key pair, and needs to be one that we created previously.
    We can use the private key to SSH to the Docker hosts.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'KeyName: 这是AWS密钥对，需要是我们之前创建的。我们可以使用私钥通过SSH连接到Docker主机。'
- en: 'DockerFrontEndImageArn: This is the ARN of the ECR repository to which we uploaded
    our Docker image for the frontend.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DockerFrontEndImageArn: 这是上传我们前端Docker镜像的ECR存储库的ARN。'
- en: 'DockerWorkerImageArn: This is the ARN of the ECR repository to which we uploaded
    our Docker image for the worker.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DockerWorkerImageArn: 这是上传我们工作Docker镜像的ECR存储库的ARN。'
- en: 'DBUsername, DBPassword, RMQUsername, and RMQPassword: These are all the credentials
    for the database and RabbitMQ; choose whatever values you want.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DBUsername, DBPassword, RMQUsername, 和 RMQPassword: 这些都是数据库和RabbitMQ的凭证；选择你想要的任何值。'
- en: After filing all the parameters, click Next. An Options form is presented—just
    click Next again. A review page is presented with our parameters and possible
    stack changes. Here, we need to check the **I acknowledge that AWS CloudFormation
    might create IAM resources with custom names.** option, and click Create. The
    creation of all the resources is going to take a few minutes—wait for the CREATE_COMPLETED state.
    To check out our application, just go to the Output tab and click on the URL.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 填写所有参数后，点击下一步。出现一个选项表单——再次点击下一步。出现一个带有我们的参数和可能的堆栈更改的审查页面。在这里，我们需要检查**我承认AWS
    CloudFormation可能会创建具有自定义名称的IAM资源**选项，并点击创建。所有资源的创建将需要几分钟时间——等待CREATE_COMPLETED状态。要检查我们的应用程序，只需转到输出选项卡并点击URL。
- en: 'Now, let''s see how easily we can develop and deploy a code change. First,
    make a simple code change. For example, in the `webapp/templates/head.html` file,
    find the following line:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们如何轻松地开发和部署代码更改。首先，进行简单的代码更改。例如，在`webapp/templates/head.html`文件中，找到以下行：
- en: '[PRE50]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, change the preceding line to the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将前面的行更改为以下内容：
- en: '[PRE51]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then create a new Docker image, and tag it with `v2`, as shown here:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 然后创建一个新的Docker镜像，并使用`v2`进行标记，如下所示：
- en: '[PRE52]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, push this image to AWS ECR using the following command:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用以下命令将此镜像推送到AWS ECR：
- en: '[PRE53]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Then, go to AWS console and choose our previously created stack. On Actions,
    choose Update Stack. On the first form, choose Use current template. Then, in
    the input parameters, we need to change `DockerFrontEndImageArn`—update it with
    the new tag, and postfix it with `:v2`. The new ARN should look something like
    this: `XXXXXXXX.dkr.ecr.eu-central-1.amazonaws.com/myblog:v2`**. **Then, click
    Next, and on the Options forms click Next again. On the preview form, notice how,
    in the Preview your Changes section, the updater identifies exactly what needs
    to be updated. In this case, `FrontEndTask` and `MyBlogFrontendService` are selected
    for updates, so let's update them. While we wait for the UPDATE_COMPLETE state,
    just keep using the application—notice how no downtime occurs. After one to two
    minutes. notice how our Blog displays the main title as My Blog v2.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，转到AWS控制台并选择我们之前创建的堆栈。在操作中，选择更新堆栈。在第一个表单中，选择使用当前模板。然后，在输入参数中，我们需要更改`DockerFrontEndImageArn`——使用新标签更新它，并在其后加上`:v2`后缀。新的ARN应类似于这样：`XXXXXXXX.dkr.ecr.eu-central-1.amazonaws.com/myblog:v2`**。**然后，点击下一步，在选项表单中再次点击下一步。在预览表单中，注意在预览您的更改部分，更新器会准确地识别需要更新的内容。在这种情况下，`FrontEndTask`和`MyBlogFrontendService`被选中进行更新，所以让我们更新它们。在我们等待UPDATE_COMPLETE状态时，只需继续使用应用程序——注意没有停机时间发生。一到两分钟后，注意我们的博客显示的主要标题为My
    Blog v2。
- en: In the next section, we will see how to integrate this approach with a modern
    CI/CD system to build, run tests, check code quality, and deploy on different
    environments.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何将这种方法与现代CI/CD系统集成，以构建、运行测试、检查代码质量，并在不同的环境中部署。
- en: Building and deploying highly available applications readily
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速构建和部署高可用性应用
- en: Whether our web app is on the cloud or in a data center, we should aim for reliability.
    Reliability can impact the user is various ways, either by downtime, data loss,
    application error, response time degradation, or even on user deploy delay. Next,
    we are going to cover some aspects to help you think about architecture and reliability,
    to help you plan ahead to handle issues, such as failures or increased load. First
    of all, we will cover the necessary steps for you to deploy rapidly and, of course,
    reliably.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们的Web应用是在云端还是数据中心，我们都应该追求可靠性。可靠性可以通过多种方式影响用户，无论是通过停机、数据丢失、应用错误、响应时间下降，甚至是用户部署延迟。接下来，我们将介绍一些方面，帮助您思考架构和可靠性，以便您提前规划以处理问题，例如故障或负载增加。首先，我们将介绍您快速且可靠部署所需的必要步骤。
- en: Building and deploying reliably
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可靠地构建和部署
- en: With today's demanding markets, we need to build and deploy easily and quickly.
    But the speed of our deployment must also deliver reliability. One of the steps
    needed to achieve this is to use automation via scripts, or with CI/CD tools.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天竞争激烈的市场中，我们需要快速且轻松地构建和部署。但我们的部署速度也必须保证可靠性。实现这一目标的一个步骤是使用脚本或CI/CD工具进行自动化。
- en: To help us set up the entire process, we should use a CI/CD tool, such as Jenkins,
    Bamboo, TeamCity, or Travis. First, what exactly is CI/CD?
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们设置整个流程，我们应该使用CI/CD工具，如Jenkins、Bamboo、TeamCity或Travis。首先，CI/CD究竟是什么？
- en: '**CI** stands for **Continuous Integration**, and is the process defined for
    integrating software changes, made by many developers, into a main repository—and,
    of course, doing so quickly and reliably. Let''s enumerate what we need, from
    bottom to top:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '**CI**代表**持续集成**，是指将许多开发者做出的软件更改集成到主仓库的过程——当然，这样做要快速且可靠。让我们从下到上列举我们需要的东西：'
- en: First, it is imperative to use a source control and versioning system, such
    as Git, along with a well established and internally defined branching model,
    such as **GitFlow**. This will give us a clear view of code changes, along with
    the ability to accept and test them, at either feature or hotfix level. This will
    also make it easy to rollback to a previous version.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，使用源代码控制和版本控制系统至关重要，例如Git，以及一个良好建立且内部定义的分支模型，例如**GitFlow**。这将让我们清楚地看到代码更改，并能够在功能或热修复级别接受和测试它们。这将使我们能够轻松回滚到之前的版本。
- en: Before approving any merges proposed by pull requests, make sure to set up automated
    triggering of tests and reviewing of code. Pull-request reviewers can then make
    more informed decisions before approving a merge. Failed tests are certainly a
    warning sign that we want to see before merging code that will end up on production.
    Fail fast, and don't be afraid to fail often.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在批准任何由pull request提出的合并之前，请确保设置测试的自动触发和代码审查。然后，pull-request审查员在批准合并之前可以做出更明智的决定。失败的测试当然是我们希望在合并最终进入生产环境的代码之前看到的警告信号。快速失败，不要害怕经常失败。
- en: As was said previously, we have several tools to automate this process. One
    easy way to do this is to use GitHub with Travis and landscape.io. You can freely
    create an account on all three of them and try them out. After this, just create
    the following two files on your repository.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们有几个工具来自动化此过程。一种简单的方法是使用GitHub、Travis和landscape.io。你可以在所有三个平台上自由创建账户并尝试它们。之后，只需在你的仓库中创建以下两个文件。
- en: 'Create a `.travis.yml` file, which should contain the following:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`.travis.yml`文件，它应该包含以下内容：
- en: '[PRE54]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This is all we need to have automated tests running on every commit. Also, our
    tests will run independently using Python versions 3.6, 3.3, and 2.7\. GitHub
    and Travis integration will also give us the result of these tests on every pull
    request.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们需要的所有内容，以便在每次提交时自动运行自动化测试。此外，我们的测试将使用Python版本3.6、3.3和2.7独立运行。GitHub和Travis集成还将给我们提供每次pull
    request的测试结果。
- en: For code quality control, landscape.io is very easy to use with GitHub (other
    tools include flake8, Sonarqube, and Codacy, for example).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码质量控制，landscape.io与GitHub（其他工具包括flake8、Sonarqube和Codacy等）非常容易使用。
- en: 'To set up landscape.io, we just have to create the following `.landscape.yml` file
    at the root of our project:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置landscape.io，我们只需在我们的项目根目录下创建以下`.landscape.yml`文件：
- en: '[PRE55]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Further automation can be achieved by merging every branch automatically to
    the develop branch, for example, but we need a third tool to automate this process
    on GitHub.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将每个分支自动合并到develop分支，例如，可以实现进一步的自动化，但我们需要一个第三方工具来自动化GitHub上的此过程。
- en: '**CD** stands for** Continuous Delivery**,and is based on reduced cycles of
    development and the actual delivery of changes. This must be done quickly and
    reliably, and rollback should always be accounted for. To help us define and execute
    this process, we can use **Jenkins/Blue Ocean pipelines.**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**CD**代表**持续交付**，它基于缩短的开发周期和实际交付变更。这必须快速且可靠地完成，并且应该始终考虑回滚。为了帮助我们定义和执行此过程，我们可以使用**Jenkins/Blue
    Ocean管道**。'
- en: 'Using Jenkins pipelines, we can define the entire pipeline process, from build
    to deployment. This process is defined using a `Jenkinsfile` at the root of our
    project. First, let''s create and start our Jenkins CI server from the CLI, as
    follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Jenkins管道，我们可以定义从构建到部署的整个管道过程。此过程使用位于我们项目根目录的`Jenkinsfile`定义。首先，让我们从CLI创建并启动我们的Jenkins
    CI服务器，如下所示：
- en: '[PRE56]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'On start, the Docker output will show the following:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动时，Docker的输出将显示以下内容：
- en: '[PRE57]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Copy the password from your output and open Jenkins in your browser by going
    to `http://localhost:8080`. On startup, Jenkins will ask for a one-time password—paste
    in the password provided by the Docker output. Next, Jenkins will ask you for
    some initial configuration. This consists of creating an Admin user, and installing
    plugins (for our example, you can simply accept the suggested plugins).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中复制密码，并通过访问`http://localhost:8080`在浏览器中打开Jenkins。在启动时，Jenkins将要求一次性密码——粘贴由Docker输出提供的密码。接下来，Jenkins将要求你进行一些初始配置。这包括创建一个管理员用户，并安装插件（在我们的示例中，你可以简单地接受建议的插件）。
- en: To set up an automated approach to build and deploy our Docker images to AWS
    ECR, we need an extra plugin called Amazon ECR. To install this plugin, go to Manage
    Jenkins, then choose Manage Plugins, and click on the Available Tab for a list
    of available and not-yet-installed plugins. From this list, choose the Amazon
    ECR plugin, and finally click on the Install without restart option.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置自动构建和部署我们的Docker镜像到AWS ECR的方法，我们需要一个额外的插件，称为Amazon ECR。要安装此插件，请转到“管理Jenkins”，然后选择“管理插件”，并点击“可用”选项卡以查看可用和尚未安装的插件列表。从该列表中选择Amazon
    ECR插件，并最终点击“不重启安装”选项。
- en: 'Next, we must configure a set of credentials, so that Jenkins can authenticate
    on AWS and push our newly built Docker images. For this, on the left-hand menu,
    choose Credentials, then choose Jenkins credential scope and Global credentials.
    Now, on the left-hand panel, choose Add credentials and fill the form with the
    following info:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须配置一组凭据，以便Jenkins可以在AWS上进行身份验证并推送我们新构建的Docker镜像。为此，在左侧菜单中选择凭据，然后选择Jenkins凭据范围和全局凭据。现在，在左侧面板中选择添加凭据并填写以下信息：
- en: 'Kind: AWS Credentials'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型：AWS凭据
- en: 'Scope: Global'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 范围：全局
- en: ID: ecr-credentials
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ID：ecr-credentials
- en: Description: ecr-credentials
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述：ecr-credentials
- en: 'Access Key ID: Use the AWS Access Key ID that you already created in the previous
    section for pushing your Docker images'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问密钥ID：使用你之前章节中创建的AWS访问密钥ID来推送你的Docker镜像
- en: Secret Access key:  Use the AWS Secret Access Key that you already created in
    the previous section for pushing your Docker images
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密钥访问密钥：使用你之前章节中创建的AWS密钥访问密钥来推送你的Docker镜像
- en: For security reasons, it's better to choose the IAM role approach. However,
    for the sake of simplicity, we are using AWS keys here. If you still want to use
    AWS keys, remember to never use your personal keys on automation processes—instead,
    create a specific user for the process with contained and managed privileges.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安全原因，最好选择IAM角色方法。然而，为了简化，我们在这里使用AWS密钥。如果你仍然想使用AWS密钥，请记住永远不要在自动化过程中使用你的个人密钥——相反，为该过程创建一个具有受限和管理权限的特定用户。
- en: 'Now we are ready to create our first CI/CD pipeline. Follow these steps:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好创建我们的第一个CI/CD管道。按照以下步骤操作：
- en: On the main page, choose the Create new Jobs link
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主页上，选择创建新作业链接
- en: On the input box for "nter an item name, write `myblog`
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“输入项目名称”的输入框中，写`myblog`
- en: Choose the Multibranch pipeline option. Then click Ok
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择多分支管道选项。然后点击确定
- en: 'On the Jobs configuration, you need to fill in the following fields:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在作业配置中，你需要填写以下字段：
- en: 'Branch Sources: Create new Jenkins'' credentials for your GitHub account, or
    set up using your own credentials from your private Git repository. Then, choose
    the GitHub repository for this book, or use your private repository URL.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支源：为你的GitHub账户创建新的Jenkins凭据，或者使用你从私有Git仓库的凭据设置。然后，选择这本书的GitHub仓库，或者使用你的私有仓库URL。
- en: 'Then, for now, remove all behaviors except "Discover branches", as shown here:'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，目前，请移除所有行为，除了“发现分支”，如下所示：
- en: '![](img/2fd29995-b9d8-4b05-af7d-6d2cdf3e6895.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2fd29995-b9d8-4b05-af7d-6d2cdf3e6895.png)'
- en: On the "Build Configuration" job section, change the "Script Path" to `Chapter-13/Jenkinsfile` if
    you're using this book's GitHub repository. This is required because the repository
    is organised by chapters, and the `Jenkinsfile` is not at the root of the repository.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在“构建配置”作业部分，如果你使用这本书的GitHub仓库，将“脚本路径”更改为`Chapter-13/Jenkinsfile`。这是必需的，因为仓库是按章节组织的，而`Jenkinsfile`不在仓库的根目录中。
- en: 'This is all it takes, because the heavy lifting is done using the `Jenkinsfile`
    pipeline definition. Let''s take a look at this file:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部，因为繁重的工作是通过`Jenkinsfile`管道定义完成的。让我们看看这个文件：
- en: '[PRE58]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The Jenkins pipeline definition gives you a huge amount of configuration options.
    We can even use Groovy scripts embedded in it. Please take a look at the documentation
    for more details, available at [https://jenkins.io/doc/book/pipeline/jenkinsfile/](https://jenkins.io/doc/book/pipeline/jenkinsfile/).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins管道定义为你提供了大量的配置选项。我们甚至可以使用嵌入其中的Groovy脚本。请查看文档以获取更多详细信息，文档可在[https://jenkins.io/doc/book/pipeline/jenkinsfile/](https://jenkins.io/doc/book/pipeline/jenkinsfile/)找到。
- en: On the `pipeline` main section, we have created a manual parameter for you to
    fill out the AWS ECR URL to which the images should be pushed. This section also
    configures some necessary environment variable to make our stages more dynamic.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在“pipeline”主部分，我们为你创建了一个手动参数，以便填写应推送图像的AWS ECR URL。此部分还配置了一些必要的环境变量，使我们的阶段更加动态。
- en: 'Next, let''s take a look at the pipeline stages section:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看管道阶段部分：
- en: '[PRE59]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The `stages` section will hold all the stages necessary to build, test, check,
    and deploy our application. The build declared with `stage('Build')` just executes
    a checkout of our repository using `checkout scm`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '`stages`部分将包含构建、测试、检查和部署我们的应用程序所需的所有阶段。使用`stage(''Build'')`声明的构建只是使用`checkout
    scm`执行我们的仓库的检出。'
- en: In the *Style* stage, we will check the code style using **flake8**. We are
    assuming that a critical style problem is enough to make the pipeline fail, and
    never deploy the application. To run it, we tell Jenkins to run a Docker container
    with Python 3 by using the `docker 'python:3'` command, and inside, we install
    all the necessary dependencies and run **flake8 **against our code.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在*风格*阶段，我们将使用**flake8**检查代码风格。我们假设一个关键的风格问题足以使管道失败，并且永远不会部署应用程序。要运行它，我们告诉Jenkins使用`docker
    'python:3'`命令运行一个Python 3的Docker容器，并在其中安装所有必要的依赖项并运行**flake8**对代码进行检查。
- en: Next you will find a *Test* stage, which very similar to the St*y*le stage.
    Notice that we can easily define tests for Python 3 and 2.7 using specific Docker
    containers to run it.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将找到一个*测试*阶段，它与*风格*阶段非常相似。请注意，我们可以轻松地定义用于Python 3和2.7的测试，使用特定的Docker容器来运行它。
- en: 'The Docker build stage is as follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: Docker构建阶段如下：
- en: '[PRE60]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: In this stage, we use Groovy to build our images for the frontend and Celery
    workers. The images will be produced and tagged with the Jenkins build identification,
    which we can use as an `env.BUILD_ID` environment variable.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们使用Groovy为前端和Celery工作进程构建镜像。这些镜像将被生成并带有Jenkins构建标识符，我们可以将其用作`env.BUILD_ID`环境变量。
- en: 'In the final stage, we push the newly created images to the AWS ECR Docker
    image repository as follows:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终阶段，我们将新创建的镜像推送到AWS ECR Docker镜像存储库，如下所示：
- en: '[PRE61]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Finally, to run our job, choose the "myblog" job, then "master," and on the
    left panel, choose "Build with parameters." Fill in your AWS ECR URL (this URL
    takes the form `http://<ACCOUNT_NUMBER>.dkr.ecr.<REGION>.amazonaws.com`), and
    then click Build. After the build is done, we just have to update our CloudFormation
    with the newly created Docker images.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了运行我们的任务，选择“myblog”任务，然后选择“master”，在左侧面板中选择“带参数构建”。填写您的AWS ECR URL（此URL的格式为`http://<ACCOUNT_NUMBER>.dkr.ecr.<REGION>.amazonaws.com`），然后点击构建。构建完成后，我们只需更新我们的CloudFormation，以包含新创建的Docker镜像。
- en: 'A great final stage would be to update the previously deployed CloudFormation,
    scripting the process with what we''ve already tested in this book, in the previous
    *Create and Update a CloudFormation Stack* section. For this, we could use the
    "pipeline: AWS steps" plugin.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '一个很好的最终阶段将是更新之前部署的CloudFormation，使用我们在本书中之前测试的脚本过程。为此，我们可以使用“pipeline: AWS
    steps”插件。'
- en: Creating highly available applications that scale
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建高度可用的可扩展应用程序
- en: '**High availability** (**HA**) and scalability is an ever more important subject.
    It should be taken into consideration from the development phase, all the way
    up to the release stage. Monolithic architectures, where all the features and
    services that comprise your application can''t be separated or are installed on
    one single instance, will not resist failure, and won''t scale either. Vertical
    scaling will only go so far, and in case of failure, will increase recovery times,
    as well as the impact on the user. This is an important and complex subject and,
    as you may have guessed, there is no single solution to solve it.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**高可用性**（**HA**）和可扩展性是一个越来越重要的主题。它应该从开发阶段一直考虑到发布阶段。单体架构，其中所有组成应用程序的功能和服务都无法分离或安装在单个实例上，将无法抵抗故障，也无法扩展。垂直扩展只能走这么远，而且在故障的情况下，将增加恢复时间，以及用户的影响。这是一个重要且复杂的问题，正如你可能猜到的，没有单一的解决方案可以解决这个问题。'
- en: To think about HA, we have to be pessimistic. Remember—failure can't be eliminated,
    but failure points can be identified, and recovery plans should be put in place
    so that downtime takes seconds or minutes, instead of hours or even days.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 要考虑HA，我们必须持悲观态度。记住——故障无法消除，但可以识别故障点，并应制定恢复计划，以便停机时间只需几秒或几分钟，而不是几小时甚至几天。
- en: 'First, let''s think about all the components that our Blog application has,
    and identify the stateless ones:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考虑我们的博客应用程序的所有组件，并识别无状态的组件：
- en: '**Frontend**: Webserver and uWSGI – stateless'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前端**: Web服务器和uWSGI – 无状态'
- en: '**Celery workers**: Celery – stateless'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Celery工作进程**: Celery – 无状态'
- en: '**Message queue**: RabbitMQ or AWS SQS – state'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息队列**: RabbitMQ或AWS SQS – 有状态'
- en: '**Cache**: Redis – state'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓存**: Redis – 有状态'
- en: '**Database**: SQL or NoSQL – state'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**: SQL或NoSQL – 有状态'
- en: 'Our first goal is to identify all the **Single Points of Failure** (**SPOF**)
    in our application, and try to eliminate them. For this, we have to think about
    redundancy:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的首要目标是识别我们应用程序中的所有**单点故障**（**SPOF**），并尝试消除它们。为此，我们必须考虑冗余：
- en: '**Frontend**: This is a stateless service that receives direct requests from
    the users. We can balance these requests using a load balancer, and by always
    having at least two instances. If one fails, the other immediately starts receiving
    all the load. Looks good? Maybe, but can a single instance support all the load?
    Huge response times are a failure too, so think about it—maybe you need at least
    three instances. Next, can your load balancer fail too? This is not a problem
    when using some sort of cloud-based load balancer, such as AWS ELB or ALB, but
    if you aren''t using these, then set up redundancy on this layer as well.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前端**: 这是一个无状态服务，直接接收来自用户的请求。我们可以使用负载均衡器来平衡这些请求，并且始终至少有两个实例。如果一个实例失败了，另一个立即开始接收所有负载。看起来不错？也许吧，但单个实例能支持所有负载吗？巨大的响应时间也是一种失败，所以考虑一下——你可能至少需要三个实例。接下来，你的负载均衡器也会失败吗？当使用某种基于云的负载均衡器，如AWS
    ELB或ALB时，这不是问题，但如果你没有使用这些，那么在这个层面上也要设置冗余。'
- en: '**Celery workers**: Workers are stateless, and a complete failure does not
    have an immediate impact on users. You can have at least one instance, as long
    as recovery is done automatically, or failure can be easily identified and a failed
    instance can rapidly be replaced with a new one.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Celery工作进程**: 工作进程是无状态的，完全失败不会立即对用户产生影响。只要恢复是自动完成的，或者失败可以轻松识别，并且一个失败的实例可以快速用新实例替换，你至少可以有一个实例。'
- en: '**Message queue**: If using AWS SQS or CloudMQ, failure is already accounted
    for. If not, a clustered RabbitMQ can be an option, or you can make sure that
    message loss is an option, and that RabbitMQ replacement is automatic, or can
    at least be rapidly executed.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息队列**: 如果使用AWS SQS或CloudMQ，已经考虑了失败的情况。如果没有，集群化的RabbitMQ可以是一个选择，或者你可以确保消息丢失是一个选项，并且RabbitMQ的替换是自动的，或者至少可以快速执行。'
- en: '**Cache: **Make sure you have more then one memcached instance (using cluster
    key sharding), or your application can gracefully account for failure. Remember
    that a memcached replacement comes with a cold cache, which can have a huge impact
    on the database, depending on your load.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓存**: 确保你有多于一个的memcached实例（使用集群键分片），或者你的应用程序可以优雅地处理失败。记住，memcached的替换会带来一个冷缓存，这可能会对你的数据库产生巨大影响，这取决于你的负载。'
- en: '**Database**: Make sure you have an SQL or NoSQL slave/cluster in place, ready
    to replace writes from the failed master.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库**: 确保你有一个SQL或NoSQL从属/集群就绪，以替换失败的master的写入。'
- en: Layers that contain state are more problematic, and a small failure (seconds
    or milliseconds) may be inevitable. Hot standbys or cold standbys should be accounted
    for. It's very useful to test system failures of all your services while load
    testing. Redundancy is like a software feature—if not tested, it's probably broken.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 包含状态的层更成问题，即使是小的失败（几秒或毫秒）也可能是不可避免的。热备用或冷备用应该被考虑。在负载测试的同时测试你所有服务的系统故障非常有用。冗余就像一个软件特性——如果不测试，它可能已经损坏了。
- en: Scaling can be verified with load tests. It's a very good idea to include it
    somewhere along the way in your production pipeline release. **Locust** is an
    excellent Python tool to implement highly configurable load tests that can scale
    to any load level you want. These kinds of tests are a great opportunity to verify
    your high availability setup. Take down instances while simulating your expected
    load, and load test until you break your stack. This way you will know your limits—knowing
    what will break first *before* it breaks on production will help you test performance
    tuning.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过负载测试来验证扩展性。在生产管道发布过程中包含它是一个非常好的主意。**Locust**是一个出色的Python工具，可以实施高度可配置的负载测试，可以扩展到任何你想要的负载级别。这类测试是验证你的高可用性设置的好机会。在模拟预期负载的同时关闭实例，并负载测试直到你的堆栈崩溃。这样你将知道你的极限——在它在生产中崩溃之前知道什么会先崩溃，将有助于你测试性能调整。
- en: Locust python package documentation is available at [https://docs.locust.io/en/stable/](https://docs.locust.io/en/stable/).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: Locust Python包的文档可在[https://docs.locust.io/en/stable/](https://docs.locust.io/en/stable/)找到。
- en: Scaling using cloud infrastructure, such as AWS, Azure, and GCP, is all about
    automation. You need to set up your instances automatically, so that monitoring
    metrics can automatically trigger the creation of new VMs or Dockers containers.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云基础设施，如AWS、Azure和GCP进行扩展，全部关于自动化。你需要自动设置你的实例，以便监控指标可以自动触发新虚拟机或Docker容器的创建。
- en: Finally, please make sure you backup your database periodically. The delta time
    between backups is a point of possible data loss, so identify it and report back.
    Also, it's very important to restore your production backups—again, if not tested,
    then they're probably broken.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请确保您定期备份您的数据库。备份之间的时间差是可能数据丢失的点，所以请识别它并报告回来。同样，恢复您的生产备份也非常重要——如果未经测试，那么它们可能已经损坏。
- en: Monitoring and collecting logs
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和收集日志
- en: Monitor all your systems and components, collect OS level metrics, and produce
    application metrics. You have great tools for doing this, including DataDog; NewRelic;
    a combination of StatsD, Graphana, InfluxDB, and Prometheus; and ELK.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 监控所有系统和组件，收集操作系统级别的指标，并生成应用程序指标。您有很好的工具来做这件事，包括DataDog；NewRelic；StatsD、Graphana、InfluxDB和Prometheus的组合；以及ELK。
- en: Set up alarms on failures based on metric thresholds. It's very important not
    to go overboard on the amount of alarms you create—make sure that a critical alarm
    really implies that the system is down or severely impaired. Set up time charts
    so that you can identify issues or upscale necessities early.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 根据指标阈值设置故障警报。非常重要的一点是不要过度设置您创建的警报数量——确保一个关键警报确实意味着系统已关闭或严重受损。设置时间图表，以便您可以提前识别问题或升级需求。
- en: Collect logs from OS, applications, and cloud services. Parsing, structuring,
    and adding metadata to your logs enriches your data, and enables proper log aggregation,
    filtering, and charting. Being able to easily filter all of your logs relative
    to a specific user, IP, or country is a step forward.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 从操作系统、应用程序和云服务中收集日志。解析、结构化和向您的日志添加元数据丰富了您的数据，并使适当的日志聚合、过滤和图表成为可能。能够轻松地根据特定用户、IP或国家过滤所有日志是一个进步。
- en: 'Log collection has become more critical on the cloudc and even more so on containers,
    because they are short-lived and break your applications down into microservices,
    so that by the time something happens, your logs may no longer exist, or you may
    have to manually go through dozens, if not thousands, of log files to find out
    what was and is happening. This is increasingly becoming impossible to do. There
    are many good solutions out there, however: you can use ELK (ElasticSearch, logstash,
    and Kibana) or EFK (ElasticSearch, Fluentd, and Kibana) stacks, Sumo logic, or
    DataDog.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 日志收集在云环境中变得更加重要，在容器中更是如此，因为它们是短暂的，并将您的应用程序分解成微服务，因此当发生某些事情时，您的日志可能已经不存在，或者您可能需要手动浏览数十个，甚至数千个日志文件来找出发生了什么。这越来越难以做到。然而，有许多好的解决方案：您可以使用ELK（ElasticSearch、logstash和Kibana）或EFK（ElasticSearch、Fluentd和Kibana）堆栈、Sumo
    logic或DataDog。
- en: Summary
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: As this chapter explained, there are many different options for hosting your
    application, each with their own pros and cons. Deciding on one depends on the
    amount of time and money you are willing to spend, as well as the total number
    of users you expect.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章所解释的，托管您的应用程序有许多不同的选项，每个选项都有其自身的优缺点。选择哪一个取决于您愿意投入的时间和金钱，以及您预期的总用户数量。
- en: Now, we have reached the conclusion of the book. I hope that this book was helpful
    in building your understanding of Flask, and how it can be used to create applications
    of any degree of complexity with both ease and simple maintainability.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经到达了本书的结尾。我希望这本书在构建您对Flask的理解以及如何用它来创建任何复杂度的应用程序，既简单又易于维护方面有所帮助。
- en: Web application development is a fast paced area that touches different technologies
    and concepts. Don't stop here—keep improving your Python skills, read about UX
    design, improve your knowledge on CSS and HTML, master SQL and query performance,
    and develop a single page application using Flask and Javascript. Each chapter
    of this book is an invitation for further knowledge.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 网络应用程序开发是一个快速发展的领域，涉及不同的技术和概念。不要止步于此——继续提高您的Python技能，了解用户体验设计，提高您对CSS和HTML的知识，掌握SQL和查询性能，并使用Flask和JavaScript开发单页应用程序。本书的每一章都是进一步了解知识的邀请。
