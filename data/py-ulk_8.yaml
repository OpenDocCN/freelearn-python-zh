- en: Chapter 8. Scaling Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。扩展Python
- en: 'In this chapter, we will try to understand how we can make our program work
    for more inputs by making the program scalable. We will do this by both optimizing
    and adding computing power to the system. We will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将尝试通过使程序可扩展来让我们的程序能够处理更多的输入。我们将通过优化和增加系统计算能力来实现这一点。我们将涵盖以下主题：
- en: Going multithreaded
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程
- en: Using multiple processes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个进程
- en: Going asynchronous
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步处理
- en: Scaling horizontally
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平扩展
- en: The major reason a system is not able to scale is state. Events can change the
    state of a system permanently for both that request or further requests from that
    endpoint.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 系统无法扩展的主要原因是状态。事件可以永久改变系统的状态，无论是针对该请求还是来自该端点的后续请求。
- en: Normally state is stored in the database, and reactions to events are worked
    on sequentially, and changes to state due to events are then stored in DB.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 通常状态存储在数据库中，对事件的响应是按顺序处理的，由于事件而引起的状态变化随后存储在数据库中。
- en: 'Task can be computation intensive (CPU load) or IO bound in which system needs
    answers from some other entity. Here, `taskg` and `taskng` are GIL and nonGIL
    versions of a task. The `taskng` task is in C module compiled via SWIG by enabling
    its threads:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以是计算密集型（CPU负载）或I/O密集型，其中系统需要从其他实体那里获得答案。在这里，`taskg`和`taskng`是任务的GIL和非GIL版本。`taskng`任务是在C模块中通过SWIG编译并启用其线程的：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For example, I have created a test server that responds to requests after 1
    sec. To create a comparison for scenarios, we first create a simple serial program.
    As expected, both IO and CPU tasks time add up:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我创建了一个在1秒后响应请求的测试服务器。为了比较场景，我们首先创建一个简单的串行程序。正如预期的那样，IO和CPU任务的时间相加：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Outputs can be easily summarized as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可以简单地总结如下：
- en: '![Scaling Python](img/B04885_08_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![扩展Python](img/B04885_08_01.jpg)'
- en: Going multithreaded
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程
- en: '**Key 1: Using threads to process in parallel.**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键1：使用线程并行处理。**'
- en: 'Let''s see how threads can help us in improving performance. In Python, due
    to Global Interpreter Lock, only one thread runs at a given time. Also, context
    is switched as all of them are given a chance to run. Hence, this is load in addition
    to computation. Hence, CPU-intensive tasks should take the same or more time.
    IO tasks are not doing anything but waiting, so they will get the boost. In the
    following code segment, `threaded_iotask` and `threaded_cputask` are two functions
    that are executed using separate threads. The code is run for various values to
    get results. The process function invokes multiple threads for tasks and sums
    up the timings taken:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看线程如何帮助我们提高性能。在Python中，由于全局解释器锁，一次只有一个线程运行。此外，上下文切换，因为所有这些线程都被给予运行的机会。因此，这除了计算之外还有负载。因此，CPU密集型任务应该花费相同或更多的时间。I/O任务并没有做任何事情，只是在等待，所以它们会得到提升。在以下代码段中，`threaded_iotask`和`threaded_cputask`是使用单独线程执行的两个函数。代码运行于各种值以获取结果。进程函数调用多个线程以对任务进行操作并汇总所花费的时间：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Plotting various results onscreen, we can easily see that threading is helping
    IO tasks but not CPU tasks:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕上绘制各种结果，我们可以轻松地看到线程有助于IO任务，但不是CPU任务：
- en: '![Going multithreaded](img/B04885_08_02.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![多线程](img/B04885_08_02.jpg)'
- en: As discussed, this is due to GIL. Our CPU task is defined in C, we can give
    up GIL to see whether that helps. The following is plot of run with no GIL for
    tasks. We can see that CPU tasks are now taking a lot less time than before. But,
    GIL is there for a reason. If we give up GIL, atomicity for data structures is
    not guaranteed as there may be two threads working on same data structure at a
    given time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这是由于全局解释器锁（GIL）。我们的CPU任务是用C定义的，我们可以放弃GIL来看看是否有所帮助。以下是没有GIL的任务运行图的示例。我们可以看到，CPU任务现在所需的时间比之前少得多。但是，GIL的存在是有原因的。如果我们放弃GIL，数据结构的原子性就无法保证，因为在给定时间内可能有多个线程在处理相同的数据结构。
- en: '![Going multithreaded](img/B04885_08_03.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![多线程](img/B04885_08_03.jpg)'
- en: Using multiple processes
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个进程
- en: '**Key 2: Churning CPU-intensive tasks.**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键2：处理CPU密集型任务。**'
- en: 'Multiple processes are helpful to fully utilize all CPU cores. It helps in
    CPU-intensive work as tasks are run in separate processes, and there is no GIL
    between actual working processes. The setup and communication cost between processes
    is higher than threads. In the following code section, `proc_iotask`, `proc_cputask`
    are processes that run them for various inputs:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程有助于充分利用所有CPU核心。它有助于CPU密集型工作，因为任务是在单独的进程中运行的，并且实际工作进程之间没有GIL。进程之间的设置和通信成本高于线程。在以下代码部分中，`proc_iotask`和`proc_cputask`是针对各种输入运行的进程：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the following diagram, we can see the multiple IO operations are getting
    a boost from multiprocessing. CPU tasks are also getting a boost from multiprocessing:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图中，我们可以看到多个IO操作从多进程中得到了提升。CPU任务也因多进程而得到提升：
- en: '![Using multiple processes](img/B04885_08_04.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![使用多进程](img/B04885_08_04.jpg)'
- en: 'If we compare all four: serial, threads, threads without GIL, and multiprocesses,
    we will observe that threads without GIL and multiprocesses are taking almost
    the same time. Also, serial and threads are taking the same time, which shows
    little benefit of using threads in CPU-intensive tasks:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较所有四种：串行、线程、无GIL的线程和多进程，我们会观察到无GIL的线程和多进程几乎花费了相同的时间。此外，串行和线程花费了相同的时间，这表明在CPU密集型任务中使用线程的好处很小：
- en: '![Using multiple processes](img/B04885_08_05.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![使用多进程](img/B04885_08_05.jpg)'
- en: Going asynchronous
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步进行
- en: '**Key 3: Being asynchronous for parallel execution.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键3：为了并行执行而异步。**'
- en: We can also process more than one request by being asynchronous as well. In
    this method, instead of us polling for updates from objects, they tell us when
    they have a result. Hence, the main thread in the meantime can execute other stuff.
    Asyncio, Twisted, and Tornado are libraries in Python that can help us write such
    code. Asyncio, and Tornado are supported in Python 3, and some portions of Twisted
    also run on Python 3 as of now. Python 3.5 introduced the `async` and `await`
    keywords that helps write asynchronous code. The `async` keyword defines that
    the function is an asynchronous function and that the result may not be available
    right away. The `await` keyword waits until the results are captured and returns
    the result.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过异步处理多个请求。在这种方法中，我们不是轮询对象的更新，而是它们告诉我们何时有结果。因此，在同时，主线程可以执行其他操作。Asyncio、Twisted和Tornado是Python中的库，可以帮助我们编写这样的代码。Asyncio和Tornado在Python
    3中得到支持，目前Twisted的一些部分也可以在Python 3上运行。Python 3.5引入了`async`和`await`关键字，有助于编写异步代码。`async`关键字定义了函数是一个异步函数，并且结果可能不会立即可用。`await`关键字等待直到结果被捕获并返回结果。
- en: 'In the following code, `await` in the main function waits for all the results
    to be available:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，主函数中的`await`等待所有结果都可用：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Plotting results on the graph, we can see that we got a boost on the IO portion,
    but for CPU-intensive work, it takes time similar to serial:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在图上绘制结果，我们可以看到我们在IO部分得到了提升，但对于CPU密集型工作，它花费的时间与串行相似：
- en: '![Going asynchronous](img/B04885_08_06.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![异步进行](img/B04885_08_06.jpg)'
- en: 'CPU tasks are blocking everything, hence, this is a bad design. We have to
    use either threads, or better multiprocessing to help in CPU-intensive tasks.
    To run tasks in threads or processes, we can use `ThreadPoolExecutor`, and `ProcessPoolExecutor`
    from the `concurrent.futures` package. The following is the code for `ThreadPoolExecutor`:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CPU任务阻塞了所有操作，因此，这是一个糟糕的设计。我们必须使用线程或更好的多进程来帮助处理CPU密集型任务。要使用线程或进程运行任务，我们可以使用`concurrent.futures`包中的`ThreadPoolExecutor`和`ProcessPoolExecutor`。以下是`ThreadPoolExecutor`的代码：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For `ProcessPoolExecutor`, we have to use a multiprocessing queue to collect
    results back, as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`ProcessPoolExecutor`，我们必须使用多进程队列来收集结果，如下所示：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Plotting the results, we can see that threads are taking more or less the same
    time as without them, but they can still help make the program more responsive
    as the program will be able to perform other IO tasks in the meantime. Multiprocessing
    gives the max boost:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制结果，我们可以看到线程花费的时间与没有它们时大致相同，但它们仍然可以帮助使程序更响应，因为程序可以在同时执行其他IO任务。多进程提供了最大的提升：
- en: '![Going asynchronous](img/B04885_08_07.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![异步进行](img/B04885_08_07.jpg)'
- en: 'Async systems are used mostly when IO is the main thing. As you can see, it
    is similar to serial for CPU. Let''s now take a look at which one is better, threading
    or `async`, for our scalable IO-based application. We used the same IO task but
    on higher loads. Asyncio gives failures and takes more time than threads. I tested
    this on Python 3.5:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 异步系统主要用于IO是主要任务时。如您所见，对于CPU来说，它与串行相似。现在让我们看看对于我们的可扩展IO应用，线程或`async`哪一个更好。我们使用了相同的IO任务，但在更高的负载下。Asyncio提供了失败，并且比线程花费更多的时间。我在Python
    3.5上进行了测试：
- en: '![Going asynchronous](img/B04885_08_08.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![异步进行](img/B04885_08_08.jpg)'
- en: The last advice will be to look at other implementations as well, such as PyPy,
    Jython, IronPython, and so on.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的建议是也要看看其他实现，例如PyPy、Jython、IronPython等等。
- en: Scaling horizontally
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 横向扩展
- en: If we add further nodes to the application, it must add to the total processing
    power. To create frontend systems that perform more data transmission than computation,
    `async` frameworks are better suited. If we use PyPy, it will give a performance
    boost to the application. Code for Python 3 or Python 2 compatibility using six
    or other such libraries so that we can use anything available for optimization.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们向应用程序添加更多节点，它必须增加总处理能力。为了创建执行更多数据传输而不是计算的客户端系统，`async` 框架更适合。如果我们使用 PyPy，它将为应用程序提供性能提升。使用
    six 或其他类似库的 Python 3 或 Python 2 兼容代码，以便我们可以使用任何可用的优化。
- en: We can use message pack or JSON for message transfer. I prefer JSON for language
    agnostic and easy-text representation. Workers can be multiprocessing workers
    for CPU-bound tasks or thread-based for other scenarios.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用消息打包或 JSON 进行消息传输。我更喜欢 JSON，因为它对语言无关且易于文本表示。工作者可以是用于 CPU 密集型任务的进程多线程工作者，或其他场景的线程基础工作者。
- en: The system should not store the state but pass it with messages. Everything
    doesn't need to be in DB. We can take some things out when not necessary.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 系统不应该存储状态，而应该通过消息传递状态。并不是所有东西都需要在数据库中。当不需要时，我们可以取出一些东西。
- en: 'ZeroMQ (messageQueue): ZMQ is a wonderful library that acts as a glue to connect
    your programs together. It has connectors for almost all language. You can easily
    use multiple languages/frameworks to enable their communication with ZMQ and among
    themselves. It also provides tools to create various utilities. Let''s now look
    at how we can create a load-balanced worker system easily using ZMQ. In the following
    code snippet, we created a client (requester) that can ask for a result from a
    group of servers (workers) that are load balanced. In the following code, we can
    see the socket type is `DEALER`. Sockets in ZMQ can be thought of as mini servers.
    The `req` sockets do not actually transmit until they get a response for the previous
    one. `DEALER` and `ROUTER` sockets are better suited for real-life scenarios.
    The code for synchronization is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 'ZeroMQ (消息队列): ZMQ 是一个出色的库，它充当连接你程序的粘合剂。它几乎为所有语言提供了连接器。你可以轻松地使用多种语言/框架，使它们能够与
    ZMQ 通信，并在彼此之间通信。它还提供了创建各种实用工具的工具。现在让我们看看如何使用 ZMQ 轻松地创建一个负载均衡的工作系统。在下面的代码片段中，我们创建了一个客户端（请求者），它可以从一组负载均衡的服务器（工作者）那里请求结果。在下面的代码中，我们可以看到套接字类型是
    `DEALER`。ZMQ 中的套接字可以被视为迷你服务器。`req` 套接字实际上只有在收到前一个响应后才会传输。`DEALER` 和 `ROUTER` 套接字更适合现实场景。同步代码如下：'
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is the code for servers or actual workers. We can have many of
    them and the load is distributed in a round-robin fashion among them:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为服务器或实际工作者提供的代码。我们可以拥有很多这样的服务器，负载将以轮询方式在他们之间分配：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following is the result from the run:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从运行中得到的输出：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can use the third-party package `Supervisord` to make workers restart on
    failure.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用第三方包 `Supervisord` 来使工作者在失败时重启。
- en: The real power of ZMQ is in creating network architecture and nodes as required
    by the project from simpler components. You can test the framework easily as it
    can support IPC, TCP, UDP, and many more protocols. They can also be used interchangeably.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ZMQ 的真正力量在于根据项目需求从更简单的组件中创建网络架构和节点。你可以轻松地测试框架，因为它可以支持 IPC、TCP、UDP 以及更多协议。它们也可以互换使用。
- en: There are other libraries/frameworks as well that can help a lot in this space,
    such as NSQ, Python parallel. Many projects go for RabbitMQ as the broker and
    AMQP as the protocol. Choosing good communication is very important for the design
    and scalability of a system, and it depends on the project requirement.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他库/框架也可以在这个领域提供大量帮助，例如 NSQ、Python 并行。许多项目选择 RabbitMQ 作为代理，AMQP 作为协议。选择良好的通信对于系统的设计和可扩展性非常重要，并且它取决于项目需求。
- en: Summary
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Making a program scalable is easy if we separate portions of program and use
    each part tuned for best performance. In this chapter, we saw how various portions
    of Python help in vertical as well as horizontal scaling. All this information
    must be taken into consideration when designing architecture of the application.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将程序的部分分离并使用每个部分以最佳性能进行调优，那么使程序可扩展是很容易的。在本章中，我们看到了 Python 的各个部分如何帮助垂直和水平扩展。在设计应用程序架构时，必须考虑所有这些信息。
