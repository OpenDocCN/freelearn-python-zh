- en: Using Regex to Extract Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正则表达式提取数据
- en: If these libraries don't exist in your current Python setup, refer to [Chapter
    2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python and the Web – Using urllib
    and Requests*, the *Setting things up* section, for more information on their
    installation and how to set them up. So far, we have learned about web technologies,
    data finding techniques, and how to access web content using Python libraries.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您当前的Python设置中不存在这些库，请参考[第2章](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml)，*Python和Web
    - 使用urllib和Requests*，*设置事项*部分，了解有关其安装和设置的更多信息。到目前为止，我们已经学习了关于Web技术、数据查找技术以及如何使用Python库访问Web内容的知识。
- en: '**Regular Expressions** (**Regex** or **regex**) is actually a pattern that''s
    built using predefined commands and formats to match the desired content. Regex provides
    a great value during data extraction when there is no particular layout or markup
    patterns to be chosen and can be applied with other techniques such as XPath,
    and CSS selectors.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**正则表达式**（**Regex**或**regex**）实际上是使用预定义命令和格式构建的模式，以匹配所需内容。在数据提取过程中，当没有特定的布局或标记模式可供选择时，正则表达式提供了很大的价值，并且可以与XPath、CSS选择器等其他技术一起应用。'
- en: Complex web content and data in general text or character format might require
    the use of Regex to complete activities, such as matching and extraction, plus
    function replacing, splitting, and so on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的网页内容和一般文本或字符格式的数据可能需要使用正则表达式来完成匹配和提取等活动，还包括函数替换、拆分等。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Overview of Regex
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式概述
- en: Using Regex to extract data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则表达式提取数据
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'A web browser (Google Chrome or Mozilla Firefox) is required for this chapter.
    We will be using the following Python libraries:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要一个Web浏览器（Google Chrome或Mozilla Firefox）。我们将使用以下Python库：
- en: '`requests`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`请求`'
- en: '`re`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re`'
- en: '`bs4`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bs4`'
- en: If these libraries don't exist in your current Python setup, refer to [Chapter
    2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python and the Web – Using urllib
    and Requests**,* the* Setting things up *section, for more information on their
    installation and how to set them up.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您当前的Python设置中不存在这些库，请参考[第2章](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml)，*Python和Web
    - 使用urllib和Requests*，*设置事项*部分，了解有关其安装和设置的更多信息。
- en: The code files for this chapter are available in this book's GitHub repository: [https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter09)。
- en: Those of you who are already using `re` can refer to the *Using regular expressions
    to extract data* section.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那些已经使用`re`的人可以参考*使用正则表达式提取数据*部分。
- en: Overview of regular expressions
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式概述
- en: Regular expressions are used to match patterns found in text or strings. Regex can
    be used for testing and finding patterns as desired against text or web content.
    Regex contains various ways to define patterns and special notations, such as *escape
    codes* to apply some predefined rules. For more information on Regex, please refer
    to the *Further reading* section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式用于匹配文本或字符串中找到的模式。正则表达式可以用于根据需要对文本或网页内容进行测试和查找模式。正则表达式包含各种定义模式和特殊符号的方法，例如*转义代码*，以应用一些预定义规则。有关正则表达式的更多信息，请参考*进一步阅读*部分。
- en: There are various cases where Regex can be quite effective and quick for obtaining
    the desired results. Regex can be applied to content (text or web sources) alone
    and can be used to target specific information patterns that aren't easily extractable
    while using XPath, CSS selectors, BS4*,* PyQuery, and so on.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种情况下，正则表达式可以非常有效和快速地获得所需的结果。正则表达式可以仅应用于内容（文本或网页源代码），并且可以用于针对不易使用XPath、CSS选择器、BS4*、*PyQuery等提取的特定信息模式。
- en: Sometimes, cases may arise that will demand Regex and XPath or CSS selectors
    to be used together in order to obtain the desired output. This output can then
    be tested using Regex in order to find patterns or to clean and manage data. Code
    editors, document writers, and readers also provide embedded Regex-based utilities.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，可能会出现需要同时使用正则表达式和XPath或CSS选择器才能获得所需输出的情况。然后可以使用正则表达式对输出进行测试，以查找模式或清理和管理数据。代码编辑器、文档编写器和阅读器还提供了嵌入式基于正则表达式的实用工具。
- en: 'Regex can be applied to any text or strings of characters, HTML sources, and
    so on that contain proper or improper formatting. Regex can be used for various
    applications, such as the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式可以应用于任何包含正确或不正确格式的文本或字符字符串、HTML源代码等。正则表达式可以用于各种应用，例如以下内容：
- en: Content based on a particular pattern
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于特定模式的内容
- en: Page links
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 页面链接
- en: Image titles and links
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像标题和链接
- en: Texts inside links
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接内的文本
- en: Matching and validating email addresses
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配和验证电子邮件地址
- en: Matching a postal code or zip code from address strings
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从地址字符串中匹配邮政编码或邮政编码
- en: Validating phone numbers, and so on
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证电话号码等
- en: Using tools such as searching, finding, splitting, substituting, matching, and
    iterating, are applicable with or without other technology interference.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用搜索、查找、拆分、替换、匹配和迭代等工具，无论是否有其他技术干扰，都可以适用。
- en: In the following sections, we will be using the `re` Python module and exploring
    its methods, which we can then apply to Regex.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将使用`re` Python模块并探索其方法，然后将其应用于正则表达式。
- en: Regular expressions and Python
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式和Python
- en: '`re` is a standard Python library that''s used to deal with Regex. Every default
    Python installation contains the `re` library. If the library doesn''t exist,
    please refer to [Chapter 2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python
    and the Web – Using urllib and Requests**,* the *Setting things up* section, to
    learn how to set it up.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`re`是一个标准的Python库，用于处理正则表达式。每个默认的Python安装都包含`re`库。如果该库不存在，请参考[第2章](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml)，*Python和Web
    - 使用urllib和Requests**,* *设置事物*部分，了解如何设置它。'
- en: '`>>>` in code represents the use of the Python IDE. It accepts the code or
    instructions it''s given and displays the output on the next line.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`>>>` 在代码中表示使用Python IDE。它接受给定的代码或指令，并在下一行显示输出。'
- en: 'Let''s begin by importing `re` using the Python IDE and listing its properties
    using the `dir()` function:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始通过Python IDE导入`re`并使用`dir()`函数列出其属性：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following is the output of the preceding command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面命令的输出：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As we can see from the preceding output, there are various functions available
    in `re`. We will be using a few of these functions from a content extraction perspective,
    and we will explain the basics of Regex fundamentals by using examples such as
    the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中可以看出，在`re`中有各种可用的函数。我们将从内容提取的角度使用其中的一些函数，并通过使用以下示例来解释正则表达式的基础知识：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`sentence` we declared previously contains brief information regarding Python
    jobs and job descriptions. We will be using this sentence to explain basic Regex
    functionalities.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前声明的`sentence`包含有关Python工作和工作描述的简要信息。我们将使用这个句子来解释基本的正则表达式功能。
- en: 'The `split()` function explodes the string and returns the list of individual
    words, which are separated by the *space* character by default. We can also split
    the string object using `re.split()`. In this case, `split()` accepts the Regex
    pattern to split the sentence, for example, `re.split(r''\s+'',sentence)`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`split()`函数将字符串分解并返回由*空格*字符默认分隔的单词列表。我们也可以使用`re.split()`来拆分字符串对象。在这种情况下，`split()`接受正则表达式模式来拆分句子，例如`re.split(r''\s+'',sentence)`： '
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The length of `sentence` and the Python `splitSentence` list object is obtained
    and printed using the preceding code. These counts of element and character will
    be helpful while comparing answers that are returned from the following examples:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的代码获取并打印`sentence`的长度和Python的`splitSentence`列表对象的长度。这些元素和字符的计数将有助于比较从以下示例返回的答案：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`re.findall()` accepts a pattern to search and the content to look for regarding
    the provided pattern. Normally, patterns can be provided directly to functions
    as an argument and as a *raw* string preceded with `r`, such as `r''([A-Z]+)''`,
    or a variable containing a *raw* string.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`re.findall()`接受要搜索的模式和要查找的与提供的模式相关的内容。通常，模式可以直接作为参数提供给函数，并且作为*原始*字符串前面带有`r`，例如`r''([A-Z]+)''`，或包含*原始*字符串的变量。'
- en: 'In the preceding code, we can see similar patterns with certain additional
    characters provided, but they differ in output. A general explanation is provided
    for some of these patterns, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到类似的模式，提供了一些额外的字符，但它们的输出不同。以下是一些这些模式的一般解释：
- en: '`[A-Z]`: Square brackets in the pattern match a set of characters and are case-sensitive.
    Here, it matches characters from `A` to `Z` but not `a` to `z`. We can provide
    a set of characters such as `[A-Za-z0-9]`, which matches any characters from `A` to
    `Z` and `a` to `z`, as well as numeric characters from `0` to `9`. Additional
    characters, if required, can be passed inside the set as `[A-Z+]`; the `+` character
    can exist with `A` to `Z` of characters, for example, C++ or C.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[A-Z]`：模式中的方括号匹配一组字符，并且区分大小写。在这里，它匹配从`A`到`Z`的字符，但不匹配`a`到`z`的字符。我们可以提供一组字符，例如`[A-Za-z0-9]`，它匹配从`A`到`Z`和`a`到`z`的任何字符，以及从`0`到`9`的数字字符。如果需要，可以在集合中传递其他字符，例如`[A-Z+]`；`+`字符可以与`A`到`Z`的字符一起存在，例如C++或C。'
- en: '`()`: Round brackets in the pattern hold the group of values that were matched.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`()`: 模式中的圆括号包含匹配的值组。'
- en: '`+` (used for repetition): Found outside of the character set, it matches one
    or more occurrences of the pattern it follows. `[A-Z]+` will match at least one
    or more combinations that''s found with the `A` to `Z` characters, for example, `R` and
    `MATLAB` from the preceding code. There are a few more characters for specifying
    repetition or occurrences, also known as Regex quantifiers:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`+`（用于重复）：在字符集之外找到时，它匹配模式的一个或多个出现。`[A-Z]+`将匹配至少一个或多个`A`到`Z`的字符组合，例如，前面代码中的`R`和`MATLAB`。还有一些用于指定重复或出现次数的其他字符，也称为正则表达式量词：'
- en: '`*` matches zero or more occurrences of the patterns'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`*` 匹配零次或多次模式'
- en: '`?` matches zero or one occurrence of the pattern'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`?` 匹配模式的零次或一次出现'
- en: '`{m,n}` matches the minimum, `m`, and maximum, `n`, numbers of repetition,
    respectively:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{m,n}` 分别匹配重复的最小`m`和最大`n`次数：'
- en: '`{2,5}`: Minimum 2 or maximum 5'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{2,5}`：最少2次或最多5次'
- en: '`{2,}`: Minimum 2 or could be more'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{2,}`：最少2次或更多'
- en: '`{,5}`: Maximum 5'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{,5}`：最多5次'
- en: '`{3}`: 3 occurrences'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{3}`：3次出现'
- en: '`\,` (comma): In Regex, characters other than `[A-Za-z0-9]` are normally written
    as escaped characters in order to mention that particular character (`\,` for
    comma, `\.` for period, `\?` for question mark, and so on).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\,`（逗号）：在正则表达式中，除了`[A-Za-z0-9]`之外的字符通常被写为转义字符，以便提及特定的字符（`\,`代表逗号，`\.`代表句号，`\?`代表问号等）。'
- en: 'Regex quantifiers are also categorized as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式量词也分为以下几类：
- en: '**Greedy quantifiers**: These match any element as many times as possible.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贪婪量词**：这些量词尽可能多地匹配任何元素。'
- en: '**Lazy or non-greedy quantifiers**: These match any element as few times as
    possible. Normally, a greedy quantifier is converted into a lazy quantifier by
    adding `?` to it.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**懒惰或非贪婪量词**：这些量词尽可能少地匹配任何元素。通常，通过在贪婪量词后添加`?`将其转换为懒惰量词。'
- en: Patterns such as `([A-Z+]+)\,` match the set of characters from `A` to `Z` and
    `+` that can exist in at least one or more characters, followed by `,`. In `sentence` in
    the preceding code, we can find `R`, `MATLAB`, `SAS`, `Mathematica`, `Java`, `C`,
    `C++`, `VB`, and `JavaScript` (there's also `FORTRAN`), that is, names followed
    by `,` (but not in the case of `FORTRAN`; this is why it's been excluded in the
    output for provided patterns).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 `([A-Z+]+)\,` 的模式匹配从 `A` 到 `Z` 和 `+` 中至少一个或多个字符，后跟`,`。在前面的代码中的`sentence`中，我们可以找到`R`、`MATLAB`、`SAS`、`Mathematica`、`Java`、`C`、`C++`、`VB`和`JavaScript`（还有`FORTRAN`），即名称后跟`,`（但不适用于`FORTRAN`的情况；这就是为什么它在提供的模式的输出中被排除的原因）。
- en: 'In the following code, we are trying to match`FORTRAN` that was found in `sentence`,
    which is being omitted with the patterns we tried in the code previously:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们试图匹配在`sentence`中找到的`FORTRAN`，并使用先前在代码中尝试的模式进行省略：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As shown in the preceding code block, the Python library, `re`, possesses various
    functions, which are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码块所示，Python库`re`具有各种函数，如下所示：
- en: '`re.match()`: This matches a pattern provided at the start of the string and
    returns the matched object.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.match()`: 这匹配提供的模式在字符串的开头，并返回匹配的对象。'
- en: '`re.sub()`: This finds a pattern and substitutes it with the provided string.
    It works similar to find and replace in text.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.sub()`: 这会找到一个模式并用提供的字符串替换它。它类似于文本中的查找和替换。'
- en: '`re.search()`: This matches a pattern in the string and returns the matched
    object that''s found.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.search()`: 这在字符串中匹配模式并返回找到的匹配对象。'
- en: '`\s`: This represents the *space*, *tab*, and *newline characters*. Here, `[\sorA-Z+]+\)` is
    matching one or more characters, including `A-Z`, `o`,`r`, `\s`, and `+`, followed
    by `\)` (closing parenthesis). There are a few more escape codes found in Regex,
    as follows:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\s`: 这表示*空格*、*制表符*和*换行符*。在这里，`[\sorA-Z+]+\)`匹配一个或多个字符，包括`A-Z`、`o`、`r`、`\s`和`+`，后跟`\)`（右括号）。在正则表达式中还有一些其他转义代码，如下所示：'
- en: '`\d`: Matches a digit'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\d`: 匹配数字'
- en: '`\D`: Matches a non-digit'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\D`: 匹配非数字'
- en: '`\s`: Matches whitespace'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\s`: 匹配空白'
- en: '`\S`: Matches non-whitespace'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\S`: 匹配非空白'
- en: '`\w`: Matches alphanumeric characters'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\w`: 匹配字母数字字符'
- en: '`\W`: Matches non-alphanumeric characters'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\W`: 匹配非字母数字字符'
- en: '`\b`: Matches a word boundary'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\b`: 匹配单词边界'
- en: '`\B`: Matches a non-word boundary'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\B`: 匹配非单词边界'
- en: '`^`: This matches the start of the string.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`^`: 这匹配字符串的开头。'
- en: 'Note: `r''[^a-z]''` (the caret or `^`), when used inside a character set, acts
    as negation. Here, this means *except* or *exclude* `[a-z]`.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：`r'[^a-z]'`（插入符号或`^`）在字符集内使用时起否定作用。这意味着*除了*或*排除*`[a-z]`。
- en: '`$`: This matches the end of the string.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`$`: 这匹配字符串的结尾。'
- en: '`|`: This implements the logical expression, `OR`, in the pattern. For example,
    `r''a|b''` will match any true expression, that is, `a` or `b`.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`|`: 这在模式中实现逻辑表达式`OR`。例如，`r''a|b''`将匹配任何真实表达式，即`a`或`b`。'
- en: 'The following code shows the use of some of these Regex patterns and the `findall()`
    function, along with their output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了一些这些正则表达式模式和`findall()`函数的使用，以及它们的输出：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following functions were found in the preceding code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中找到了以下函数：
- en: '`re` functions also support an optional *flags* argument. There''s also an
    abbreviation for these flags (`i` for `re.IGNORECASE`, `s` for `re.DOTALL`, and
    `M` for `re.MULTILINE`). These can be used in patterns by including them at the
    beginning of the expressions. For example, `r''(?i)\s(MAT.*?)\,` will return [`MATLAB`,
    `Mathematica`]. The following are some other `re` functions that were found in
    the code:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re` 函数还支持可选的*flags* 参数。这些标志也有缩写形式（`i`代表`re.IGNORECASE`，`s`代表`re.DOTALL`，`M`代表`re.MULTILINE`）。它们可以通过在表达式开头包含它们来在模式中使用。例如，`r''(?i)\s(MAT.*?)\,`将返回[`MATLAB`,
    `Mathematica`]。以下是在代码中找到的一些其他`re`函数：'
- en: '`re.IGNORECASE` : Ignores the case-sensitivity found in the pattern that''s
    provided'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.IGNORECASE` : 忽略提供的模式中发现的大小写敏感性'
- en: '`re.DOTALL` : Allows `.` (period) to match a newline, and works with strings
    containing multiple lines'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.DOTALL` : 允许`.` (句号)匹配换行符，并且适用于包含多行的字符串'
- en: '`re.MULTILINE` : Works with multiline strings and searches for patterns, including
    newline (`"\n"`)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.MULTILINE` : 与多行字符串一起使用，并搜索包括换行符(`"\n"`)在内的模式'
- en: '`.` or period: This matches any single character but not the newline (`"\n"`).
    It''s used in patterns mostly with repetition characters. A period or `.` is required
    to be matched in the string, and should be used as `\.`:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.` 或句号: 这匹配任何单个字符，但不包括换行符(`"\n"`)。它通常与重复字符一起在模式中使用。句号或`.` 需要在字符串中匹配，并且应该使用`\.`：'
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`re.split()`: This splits the provided content based on the pattern and returns
    a list with results. A `split()` also exists, which can be used with a string
    to explode with the default or provided characters. It''s used in a similar fashion
    to `splitSentence`, from earlier in this section.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.split()`: 这根据模式拆分提供的内容并返回带有结果的列表。还有一个`split()`，它可以与字符串一起使用以使用默认或提供的字符进行分割。它的使用方式与本节中稍早的`splitSentence`类似。'
- en: You are suggested to compare the results of `matchesOne` and `matchesTwo` from
    this section**.**
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您比较此部分中`matchesOne`和`matchesTwo`的结果**。**
- en: 'In code below we are trying to apply the regex pattern for the value found
    inside datetime attribute. Pattern defined will be compiled and then used to search
    in the code block:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们尝试应用datetime属性中找到的值的正则表达式模式。定义的模式将被编译，然后用于在代码块中搜索：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`re.compile()`: This is used to compile a Regex pattern and receive a pattern
    object (`_sre.SRE_Pattern`). The object that''s received can be used with other
    Regex features.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.compile()`: 用于编译正则表达式模式并接收模式对象（`_sre.SRE_Pattern`）。接收到的对象可以与其他正则表达式功能一起使用。'
- en: 'Group matches can be individually explored by using the `group()` method, as
    shown in the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用`group()`方法单独探索组匹配，如下面的代码所示：
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As we can see, though the pattern has been searched against multiline `timeDate`,
    it results in a single group; an individual group can be returned using the index
    too. An `re`-related match object contains the `groups()` and `group()`functions;
    `groups(0)` results in the same output as `groups()`. Individual elements in `groups()`
    will require an index starting from `1`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，尽管该模式已经针对多行 `timeDate` 进行了搜索，但结果是一个单独的分组；也可以使用索引返回单个分组。一个与 `re` 相关的匹配对象包含了
    `groups()` 和 `group()` 函数；`groups(0)` 的结果与 `groups()` 相同。`groups()` 中的单个元素将需要从
    `1` 开始的索引。
- en: '`re.finditer()`: This is used to iterate over resulting matches that are obtained
    for the pattern or pattern object found in the content that''s provided. It returns
    a match (`_sre.SRE_Match`) object that''s found from `re.match()`.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.finditer()`: 用于迭代在提供的内容中找到的模式或模式对象的结果匹配。它返回一个从 `re.match()` 中找到的匹配（`_sre.SRE_Match`）对象。'
- en: '`re.match()` returns an object that contains various functions and attributes
    that are used in code examples. These are as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`re.match()` 返回一个包含在代码示例中使用的各种函数和属性的对象。这些如下：'
- en: '`start()`: Returns the starting character index that matches the expression'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start()`: 返回与表达式匹配的起始字符索引'
- en: '`end()`: Returns the ending character index that matches the expression'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end()`: 返回与表达式匹配的结束字符索引'
- en: '`span()`: Returns the starting and ending character indexes of the matching
    expression'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`span()`: 返回匹配表达式的起始和结束字符索引'
- en: '`lastindex`: Returns the index of the last matched expression'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lastindex`: 返回最后匹配表达式的索引'
- en: '`groupdict()`: Returns the matching group dictionary with a pattern string
    and matched values'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupdict()`: 返回匹配组字典与模式字符串和匹配值'
- en: '`groups()`: Returns all matching elements'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groups()`: 返回所有匹配的元素'
- en: '`group()`: Returns an individual group and can be accessed with the group name'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group()`: 返回一个单独的分组，并可以通过分组名称访问'
- en: '`lastgroup`: Returns the name of the last group'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lastgroup`: 返回最后一个组的名称'
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Patterns can also specify string names for the groups they are in; for example,
    `r'(?P<year>[0-9]{4})'` matches the `year` group. Using group-based patterns in
    Regex helps us to read the pattern and manage the output more accurately; this
    means that we don't have to worry about indexing.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 模式也可以为它们所在的组指定字符串名称；例如，`r'(?P<year>[0-9]{4})'` 匹配 `year` 组。在正则表达式中使用基于组的模式可以帮助我们更准确地读取模式并管理输出；这意味着我们不必担心索引。
- en: 'Let''s consider the patterns `pDate` (implementing `group()`, `groupdict()`,
    `start()`, `end()`, `lastgroup`, and `lastindex`) with a group name and code that
    are exhibiting the outputs for date and time, respectively:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑模式 `pDate`（实现 `group()`, `groupdict()`, `start()`, `end()`, `lastgroup`,
    和 `lastindex`）与一个分组名称和代码，分别展示日期和时间的输出：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code results in the following output:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将产生以下输出：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following code shows the use of `pTime` (implementing `span()`):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了使用 `pTime`（实现 `span()`）：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding code will result in the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将产生以下输出：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this section, we have covered a general introduction to Regex and the features
    of the `re` Python library, along with some practical examples. Please refer to
    the *Further reading* section for more information regarding Regex. In the next
    section, we will be applying Regex to extract data from web-based content.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经介绍了正则表达式的一般概述和 `re` Python 库的特性，以及一些实际示例。请参考*进一步阅读*部分以获取有关正则表达式的更多信息。在下一节中，我们将应用正则表达式来从基于
    web 的内容中提取数据。
- en: Using regular expressions to extract data
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正则表达式提取数据
- en: Now that we've covered the basics and had an overview of Regex, we will use
    Regex to scrape (extract) data in bulk in a similar manner to using XPath, CSS
    selectors, `pyquery`, `bs4`, and so on by choosing between the implementation
    of Regex, XPath, `pyquery`, and more. This depends on the requirements and feasibility
    of web access and the availability of the content.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了基础知识并概述了正则表达式，我们将使用正则表达式以类似于使用 XPath、CSS 选择器、`pyquery`、`bs4` 等的方式批量抓取（提取）数据，通过选择在正则表达式、XPath、`pyquery`
    等之间的实现来满足网页访问的要求和可行性以及内容的可用性。
- en: It's not always a requirement that the content should be unstructured to apply
    Regex and extract data. Regex can be implemented for both structured and unstructured
    web content that's found in order to extract the desired data. In this section,
    we'll explore a few examples while using Regex and its various properties.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 并不总是要求内容应该是无结构的才能应用正则表达式并提取数据。正则表达式可以用于结构化和非结构化的网页内容，以提取所需的数据。在本节中，我们将探讨一些示例，同时使用正则表达式及其各种属性。
- en: Example 1 – extracting HTML-based content
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 1 - 提取基于 HTML 的内容
- en: 'In this example, we will be using the HTML content from the `regexHTML.html` file
    and apply a Regex pattern to extract information such as the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用来自 `regexHTML.html` 文件的 HTML 内容，并应用正则表达式模式来提取以下信息：
- en: HTML elements
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML 元素
- en: The element's attributes (`key` and `values`)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素的属性（`key` 和 `values`）
- en: The element's content
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素的内容
- en: 'This example will provide you with a general overview of how we can deal with
    various elements, values, and so on that exist inside web content and how we can
    apply Regex to extract that content. The steps we will be applying in the following
    code will be helpful for processing HTML and similar content:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子将为您提供一个如何处理网页内容中存在的各种元素、值等以及如何应用正则表达式来提取内容的概述。我们将在接下来的代码中应用以下步骤来处理 HTML
    和类似内容：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding code is the HTML page source we will be using. The content here
    is structured, and there are numerous ways that we can deal with it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码是我们将要使用的 HTML 页面源代码。这里的内容是结构化的，我们可以用多种方式处理它。
- en: 'In the following code, we will be using functions such as the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将使用以下函数：
- en: '`read_file()`: This will read the HTML file and return the page source for
    further processing.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_file()`: 这将读取 HTML 文件并返回页面源代码以供进一步处理。'
- en: '`applyPattern()`: This accepts a `pattern` argument, that is, the Regex pattern
    for finding content, which is applied to the HTML source using `re.findall()`
    and prints information such as a list of searched elements and their counts.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`applyPattern()`: 这个函数接受一个`pattern`参数，即用于查找内容的正则表达式模式，它使用`re.findall()`应用于HTML源代码，并打印诸如搜索元素列表和它们的计数之类的信息。'
- en: 'To begin with, let''s import `re` and `bs4`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入`re`和`bs4`：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here, `page` is an HTML page source that''s read from an HTML file using `read_file()`.
    We have also imported `BeautifulSoup` in the preceding code to extract individual
    HTML tag names and just to compare the implementation of code and results found
    by using `soup.find_all()` and a Regex pattern that we will be applying:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`page`是从HTML文件中使用`read_file()`读取的HTML页面源。我们还在前面的代码中导入了`BeautifulSoup`，以提取单独的HTML标签名称，并通过使用`soup.find_all()`和我们将应用的正则表达式模式来比较代码的实现和结果：
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: For finding all of the HTML tags that exist inside `page`, we used the `find_all()`
    method with `soup` as an object of `BeautifulSoup` using the `lxml` parser.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到`page`中存在的所有HTML标签，我们使用了`find_all()`方法，`soup`作为`BeautifulSoup`的对象，使用`lxml`解析器。
- en: For more information on Beautiful Soup, please visit [Chapter 5](5869ee86-6c67-4e6f-8151-61093795d94f.xhtml),
    *Web Scraping using Scrapy and Beautiful Soup*, the *Web scraping using Beautiful
    Soup* section.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Beautiful Soup的更多信息，请访问[第5章](5869ee86-6c67-4e6f-8151-61093795d94f.xhtml)，*使用Scrapy和Beautiful
    Soup进行Web抓取*，*使用Beautiful Soup进行Web抓取*部分。
- en: 'Here, we are finding all HTML tag names that don''t have any attributes. `\w+` matches
    any word with one or more character:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在查找所有没有任何属性的HTML标签名称。`\w+`匹配任何一个或多个字符的单词：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finding all HTML tags or elements that don''t end with *`>` *or contain some
    attributes can be found with the help of the space character, that is, `\s`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用空格字符`\s`来查找所有不以`>`结尾或包含某些属性的HTML标签或元素：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, by combining all of these patterns, we are listing all HTML tags that
    were found in the page source. The same result was also obtained in the previous
    code by using `soup.find_all()` and the `name` attribute:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过结合所有这些模式，我们正在列出在页面源中找到的所有HTML标签。通过使用`soup.find_all()`和`name`属性，前面的代码也得到了相同的结果：
- en: '[PRE20]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s find the attribute''s name, as found in the HTML element:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找到HTML元素中的属性名称：
- en: '[PRE21]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As we can see, there were only 10 attributes listed. In the HTML source, a few
    tags contain more than one attribute, such as `<a href="https://www.google.com"
    style="color:red;">Google</a>`, and only the first attribute was found using the
    provided pattern.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，只列出了10个属性。在HTML源代码中，一些标签包含多个属性，比如`<a href="https://www.google.com"
    style="color:red;">Google</a>`，只有使用提供的模式找到了第一个属性。
- en: 'Let''s rectify this. We can select words with the `=` character after them
    by using the `r''(\w+)=''` pattern, which will result in all of the attributes
    found in the page source being returned:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们纠正这一点。我们可以使用`r'(\w+)='`模式选择紧跟着`=`字符的单词，这将导致返回页面源中找到的所有属性：
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Similarly, let''s find all of the values for the attributes we''ve found. The
    following code lists the values of the attributes and compares the `18` attributes
    we listed previously. Only `9` values were found. With the pattern we used here, `r''=\"(\w+)\"''` will
    only find the word characters. Some of the attribute values contained non-word
    characters, such as `<a href="https://www.google.com" style="color:red;">`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，让我们找到我们找到的属性的所有值。以下代码列出了属性的值，并比较了我们之前列出的`18`个属性。只找到了`9`个值。使用的模式`r'=\"(\w+)\"'`只会找到单词字符。一些属性值包含非单词字符，比如`<a
    href="https://www.google.com" style="color:red;">`：
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, the complete attribute values are listed by using the proper pattern we
    analyzed. The content attribute values also contained non-word characters such
    as `;`, `/`, `:`, and `.`*.* In Regex, we can include such characters in the pattern
    individually, but this approach may not be appropriate in all cases.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用我们分析的适当模式列出了完整的属性值。内容属性值还包含非单词字符，如`;`、`/`、`:`和`.`。在正则表达式中，我们可以单独包含这些字符，但这种方法可能并不适用于所有情况。
- en: 'In this case, the pattern that includes `\w` and the non-whitespace character, `\S`, fits
    perfectly, that is, `r''=\"([\w\S]+)\"`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，包括`\w`和非空白字符`\S`的模式非常合适，即`r'=\"([\w\S]+)\"`：
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, let''s collect all of the text inside the HTML elements that are found
    in-between the opening and closing HTML tags:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们收集在HTML标签的开头和结尾之间找到的所有文本：
- en: '[PRE25]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: While applying Regex to the content, preliminary analysis for the type of content
    and the values to be extracted is compulsory. This will help to obtain the required
    results and can be done in one attempt.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在对内容应用正则表达式时，必须进行内容类型和要提取的值的初步分析。这将有助于在一次尝试中获得所需的结果。
- en: Example 2 – extracting dealer locations
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例2 - 提取经销商位置
- en: 'In this example, we will be extracting content from [http://godfreysfeed.com/dealersandlocations.php](http://godfreysfeed.com/dealersandlocations.php).
    This website contains dealer locations information, which is shown in the screenshot
    that follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将从[http://godfreysfeed.com/dealersandlocations.php](http://godfreysfeed.com/dealersandlocations.php)提取内容。这个网站包含经销商位置信息，如下面的屏幕截图所示：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: For this and the other examples in this section, we will be using the `re` and
    `requests` libraries in order to retrieve the page source, that is, `pageSource`.
    Here, we will be using the `read_url()` function to do so.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节和其他示例中，我们将使用`re`和`requests`库来检索页面源代码，即`pageSource`。在这里，我们将使用`read_url()`函数来实现。
- en: 'The page contains HTML `<form>` elements so that we can search for dealers
    based on the `zipcode` entered. There''s also a geographic map with markers:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 页面包含HTML`<form>`元素，以便我们可以根据输入的`zipcode`搜索经销商。还有一个带有标记的地理地图：
- en: '![](assets/6a8edbca-0e35-4112-8341-44add5a180f2.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6a8edbca-0e35-4112-8341-44add5a180f2.png)'
- en: Godfreysfeed Dealers front page
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Godfreysfeed经销商首页
- en: You can either perform form submission with `zipcode` or extract content from
    the map.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`zipcode`进行表单提交，也可以从地图中提取内容。
- en: 'By analyzing the page source, we will find that there''s no HTML elements with
    dealers'' information. Implementing Regex fits this case perfectly. Here, dealers''
    information is found inside JavaScript code with variables such as `latLng` and
    `infoWindowContent`, as shown in the following screenshot:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析页面源，我们将发现没有包含经销商信息的HTML元素。实现Regex非常适合这种情况。在这里，经销商的信息是在JavaScript代码中找到的，其中包含`latLng`和`infoWindowContent`等变量，如下截图所示：
- en: '![](assets/5026c2bb-c5ec-42a4-ad46-e7d3c9d53192.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5026c2bb-c5ec-42a4-ad46-e7d3c9d53192.png)'
- en: Godfreysfeed Dealers page source
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Godfreysfeed经销商页面源
- en: 'We will now proceed with loading the page source for the desired URL and implementing
    Regex to find data:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将继续加载所需URL的页面源，并实现Regex来查找数据：
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'With the page source obtained from `read_url()`, let''s do a basic analysis
    and build a pattern to collect latitude and longitude information. We will need
    two distinct patterns for the dealer''s address and coordinate values, respectively.
    Output from both patterns can be combined to obtain the final results:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从`read_url()`获取的页面源，让我们进行基本分析并构建一个模式来收集纬度和经度信息。我们需要两个不同的模式来分别获取经销商的地址和坐标值。从这两个模式的输出可以合并以获得最终结果：
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'By using the `pLatLng` pattern, a total of `55` coordinate values were found:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`pLatLng`模式，共找到了`55`个坐标值：
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now that we have the dealer''s coordinates, let''s find out the dealer''s name,
    address, and more:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了经销商的坐标，让我们找出经销商的名称、地址等信息：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'There was also a total of `55` pieces of address-based information, which was
    found by using the `pDealers`pattern.Note that the dealer''s content is in HTML
    format and that further implementation of Regex will be required to obtain individual
    titles such as `name`, `address`, and `city`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 还有`55`个基于地址的信息，是通过使用`pDealers`模式找到的。请注意，经销商的内容是以HTML格式呈现的，需要进一步实现Regex以获取诸如`name`、`address`和`city`等个别标题：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now that we have results from both `latlngs` and `dealers`, let''s collect
    the individual portions of the dealer''s address. Raw data for the dealers contains
    some HTML tags, and has been used to split and clean the dealer''s address information.
    Since `re.findall()` returns the Python list, indexing can also be useful for
    retrieving address components:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了`latlngs`和`dealers`的结果，让我们收集经销商地址的各个部分。经销商的原始数据包含一些HTML标签，已被用于拆分和清理经销商的地址信息。由于`re.findall()`返回Python列表，索引也可以用于检索地址组件：
- en: '[PRE32]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Finally, `dataSet` will contain an individual dealer''s information that''s
    been merged from `dealers` and `latlngs` in the listing:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`dataSet`将包含从`dealers`和`latlngs`中合并的单个经销商信息：
- en: '[PRE33]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In this example, we tried to extract data using different patterns and retrieved
    a dealer's information from the URL provided.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们尝试使用不同的模式提取数据，并从提供的URL中检索了经销商的信息。
- en: Example 3 – extracting XML content
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例3 - 提取XML内容
- en: 'In this example, we will be extracting contents from the `sitemap.xml` file,
    which can be downloaded from **[https://webscraping.com/sitemap.xml](https://webscraping.com/sitemap.xml)**:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将从`sitemap.xml`文件中提取内容，可以从**[https://webscraping.com/sitemap.xml](https://webscraping.com/sitemap.xml)**下载：
- en: '![](assets/060d674a-0e48-4325-b8a3-720edd7f4a0a.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/060d674a-0e48-4325-b8a3-720edd7f4a0a.png)'
- en: The sitemap.xml file from https://webscraping.com
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 来自https://webscraping.com的sitemap.xml文件
- en: 'By analyzing the XML content, we can see that different types of URLs exist
    as child nodes, that is, `<loc>`. From these URLs, we will be extracting the following:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析XML内容，我们可以看到不同类型的URL存在于子节点中，即`<loc>`。我们将从这些URL中提取以下内容：
- en: Blog URLs (URLs with a `/blog/` string, such as [https://webscraping.com/blog/Why-Python/](https://webscraping.com/blog/Why-Python/))
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 博客URL（包含`/blog/`字符串的URL，如[https://webscraping.com/blog/Why-Python/](https://webscraping.com/blog/Why-Python/)）
- en: Titles obtained from the blog URLs (*Why-Python*)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从博客URL获取的标题（*Why-Python*）
- en: Category URLs (URLs with a `/category/` string, such as [https://webscraping.com/blog/category/beautifulsoup](https://webscraping.com/blog/category/beautifulsoup))
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别URL（包含`/category/`字符串的URL，如[https://webscraping.com/blog/category/beautifulsoup](https://webscraping.com/blog/category/beautifulsoup)）
- en: Category titles obtained from category URLs (*beautifulsoup)*
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从类别URL获取的类别标题（*beautifulsoup*）
- en: Blog titles and category titles that are obtained from code are retrieved from
    the URL or representations of the real content that's available from the URL.
    Actual titles might be different.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码中获取的博客标题和类别标题是从URL或实际可用的内容的表示中检索出来的。实际标题可能会有所不同。
- en: 'To begin with, let''s import the `re` Python library and read the file''s contents,
    as well as create a few Python lists in order to collect relevant data:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入`re` Python库并读取文件内容，以及创建一些Python列表以收集相关数据：
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From the XML content, that is, `page`, we need to find the URL pattern. `pattern`
    used in code matches and returns all of the URLs inside the `<loc>` node. `urlPatterns`
    (`<class ''list''>`) is a Python list object that contains searched URLs and is
    iterated to collect and process the desired information:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 从XML内容，也就是`page`中，我们需要找到URL模式。代码中使用的`pattern`匹配并返回`<loc>`节点内的所有URL。`urlPatterns`（`<class
    'list'>`）是一个包含搜索URL的Python列表对象，可以迭代收集和处理所需的信息：
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now, let's match a `url`, such as [https://webscraping.com/blog/Google-App-Engine-limitations/](https://webscraping.com/blog/Google-App-Engine-limitations/),
    which contains a `blog` string and append it to `dataSetBlogURL`. There are also
    few other URLs, such as [https://webscraping.com/blog/8/](https://webscraping.com/blog/8/),
    which will be ignored while we extract `blogTitle`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们匹配一个`url`，比如[https://webscraping.com/blog/Google-App-Engine-limitations/](https://webscraping.com/blog/Google-App-Engine-limitations/)，其中包含一个`blog`字符串，并将其附加到`dataSetBlogURL`。还有一些其他URL，比如[https://webscraping.com/blog/8/](https://webscraping.com/blog/8/)，在我们提取`blogTitle`时将被忽略。
- en: 'Also, any `blogTitle` that''s found as text equal to `category` will be ignored.
    The `r''blog/([A-Za-z0-9\-]+)` pattern matches alphabetical and numerical values
    with the `-` character:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，任何作为文本等于`category`的`blogTitle`都将被忽略。`r'blog/([A-Za-z0-9\-]+)`模式匹配包含`-`字符的字母和数字值：
- en: '[PRE36]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here''s the output for `dataSetBlogURL`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`dataSetBlogURL`的输出：
- en: '[PRE37]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`dataSetBlog` will contain the following titles (URL portion). The `set()`
    method, when applied to `dataSetBlog`, will return unique elements from `dataSetBlog`.
    As shown in the following code, there''s no duplicate title inside `dataSetBlog`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataSetBlog`将包含以下标题（URL部分）。将`set()`方法应用于`dataSetBlog`时，将从`dataSetBlog`返回唯一元素。如下所示，`dataSetBlog`中没有重复的标题：'
- en: '[PRE38]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, let''s extract information that''s relevant to the URL by using `category`.
    The `r''.*category''` Regex pattern, which matches `url` from the iteration, is
    collected or appended to `datasetCategoryURL`. `categoryTitle` is extracted from
    `url` that matches the `r''category/([\w\s\-]+)` pattern and is added to `dataSetCategory`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用`category`来提取与URL相关的信息。`r'.*category'`正则表达式模式匹配迭代中的`url`，并将其收集或附加到`datasetCategoryURL`。从与`r'category/([\w\s\-]+)`模式匹配的`url`中提取`categoryTitle`，并将其添加到`dataSetCategory`：
- en: '[PRE39]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`dataSetCategoryURL` will result in the following values:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataSetCategoryURL`将产生以下值：'
- en: '[PRE40]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, the following output displays the title that was retrieved from `dataSetCategory`,
    as well as its counts:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下输出显示了从`dataSetCategory`中检索到的标题，以及其计数：
- en: '[PRE41]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: From these example cases, we can see that, by using Regex, we can write patterns
    that target specific data from sources such as web pages, HTML, or XML.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些示例中，我们可以看到，通过使用正则表达式，我们可以编写针对来自网页、HTML或XML等来源的特定数据的模式。
- en: Regex features such as searching, splitting, and iterating can be implemented
    with the help of various functions from the `re` Python library. Although Regex
    can be implemented on any type of content, unstructured content is preferred.
    Structured web content with elements that carry attributes are preferred when
    using XPath and CSS selectors.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索、分割和迭代等正则表达式功能可以通过`re` Python库中的各种函数来实现。尽管正则表达式可以应用于任何类型的内容，但首选非结构化内容。使用XPath和CSS选择器时，首选带有属性的结构化网页内容。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about regular expressions and their implementation
    by using the `re` Python library.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了正则表达式及其在`re` Python库中的实现。
- en: So far, we've learned about various scraping-based tools and techniques. Regex
    can provide more flexibility when it comes to extraction tasks and can be used
    with other tools.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了各种基于抓取的工具和技术。当涉及到提取任务时，正则表达式可以提供更多的灵活性，并且可以与其他工具一起使用。
- en: In the next chapter, we will be learning about further steps and topics that
    could be beneficial in a learning context, such as managing scraped data, visualization
    and analysis, and an introduction to machine learning and data mining, as well
    as exploring some related resources.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习进一步的步骤和主题，这些对于学习环境可能是有益的，比如管理抓取的数据，可视化和分析，以及机器学习和数据挖掘的介绍，以及探索一些相关资源。
- en: Further reading
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Regular Expression HOWTO: [https://docs.python.org/2/howto/regex.html](https://docs.python.org/2/howto/regex.html)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式指南：[https://docs.python.org/2/howto/regex.html](https://docs.python.org/2/howto/regex.html)
- en: Regular Expressions – JavaScript: [https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式 - JavaScript：[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions)
- en: Python Regular Expressions: [https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python正则表达式：[https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions)
- en: Online Regex Tester and Debugger: [https://regex101.com/](https://regex101.com/)
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线正则表达式测试器和调试器：[https://regex101.com/](https://regex101.com/)
- en: '*Regular Expressions Cookbook: 2nd Edition, 2012* by Jan Goyvaerts and Steven
    Levithan'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*正则表达式食谱：第二版，2012* 作者：Jan Goyvaerts和Steven Levithan'
- en: Regular Expressions References: [https://regexone.com/references/python](https://regexone.com/references/python)
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式参考：[https://regexone.com/references/python](https://regexone.com/references/python)
- en: Regular Expressions – Information: [http://www.regular-expressions.info/python.html](http://www.regular-expressions.info/python.html)
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式 - 信息：[http://www.regular-expressions.info/python.html](http://www.regular-expressions.info/python.html)
