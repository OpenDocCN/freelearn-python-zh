- en: '*Chapter 8*: Parallel Processing'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*: 并行处理'
- en: With parallel processing using multiple cores, you can increase the number of
    calculations your program can do in a given time frame without needing a faster
    processor. The main idea is to divide a problem into independent subunits and
    use multiple cores to solve those subunits in parallel.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多核并行处理，你可以在不使用更快的处理器的情况下，在给定的时间框架内增加程序可以完成的计算数量。主要思想是将问题分解成独立的子单元，并使用多个核心并行解决这些子单元。
- en: Parallel processing is necessary to tackle large-scale problems. Every day,
    companies produce massive quantities of data that needs to be stored in multiple
    computers and analyzed. Scientists and engineers run parallel code on supercomputers
    to simulate massive systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理是解决大规模问题的必要手段。每天，公司都会产生大量的数据，需要存储在多台计算机上并进行分析。科学家和工程师在超级计算机上运行并行代码来模拟大规模系统。
- en: Parallel processing allows you to take advantage of multicore **central processing
    units** (**CPUs**) as well as **graphics processing units** (**GPUs**) that work
    extremely well with highly parallel problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理允许你利用多核**中央处理器**（**CPUs**）以及与高度并行问题配合得非常好的**图形处理器**（**GPUs**）。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introduction to parallel programming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行编程简介
- en: Using multiple processes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个进程
- en: Parallel Cython with **Open Multi-Processing** (**OpenMP**)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Open Multi-Processing**（**OpenMP**）的并行 Cython
- en: Automatic parallelism
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动并行化
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code files for this chapter can be accessed through this link: [https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter08](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter08).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以通过此链接访问：[https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter08](https://github.com/PacktPublishing/Advanced-Python-Programming-Second-Edition/tree/main/Chapter08)。
- en: Introduction to parallel programming
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行编程简介
- en: To parallelize a program, it is necessary to divide the problem into subunits
    that can run independently (or almost independently) from each other.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行化一个程序，有必要将问题分解成可以独立（或几乎独立）运行的子单元。
- en: A problem where the subunits are totally independent of each other is called
    *embarrassingly parallel*. An element-wise operation on an array is a typical
    example—the operation needs to only know the element it is handling now. Another
    example is our particle simulator. Since there are no interactions, each particle
    can evolve independently from the others. Embarrassingly parallel problems are
    very easy to implement and perform very well on parallel architectures.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当子单元之间完全独立时，这种问题被称为*令人尴尬的并行*。对数组进行元素级操作是一个典型的例子——操作只需要知道它现在处理的元素。另一个例子是我们的粒子模拟器。由于没有相互作用，每个粒子可以独立于其他粒子发展。令人尴尬的并行问题很容易实现，并且在并行架构上表现良好。
- en: Other problems may be divided into subunits but must share some data to perform
    their calculations. In those cases, the implementation is less straightforward
    and can lead to performance issues because of the communication costs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其他问题可能被划分为子单元，但必须共享一些数据以执行它们的计算。在这些情况下，实现方式不太直接，并且由于通信成本可能导致性能问题。
- en: 'We will illustrate the concept with an example. Imagine that you have a particle
    simulator, but this time, the particles attract other particles within a certain
    distance (as shown in the following figure):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个例子来说明这个概念。想象一下，你有一个粒子模拟器，但这次，粒子在一定的距离内会吸引其他粒子（如下面的图所示）：
- en: '![Figure 8.1 – Illustration of a neighboring region ](img/B17499_Figure_8.1.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 邻近区域的示意图](img/B17499_Figure_8.1.jpg)'
- en: Figure 8.1 – Illustration of a neighboring region
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 邻近区域的示意图
- en: To parallelize this problem, we divide the simulation box into regions and assign
    each region to a different processor. If we evolve the system one step at a time,
    some particles will interact with particles in a neighboring region. To perform
    the next iteration, communication with the new particle positions of the neighboring
    region is required.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行化这个问题，我们将模拟区域划分为区域，并将每个区域分配给不同的处理器。如果我们一次进化系统的一步，一些粒子将与相邻区域的粒子相互作用。为了执行下一次迭代，需要与相邻区域的新粒子位置进行通信。
- en: 'Communication between processes is costly and can seriously hinder the performance
    of parallel programs. There exist two main ways to handle data communication in
    parallel programs: shared memory and distributed memory.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 进程间的通信成本高昂，可能会严重阻碍并行程序的性能。在并行程序中处理数据通信存在两种主要方式：共享内存和分布式内存。
- en: In **shared memory**, the subunits have access to the same memory space. An
    advantage of this approach is that you don't have to explicitly handle the communication
    as it is sufficient to write or read from the shared memory. However, problems
    arise when multiple processes try to access and change the same memory location
    at the same time. Care should be taken to avoid such conflicts using synchronization
    techniques.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在**共享内存**中，子单元可以访问相同的内存空间。这种方法的优点是，你不需要显式处理通信，因为从共享内存中写入或读取就足够了。然而，当多个进程同时尝试访问和更改相同的内存位置时，会出现问题。应谨慎使用同步技术来避免此类冲突。
- en: In the **distributed memory** model, each process is completely separated from
    the others and possesses its own memory space. In this case, communication is
    handled explicitly between the processes. The communication overhead is typically
    costlier compared to shared memory as data can potentially travel through a network
    interface.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在**分布式内存**模型中，每个进程与其他进程完全隔离，并拥有自己的内存空间。在这种情况下，进程间的通信是显式处理的。与共享内存相比，通信开销通常更昂贵，因为数据可能需要通过网络接口传输。
- en: 'One common way to achieve parallelism with the shared memory model is through
    **threads**. Threads are independent subtasks that originate from a process and
    share resources, such as memory. This concept is further illustrated in the following
    diagram:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在共享内存模型中实现并行的一种常见方式是通过**线程**。线程是从进程派生出来的独立子任务，并共享资源，如内存。以下图表进一步说明了这一概念：
- en: '![Figure 8.2 – Illustration of the difference between threads and processes
    ](img/B17499_Figure_8.2.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 线程和进程之间的差异说明](img/B17499_Figure_8.2.jpg)'
- en: Figure 8.2 – Illustration of the difference between threads and processes
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 线程和进程之间的差异说明
- en: Threads produce multiple execution contexts and share the same memory space,
    while processes provide multiple execution contexts that possess their own memory
    space, and communication must be handled explicitly.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 线程产生多个执行上下文并共享相同的内存空间，而进程提供多个具有自己内存空间的执行上下文，并且通信必须显式处理。
- en: Python can spawn and handle threads, but they can't be used to increase performance;
    due to the Python interpreter design, only one Python instruction is allowed to
    run at a time—this mechanism is called the **Global Interpreter Lock** (**GIL**).
    What happens is that each time a thread executes a Python statement, the thread
    acquires a lock and, when the execution is completed, the same lock is released.
    Since the lock can be acquired only by one thread at a time, other threads are
    prevented from executing Python statements while some other thread holds the lock.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Python可以创建和处理线程，但它们不能用来提高性能；由于Python解释器的设计，一次只能允许执行一条Python指令——这种机制称为**全局解释器锁**（**GIL**）。发生的情况是，每次线程执行Python语句时，线程都会获取一个锁，当执行完成后，该锁被释放。由于锁一次只能被一个线程获取，因此当某个线程持有锁时，其他线程将无法执行Python语句。
- en: Even though the GIL prevents parallel execution of Python instructions, threads
    can still be used to provide concurrency in situations where the lock can be released,
    such as in time-consuming **input/output** (**I/O**) operations or in C extensions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GIL阻止了Python指令的并行执行，但在可以释放锁的情况（如耗时的**输入/输出**（**I/O**）操作或在C扩展中）下，线程仍然可以用来提供并发性。
- en: Why Not Remove the GIL?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不移除GIL？
- en: In past years, many attempts have been made, including the most recent *Gilectomy*
    experiment. First, removing the GIL is not an easy task and requires modification
    of most of the Python data structures. Additionally, such fine-grained locking
    can be costly and may introduce substantial performance loss in single-threaded
    programs. Despite this, some Python implementations (notable examples are Jython
    and IronPython) do not use the GIL.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，已经进行了许多尝试，包括最近的*Gilectomy*实验。首先，移除GIL不是一项容易的任务，需要修改大多数Python数据结构。此外，这种细粒度的锁定可能成本高昂，并可能在单线程程序中引入显著的性能损失。尽管如此，一些Python实现（如Jython和IronPython）并不使用GIL。
- en: 'The GIL can be completely sidestepped using processes instead of threads. Processes
    don''t share the same memory area and are independent of each other—each process
    has its own interpreter. Processes have a few disadvantages: starting up a new
    process is generally slower than starting a new thread, they consume more memory,
    and **inter-process communication** (**IPC**) can be slow. On the other hand,
    processes are still very flexible, and they scale better as they can be distributed
    on multiple machines.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用进程而不是线程来完全绕过GIL。进程不共享相同的内存区域，并且彼此独立——每个进程都有自己的解释器。进程有一些缺点：启动一个新的进程通常比启动一个新的线程慢，它们消耗更多的内存，并且**进程间通信**（**IPC**）可能很慢。另一方面，进程仍然非常灵活，并且随着它们可以在多台机器上分布而更好地扩展。
- en: GPUs
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU
- en: GPUs are special processors designed for computer graphics applications. Those
    applications usually require processing the geometry of a **three-dimensional**
    (**3D**) scene and output an array of pixels to the screen. The operations performed
    by GPUs involve array and matrix operations on floating-point numbers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: GPU（图形处理器）是专为计算机图形应用设计的特殊处理器。这些应用通常需要处理**三维**（**3D**）场景的几何形状，并将像素数组输出到屏幕上。GPU执行的操作涉及浮点数的数组和矩阵运算。
- en: GPUs are designed to run this graphics-related operation very efficiently, and
    they achieve this by adopting a highly parallel architecture. Compared to a CPU,
    a GPU has many more (thousands) of small processing units. GPUs are intended to
    produce data at about 60 **frames per second** (**FPS**), which is much slower
    than the typical response time of a CPU, which possesses higher clock speeds.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: GPU被设计成非常高效地运行与图形相关的操作，它们通过采用高度并行的架构来实现这一点。与CPU相比，GPU拥有更多的（数千个）小型处理单元。GPU旨在以大约每秒60**帧**（**FPS**）的速度产生数据，这比具有更高时钟速度的CPU的典型响应时间慢得多。
- en: GPUs possess a very different architecture from a standard CPU and are specialized
    for computing floating-point operations. Therefore, to compile programs for GPUs,
    it is necessary to utilize special programming platforms, such as **Compute Unified
    Device Architecture** (**CUDA**) and **Open Computing Language** (**OpenCL**).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: GPU的架构与标准CPU非常不同，专门用于计算浮点运算。因此，为了为GPU编译程序，需要利用特殊的编程平台，例如**统一计算设备架构**（**CUDA**）和**开放计算语言**（**OpenCL**）。
- en: CUDA is a proprietary NVIDIA technology. It provides an **application programming
    interface** (**API**) that can be accessed from other languages. CUDA provides
    the **NVIDIA CUDA Compiler** (**NVCC**) tool that can be used to compile GPU programs
    written in a language such as C (CUDA C), as well as numerous libraries that implement
    highly optimized mathematical routines.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA是NVIDIA的专有技术。它提供了一个**应用程序编程接口**（**API**），可以从其他语言访问。CUDA提供了**NVIDIA CUDA编译器**（**NVCC**）工具，可用于编译用C（CUDA
    C）等语言编写的GPU程序，以及实现高度优化的数学例程的众多库。
- en: '**OpenCL** is an open technology with an ability to write parallel programs
    that can be compiled for a variety of target devices (CPUs and GPUs of several
    vendors) and is a good option for non-NVIDIA devices.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenCL**是一种开放技术，具有编写可编译为各种目标设备（多个供应商的CPU和GPU）的并行程序的能力，对于非NVIDIA设备来说是一个不错的选择。'
- en: GPU programming sounds wonderful on paper. However, don't throw away your CPU
    yet. GPU programming is tricky, and only specific use cases benefit from the GPU
    architecture. Programmers need to be aware of the costs incurred in memory transfers
    to and from the main memory and how to implement algorithms to take advantage
    of the GPU architecture.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: GPU编程在纸面上听起来很美妙。然而，不要扔掉你的CPU。GPU编程很复杂，只有特定的用例才能从GPU架构中受益。程序员需要意识到内存传输到和从主内存产生的成本，以及如何实现算法以利用GPU架构。
- en: Generally, GPUs are great at increasing the number of operations you can perform
    per unit of time (also called **throughput**); however, they require more time
    to prepare the data for processing. In contrast, CPUs are much faster at producing
    an individual result from scratch (also called **latency**).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，GPU擅长在单位时间内增加你可以执行的操作数量（也称为**吞吐量**）；然而，它们需要更多的时间来准备数据以进行处理。相比之下，CPU在从头开始生成单个结果方面要快得多（也称为**延迟**）。
- en: For the right problem, GPUs provide extreme (10 to 100 times) speedup. For this
    reason, they often constitute a very inexpensive solution (the same speedup will
    require hundreds of CPUs) to improve the performance of numerically intensive
    applications. We will illustrate how to execute some algorithms on a GPU in the
    *Automatic parallelism* section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正确的问题，GPU 提供了极端（10 到 100 倍）的速度提升。因此，它们通常构成了一种非常经济的解决方案（相同的速度提升将需要数百个 CPU），以提高数值密集型应用程序的性能。我们将在
    *自动并行化* 部分说明如何在 GPU 上执行一些算法。
- en: Having said that, we will begin our discussion on multiprocessing using standard
    processes in the next section.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们将在下一节开始讨论使用标准进程的多进程。
- en: Using multiple processes
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个进程
- en: The standard `multiprocessing` module can be used to quickly parallelize simple
    tasks by spawning several processes while avoiding the GIL problem. Its interface
    is easy to use and includes several utilities to handle task submission and synchronization.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的 `multiprocessing` 模块可以通过在避免 GIL 问题的情况下启动多个进程来快速并行化简单任务。它的接口易于使用，包括几个用于处理任务提交和同步的实用工具。
- en: The Process and Pool classes
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进程和池类
- en: 'You can create a process that runs independently by subclassing `multiprocessing.Process`.
    You can extend the `__init__` method to initialize resources, and you can write
    a portion of the code that will be executed in a subprocess by implementing the
    `Process.run` method. In the following code snippet, we define a `Process` class
    that will wait for 1 second and print its assigned `id` value:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过继承 `multiprocessing.Process` 来创建一个独立运行的进程。你可以扩展 `__init__` 方法来初始化资源，并通过实现
    `Process.run` 方法来编写将在子进程中执行的代码的一部分。在以下代码片段中，我们定义了一个 `Process` 类，它将等待 1 秒并打印其分配的
    `id` 值：
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To spawn the process, we must instantiate the `Process` class and call the
    `Process.start` method. Note that you don''t directly call `Process.run`; the
    call to `Process.start` will create a new process that, in turn, will call the
    `Process.run` method. We can add the following lines at the end of the preceding
    snippet to create and start the new process:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动进程，我们必须实例化 `Process` 类并调用 `Process.start` 方法。注意，你不会直接调用 `Process.run`；调用
    `Process.start` 将创建一个新的进程，然后该进程将调用 `Process.run` 方法。我们可以在前面代码片段的末尾添加以下行来创建并启动新进程：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The special __name__ Variable
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊的 __name__ 变量
- en: Note that we need to place any code that manages processes inside the `if __name__
    == '__main__'` condition, as shown in the previous code snippet, to avoid many
    undesirable behaviors. All the code shown in this chapter will be assumed to follow
    this practice.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们需要将管理进程的任何代码放在 `if __name__ == '__main__'` 条件中，正如前面代码片段所示，以避免许多不希望的行为。本章中展示的所有代码都将假定遵循此惯例。
- en: 'The instructions after `Process.start` will be executed immediately without
    waiting for the `p` process to finish. To wait for the task completion, you can
    use the `Process.join` method, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用 `Process.start` 之后，指令将立即执行，无需等待 `p` 进程完成。为了等待任务完成，你可以使用 `Process.join` 方法，如下所示：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can launch four different processes that will run in parallel in the same
    way. In a serial program, the total required time will be 4 seconds. Since the
    execution is concurrent, the resulting wall clock time will be of 1 second. In
    the following code snippet, we create four processes that will execute concurrently:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以启动四个不同的进程，它们将以相同的方式并行运行。在串行程序中，所需的总时间将是 4 秒。由于执行是并发的，因此结果的实际时钟时间将是 1 秒。在以下代码片段中，我们创建了四个将并发执行的进程：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that the order of the execution for parallel processes is unpredictable
    and ultimately depends on how the **operating system** (**OS**) schedules this.
    You can verify this behavior by executing the program multiple times; the order
    will likely be different between runs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，并行进程的执行顺序是不可预测的，最终取决于 **操作系统**（**OS**）如何调度。你可以通过多次执行程序来验证此行为；运行之间的顺序可能会不同。
- en: The `multiprocessing` module exposes a convenient interface that makes it easy
    to assign and distribute tasks to a set of processes that reside in the `multiprocessing.Pool`
    class.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing` 模块提供了一个方便的接口，使得将任务分配和分配给 `multiprocessing.Pool` 类中驻留的一组进程变得容易。'
- en: The `multiprocessing.Pool` class spawns a set of processes—called *workers*—and
    lets us submit tasks through the `apply`/`apply_async` and `map`/`map_async` methods.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Pool` 类启动一组进程——称为 *工作者*——并允许我们通过 `apply`/`apply_async` 和 `map`/`map_async`
    方法提交任务。'
- en: The `pool.map` method applies a function to each element of a list and returns
    a list of results. Its usage is equivalent to the built-in (serial) `map`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`pool.map` 方法将一个函数应用于列表中的每个元素，并返回一个结果列表。它的用法与内置的（串行）`map` 相当。'
- en: 'To use a parallel map, you should first initialize a `multiprocessing.Pool`
    object that takes the number of workers as its first argument; if not provided,
    that number will be equal to the number of cores in the system. You can initialize
    a `multiprocessing.Pool` object in the following way:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用并行映射，你应该首先初始化一个 `multiprocessing.Pool` 对象，该对象将工作线程的数量作为其第一个参数；如果没有提供，该数字将等于系统中的核心数。你可以以下面的方式初始化一个
    `multiprocessing.Pool` 对象：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s see `pool.map` in action. If you have a function that computes the square
    of a number, you can map the function to the list by calling `pool.map` and passing
    the function and the list of inputs as arguments, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `pool.map` 的实际应用。如果你有一个计算数字平方的函数，你可以通过调用 `pool.map` 并将函数和输入列表作为参数传递来将该函数映射到列表上，如下所示：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `pool.map_async` function is just like `pool.map` but returns an `AsyncResult`
    object instead of the actual result. When we call `pool.map`, the execution of
    the main program is stopped until all the workers are finished processing the
    result. With `map_async`, the `AsyncResult` object is returned immediately without
    blocking the main program and the calculations are done in the background. We
    can then retrieve the result using the `AsyncResult.get` method at any time, as
    shown in the following lines of code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`pool.map_async` 函数与 `pool.map` 类似，但返回的是一个 `AsyncResult` 对象而不是实际的结果。当我们调用 `pool.map`
    时，主程序的执行会停止，直到所有工作线程完成处理结果。使用 `map_async`，`AsyncResult` 对象会立即返回，而不会阻塞主程序，计算在后台进行。然后我们可以使用
    `AsyncResult.get` 方法在任何时候检索结果，如下面的代码行所示：'
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`pool.apply_async` assigns a task consisting of a single function to one of
    the workers. It takes the function and its arguments and returns an `AsyncResult`
    object. We can obtain an effect similar to `map` using `apply_async`, as shown
    here:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`pool.apply_async` 将一个由单个函数组成的任务分配给一个工作线程。它接受函数及其参数，并返回一个 `AsyncResult` 对象。我们可以使用
    `apply_async` 来实现类似于 `map` 的效果，如下所示：'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To use the results computed and returned by these processes, we can simply access
    the data stored in `results`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些进程计算并返回的结果，我们可以简单地访问存储在 `results` 中的数据。
- en: The Executor interface
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行器接口
- en: From version 3.2 onward, it is possible to execute Python code in parallel using
    the `Executor` interface provided in the `concurrent.futures` module. We already
    saw the `Executor` interface in action in the previous chapter, when we used `ThreadPoolExecutor`
    to perform multiple tasks concurrently. In this subsection, we'll demonstrate
    the usage of the `ProcessPoolExecutor` class.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从版本 3.2 开始，可以使用 `concurrent.futures` 模块中提供的 `Executor` 接口并行执行 Python 代码。我们已经在上一章中看到了
    `Executor` 接口的应用，当时我们使用 `ThreadPoolExecutor` 来并发执行多个任务。在本小节中，我们将演示 `ProcessPoolExecutor`
    类的用法。
- en: '`ProcessPoolExecutor` exposes a very lean interface, at least when compared
    to the more featureful `multiprocessing.Pool`. A `ProcessPoolExecutor` class can
    be instantiated, similar to `ThreadPoolExecutor`, by passing a number of worker
    threads using the `max_workers` argument (by default, `max_workers` will be the
    number of CPU cores available). The main methods available to the `ProcessPoolExecutor`
    class are `submit` and `map`.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`ProcessPoolExecutor` 提供了一个非常简洁的接口，至少与功能更丰富的 `multiprocessing.Pool` 相比是这样。可以通过使用
    `max_workers` 参数（默认情况下，`max_workers` 将等于系统中的核心数）传递工作线程的数量来实例化一个 `ProcessPoolExecutor`
    类，类似于 `ThreadPoolExecutor`。`ProcessPoolExecutor` 类的主要方法有 `submit` 和 `map`。'
- en: 'The `submit` method will take a function and return a `Future` instance that
    will keep track of the execution of the submitted function. The `map` method works
    similarly to the `pool.map` function, except that it returns an iterator rather
    than a list. The code is illustrated in the following snippet:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`submit` 方法将接受一个函数并返回一个 `Future` 实例，该实例将跟踪提交函数的执行。`map` 方法与 `pool.map` 函数类似，但返回的是一个迭代器而不是列表。代码在以下代码片段中展示：'
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To extract the result from one or more `Future` instances, you can use the
    `concurrent.futures.wait` and `concurrent.futures.as_completed` functions. The
    `wait` function accepts a list of `future` instances and will block the execution
    of the programs until all the futures have completed their execution. The result
    can then be extracted using the `Future.result` method. The `as_completed` function
    also accepts a function but will, instead, return an iterator over the results.
    The code is illustrated in the following snippet:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要从一个或多个`Future`实例中提取结果，你可以使用`concurrent.futures.wait`和`concurrent.futures.as_completed`函数。`wait`函数接受一个`future`实例列表，并将阻塞程序的执行，直到所有未来都完成执行。然后可以使用`Future.result`方法提取结果。`as_completed`函数也接受一个函数，但它将返回一个结果迭代器。以下代码片段展示了代码示例：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Alternatively, you can generate futures using the `asyncio.run_in_executor`
    function and manipulate the results using all the tools and syntax provided by
    the `asyncio` libraries so that you can achieve concurrency and parallelism at
    the same time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用`asyncio.run_in_executor`函数生成未来，并使用`asyncio`库提供的所有工具和语法来操作结果，这样你就可以同时实现并发和并行。
- en: Monte Carlo approximation of pi
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Monte Carlo近似π
- en: 'As an example, we will implement a canonical, embarrassingly parallel program—**the
    Monte Carlo approximation of pi**. Imagine that we have a square of size 2 units;
    its area will be 4 units. Now, we inscribe a circle of 1 unit radius in this square;
    the area of the circle will be ![](img/Formula_8.1_B17499.png). By substituting
    the value of *r* in the previous equation, we get that the numerical value for
    the area of the circle is ![](img/Formula_8.2_B17499.png) *= pi*. You can refer
    to the following screenshot for a graphical representation of this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我们将实现一个典型的、明显并行的程序——**蒙特卡洛近似π**。想象一下，我们有一个边长为2个单位的正方形；其面积将是4个单位。现在，我们在正方形内画一个半径为1个单位的圆；圆的面积将是![img/Formula_8.1_B17499.png](img/Formula_8.1_B17499.png)。通过在上一个方程中代入*r*的值，我们得到圆的面积数值为![img/Formula_8.2_B17499.png](img/Formula_8.2_B17499.png)
    *= π*。你可以参考以下截图来查看这个图形表示：
- en: '![Figure 8.3 – Illustration of our strategy of approximation of pi ](img/B17499_Figure_8.3.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 我们近似π的策略示意图](img/B17499_Figure_8.3.jpg)'
- en: Figure 8.3 – Illustration of our strategy of approximation of pi
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 我们近似π的策略示意图
- en: 'If we shoot a lot of random points on this, some points will fall into the
    circle, which we''ll call *hits*, while the remaining points, *misses*, will be
    outside the circle. The area of the circle will be proportional to the number
    of hits, while the area of the square will be proportional to the total number
    of shots. To get the value of pi, it is sufficient to divide the area of the circle
    (equal to *pi*) by the area of the square (equal to 4), as illustrated in the
    following code snippet:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在上面随机射出很多点，一些点会落在圆内，我们将它们称为*命中*，而剩下的点，*未命中*，将位于圆外。圆的面积将与命中点的数量成正比，而正方形的面积将与射击总数成正比。为了得到π的值，只需将圆的面积（等于*π*）除以正方形的面积（等于4），如下代码片段所示：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The strategy we will employ in our program will be as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在程序中采用的策略如下：
- en: Generate a lot of uniformly random (*x*, *y*) numbers in the range (-1, 1).
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在范围(-1, 1)内生成大量的均匀随机(*x*, *y*)数字。
- en: Test whether those numbers lie inside the circle by checking whether *x**2 +
    y**2 <= 1*.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过检查*x**2 + y**2 <= 1*来测试这些数字是否位于圆内。
- en: 'The first step when writing a parallel program is to write a serial version
    and verify that it works. In a real-world scenario, you also want to leave parallelization
    as the last step of your optimization process—first, because we need to identify
    the slow parts, and second, parallelization is time-consuming and *gives you at
    most a speedup equal to the number of processors*. The implementation of the serial
    program is shown here:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 编写并行程序的第一步是编写一个串行版本并验证其是否工作。在现实场景中，你希望将并行化作为优化过程的最后一步——首先，因为我们需要识别出慢速部分，其次，并行化耗时且*最多只能将速度提升到处理器数量的水平*。串行程序的实现如下所示：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The accuracy of our approximation will improve as we increase the number of
    samples. Note that each loop iteration is independent of the other—this problem
    is embarrassingly parallel.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 随着样本数量的增加，我们的近似精度将提高。请注意，每个循环迭代都是独立的——这个问题是明显并行的。
- en: 'To parallelize this code, we can write a function, called `sample`, that corresponds
    to a single hit-miss check. If the sample hits the circle, the function will return
    `1`; otherwise, it will return `0`. By running `sample` multiple times and summing
    the results, we''ll get the total number of hits. We can run `sample` over multiple
    processors with `apply_async` and get the results in the following way:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行化这段代码，我们可以编写一个名为 `sample` 的函数，它对应于单次命中-未命中检查。如果样本击中圆圈，该函数将返回 `1`；否则，它将返回
    `0`。通过多次运行 `sample` 并汇总结果，我们将得到总命中数。我们可以使用 `apply_async` 在多个处理器上运行 `sample` 并以以下方式获取结果：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can wrap the two versions in the `pi_serial` and `pi_apply_async` functions
    (you can find their implementation in the `pi.py` file) and benchmark the execution
    speed, as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这两个版本包裹在 `pi_serial` 和 `pi_apply_async` 函数中（你可以在 `pi.py` 文件中找到它们的实现）并比较执行速度，如下所示：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As shown in the earlier benchmark, our first parallel version literally cripples
    our code, the reason being that the time spent doing the actual calculation is
    small compared to the overhead required to send and distribute the tasks to the
    workers.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的基准测试所示，我们的第一个并行版本实际上削弱了我们的代码，原因是实际计算所需的时间与发送和分配任务到工作进程所需的开销相比非常小。
- en: 'To solve the issue, we have to make the overhead negligible compared to the
    calculation time. For example, we can ask each worker to handle more than one
    sample at a time, thus reducing the task communication overhead. We can write
    a `sample_multiple` function that processes more than one hit and modifies our
    parallel version by dividing our problem by 10; more intensive tasks are shown
    in the following code snippet:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们必须使开销与计算时间相比可以忽略不计。例如，我们可以要求每个工作进程一次处理多个样本，从而减少任务通信开销。我们可以编写一个 `sample_multiple`
    函数，它处理多个命中，并通过将问题分成10份来修改我们的并行版本；更复杂的工作在以下代码片段中展示：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can wrap this in a function called `pi_apply_async_chunked` and run it as
    follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个功能包裹在一个名为 `pi_apply_async_chunked` 的函数中，并按以下方式运行它：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The results are much better; we more than doubled the speed of our program.
    You can also notice that the `user` metric is larger than `real`; the total CPU
    time is larger than the total time because more than one CPU worked at the same
    time. If you increase the number of samples, you will note that the ratio of communication
    to calculation decreases, giving even better speedups.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 结果要好得多；我们的程序速度提高了不止一倍。你也可以注意到 `user` 指标大于 `real`；总CPU时间大于总时间，因为同时使用了多个CPU。如果你增加样本数量，你会注意到通信与计算的比率降低，从而提供更好的加速。
- en: Everything is nice and simple when dealing with embarrassingly parallel problems.
    However, you sometimes have to share data between processes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 处理令人尴尬的并行问题时，一切都很简单明了。然而，有时你必须在进程之间共享数据。
- en: Synchronization and locks
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步和锁
- en: 'Even if `multiprocessing` uses processes (with their own independent memory),
    it lets you define certain variables and arrays as shared memory. You can define
    a shared variable using `multiprocessing.Value`, passing its data type as a string
    (`i` for integer, `d` for double, `f` for float, and so on). You can update the
    content of the variable through the `value` attribute, as shown in the following
    code snippet:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 即使 `multiprocessing` 使用进程（它们有自己独立的内存），它也允许你定义某些变量和数组作为共享内存。你可以使用 `multiprocessing.Value`
    定义一个共享变量，并通过字符串传递其数据类型（`i` 表示整数，`d` 表示双精度，`f` 表示浮点等）。你可以通过 `value` 属性更新变量的内容，如下面的代码片段所示：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When using shared memory, you should be aware of concurrent access. Imagine
    that you have a shared integer variable, and each process increments its value
    multiple times. You will define a `Process` class, as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用共享内存时，你应该注意并发访问。想象一下，你有一个共享的整数变量，每个进程都会多次增加它的值。你将定义一个 `Process` 类，如下所示：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You can initialize the shared variable in the main program and pass it to `4`
    processes, as shown in the following code snippet:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在主程序中初始化共享变量并将其传递给 `4` 个进程，如下面的代码片段所示：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: If you run this program (`shared.py` in the code directory), you will note that
    the final value of `counter` is not `4000`, but it has random values (on my machine,
    they are between `2000` and `2500`). If we assume that the arithmetic is correct,
    we can conclude that there's a problem with the parallelization.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个程序（代码目录中的 `shared.py`），你会注意到 `counter` 的最终值不是 `4000`，而是有随机值（在我的机器上，它们在
    `2000` 和 `2500` 之间）。如果我们假设算术是正确的，我们可以得出结论，并行化存在问题。
- en: What happens is that multiple processes are trying to access the same shared
    variable at the same time. The situation is best explained by looking at the following
    diagram. In a serial execution, the first process reads the number (`0`), increments
    it, and writes the new value (`1`); the second process reads the new value (`1`),
    increments it, and writes it again (`2`).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 发生的情况是多个进程同时尝试访问同一个共享变量。这种情况最好通过以下图表来解释。在串行执行中，第一个进程读取数字（`0`），增加它，并写入新值（`1`）；第二个进程读取新值（`1`），增加它，并再次写入（`2`）。
- en: 'In parallel execution, the two processes read the number (`0`), increment it,
    and write the value (`1`) at the same time, leading to a wrong answer:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行执行中，两个进程同时读取数字（`0`），增加它，并写入值（`1`），导致错误答案：
- en: '![Figure 8.4 – Multiple processes accessing the same variable, leading to incorrect
    behavior ](img/B17499_Figure_8.4.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4 – 多个进程访问同一变量，导致行为不正确](img/B17499_Figure_8.4.jpg)'
- en: Figure 8.4 – Multiple processes accessing the same variable, leading to incorrect
    behavior
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 – 多个进程访问同一变量，导致行为不正确
- en: To solve this problem, we need to synchronize the access to this variable so
    that only one process at a time can access, increment, and write the value on
    the shared variable. This feature is provided by the `multiprocessing.Lock` class.
    A lock can be acquired and released through the `acquire` and `release` methods
    respectively or by using the lock as a context manager. Since the lock can be
    acquired by only one process at a time, this method prevents multiple processes
    from executing the protected section of code at the same time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要同步对这个变量的访问，以确保一次只有一个进程可以访问、增加并写入共享变量的值。这个功能由`multiprocessing.Lock`类提供。可以通过`acquire`和`release`方法分别获取和释放锁，或者使用锁作为上下文管理器。由于锁一次只能被一个进程获取，这种方法可以防止多个进程同时执行受保护的代码段。
- en: 'We can define a global lock and use it as a context manager to restrict access
    to the counter, as shown in the following code snippet:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个全局锁，并使用它作为上下文管理器来限制对计数器的访问，如下面的代码片段所示：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Synchronization primitives, such as locks, are essential to solving many problems,
    but they should be kept to a minimum to improve the performance of your program.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 同步原语，如锁，对于解决许多问题是必不可少的，但应该将其保持到最小，以提高程序的性能。
- en: Tip
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: The `multiprocessing` module includes other communication and synchronization
    tools; you can refer to the official documentation at [http://docs.python.org/3/library/multiprocessing.html](http://docs.python.org/3/library/multiprocessing.html)
    for a complete reference.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块包括其他通信和同步工具；你可以参考官方文档[http://docs.python.org/3/library/multiprocessing.html](http://docs.python.org/3/library/multiprocessing.html)以获取完整的参考。'
- en: In [*Chapter 4*](B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068), *C Performance
    with Cython*, we discussed Cython as a method of speeding up our programs. Cython
    itself also allows parallel processing via OpenMP, which we will examine next.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068) *使用Cython提高C性能*中，我们讨论了Cython作为加快我们程序的方法。Cython本身也允许通过OpenMP进行并行处理，我们将在下一节中探讨。
- en: Parallel Cython with OpenMP
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带OpenMP的并行Cython
- en: Cython provides a convenient interface to perform shared-memory parallel processing
    through *OpenMP*. This lets you write extremely efficient parallel code directly
    in Cython without having to create a C wrapper.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Cython通过*OpenMP*提供了一个方便的接口来执行共享内存并行处理。这让你可以直接在Cython中编写非常高效的并行代码，而无需创建C包装器。
- en: OpenMP is a specification and an API designed to write multithreaded, parallel
    programs. The OpenMP specification includes a series of C preprocessor directives
    to manage threads and provides communication patterns, load balancing, and other
    synchronization features. Several C/C++ and Fortran compilers (including the **GNU
    Compiler Collection** (**GCC**)) implement the OpenMP API.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP是一个用于编写多线程、并行程序的规范和API。OpenMP规范包括一系列C预处理器指令来管理线程，并提供通信模式、负载均衡和其他同步功能。几个C/C++和Fortran编译器（包括**GNU编译器集合**（**GCC**））实现了OpenMP
    API。
- en: We can introduce the Cython parallel features with a small example. Cython provides
    a simple API based on OpenMP in the `cython.parallel` module. The simplest way
    to achieve parallelism is through `prange`, which is a construct that automatically
    distributes loop operations in multiple threads.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个小示例引入Cython的并行功能。Cython在`cython.parallel`模块中提供了一个基于OpenMP的简单API。实现并行化的最简单方法是使用`prange`，这是一个自动在多个线程中分配循环操作的构造。
- en: 'First of all, we can write the serial version of a program that computes the
    square of each element of a NumPy array in the `hello_parallel.pyx` file. We define
    a function, `square_serial`, that takes a buffer as input and populates an output
    array with the squares of the input array elements; `square_serial` is shown in
    the following code snippet:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以在`hello_parallel.pyx`文件中编写一个程序的串行版本，该程序计算NumPy数组中每个元素的平方。我们定义一个函数`square_serial`，它接受一个缓冲区作为输入，并用输入数组元素的平方填充输出数组；`square_serial`在以下代码片段中显示：
- en: '[PRE20]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Implementing a parallel version of the loop over the array elements involves
    substituting the `range` call with `prange`. There's a caveat—to use `prange`,
    the body of the loop must be interpreter-free. As already explained, we need to
    release the GIL and, since interpreter calls generally acquire the GIL, they need
    to be avoided to make use of threads.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 实现数组元素循环的并行版本涉及用`prange`替换`range`调用。有一个注意事项——要使用`prange`，循环体必须是解释器无关的。如前所述，我们需要释放GIL，由于解释器调用通常获取GIL，因此需要避免这些调用以利用线程。
- en: 'In Cython, you can release the GIL using the `nogil` context, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在Cython中，您可以使用`nogil`上下文释放GIL，如下所示：
- en: '[PRE21]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Alternatively, you can use the `nogil=True` option of `prange` that will automatically
    wrap the loop body in a `nogil` block, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用`prange`的`nogil=True`选项，这将自动将循环体包装在一个`nogil`块中，如下所示：
- en: '[PRE22]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Attempts to call Python code in a `prange` block will produce an error. Prohibited
    operations include function calls, object initialization, and so on. To enable
    such operations in a `prange` block (you may want to do so for debugging purposes),
    you have to re-enable the GIL using a `with gil` statement, as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在`prange`块中调用Python代码将产生错误。禁止的操作包括函数调用、对象初始化等。为了在`prange`块中启用此类操作（您可能希望为了调试目的这样做），您必须使用`with
    gil`语句重新启用GIL，如下所示：
- en: '[PRE23]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can now test our code by compiling it as a Python extension module. To enable
    OpenMP support, it is necessary to change the `setup.py` file so that it includes
    the `-fopenmp` compilation option. This can be achieved by using the `distutils.extension.Extension`
    class in `distutils` and passing it to `cythonize`. The complete `setup.py` file
    looks like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过将其编译为Python扩展模块来测试我们的代码。为了启用OpenMP支持，需要更改`setup.py`文件，使其包含`-fopenmp`编译选项。这可以通过在`distutils`中使用`distutils.extension.Extension`类并将其传递给`cythonize`来实现。完整的`setup.py`文件如下所示：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Using `prange`, we can easily parallelize the Cython version of our `ParticleSimulator`
    class. The following code snippet contains the `c_evolve` function of the `cevolve.pyx`
    Cython module that was written in [*Chapter 4*](B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068),
    *C Performance with Cython*:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`prange`，我们可以轻松地将`ParticleSimulator`类的Cython版本并行化。以下代码片段包含在[*第4章*](B17499_04_Final_SS_ePub.xhtml#_idTextAnchor068)中编写的`cevolve.pyx`
    Cython模块的`c_evolve`函数，*C与Cython的性能*：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'First, we will invert the order of the loops so that the outermost loop will
    be executed in parallel (each iteration is independent of the other). Since the
    particles don''t interact with each other, we can change the order of iteration
    safely, as shown in the following code snippet:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将循环的顺序颠倒，以便最外层循环将并行执行（每个迭代与其他迭代独立）。由于粒子之间没有相互作用，我们可以安全地更改迭代的顺序，如下所示：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, we will replace the `range` call of the outer loop with `prange` and
    remove calls that acquire the GIL. Since our code was already enhanced with static
    types, the `nogil` option can be applied safely, as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将用`prange`替换外部循环的`range`调用，并移除获取GIL的调用。由于我们的代码已经通过静态类型进行了增强，因此可以安全地应用`nogil`选项，如下所示：
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can now compare the functions by wrapping them in the `benchmark` function
    to assess any performance improvement, as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过将它们包装在`benchmark`函数中来比较这些函数，以评估任何性能改进，如下所示：
- en: '[PRE28]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Interestingly, we achieved a two-times speedup by writing a parallel version
    using `prange`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们通过编写使用`prange`的并行版本实现了两倍的速度提升。
- en: As we mentioned earlier, normal Python programs have trouble achieving thread
    parallelism because of the GIL. So far, we worked around this problem using separate
    processes; starting a process, however, takes significantly more time and memory
    than starting a thread.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，由于 GIL，常规的 Python 程序在实现线程并行化方面有困难。到目前为止，我们通过使用单独的进程来解决这个问题；然而，启动进程比启动线程花费更多的时间和内存。
- en: We also saw that sidestepping the Python environment allowed us to achieve a
    two-times speedup on already fast Cython code. This strategy allowed us to achieve
    lightweight parallelism but required a separate compilation step. In the next
    section, we will further explore this strategy using special libraries that are
    capable of automatically translating our code into a parallel version for efficient
    execution.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到，绕过 Python 环境使我们能够在已经很快的 Cython 代码上实现两倍的速度提升。这种策略使我们能够实现轻量级并行化，但需要单独的编译步骤。在下一节中，我们将进一步探讨这种策略，使用能够自动将我们的代码转换为并行版本的专用库，以实现高效的执行。
- en: Automatic parallelism
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动并行化
- en: Examples of packages that implement automatic parallelism are the (by now) familiar
    `numexpr` and Numba. Other packages have been developed to automatically optimize
    and parallelize array and matrix-intensive expressions, which are crucial in specific
    numerical and **machine learning** (**ML**) applications.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 实现自动并行化的包示例包括现在大家熟悉的 `numexpr` 和 Numba。其他包已被开发出来以自动优化和并行化数组密集型表达式，这在特定的数值和**机器学习**（**ML**）应用中至关重要。
- en: '**Theano** is a project that allows you to define a mathematical expression
    on arrays (more generally, *tensors*), and compile them to a fast language, such
    as C or C++. Many of the operations that Theano implements are parallelizable
    and can run on both the CPU and GPU.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**Theano** 是一个项目，允许您在数组（更一般地说，*张量*）上定义数学表达式，并将它们编译为快速语言，如 C 或 C++。Theano 实现的大多数操作都是可并行化的，并且可以在
    CPU 和 GPU 上运行。'
- en: '**TensorFlow** is another library that, similar to Theano, is targeted toward
    array-intensive mathematical expressions but, rather than translating the expressions
    to specialized C code, executes the operations on an efficient C++ engine.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow** 是另一个库，与 Theano 类似，针对数组密集型数学表达式，但它不是将表达式转换为专门的 C 代码，而是在高效的 C++
    引擎上执行操作。'
- en: Both Theano and TensorFlow are ideal when the problem at hand can be expressed
    in a chain of matrix and element-wise operations (such as *neural networks*).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当手头的问题可以用矩阵和逐元素操作的链表达时（例如 *神经网络*），Theano 和 TensorFlow 都是理想的。
- en: Getting started with Theano
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Theano 入门
- en: Theano is somewhat similar to a compiler but with the added bonus of being able
    to express, manipulate, and optimize mathematical expressions as well as run code
    on the CPU and GPU. Since 2010, Theano has improved release after release and
    has been adopted by several other Python projects as a way to automatically generate
    efficient computational models on the fly.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Theano 类似于一个编译器，但额外的好处是能够表达、操作和优化数学表达式，以及能够在 CPU 和 GPU 上运行代码。自 2010 年以来，Theano
    在版本更新后不断改进，并被几个其他 Python 项目采用，作为自动生成高效计算模型的方法。
- en: 'The package may be installed using the following command:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令安装此包：
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In Theano, you first define the function you want to run by specifying variables
    and transformation using a pure Python API. This specification will then be compiled
    into machine code for execution.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Theano 中，您首先通过指定变量和使用纯 Python API 进行转换来定义您想要运行的函数。然后，此规范将被编译成机器代码以执行。
- en: 'As a first example, let''s examine how to implement a function that computes
    the square of a number. The input will be represented by a scalar variable, `a`,
    and then we will transform it to obtain its square, indicated by `a_sq`. In the
    following code snippet, we will use the `T.scalar` function to define a variable
    and use the normal `**` operator to obtain a new variable:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个例子，让我们看看如何实现一个计算数字平方的函数。输入将由一个标量变量 `a` 表示，然后我们将对其进行转换以获得其平方，表示为 `a_sq`。在下面的代码片段中，我们将使用
    `T.scalar` 函数定义一个变量，并使用正常的 `**` 运算符来获取一个新的变量：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As you can see, no specific value is computed, and the transformation we apply
    is purely symbolic. In order to use this transformation, we need to generate a
    function. To compile a function, you can use the `th.function` utility that takes
    a list of the input variables as its first argument and the output transformation
    (in our case, `a_sq`) as its second argument, as illustrated in the following
    code snippet:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，没有计算特定的值，我们应用的是纯符号变换。为了使用这个变换，我们需要生成一个函数。要编译一个函数，您可以使用`th.function`实用程序，它将输入变量的列表作为其第一个参数，输出变换（在我们的情况下，`a_sq`）作为其第二个参数，如下所示：
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Theano will take some time and translate the expression to efficient C code
    and compile it, all in the background! The return value of `th.function` will
    be a ready-to-use Python function, and its usage is demonstrated in the next line
    of code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Theano将花费一些时间将表达式转换为高效的C代码并编译它，所有这些都在后台完成！`th.function`的返回值将是一个可用的Python函数，其用法在下一行代码中演示：
- en: '[PRE32]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Unsurprisingly, `compute_square` correctly returns the input value squared.
    Note, however, that the return type is not an integer (like the input type) but
    a floating-point number. This is because the Theano default variable type is `float64`.
    You can verify that by inspecting the `dtype` attribute of the `a` variable, as
    follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，`compute_square`正确地返回了输入值的平方。然而，请注意，返回类型不是整数（如输入类型），而是一个浮点数。这是因为Theano默认变量类型是`float64`。您可以通过检查`a`变量的`dtype`属性来验证这一点，如下所示：
- en: '[PRE33]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The Theano behavior is very different compared to what we saw with Numba. Theano
    doesn't compile generic Python code and, also, doesn't do any type of inference;
    defining Theano functions requires a more precise specification of the types involved.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前看到的Numba相比，Theano的行为非常不同。Theano不编译通用的Python代码，也不进行任何类型的推断；定义Theano函数需要更精确地指定涉及的类型。
- en: 'The real power of Theano comes from its support for array expressions. Defining
    a `T.vector` function; the returned variable supports broadcasting operations
    with the same semantics of NumPy arrays. For instance, we can take two vectors
    and compute the element-wise sum of their squares, as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Theano的真实力量来自于其对数组表达式的支持。定义一个`T.vector`函数；返回的变量支持与NumPy数组相同的广播操作语义。例如，我们可以取两个向量并计算它们平方的逐元素和，如下所示：
- en: '[PRE34]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The idea is, again, to use the Theano API as a mini-language to combine various
    NumPy array expressions that will be compiled as efficient machine code.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法再次是使用Theano API作为一个迷你语言来组合各种NumPy数组表达式，这些表达式将被编译成高效的机器代码。
- en: Note
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: One of the selling points of Theano is its ability to perform arithmetic simplifications
    and automatic gradient calculations. For more information, refer to the official
    documentation ([https://theano-pymc.readthedocs.io/en/latest/](https://theano-pymc.readthedocs.io/en/latest/)).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Theano的一个卖点是其执行算术简化和自动梯度计算的能力。有关更多信息，请参阅官方文档([https://theano-pymc.readthedocs.io/en/latest/](https://theano-pymc.readthedocs.io/en/latest/))。
- en: 'To demonstrate Theano functionality on a familiar use case, we can implement
    our parallel calculation of pi again. Our function will take a collection of two
    random coordinates as input and return the `pi` estimate. The input random numbers
    will be defined as vectors named `x` and `y`, and we can test their position inside
    the circle using a standard element-wise operation that we will store in the `hit_test`
    variable, as illustrated in the following code snippet:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示Theano在熟悉的使用场景中的功能，我们可以再次实现我们的并行计算`pi`。我们的函数将接受两个随机坐标的集合作为输入，并返回`pi`估计值。输入的随机数将被定义为名为`x`和`y`的向量，我们可以使用一个标准的逐元素操作来测试它们在圆内的位置，这个操作我们将存储在`hit_test`变量中，如下所示：
- en: '[PRE35]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'At this point, we need to count the number of `True` elements in `hit_test`,
    which can be done by taking its sum (it will be implicitly cast to integer). To
    obtain the `pi` estimate, we finally need to calculate the ratio of hits versus
    the total number of trials. The calculation is illustrated in the following code
    snippet:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要计算`hit_test`中`True`元素的数量，这可以通过取其和来完成（它将被隐式转换为整数）。为了获得`pi`估计值，我们最后需要计算击中次数与总试验次数的比率。计算过程在以下代码片段中展示：
- en: '[PRE36]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We can benchmark the execution of the Theano implementation using `th.function`
    and the `timeit` module. In our test, we will pass two arrays of size `30000`
    and use the `timeit.timeit` utility to execute the `calculate_pi` function multiple
    times, as illustrated in the following code snippet:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`th.function`和`timeit`模块来基准测试Theano实现的执行。在我们的测试中，我们将传递两个大小为`30000`的数组，并使用`timeit.timeit`实用工具多次执行`calculate_pi`函数，如下面的代码片段所示：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The serial execution of this function takes about 10 seconds. Theano is capable
    of automatically parallelizing the code by implementing element-wise and matrix
    operations using specialized packages, such as OpenMP and the **Basic Linear Algebra
    Subprograms** (**BLAS**) linear algebra routines. Parallel execution can be enabled
    using configuration options.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数的串行执行大约需要10秒。Theano能够通过实现使用专用包（如OpenMP和**基本线性代数子程序**（**BLAS**）线性代数例程）的元素和矩阵操作来自动并行化代码。可以通过配置选项启用并行执行。
- en: 'In Theano, you can set up configuration options by modifying variables in the
    `theano.config` object at import time. For example, you can issue the following
    commands to enable OpenMP support:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在Theano中，您可以通过在导入时修改`theano.config`对象中的变量来设置配置选项。例如，您可以使用以下命令来启用OpenMP支持：
- en: '[PRE38]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The parameters relevant to OpenMP are outlined here:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 与OpenMP相关的参数在此概述：
- en: '`openmp_elemwise_minsize`: This is an integer number that represents the minimum
    size of the arrays where element-wise parallelization should be enabled (the overhead
    of the parallelization can harm performance for small arrays).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openmp_elemwise_minsize`：这是一个整数，表示应该启用元素并行化的数组的最小大小（对于小数组，并行化的开销可能会损害性能）。'
- en: '`openmp`: This is a Boolean flag that controls the activation of OpenMP compilation
    (it should be activated by default).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openmp`：这是一个布尔标志，用于控制OpenMP编译的激活（默认情况下应该被激活）。'
- en: Controlling the number of threads assigned for OpenMP execution can be done
    by setting the `OMP_NUM_THREADS` environmental variable before executing the code.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在执行代码之前设置`OMP_NUM_THREADS`环境变量，可以控制分配给OpenMP执行的线程数。
- en: 'We can now write a simple benchmark to demonstrate OpenMP usage in practice.
    In a `test_theano.py` file, we will put the complete code for the `pi` estimation
    example, as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以编写一个简单的基准测试来演示在实际中OpenMP的使用。在`test_theano.py`文件中，我们将放置`pi`估计示例的完整代码，如下所示：
- en: '[PRE39]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'At this point, we can run the code from the command line and assess the scaling
    with an increasing number of threads by setting the `OMP_NUM_THREADS` environment
    variable, as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以从命令行运行代码，并通过设置`OMP_NUM_THREADS`环境变量来评估随着线程数的增加而进行的扩展，如下所示：
- en: '[PRE40]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Interestingly, there is a small speedup when using two threads, but the performance
    degrades quickly as we increase their number. This means that for this input size,
    it is not advantageous to use more than two threads as the price you pay to start
    new threads and synchronize their shared data is higher than the speedup that
    you can obtain from the parallel execution.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，使用两个线程时，确实有轻微的加速，但随着线程数的增加，性能会迅速下降。这意味着对于这个输入大小，使用超过两个线程并不有利，因为启动新线程和同步它们共享数据的代价高于您可以从并行执行中获得的速度提升。
- en: Achieving good parallel performance can be tricky as this will depend on the
    specific operations and how they access the underlying data. As a general rule,
    measuring the performance of a parallel program is crucial, and obtaining substantial
    speedups is a work of trial and error.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 实现良好的并行性能可能很棘手，因为这将取决于特定的操作以及它们如何访问底层数据。一般来说，测量并行程序的性能至关重要，获得显著的加速是一个反复试验的过程。
- en: 'As an example, we can see that the parallel performance quickly degrades using
    slightly different code. In our hit test, we used the `sum` method directly and
    relied on the explicit casting of the `hit_tests` Boolean array. If we make the
    cast explicit, Theano will generate slightly different code that benefits less
    from multiple threads. We can modify the `test_theano.py` file to verify this
    effect, as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到，使用稍微不同的代码，并行性能会迅速下降。在我们的击中测试中，我们直接使用了`sum`方法，并依赖于`hit_tests`布尔数组的显式转换。如果我们显式进行转换，Theano将生成略微不同的代码，这从多个线程中获得的益处较少。我们可以修改`test_theano.py`文件来验证这一效果，如下所示：
- en: '[PRE41]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'If we rerun our benchmark, we see that the number of threads does not affect
    the running time significantly, as illustrated here:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重新运行我们的基准测试，我们会看到线程数对运行时间的影响并不显著，如下所示：
- en: '[PRE42]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Despite that, the timings improved considerably compared to the original version.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，与原始版本相比，时间有所显著提高。
- en: Profiling Theano
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析Theano
- en: 'Given the importance of measuring and analyzing performance, Theano provides
    powerful and informative profiling tools. To generate profiling data, the only
    modification needed is the addition of the `profile=True` option to `th.function`,
    as illustrated in the following code snippet:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到测量和分析性能的重要性，Theano提供了强大且信息丰富的性能分析工具。要生成性能分析数据，所需的唯一修改是在`th.function`中添加`profile=True`选项，如下面的代码片段所示：
- en: '[PRE43]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The profiler will collect data as the function is being run (for example, through
    `timeit` or direct invocation). The profiling summary can be printed to the output
    by issuing the `summary` command, as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析器将在函数运行时收集数据（例如，通过`timeit`或直接调用）。可以通过发出`summary`命令将性能分析摘要打印到输出中，如下所示：
- en: '[PRE44]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: To generate profiling data, we can rerun our script after adding the `profile=True`
    option (for this experiment, we will set the `OMP_NUM_THREADS` environmental variable
    to `1`). Also, we will revert our script to the version that performed the casting
    of `hit_tests` implicitly.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成性能分析数据，我们可以在添加`profile=True`选项后重新运行我们的脚本（对于这个实验，我们将`OMP_NUM_THREADS`环境变量设置为`1`）。此外，我们将我们的脚本恢复到执行`hit_tests`隐式转换的版本。
- en: Note
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can also set up profiling globally using the `config.profile` option.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用`config.profile`选项全局设置性能分析。
- en: 'The output printed by `calculate_pi.profile.summary()` is quite long and informative.
    A part of it is reported in the next block of code. The output is comprised of
    three sections that refer to timings sorted by `Class`, `Ops`, and `Apply`. In
    our example, we are concerned with `Ops`, which roughly maps to the functions
    used in the Theano compiled code. As you can see here, roughly 80% of the time
    is spent in taking the element-wise square and sum of the two numbers, while the
    rest of the time is spent calculating the sum:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`calculate_pi.profile.summary()`打印的输出相当长且信息丰富。其中一部分在下一块代码中报告。输出由三个部分组成，分别按`Class`、`Ops`和`Apply`排序。在我们的例子中，我们关注的是`Ops`，它大致对应于Theano编译代码中使用的函数。正如你所看到的，大约80%的时间用于计算两个数的元素级平方和，其余时间用于计算总和：'
- en: '[PRE45]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This information is consistent with what was found in our first benchmark. The
    code went from about 11 seconds to roughly 8 seconds when two threads were used.
    From these numbers, we can analyze how the time was spent.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这个信息与我们第一次基准测试的结果一致。当使用两个线程时，代码从大约11秒减少到大约8秒。从这些数字中，我们可以分析时间是如何被花费的。
- en: Out of these 11 seconds, 80% of the time (about 8.8 seconds) was spent doing
    element-wise operations. This means that, in perfectly parallel conditions, the
    increase in speed by adding two threads will be 4.4 seconds. In this scenario,
    the theoretical execution time would be 6.6 seconds. Considering that we obtained
    a timing of about 8 seconds, it looks like there is some extra overhead (1.4 seconds)
    for the thread usage.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这11秒中，80%的时间（大约8.8秒）用于执行元素级操作。这意味着，在完全并行的情况下，增加两个线程的速度提升将是4.4秒。在这种情况下，理论上的执行时间将是6.6秒。考虑到我们获得了大约8秒的时间，看起来线程使用存在一些额外的开销（1.4秒）。
- en: TensorFlow
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow
- en: TensorFlow is another library designed for fast numerical calculations and automatic
    parallelism. It was released as an open source project by Google in 2015\. TensorFlow
    works by building mathematical expressions similar to Theano, except that the
    computation is not compiled as machine code but is executed on an external engine
    written in C++. TensorFlow supports the execution and deployment of parallel code
    on one or more CPUs and GPUs.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是另一个为快速数值计算和自动并行化设计的库。它于2015年由谷歌作为开源项目发布。TensorFlow通过构建类似于Theano的数学表达式来工作，不同之处在于计算不是编译成机器代码，而是在用C++编写的外部引擎上执行。TensorFlow支持在单个或多个CPU和GPU上执行和部署并行代码。
- en: 'We can install TensorFlow using the following command:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令安装TensorFlow：
- en: '[PRE46]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: TensorFlow Version Compatibility
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow版本兼容性
- en: Note that as the default option, TensorFlow 2.x will be installed without further
    specifications. However, since the number of users of TensorFlow 1.x is still
    considerable, the code we use next will follow the syntax of TensorFlow 1.x. You
    can either install version 1 by specifying `pip install tensorflow==1.15` or disable
    version 2's behavior using `import tensorflow.compat.v1 as tf; tf.disable_v2_behavior()`
    when importing the library, as shown next.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，TensorFlow 2.x将不进行进一步指定而安装。然而，由于TensorFlow 1.x的用户数量仍然相当可观，我们接下来使用的代码将遵循TensorFlow
    1.x的语法。你可以通过指定`pip install tensorflow==1.15`来安装版本1，或者在使用库时使用`import tensorflow.compat.v1
    as tf; tf.disable_v2_behavior()`来禁用版本2的行为，如下所示。
- en: 'The usage of TensorFlow is quite similar to that of Theano. To create a variable
    in TensorFlow, you can use the `tf.placeholder` function that takes a data type
    as input, as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的使用方式与Theano非常相似。要在TensorFlow中创建一个变量，你可以使用`tf.placeholder`函数，该函数接受一个数据类型作为输入，如下所示：
- en: '[PRE47]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: TensorFlow mathematical expressions can be expressed quite similarly to Theano,
    except for a few different naming conventions as well as more restricted support
    for the NumPy semantics.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的数学表达式可以相当类似于Theano，除了几个不同的命名约定以及更有限的NumPy语义支持。
- en: TensorFlow doesn't compile functions to C and then machine code like Theano
    does, but serializes the defined mathematical functions (the data structure containing
    variables and transformations is called a `tf.Session` object.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow不会像Theano那样将函数编译成C和机器代码，而是序列化定义的数学函数（包含变量和转换的数据结构称为`tf.Session`对象）。
- en: 'Once the desired expression is defined, a `tf.Session` object needs to be initialized
    and can be used to execute computation graphs using the `Session.run` method.
    In the following example, we demonstrate the usage of the TensorFlow API to implement
    a simple element-wise sum of squares:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了所需的表达式，就需要初始化一个`tf.Session`对象，并可以使用`Session.run`方法来执行计算图。在以下示例中，我们展示了如何使用TensorFlow
    API实现一个简单的逐元素平方和：
- en: '[PRE48]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Parallelism in TensorFlow is achieved automatically by its smart execution engine,
    and it generally works well without much fiddling. However, note that it is mostly
    suited for **deep learning** (**DL**) workloads that involve the definition of
    complex functions that use a lot of matrix multiplications and calculate their
    gradient.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow通过其智能执行引擎自动实现并行性，通常无需过多调整即可良好工作。然而，请注意，它主要适用于涉及定义复杂函数的**深度学习**（**DL**）工作负载，这些函数使用大量的矩阵乘法并计算它们的梯度。
- en: 'We can now replicate the estimation of pi example using TensorFlow capabilities
    and benchmark its execution speed and parallelism against the Theano implementation.
    What we will do is this:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用TensorFlow的功能来复制估计π的示例，并对其执行速度和并行性进行基准测试，与Theano实现进行比较。我们将这样做：
- en: Define our `x` and `y` variables and perform a hit test using broadcasted operations.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义我们的`x`和`y`变量，并使用广播操作执行碰撞测试。
- en: Calculate the sum of `hit_tests` using the `tf.reduce_sum` function.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`tf.reduce_sum`函数计算`hit_tests`的总和。
- en: Initialize a `Session` object with the `inter_op_parallelism_threads` and `intra_op_parallelism_threads`
    configuration options. These options control the number of threads used for different
    classes of parallel operations. Note that the first `Session` instance created
    with such options sets the number of threads for the whole script (even future
    `Session` instances).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`inter_op_parallelism_threads`和`intra_op_parallelism_threads`配置选项初始化一个`Session`对象。这些选项控制不同类别的并行操作使用的线程数。请注意，使用这些选项创建的第一个`Session`实例将设置整个脚本（甚至未来的`Session`实例）的线程数。
- en: 'We can now write a script name, `test_tensorflow.py`, containing the following
    code. Note that the number of threads is passed as the first argument of the script
    (`sys.argv[1]`):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以编写一个名为`test_tensorflow.py`的脚本，其中包含以下代码。注意，线程数作为脚本的第一个参数传递（`sys.argv[1]`）：
- en: '[PRE49]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'If we run the script multiple times with different values of `NUM_THREADS`,
    we see that the performance is quite similar to Theano and that the speedup increased
    by parallelization is quite modest, as illustrated here:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们多次运行脚本并使用不同的`NUM_THREADS`值，我们会看到性能与Theano相当，并且通过并行化获得的速度提升相当适度，如下所示：
- en: '[PRE50]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The main advantage of using software packages such as TensorFlow and Theano
    is the support for parallel matrix operations that are commonly used in ML algorithms.
    This is very effective because those operations can achieve impressive performance
    gains on GPU hardware that is designed to perform these operations with high throughput.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如TensorFlow和Theano之类的软件包的主要优势是支持在机器学习算法中常用到的并行矩阵运算。这非常有效，因为这些操作可以在专为以高吞吐量执行这些操作而设计的GPU硬件上实现令人印象深刻的性能提升。
- en: Running code on a GPU
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在GPU上运行代码
- en: In this subsection, we will demonstrate the usage of a GPU with Theano and TensorFlow.
    As an example, we will benchmark the execution of very simple matrix multiplication
    on the GPU and compare it to its running time on a CPU.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将展示如何使用Theano和TensorFlow来使用GPU。作为一个例子，我们将测试在GPU上执行非常简单的矩阵乘法的执行时间，并将其与在CPU上的运行时间进行比较。
- en: Note
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The code in this subsection requires the possession of a GPU. For learning purposes,
    it is possible to use the Amazon **Elastic Compute Cloud** (**EC2**) service ([https://aws.amazon.com/ec2](https://aws.amazon.com/ec2))
    to request a GPU-enabled instance.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节中的代码需要拥有GPU。为了学习目的，可以使用Amazon **弹性计算云**（**EC2**）服务（[https://aws.amazon.com/ec2](https://aws.amazon.com/ec2)）来请求一个启用GPU的实例。
- en: 'The following code performs a simple matrix multiplication using Theano. We
    use the `T.matrix` function to initialize a `T.dot` method to perform the matrix
    multiplication:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用Theano执行简单的矩阵乘法。我们使用`T.matrix`函数初始化一个`T.dot`方法来执行矩阵乘法：
- en: '[PRE51]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'It is possible to ask Theano to execute this code on a GPU by setting the `config.device=gpu`
    option. For added convenience, we can set up the configuration value from the
    command line using the `THEANO_FLAGS` environmental variable, shown as follows.
    After copying the previous code into the `test_theano_matmul.py` file, we can
    benchmark the execution time by issuing the following command:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过设置`config.device=gpu`选项来让Theano在GPU上执行此代码。为了增加便利性，我们可以使用`THEANO_FLAGS`环境变量从命令行设置配置值，如下所示。将前面的代码复制到`test_theano_matmul.py`文件后，我们可以通过以下命令来测试执行时间：
- en: '[PRE52]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We can analogously run the same code on the CPU using the `device=cpu` configuration
    option, as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`device=cpu`配置选项类似地运行相同的代码在CPU上，如下所示：
- en: '[PRE53]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: As you can see, the *GPU is 7.2 times faster than the CPU* version for this
    example!
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，对于这个例子，*GPU比CPU版本快7.2倍*！
- en: 'For comparison, we may benchmark equivalent code using TensorFlow. The implementation
    of a TensorFlow version is shown in the next code snippet. The main differences
    with the Theano version are outlined here:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较，我们可以使用TensorFlow来测试等效代码。TensorFlow版本的实现将在下一个代码片段中展示。与Theano版本的主要区别如下：
- en: The usage of the `tf.device` config manager that serves to specify the target
    device (`/cpu:0` or `/gpu:0`).
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`tf.device`配置管理器指定目标设备（`/cpu:0`或`/gpu:0`）。
- en: The matrix multiplication is performed using the `tf.matmul` operator.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵乘法是通过`tf.matmul`运算符执行的。
- en: 'This is illustrated in the following code snippet:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下述代码片段中得到了说明：
- en: '[PRE54]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'If we run the `test_tensorflow_matmul.py` script with the appropriate `tf.device`
    option, we obtain the following timings:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用适当的`tf.device`选项运行`test_tensorflow_matmul.py`脚本，我们将获得以下计时结果：
- en: '[PRE55]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: As you can see, the performance gain is substantial (but not as good as the
    Theano version) in this simple case.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在这个简单案例中，性能提升是显著的（但不如Theano版本好）。
- en: Another way to achieve automatic GPU computation is the now-familiar Numba.
    With Numba, it is possible to compile Python code to programs that can be run
    on a GPU. This flexibility allows for advanced GPU programming as well as more
    simplified interfaces. In particular, Numba makes extremely easy-to-write, GPU-ready,
    generalized universal functions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 实现自动GPU计算的另一种方法是现在熟悉的Numba。使用Numba，可以将Python代码编译成可以在GPU上运行的程序。这种灵活性允许进行高级GPU编程以及更简化的接口。特别是，Numba使得编写GPU就绪的通用函数变得极其简单。
- en: 'In the next example, we will demonstrate how to write a universal function
    that applies an exponential function on two numbers and sums the results. As we
    already saw in [*Chapter 5*](B17499_05_Final_SS_ePub.xhtml#_idTextAnchor085),
    *Exploring Compilers*, this can be accomplished using the `nb.vectorize` function
    (we''ll also specify the `cpu` target explicitly). The code is shown here:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们将演示如何编写一个通用函数，该函数对两个数字应用指数函数并将结果相加。正如我们已经在[*第5章*](B17499_05_Final_SS_ePub.xhtml#_idTextAnchor085)中看到的那样，*探索编译器*，这可以通过使用`nb.vectorize`函数（我们还将明确指定`cpu`目标）来实现。代码如下所示：
- en: '[PRE56]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The `expon_cpu` universal function can be compiled for the GPU device using
    the `target=''cuda''` option. Also, note that it is necessary to specify the input
    types for CUDA universal functions. The implementation of `expon_gpu` is shown
    here:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '`expon_cpu`通用函数可以使用`target=''cuda''`选项编译为GPU设备。此外，请注意，对于CUDA通用函数，有必要指定输入类型。`expon_gpu`的实现如下所示：'
- en: '[PRE57]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can now benchmark the execution of the two functions by applying the functions
    on two arrays of size `1000000`. Also, note in the following code snippet that
    we execute the function before measuring the timings to trigger the Numba JIT
    compilation:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过在两个大小为`1000000`的数组上应用这两个函数来基准测试这两个函数的执行。同时，注意在下面的代码片段中，我们在测量时间之前执行了函数以触发Numba
    JIT编译：
- en: '[PRE58]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Thanks to the GPU execution, we were able to achieve a three-times speedup over
    the CPU version. Note that transferring data on the GPU is quite expensive; therefore,
    GPU execution becomes advantageous only for very large arrays.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了GPU执行，我们能够将CPU版本的速度提高了三倍。请注意，在GPU上传输数据相当昂贵；因此，GPU执行仅在非常大的数组上才有优势。
- en: When To Use Which Package
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用哪个软件包
- en: To close out this chapter, we will include a brief discussion regarding the
    parallel processing tools that we have examined thus far. First, we have seen
    how to use `multiprocessing` to manage multiple processes natively in Python.
    If you are using Cython, you may appeal to OpenMP to implement parallelism while
    being able to avoid working with C wrappers.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束本章，我们将简要讨论我们迄今为止所考察的并行处理工具。首先，我们看到了如何使用`multiprocessing`在Python中本地管理多个进程。如果你使用Cython，你可以求助于OpenMP来实现并行性，同时能够避免与C包装器一起工作。
- en: Finally, we study Theano and TensorFlow as two packages that automatically compile
    array-centric code and parallelize the execution. While these two packages offer
    similar advantages when it comes to automatic parallelism, at the time of this
    writing, TensorFlow has gained significant popularity, especially within the DL
    community, where the parallelism of matrix multiplications is the norm.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们研究了Theano和TensorFlow这两个自动编译以数组为中心的代码并并行执行执行的软件包。虽然这两个软件包在自动并行化方面提供了类似的优势，但在撰写本文时，TensorFlow已经获得了显著的流行度，尤其是在深度学习社区中，矩阵乘法的并行性已成为常态。
- en: On the other hand, the active development of Theano stopped in 2018\. While
    the package may still be utilized for automatic parallelism and DL uses, no new
    versions will be released. For this reason, TensorFlow is often preferred by Python
    programmers nowadays.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Theano的积极开发在2018年停止了。虽然这个软件包仍然可以用于自动并行化和深度学习用途，但不会再发布新版本。因此，现在Python程序员通常更倾向于使用TensorFlow。
- en: Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Parallel processing is an effective way to improve performance on large datasets.
    Embarrassingly parallel problems are excellent candidates for parallel execution
    that can be easily implemented to achieve good performance scaling.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理是提高大数据集性能的有效方法。令人尴尬的并行问题是非常适合并行执行的，可以轻松实现以实现良好的性能扩展。
- en: In this chapter, we illustrated the basics of parallel programming in Python.
    We learned how to circumvent Python threading limitations by spawning processes
    using the tools available in the Python standard library. We also explored how
    to implement a multithreaded program using Cython and OpenMP.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Python并行编程的基础。我们学习了如何使用Python标准库中的工具来生成进程以绕过Python线程的限制。我们还探讨了如何使用Cython和OpenMP实现多线程程序。
- en: For more complex problems, we learned how to use the Theano, TensorFlow, and
    Numba packages to automatically compile array-intensive expressions for parallel
    execution on CPU and GPU devices.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的问题，我们学习了如何使用Theano、TensorFlow和Numba软件包来自动编译针对CPU和GPU设备并行执行的密集数组表达式。
- en: In the next chapter, we will learn how to apply parallel programming techniques
    to build a hands-on application that makes and handles web requests concurrently.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何应用并行编程技术来构建一个实际应用，该应用可以并发地创建和处理Web请求。
- en: Questions
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why doesn't running Python code across multiple threads offer any speedup? What
    is the alternative approach that we have discussed in this chapter?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在多个线程中运行Python代码不会带来任何速度提升？在本章中我们讨论的替代方法是什么？
- en: In the `multiprocessing` module, what is the difference between the `Process`
    and the `Pool` interface in terms of implementing multiprocessing?
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`multiprocessing`模块中，就实现多进程而言，`Process`和`Pool`接口之间有什么区别？
- en: On a high level, how do libraries such as Theano and TensorFlow help in parallelizing
    Python code?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在高层次上，像Theano和TensorFlow这样的库是如何帮助并行化Python代码的？
