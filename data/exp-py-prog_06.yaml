- en: Chapter 6. Deploying Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。部署代码
- en: Even the perfect code (if it exists) is useless if it is not being run. So in
    order to serve a purpose, our code needs to be installed on the target machine
    (computer) and executed. The process of making a specific version of your application
    or service available to the end users is called deployment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 即使完美的代码（如果存在的话）如果不被运行，也是无用的。因此，为了发挥作用，我们的代码需要安装到目标机器（计算机）并执行。将特定版本的应用程序或服务提供给最终用户的过程称为部署。
- en: In case of desktop applications, this seems to be simple—your job ends on providing
    a downloadable package with optional installer, if necessary. It is the user's
    responsibility to download and install it in his/her environment. Your responsibility
    is to make this process as easy and convenient as possible. Proper packaging is
    still not a simple task, but some tools were already explained in the previous
    chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 对于桌面应用程序来说，这似乎很简单——你的工作就是提供一个可下载的包，并在必要时提供可选的安装程序。用户有责任在自己的环境中下载并安装它。你的责任是尽可能地使这个过程简单和方便。适当的打包仍然不是一项简单的任务，但一些工具已经在上一章中进行了解释。
- en: Surprisingly, things get more complicated when your code is not a product per
    se. If your application only provides a service that is being sold to the users,
    then it is your responsibility to run it on your own infrastructure. This scenario
    is typical for a web application or any "X as a Service" product. In such a situation,
    the code is deployed to set off remote machines that usually are hardly physically
    accessible to the developers. This is especially true if you are already a user
    of cloud computing services such as **Amazon Web** **Services** (**AWS**) or Heroku.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，当你的代码不是产品本身时，情况会变得更加复杂。如果你的应用程序只提供向用户出售的服务，那么你有责任在自己的基础设施上运行它。这种情况对于Web应用程序或任何“X作为服务”产品都很典型。在这种情况下，代码被部署到远程机器上，通常开发人员几乎无法物理接触到这些机器。如果你已经是云计算服务的用户，比如亚马逊网络服务（AWS）或Heroku，这一点尤其真实。
- en: 'In this chapter, we will concentrate on the aspect of code deployment to remote
    hosts because of the very high popularity of Python in the field of building various
    web-related services and products. Despite the high portability of this language,
    it has no specific quality that would make its code easily deployable. What matters
    the most is how your application is built and what processes you use to deploy
    it to the target environments. So this chapter will focus on the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将集中讨论代码部署到远程主机的方面，因为Python在构建各种与网络相关的服务和产品领域非常受欢迎。尽管这种语言具有很高的可移植性，但它没有特定的特性，可以使其代码易于部署。最重要的是你的应用程序是如何构建的，以及你用什么流程将其部署到目标环境中。因此，本章将重点讨论以下主题：
- en: What are the main challenges in deploying the code to remote environments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署代码到远程环境的主要挑战是什么
- en: How to build applications in Python that are easily deployable
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建易于部署的Python应用程序
- en: How to reload web services without downtime
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在没有停机的情况下重新加载Web服务
- en: How to leverage Python packaging ecosystem in code deployment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何利用Python打包生态系统进行代码部署
- en: How to properly monitor and instrument code that runs remotely
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何正确监控和调试远程运行的代码
- en: The Twelve-Factor App
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 十二要素应用
- en: The main requirement for painless deployment is building your application in
    a way that ensures that this process will be simple and as streamlined as possible.
    This is mostly about removing obstacles and encouraging well-established practices.
    Following such common practices is especially important in organizations where
    only specific people are responsible for development (developers team or Dev for
    short) and different people are responsible for deploying and maintaining the
    execution environments (operations team or Ops for short).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 无痛部署的主要要求是以确保这个过程简单和尽可能流畅的方式构建你的应用程序。这主要是关于消除障碍和鼓励良好的做法。在只有特定人员负责开发（开发团队或简称为Dev）的组织中，以及不同的人负责部署和维护执行环境（运维团队或简称为Ops）的组织中，遵循这样的常见做法尤为重要。
- en: All tasks related to server maintenance, monitoring, deployment, configuration,
    and so on are often put to one single bag called operations. Even in organizations
    that have no separate teams for operational tasks, it is common that only some
    of the developers are authorized to do deployment tasks and maintain the remote
    servers. The common name for such a position is DevOps. Also, it isn't such an
    unusual situation that every member of the development team is responsible for
    operations, so everyone in such a team can be called DevOps. Anyway, no matter
    how your organization is structured and what the responsibilities of each developer
    are, everyone should know how operations work and how code is deployed to the
    remote servers because, in the end, the execution environment and its configuration
    is a hidden part of the product you are building.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与服务器维护、监控、部署、配置等相关的所有任务通常被放在一个袋子里，称为运维。即使在没有专门的运维团队的组织中，通常也只有一些开发人员被授权执行部署任务和维护远程服务器。这种职位的通用名称是DevOps。此外，每个开发团队成员都负责运维并不是一种不寻常的情况，因此在这样的团队中，每个人都可以被称为DevOps。无论你的组织结构如何，每个开发人员都应该知道运维工作以及代码如何部署到远程服务器，因为最终，执行环境及其配置是你正在构建的产品的隐藏部分。
- en: 'The following common practices and conventions are important mainly for the
    following reasons:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的常见做法和约定主要是出于以下原因：
- en: At every company people quit and new ones are hired. By using best approaches,
    you are making it easier for fresh team members to jump into the project. You
    can never be sure that new employees are already familiar with common practices
    for system configuration and running applications in a reliable way, but you at
    least make their fast adaptation more probable.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每家公司，员工会离职，新员工会入职。通过使用最佳方法，你可以让新团队成员更容易地加入项目。你永远无法确定新员工是否已经熟悉了系统配置和可靠运行应用程序的常见做法，但你至少可以让他们更有可能快速适应。
- en: In organizations where only some people are responsible for deployments, it
    simply reduces the friction between the operations and development teams.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在只有一些人负责部署的组织中，它简单地减少了运维和开发团队之间的摩擦。
- en: A good source of such practices that encourage building easily deployable apps
    is a manifesto called **Twelve-Factor App**. It is a general language-agnostic
    methodology for building software-as-a-service apps. One of its purposes is making
    applications easier to deploy, but it also highlights other topics, such as maintainability
    and making applications easier to scale.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励构建易于部署应用程序的实践的一个很好的来源是一个名为**十二要素应用**的宣言。它是一个通用的、与语言无关的构建软件即服务应用程序的方法论。它的目的之一是使应用程序更容易部署，但它也强调了其他主题，比如可维护性和使应用程序更容易扩展。
- en: 'As its name says, the Twelve-Factor App consists of 12 rules:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，十二要素应用由 12 条规则组成：
- en: '**Codebase**: One codebase tracked in revision control, many deploys'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码库**：一个代码库在版本控制中跟踪，多次部署'
- en: '**Dependencies**: Explicitly declare and isolate dependencies'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖关系**：明确声明和隔离依赖关系'
- en: '**Config**: Store config in the environment'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配置**：将配置存储在环境中'
- en: '**Backing services**: Treat backing services as attached resources'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后端服务**：将后端服务视为附加资源'
- en: '**Build, release, run**: Strictly separate build and run stages'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建、发布、运行**：严格区分构建和运行阶段'
- en: '**Processes**: Execute the app as one or more stateless processes'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进程**：将应用程序作为一个或多个无状态进程执行'
- en: '**Port binding**: Export services via port binding'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口绑定**：通过端口绑定导出服务'
- en: '**Concurrency**: Scale out via the process model'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发**：通过进程模型进行扩展'
- en: '**Disposability**: Maximize robustness with fast startup and graceful shutdown'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可处置性**：通过快速启动和优雅关闭来最大化健壮性'
- en: '**Dev/prod parity**: Keep development, staging, and production as similar as
    possible'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发/生产一致性**：尽量使开发、演示和生产环境尽可能相似'
- en: '**Logs**: Treat logs as event streams'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志**：将日志视为事件流'
- en: '**Admin processes**: Run admin/management tasks as one-off processes'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理进程**：将管理任务作为一次性进程运行'
- en: Extending each of these rules here is a bit pointless because the official page
    of Twelve-Factor App methodology ([http://12factor.net/](http://12factor.net/))
    contains extensive rationale for every app factor with examples of tools for different
    frameworks and environments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里扩展每个规则有点无意义，因为十二要素应用方法论的官方页面（[http://12factor.net/](http://12factor.net/)）包含了每个应用要素的广泛原理，以及不同框架和环境的工具示例。
- en: This chapter tries to stay consistent with the above manifesto, so we will discuss
    some of them in detail when necessary. The techniques and examples that are presented
    may sometimes slightly diverge from these 12 factors, but remember that these
    rules are not carved in stone. They are great as long as they serve the purpose.
    In the end, what matters is the working application (product) and not being compatible
    with some arbitrary methodology.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本章试图与上述宣言保持一致，因此我们将在必要时详细讨论其中一些。所呈现的技术和示例有时可能略微偏离这 12 个要素，但请记住，这些规则并非铁板一块。只要能达到目的，它们就是好的。最终，重要的是工作的应用程序（产品），而不是与某种任意方法论兼容。
- en: Deployment automation using Fabric
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Fabric 进行部署自动化
- en: For very small projects, it may be possible to do deploy your code "by hand",
    that is, by manually typing the sequence of commands through the remote shell
    that are necessary to install a new version of code and execute it on a remote
    shell. Anyway, even for an average-sized project, this is error prone, tedious,
    and should be considered a waste of most the precious resource you have, your
    own time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常小的项目，可能可以手动部署代码，也就是通过远程 shell 手动输入必要的命令序列来安装新版本的代码并在远程 shell 上执行。然而，即使对于一个中等大小的项目，这种方法容易出错，繁琐，并且应该被视为浪费你最宝贵的资源，也就是你自己的时间。
- en: 'The solution for that is automation. The simple rule of thumb could be if you
    needed to perform the same task manually at least twice, you should automate it
    so you won''t need to do it for the third time. There are various tools that allow
    you to automate different things:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的方法是自动化。一个简单的经验法则是，如果你需要手动执行相同的任务至少两次，你应该自动化它，这样你就不需要第三次手动执行了。有各种工具可以让你自动化不同的事情：
- en: Remote execution tools such as Fabric are used for on-demand automated execution
    of code on multiple remote hosts.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 远程执行工具如 Fabric 用于按需在多个远程主机上自动执行代码。
- en: Configuration management tools such as Chef, Puppet, CFEngine, Salt, and Ansible
    are designed for automatized configuration of remote hosts (execution environments).
    They can be used to set up backing services (databases, caches, and so on), system
    permissions, users, and so on. Most of them can be used also as a tool for remote
    execution like Fabric, but depending on their architecture, this may be more or
    less easy.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 诸如 Chef、Puppet、CFEngine、Salt 和 Ansible 等配置管理工具旨在自动配置远程主机（执行环境）。它们可以用于设置后端服务（数据库、缓存等）、系统权限、用户等。它们大多也可以用作像
    Fabric 这样的远程执行工具，但根据它们的架构，这可能更容易或更困难。
- en: Configuration management solutions is a complex topic that deserves a separate
    book. The truth is that the simplest remote execution frameworks have the lowest
    entry barrier and are the most popular choice, at least for small projects. In
    fact, every configuration management tool that provides a way to declaratively
    specify configuration of your machines has a remote execution layer implemented
    somewhere deep inside.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 配置管理解决方案是一个复杂的话题，值得单独写一本书。事实上，最简单的远程执行框架具有最低的入门门槛，并且是最受欢迎的选择，至少对于小型项目来说是这样。事实上，每个配置管理工具都提供了一种声明性地指定机器配置的方式，深层内部都实现了远程执行层。
- en: 'Also, depending on some of the tools, thanks to their design, it may not be
    best suited for actual automated code deployment. One such example is Puppet,
    which really discourages the explicit running of any shell commands. This is why
    many people choose to use both types of solution to complement each other: configuration
    management for setting up system-level environment and on-demand remote execution
    for application deployment.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，根据某些工具的设计，由于它们的设计，它可能不适合实际的自动化代码部署。一个这样的例子是Puppet，它确实不鼓励显式运行任何shell命令。这就是为什么许多人选择同时使用这两种类型的解决方案来相互补充：配置管理用于设置系统级环境，按需远程执行用于应用程序部署。
- en: Fabric ([http://www.fabfile.org/](http://www.fabfile.org/)) is so far the most
    popular solution used by Python developers to automate remote execution. It is
    a Python library and command-line tool for streamlining the use of SSH for application
    deployment or systems administration tasks. We will focus on it because it is
    relatively easy to start with. Be aware that, depending on your needs, it may
    not be the best solution to your problems. Anyway, it is a great example of a
    utility that can add some automation to your operations, if you don't have any
    yet.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Fabric ([http://www.fabfile.org/](http://www.fabfile.org/))到目前为止是Python开发人员用来自动化远程执行的最流行的解决方案。它是一个用于简化使用SSH进行应用程序部署或系统管理任务的Python库和命令行工具。我们将重点关注它，因为它相对容易上手。请注意，根据您的需求，它可能不是解决问题的最佳方案。无论如何，它是一个很好的工具，可以为您的操作添加一些自动化，如果您还没有的话。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Fabric and Python 3**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fabric和Python 3**'
- en: This book encourages you to develop only in Python 3 (if it is possible) with
    notes about older syntax features and compatibility caveats only to make the eventual
    version switch a bit more painless. Unfortunately, Fabric, at the time of writing
    this book, still has not been officially ported to Python 3\. Enthusiasts of this
    tool are being told for at least a few years that there is ongoing Fabric 2 development
    that will bring a compatibility update. This is said to be a total rewrite with
    a lot of new features but there is no official open repository for Fabric 2 and
    almost no one has seen its code. Core Fabric developers do not accept any pull
    requests for Python 3 compatibility in the current development branch of this
    project and close every feature request for it. Such an approach to the development
    of popular open source projects is at best disturbing. The history of this issue
    does not give us a high chance of seeing the official release of Fabric 2 soon.
    Such secret development of a new Fabric release raises many questions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本书鼓励您只在Python 3中开发（如果可能的话），并提供有关旧语法特性和兼容性注意事项的注释，只是为了使最终版本切换更加轻松。不幸的是，在撰写本书时，Fabric仍未正式移植到Python
    3。这个工具的爱好者们被告知至少有几年的时间正在开发Fabric 2，将带来一个兼容性更新。据说这是一个完全重写，带有许多新功能，但目前还没有Fabric
    2的官方开放存储库，几乎没有人看到过它的代码。核心Fabric开发人员不接受当前项目的Python 3兼容性的任何拉取请求，并关闭对其的每个功能请求。这种对流行开源项目的开发方式至少是令人不安的。这个问题的历史并不让我们看到Fabric
    2的官方发布的机会很高。这种秘密开发新Fabric版本的做法引发了许多问题。
- en: 'Regardless of anyone''s opinions, this fact does not diminish the usefulness
    of Fabric in its current state. So there are two options if you already decided
    to stick with Python 3: use a fully compatible and independent fork ([https://github.com/mathiasertl/fabric/](https://github.com/mathiasertl/fabric/))
    or write your application in Python 3 and maintain Fabric scripts in Python 2\.
    The best approach would be to do it in a separate code repository.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不管任何人的观点，这个事实并不会减少Fabric在当前状态下的实用性。因此，如果您已经决定坚持使用Python 3，有两个选择：使用一个完全兼容且独立的分支（[https://github.com/mathiasertl/fabric/](https://github.com/mathiasertl/fabric/)）或者在Python
    3中编写您的应用程序，并在Python 2中维护Fabric脚本。最好的方法是在一个单独的代码存储库中进行。
- en: You could of course automate all the work using only Bash scripts, but this
    is very tedious and error-prone. Python has more convenient ways of string processing
    and encourages code modularization. Fabric is in fact only a tool for gluing execution
    of commands via SSH, so some knowledge about how the command-line interface and
    its utilities work in your environment is still required.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以只使用Bash脚本来自动化所有工作，但这非常繁琐且容易出错。Python有更方便的字符串处理方式，并鼓励代码模块化。事实上，Fabric只是一个通过SSH粘合命令执行的工具，因此仍然需要一些关于命令行界面及其实用程序在您的环境中如何工作的知识。
- en: To start working with Fabric, you need to install the `fabric` package (using
    `pip`) and create a script named `fabfile.py` that is usually located in the root
    of your project. Note that `fabfile` can be considered a part of your project
    configuration. So if you want to strictly follow the Twelve-Factor App methodology,
    you should not maintain its code in the source tree of the deployed application.
    Complex projects are in fact very often built from various components maintained
    as separate codebases, so it is another reason why it is a good approach to have
    one separate repository for all of the project component configurations and Fabric
    scripts. This makes deployment of different services more consistent and encourages
    good code reuse.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Fabric开始工作，您需要安装`fabric`包（使用`pip`），并创建一个名为`fabfile.py`的脚本，通常位于项目的根目录中。请注意，`fabfile`可以被视为项目配置的一部分。因此，如果您想严格遵循十二要素应用程序方法论，您不应该在部署的应用程序源树中维护其代码。事实上，复杂的项目通常是由维护为单独代码库的各种组件构建而成，因此，将所有项目组件配置和Fabric脚本放在一个单独的存储库中是一个很好的方法。这样可以使不同服务的部署更加一致，并鼓励良好的代码重用。
- en: 'An example `fabfile` that defines a simple deployment procedure will look like
    this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个定义了简单部署过程的示例`fabfile`将如下所示：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Every function decorated with `@task` is treated as an available subcommand
    to the `fab` utility provided with the `fabric` package. You can list all the
    available subcommands using the `-l` or `--list` switch:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 每个使用`@task`装饰的函数都被视为`fabric`包提供的`fab`实用程序的可用子命令。您可以使用`-l`或`--list`开关列出所有可用的子命令：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now you can deploy the application to the given environment type with just
    a single shell command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以只需一个shell命令将应用程序部署到给定的环境类型：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that the preceding `fabfile` serves only illustrative purposes. In your
    own code, you might want to provide extensive failure handling and also try to
    reload the application without the need to restart the web worker process. Also,
    some of the techniques presented here may be obvious right now but will be explained
    later in this chapter. These are:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的`fabfile`仅用于举例说明。在您自己的代码中，您可能希望提供全面的故障处理，并尝试重新加载应用程序，而无需重新启动Web工作进程。此外，此处介绍的一些技术现在可能很明显，但稍后将在本章中进行解释。这些是：
- en: Deploying an application using the private package repository
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用私有软件包存储库部署应用程序
- en: Using Circus for process supervision on the remote host
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在远程主机上使用Circus进行进程监控
- en: Your own package index or index mirror
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您自己的软件包索引或索引镜像
- en: 'There are three main reasons why you might want to run your own index of Python
    packages:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个主要原因您可能希望运行自己的Python软件包索引：
- en: The official Python Package Index does not have any availability guarantees.
    It is run by Python Software Foundation thanks to numerous donations. Because
    of that, it very often means that this site can be down. You don't want to stop
    your deployment or packaging process in the middle due to PyPI outage.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方Python软件包索引没有任何可用性保证。它由Python软件基金会运行，感谢众多捐赠。因此，这往往意味着该站点可能会关闭。您不希望由于PyPI中断而在中途停止部署或打包过程。
- en: It is useful to have reusable components written in Python properly packaged
    even for the closed source that will never be published publicly. It simplifies
    the code base because packages that are used across the company for different
    projects do not need to be vendored. You can simply install them from the repository.
    This simplifies maintenance for such shared code and might reduce development
    costs for the whole company if it has many teams working on different projects.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使对于永远不会公开发布的闭源代码，也有用处，因为它可以使用Python编写的可重用组件得到适当打包。这简化了代码库，因为公司中用于不同项目的软件包不需要被打包。您可以直接从存储库安装它们。这简化了这些共享代码的维护，并且如果公司有许多团队在不同项目上工作，可能会减少整个公司的开发成本。
- en: It is very good practice to have your entire project packaged using `setuptools`.
    Then, deployment of the new application version is often as simple as running
    `pip install --update my-application`.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`setuptools`对整个项目进行打包是非常好的做法。然后，部署新应用程序版本通常只需运行`pip install --update my-application`。
- en: Tip
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Code vendoring**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码打包**'
- en: Code vendoring is a practice of including sources of the external package in
    the source code (repository) of other projects. It is usually done when the project's
    code depends on a specific version of some external package that may also be required
    by other packages (and in a completely different version). For instance, the popular
    `requests` package vendors some version of `urllib3` in its source tree because
    it is very tightly coupled to it and is also very unlikely to work with any other
    version of `urllib3`. An example of a module that is particularly often vendored
    by others is `six`. It can be found in sources of numerous popular projects such
    as Django (`django.utils.six`), Boto (`boto.vedored.six`), or Matplotlib (`matplotlib.externals.six`).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打包是将外部软件包的源代码包含在其他项目的源代码（存储库）中的做法。当项目的代码依赖于某个特定版本的外部软件包时，通常会这样做，该软件包也可能被其他软件包（以完全不同的版本）所需。例如，流行的`requests`软件包在其源代码树中打包了`urllib3`的某个版本，因为它与之紧密耦合，并且几乎不太可能与`urllib3`的其他版本一起使用。一些特别经常被其他人打包的模块的例子是`six`。它可以在许多流行项目的源代码中找到，例如Django（`django.utils.six`），Boto（`boto.vedored.six`）或Matplotlib（`matplotlib.externals.six`）。
- en: Although vendoring is practiced even by some large and successful open source
    projects, it should be avoided if possible. This has justifiable usage only in
    certain circumstances and should not be treated as a substitute for package dependency
    management.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些大型和成功的开源项目甚至也会使用打包，但如果可能的话应该避免。这只在某些情况下才有合理的用途，并且不应被视为软件包依赖管理的替代品。
- en: PyPI mirroring
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyPI镜像
- en: The problem of PyPI outages can be somehow mitigated by allowing the installation
    tools to download packages from one of its mirrors. In fact, the official Python
    Package Index is already served through **CDN** (**Content Delivery Network**),
    so it is intrinsically mirrored. This does not change the fact that it seems to
    have some bad days from time to time when any attempt to download a package fails.
    Using unofficial mirrors is not a solution here because it might raise some security
    concerns.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: PyPI中断的问题可以通过允许安装工具从其镜像之一下载软件包来在一定程度上得到缓解。事实上，官方Python软件包索引已经通过**CDN**（**内容传送网络**）提供服务，因此它本质上是镜像的。这并不改变这样的事实，即它似乎偶尔会出现一些糟糕的日子，当任何尝试下载软件包失败时。在这里使用非官方镜像不是一个解决方案，因为这可能会引发一些安全顾虑。
- en: The best solution is to have your own PyPI mirror that will have all the packages
    you need. The only party that will use it is you, so it will be much easier to
    ensure proper availability. The other advantage is that whenever this service
    gets down, you don't need to rely on someone else to bring it up. The mirroring
    tool maintained and recommended by PyPA is **bandersnatch** ([https://pypi.python.org/pypi/bandersnatch](https://pypi.python.org/pypi/bandersnatch)).
    It allows you to mirror the whole content of Python Package Index and it can be
    provided as the `index-url` option for the repository section in the `.pypirc`
    file (as explained in the previous chapter). This mirror does not accept uploads
    and does not have the web part of PyPI. Anyway, beware! A full mirror might require
    hundreds of gigabytes of storage and its size will continue to grow over time.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的解决方案是拥有自己的PyPI镜像，其中包含您需要的所有软件包。唯一使用它的一方是您自己，因此更容易确保适当的可用性。另一个优势是，每当此服务关闭时，您无需依赖其他人来重新启动它。PyPA维护和推荐的镜像工具是**bandersnatch**（[https://pypi.python.org/pypi/bandersnatch](https://pypi.python.org/pypi/bandersnatch)）。它允许您镜像Python
    Package Index的全部内容，并且可以作为`.pypirc`文件中存储库部分的`index-url`选项提供（如前一章中所述）。此镜像不接受上传，也没有PyPI的Web部分。无论如何，要小心！完整的镜像可能需要数百千兆字节的存储空间，并且其大小将随着时间的推移而继续增长。
- en: 'But why stop on a simple mirror while we have a much better alternative? There
    is a very small chance that you will require a mirror of the whole package index.
    Even with a project that has hundreds of dependencies, it will be only a minor
    fraction of all the available packages. Also, not being able to upload your own
    private package is a huge limitation of such a simple mirror. It seems that the
    added value of using bandersnatch is very low for such a high price. And this
    is true in most situations. If the package mirror is to be maintained only for
    single of few projects, a much better approach is to use **devpi** ([http://doc.devpi.net/](http://doc.devpi.net/)).
    It is a PyPI-compatible package index implementation that provides both:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为什么要停留在一个简单的镜像上，而我们有一个更好的选择呢？您几乎不太可能需要整个软件包索引的镜像。即使是具有数百个依赖项的项目，它也只是所有可用软件包的一小部分。此外，无法上传自己的私有软件包是这种简单镜像的巨大局限性。似乎使用bandersnatch的附加价值与其高昂的价格相比非常低。在大多数情况下，这是正确的。如果软件包镜像仅用于单个或少数项目，那么使用**devpi**（[http://doc.devpi.net/](http://doc.devpi.net/)）将是一个更好的方法。它是一个与PyPI兼容的软件包索引实现，提供以下两种功能：
- en: A private index to upload nonpublic packages
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上传非公共软件包的私有索引
- en: Index mirroring
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引镜像
- en: The main advantage of devpi over bandersnatch is how it handles mirroring. It
    can of course do a full generic mirror of other indexes, like bandersnatch does,
    but it is not its default behavior. Instead of doing rather expensive backup of
    the whole repository, it maintains mirrors for packages that were already requested
    by clients. So whenever a package is requested by the installation tool (`pip`,
    `setuptools`, and `easyinstall`), if it does not exist in the local mirror, the
    devpi server will attempt to download it from the mirrored index (usually PyPI)
    and serve. Once the package is downloaded, the devpi will periodically check for
    its updates to maintain a fresh state of its mirror.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: devpi相对于bandersnatch的主要优势在于它如何处理镜像。它当然可以像bandersnatch一样对其他索引进行完整的通用镜像，但这不是它的默认行为。它不是对整个存储库进行昂贵的备份，而是为已被客户端请求的软件包维护镜像。因此，每当安装工具（`pip`、`setuptools`和`easyinstall`）请求软件包时，如果在本地镜像中不存在，devpi服务器将尝试从镜像索引（通常是PyPI）下载并提供。软件包下载后，devpi将定期检查其更新，以保持镜像的新鲜状态。
- en: The mirroring approach leaves a slight risk of failure when you request a new
    package that has not yet been mirrored and the upstream package index has an outage.
    Anyway, this risk is reduced thanks to the fact that in most deploys you will
    depend only on packages that were already mirrored in the index. The mirror state
    for packages that were already requested has eventual consistency with PyPI and
    new versions will be downloaded automatically. This seems to be a very reasonable
    tradeoff.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像方法在您请求尚未被镜像的新软件包并且上游软件包索引中断时留下了轻微的失败风险。无论如何，由于在大多数部署中，您将仅依赖于已在索引中镜像的软件包，因此这种风险得到了减少。对于已经请求的软件包，镜像状态与PyPI具有最终一致性，并且新版本将自动下载。这似乎是一个非常合理的权衡。
- en: Deployment using a package
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用软件包进行部署
- en: 'Modern web applications have a lot of dependencies and often require a lot
    of steps to properly install on the remote host. For instance, the typical bootstrapping
    process for a new version of the application on a remote host consists of the
    following steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现代Web应用程序有很多依赖项，并且通常需要许多步骤才能在远程主机上正确安装。例如，对于远程主机上的应用程序的新版本的典型引导过程包括以下步骤：
- en: Create new virtual environment for isolation
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为隔离创建新的虚拟环境
- en: Move the project code to the execution environment
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将项目代码移动到执行环境
- en: Install the latest project requirements (usually from the `requirements.txt`
    file)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装最新的项目要求（通常来自`requirements.txt`文件）
- en: Synchronize or migrate the database schema
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步或迁移数据库架构
- en: Collect static files from project sources and external packages to the desired
    location
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从项目源和外部软件包收集静态文件到所需位置
- en: Compile localization files for applications available in different languages
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为可用于不同语言的应用程序编译本地化文件
- en: 'For more complex sites, there might be lot of additional tasks mostly related
    to frontend code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的网站，可能会有许多与前端代码相关的附加任务：
- en: Generate CSS files using preprocessors such as SASS or LESS
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预处理器（如SASS或LESS）生成CSS文件
- en: Perform minification, obfuscation, and/or concatenation of static files (JavaScript
    and CSS files)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对静态文件（JavaScript和CSS文件）进行缩小、混淆和/或合并
- en: Compile code written in JavaScript superset languages (CoffeeScript, TypeScript,
    and so on) to native JS
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译用JavaScript超集语言（CoffeeScript、TypeScript等）编写的代码到本机JS
- en: Preprocess response template files (minification, style inlining, and so on)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理响应模板文件（缩小、内联样式等）
- en: 'All of these steps can be easily automated using tools such as Bash, Fabric,
    or Ansible but it is not a good idea to do everything on remote hosts where the
    application is being installed. Here are the reasons:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些步骤都可以使用诸如Bash、Fabric或Ansible之类的工具轻松自动化，但在安装应用程序的远程主机上做所有事情并不是一个好主意。原因如下：
- en: Some of the popular tools for processing static assets can be either CPU- or
    memory-intensive. Running them in production environments can destabilize your
    application execution.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些用于处理静态资产的流行工具可能是CPU密集型或内存密集型。在生产环境中运行它们可能会使应用程序执行不稳定。
- en: These tools very often will require additional system dependencies that may
    not be required for normal operation of your projects. These are mostly additional
    runtime environments such as JVM, Node, or Ruby. This adds complexity to configuration
    management and increases the overall maintenance costs.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些工具通常需要额外的系统依赖项，这些依赖项可能不是项目的正常运行所必需的。这些主要是额外的运行时环境，如JVM、Node或Ruby。这增加了配置管理的复杂性，并增加了整体维护成本。
- en: If you are deploying your application to multiple servers (tenths, hundredths,
    thousands), you are simply repeating a lot of work that could be done once. If
    you have your own infrastructure, then you may not experience a huge increase
    in costs, especially if you perform deployments in periods of low traffic. But
    if you run cloud computing services in the pricing model that charges you extra
    for spikes in load or generally for execution time, then this additional cost
    may be substantial on a proper scale.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您将应用程序部署到多个服务器（十个、百个、千个），那么您只是在重复很多工作，这些工作本来可以只做一次。如果您有自己的基础设施，那么您可能不会经历巨大的成本增加，特别是如果您在低流量时段进行部署。但如果您在计费模型中运行云计算服务，该模型会额外收费用于负载峰值或一般执行时间，那么这些额外成本可能在适当的规模上是相当可观的。
- en: Most of these steps just take a lot of time. You are installing your code on
    a remote server, so the last thing you want is to have your connection interrupted
    by some network issue. By keeping the deployment process quick, you are lowering
    the chance of deploy interruption.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数这些步骤只是花费了很多时间。您正在将代码安装到远程服务器上，所以您最不希望的是在部署过程中由于某些网络问题而中断连接。通过保持部署过程快速，您可以降低部署中断的几率。
- en: For obvious reasons, the results of the mentioned deployment steps can't be
    included in your application code repository. Simply, there are things that must
    be done with every release and you can't change that. It is obviously a place
    for proper automation but the clue is to do it in the right place and at the right
    time.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 出于明显的原因，上述部署步骤的结果不能包含在应用程序代码存储库中。简单地说，有些事情必须在每个发布中完成，你无法改变这一点。显然这是一个适当自动化的地方，但关键是在正确的地方和正确的时间做。
- en: 'Most of the things such as static collection and code/asset preprocessing can
    be done locally or in a dedicated environment, so the actual code that is deployed
    to the remote server requires only a minimal amount of on-site processing. The
    most notable deployment steps either in the process of building a distribution
    or installing a package are:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分静态收集和代码/资产预处理等工作可以在本地或专用环境中完成，因此部署到远程服务器的实际代码只需要进行最少量的现场处理。在构建分发或安装包的过程中，最显著的部署步骤是：
- en: Installation of Python dependencies and transferring static assets (CSS files
    and JavaScript) to the desired location can be handled as a part of the `install`
    command of the `setup.py` script
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Python依赖项和传输静态资产（CSS文件和JavaScript）到所需位置可以作为`setup.py`脚本的`install`命令的一部分来处理
- en: Preprocessing code (processing JavaScript supersets, minification/obfuscation/concatenation
    of assets, and running SASS or LESS) and things such as localized text compilation
    (for example, `compilemessages` in Django) can be a part of the `sdist`/`bdist`
    command of the `setup.py` script
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理代码（处理JavaScript超集、资产的缩小/混淆/合并，以及运行SASS或LESS）和诸如本地化文本编译（例如Django中的`compilemessages`）等工作可以作为`setup.py`脚本的`sdist`/`bdist`命令的一部分
- en: Inclusion of preprocessed code other than Python can be easily handled with
    the proper `MANIFEST.in` file. Dependencies are of course best provided as an
    `install_requires` argument of the `setup()` function call from the `setuptools`
    package.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 包括除Python以外的预处理代码可以很容易地通过适当的`MANIFEST.in`文件处理。依赖项当然最好作为`setuptools`包的`setup()`函数调用的`install_requires`参数提供。
- en: Packaging the whole application of course will require some additional work
    from you like providing your own custom `setuptools` commands or overriding the
    existing ones, but gives you a lot of advantages and makes project deployment
    a lot faster and reliable.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，打包整个应用程序将需要您进行一些额外的工作，比如提供自己的自定义`setuptools`命令或覆盖现有的命令，但这将为您带来许多优势，并使项目部署更快速和可靠。
- en: 'Let''s use a Django-based project (in Django 1.9 version) as an example. I
    have chosen this framework because it seems to be the most popular Python project
    of this type, so there is a high chance that you already know it a bit. A typical
    structure of files in such a project might look like the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个基于Django的项目（在Django 1.9版本中）为例。我选择这个框架是因为它似乎是这种类型的最受欢迎的Python项目，所以你很有可能已经对它有所了解。这样的项目中文件的典型结构可能如下所示：
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that this slightly differs from the usual Django project template. By default,
    the package that contains the WSGI application, the settings module, and the URL
    configuration has the same name as the project. Because we decided to take the
    packaging approach, this would be named `webxample`. This can cause some confusion,
    so it is better to rename it `conf`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这与通常的Django项目模板略有不同。默认情况下，包含WSGI应用程序、设置模块和URL配置的包与项目名称相同。因为我们决定采用打包的方法，这将被命名为`webxample`。这可能会引起一些混淆，所以最好将其重命名为`conf`。
- en: 'Without digging into the possible implementation details, let''s just make
    a few simple assumptions:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 不要深入可能的实现细节，让我们只做一些简单的假设：
- en: 'Our example application has some external dependencies. Here, it will be two
    popular Django packages: `djangorestframework` and `django-allauth`, plus one
    non-Django package: `gunicorn`.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的示例应用程序有一些外部依赖。在这里，将是两个流行的Django软件包：`djangorestframework` 和 `django-allauth`，以及一个非Django软件包：`gunicorn`。
- en: '`djangorestframework` and `django-allauth` are provided as `INSTALLED_APPS`
    in the `webexample.webexample.settings` module.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`djangorestframework` 和 `django-allauth` 被提供为 `webexample.webexample.settings`
    模块中的 `INSTALLED_APPS`。'
- en: The application is localized in three languages (German, English, and Polish)
    but we don't want to store the compiled `gettext` messages in the repository.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该应用程序在三种语言（德语、英语和波兰语）中进行了本地化，但我们不希望将编译的 `gettext` 消息存储在存储库中。
- en: We are tired of vanilla CSS syntax, so we decided to use the more powerful SCSS
    language that we translate to CSS using SASS.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们厌倦了普通的CSS语法，所以我们决定使用更强大的SCSS语言，我们使用SASS将其转换为CSS。
- en: 'Knowing the structure of the project, we can write our `setup.py` script in
    a way that make `setuptools` handle:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 了解项目的结构后，我们可以编写我们的 `setup.py` 脚本，使 `setuptools` 处理：
- en: Compilation of SCSS files under `webxample/myapp/static/scss`
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `webxample/myapp/static/scss` 下编译SCSS文件
- en: Compilation of `gettext` messages under `webexample/locale` from `.po` to `.mo`
    format
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `.po` 格式编译 `webexample/locale` 下的 `gettext` 消息到 `.mo` 格式
- en: Installation of requirements
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装要求
- en: A new script that provides an entry point to the package, so we will have the
    custom command instead of the `manage.py` script
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供软件包的入口点的新脚本，这样我们将有自定义命令而不是 `manage.py` 脚本
- en: 'We have a bit of luck here. Python binding for `libsass`, a C/C++ port of SASS
    engine, provides a handful integration with `setuptools` and `distutils`. With
    only little configuration, it provides a custom `setup.py` command for running
    the SASS compilation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里有点运气。 `libsass` 的Python绑定是SASS引擎的C/C++端口，它与 `setuptools` 和 `distutils`
    提供了很好的集成。只需进行少量配置，它就可以为运行SASS编译提供自定义的 `setup.py` 命令：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So instead of running the `sass` command manually or executing a subprocess
    in the `setup.py` script we can type `python setup.py build_scss` and have our
    SCSS files compiled to CSS. This is still not enough. It makes our life a bit
    easier but we want the whole distribution to be fully automated so there is only
    one step for creating new releases. To achieve this goal, we are forced to override
    a bit some of the existing `setuptools` distribution commands.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以通过键入 `python setup.py build_scss` 来将我们的SCSS文件编译为CSS，而不是手动运行 `sass` 命令或在
    `setup.py` 脚本中执行子进程。这还不够。这让我们的生活变得更容易，但我们希望整个分发过程完全自动化，因此只需一个步骤即可创建新版本。为了实现这个目标，我们不得不稍微覆盖一些现有的
    `setuptools` 分发命令。
- en: 'The example `setup.py` file that handles some of the project preparation steps
    through packaging might look like this:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 处理一些项目准备步骤的 `setup.py` 文件示例可能如下所示：
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'With such an implementation, we can build all assets and create source distribution
    of a package for the `webxample` project using this single terminal command:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种实现，我们可以使用这个单一的终端命令构建所有资产并为 `webxample` 项目创建源分发的软件包：
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you already have your own package index (created with `devpi`) you can add
    the `install` subcommand or use `twine` so this package will be available for
    installation with `pip` in your organization. If we look into a structure of source
    distribution created with our `setup.py` script, we can see that it contains the
    compiled `gettext` messages and CSS style sheets generated from SCSS files:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经拥有自己的软件包索引（使用 `devpi` 创建），则可以添加 `install` 子命令或使用 `twine`，这样该软件包将可以在您的组织中使用
    `pip` 进行安装。如果我们查看使用我们的 `setup.py` 脚本创建的源分发结构，我们可以看到它包含了从SCSS文件生成的编译的 `gettext`
    消息和CSS样式表：
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The additional benefit of using this approach is that we were able to provide
    our own entry point for the project in place of Django''s default `manage.py`
    script. Now we can run any Django management command using this entry point, for
    instance:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的额外好处是，我们能够在Django的默认 `manage.py` 脚本的位置提供我们自己的项目入口点。现在我们可以使用这个入口点运行任何Django管理命令，例如：
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This required a little change in the `manage.py` script for compatibility with
    the `entry_points` argument in `setup()`, so the main part of its code is wrapped
    with the `main()` function call:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要在 `manage.py` 脚本中进行一些小的更改，以便与 `setup()` 中的 `entry_points` 参数兼容，因此它的主要部分的代码被包装在
    `main()` 函数调用中：
- en: '[PRE9]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Unfortunately, a lot of frameworks (including Django) are not designed with
    the idea of packaging your projects that way in mind. It means that depending
    on the advancement of your application, converting it to a package may require
    a lot of changes. In Django, this often means rewriting many of the implicit imports
    and updating a lot of configuration variables in your settings file.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，许多框架（包括Django）并不是以打包项目的方式设计的。这意味着根据应用程序的进展，将其转换为包可能需要进行许多更改。在Django中，这通常意味着重写许多隐式导入并更新设置文件中的许多配置变量。
- en: The other problem is the consistency of releases created using Python packaging.
    If different team members are authorized to create application distribution, it
    is crucial that this process takes place in the same replicable environment, especially
    when you do a lot of asset preprocessing; it is possible that the package created
    in two different environments will not look the same even if created from the
    same code base. This may be due to different version of tools used during the
    build process. The best practice is to move the distribution responsibility to
    a continuous integration/delivery system such as Jenkins or Buildbot. The additional
    advantage is that you can assert that the package passes all required tests before
    going to distribution. You can even make the automated deployment as a part of
    such continuous delivery system.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是使用Python打包创建的发布的一致性。如果不同的团队成员被授权创建应用程序分发，那么在相同可复制的环境中进行此过程至关重要，特别是当您进行大量资产预处理时；即使从相同的代码库创建，可能在两个不同的环境中创建的软件包看起来也不一样。这可能是由于在构建过程中使用了不同版本的工具。最佳实践是将分发责任移交给持续集成/交付系统，如Jenkins或Buildbot。额外的好处是您可以断言软件包在分发之前通过了所有必需的测试。您甚至可以将自动部署作为这种持续交付系统的一部分。
- en: 'Despite this, distributing your code as Python packages using `setuptools`
    is not simple and effortless; it will greatly simplify your deployments, so it
    is definitely worth trying. Note that this is also in line with the detailed recommendation
    of the sixth rule in the Twelve-Factor App: execute the app as one or more stateless
    processes ([http://12factor.net/processes](http://12factor.net/processes)).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，使用`setuptools`将您的代码分发为Python软件包并不简单和轻松；它将极大简化您的部署，因此绝对值得一试。请注意，这也符合十二要素应用程序的第六条详细建议：将应用程序执行为一个或多个无状态进程（[http://12factor.net/processes](http://12factor.net/processes)）。
- en: Common conventions and practices
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的惯例和做法
- en: There is a set of common conventions and practices for deployment that not every
    developer may know but that are obvious for anyone who has done some operations
    in their life. As explained in the chapter introduction, it is crucial to know
    at least a few of them even if you are not responsible for code deployment and
    operations because it will allow you to make better design decisions during the
    development.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有一套部署的常见惯例和做法，不是每个开发人员都可能知道，但对于任何曾经进行过一些操作的人来说都是显而易见的。正如在章节介绍中所解释的那样，即使您不负责代码部署和操作，至少了解其中一些对于在开发过程中做出更好的设计决策是至关重要的。
- en: The filesystem hierarchy
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件系统层次结构
- en: 'The most obvious conventions that may come into your mind are probably about
    filesystem hierarchy and user naming. If you are looking for such suggestions
    here, then you will be disappointed. There is of course a **Filesystem Hierarchy
    Standard** that defines the directory structure and directory contents in Unix
    and Unix-like operating systems, but it is really hard to find an actual OS distribution
    that is fully compliant with FHS. If system designers and programmers cannot obey
    such standards, it is very hard to expect the same from its administrators. In
    my experience, I''ve seen application code deployed almost everywhere where it
    is possible, including nonstandard custom directories in the root filesystem level.
    Almost always, the people behind such decisions had really strong arguments for
    doing so. The only suggestions in this matter that I can give to you are as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想到的最明显的惯例可能是关于文件系统层次结构和用户命名的。如果您在这里寻找建议，那么您会感到失望。当然有一个**文件系统层次结构标准**，它定义了Unix和类Unix操作系统中的目录结构和目录内容，但真的很难找到一个完全符合FHS的实际操作系统发行版。如果系统设计师和程序员不能遵守这样的标准，那么很难期望管理员也能做到。根据我的经验，我几乎在可能的任何地方看到应用程序代码部署，包括在根文件系统级别的非标准自定义目录。几乎总是，做出这样决定的人都有非常充分的理由。在这方面我能给你的唯一建议是：
- en: Choose wisely and avoid surprises
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明智选择，避免惊喜
- en: Be consistent across all the available infrastructure of your project
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目的所有可用基础设施中保持一致
- en: Try to be consistent across your organization (the company you work in)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽量在您的组织（您所在的公司）中保持一致
- en: What really helps is to document conventions for your project. Just remember
    to make sure that this documentation is accessible for every interested team member
    and that everyone knows such a document exists.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 真正有帮助的是为您的项目记录惯例。只需确保这些文件对每个感兴趣的团队成员都是可访问的，并且每个人都知道这样的文件存在。
- en: Isolation
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隔离
- en: Reasons for isolation as well as recommended tools were already discussed in
    [Chapter 1](ch01.html "Chapter 1. Current Status of Python"), *Current Status
    of Python*. For the purpose of deployments, there is only one important thing
    to add. You should always isolate project dependencies for each release of your
    application. In practice it means that whenever you deploy a new version of the
    application, you should create a new isolated environment for this release (using
    `virtualenv` or `venv`). Old environments should be left for some time on your
    hosts, so in case of issues you can easily perform a rollback to one of the older
    versions of your application.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离的原因以及推荐的工具已经在[第1章](ch01.html "第1章。Python的当前状态")中讨论过，*Python的当前状态*。对于部署，只有一件重要的事情要补充。您应该始终为应用程序的每个发布版本隔离项目依赖关系。在实践中，这意味着每当您部署应用程序的新版本时，您应该为此版本创建一个新的隔离环境（使用`virtualenv`或`venv`）。旧环境应该在您的主机上保留一段时间，以便在出现问题时可以轻松地回滚到旧版本之一。
- en: Creating fresh environments for each release helps in managing their clean state
    and compliance with a list of provided dependencies. By fresh environment we mean
    creating a new directory tree in the filesystem instead of updating already existing
    files. Unfortunately, it may make it a bit harder to perform things such as a
    graceful reload of services, which is much easier to achieve if the environment
    is updated in-place.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个发布创建新的环境有助于管理其干净状态并符合提供的依赖项列表。通过新环境，我们指的是在文件系统中创建一个新的目录树，而不是更新已经存在的文件。不幸的是，这可能会使一些事情变得更加困难，比如优雅地重新加载服务，如果环境是就地更新的话，这将更容易实现。
- en: Using process supervision tools
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用进程监控工具
- en: Applications on remote servers usually are never expected to quit. If it is
    the web application, its HTTP server process will indefinitely wait for new connections
    and requests and will exit only if some unrecoverable error occurs.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 远程服务器上的应用程序通常不会意外退出。如果是Web应用程序，其HTTP服务器进程将无限期地等待新的连接和请求，并且只有在发生一些无法恢复的错误时才会退出。
- en: It is of course not possible to run it manually in the shell and have a never-ending
    SSH connection. Using `nohup`, `screen`, or `tmux` to semi-daemonize the process
    is not an option. Doing so is like designing your service to fail.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，无法在shell中手动运行它并保持一个永久的SSH连接。使用`nohup`、`screen`或`tmux`来半守护化进程也不是一个选择。这样做就像是在设计您的服务注定要失败。
- en: 'What you need is to have some process supervision tool that can start and manage
    your application process. Before choosing the right one you need to make sure
    it:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要的是一些进程监控工具，可以启动和管理您的应用程序进程。在选择合适的工具之前，您需要确保它：
- en: Restarts the service if it quits
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果服务退出，则重新启动服务
- en: Reliably tracks its state
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠地跟踪其状态
- en: Captures its `stdout`/`stderr` streams for logging purposes
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获其`stdout`/`stderr`流以进行日志记录
- en: Runs a process with specific user/group permissions
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以特定用户/组权限运行进程
- en: Configures system environment variables
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置系统环境变量
- en: Most of the Unix and Linux distributions have some built-in tools/subsystems
    for process supervision, such as `initd` scripts, `upstart`, and `runit`. Unfortunately,
    in most cases they are not well suited for running user-level application code
    and are really hard to maintain. Especially writing reliable `init.d` scripts
    is a real challenge because it requires a lot of Bash scripting that is hard to
    do right. Some Linux distributions such as Gentoo have a redesigned approach to
    `init.d` scripts, so writing them is a lot easier. Anyway, locking yourself to
    a specific OS distribution just for the purpose of a single process supervision
    tool is not a good idea.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数Unix和Linux发行版都有一些内置的进程监控工具/子系统，比如`initd`脚本、`upstart`和`runit`。不幸的是，在大多数情况下，它们不适合运行用户级应用程序代码，并且非常难以维护。特别是编写可靠的`init.d`脚本是一个真正的挑战，因为它需要大量的Bash脚本编写，这很难做到正确。一些Linux发行版，比如Gentoo，对`init.d`脚本有了重新设计的方法，因此编写它们变得更容易。无论如何，为了一个单一的进程监控工具而将自己锁定到特定的操作系统发行版并不是一个好主意。
- en: Two popular tools in the Python community for managing application processes
    are Supervisor ([http://supervisord.org](http://supervisord.org)) and Circus ([https://circus.readthedocs.org/en/latest/](https://circus.readthedocs.org/en/latest/)).
    They are both very similar in configuration and usage. Circus is a bit younger
    than Supervisor because it was created to address some weaknesses of the latter.
    They both can be configured in simple INI-like configuration format. They are
    not limited to running Python processes and can be configured to manage any application.
    It is hard to say which one is better because they both provide very similar functionality.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Python社区中管理应用程序进程的两种流行工具是Supervisor ([http://supervisord.org](http://supervisord.org))和Circus
    ([https://circus.readthedocs.org/en/latest/](https://circus.readthedocs.org/en/latest/))。它们在配置和使用上都非常相似。Circus比Supervisor稍微年轻一些，因为它是为了解决后者的一些弱点而创建的。它们都可以使用简单的INI格式进行配置。它们不仅限于运行Python进程，还可以配置为管理任何应用程序。很难说哪一个更好，因为它们都提供非常相似的功能。
- en: Anyway, Supervisor does not run on Python 3, so it does not get our blessing.
    While it is not a problem to run Python 3 processes under Supervisor's control,
    I will take it as an excuse and feature only the example of the Circus configuration.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，Supervisor不支持Python 3，因此我们不会推荐它。虽然在Supervisor的控制下运行Python 3进程不是问题，但我将以此为借口，只展示Circus配置的示例。
- en: 'Let''s assume that we want to run the webxample application (presented previously
    in this chapter) using `gunicorn` webserver under Circus control. In production,
    we would probably run Circus under applicable system-level process supervision
    tools (`initd`, `upstart`, and `runit`), especially if it was installed from the
    system packages repository. For the sake of simplicity, we will run this locally
    inside of the virtual environment. The minimal configuration file (here named
    `circus.ini`) that allows us to run our application in Circus looks like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要在Circus控制下使用`gunicorn` web服务器运行webxample应用程序（在本章前面介绍过）。在生产环境中，我们可能会在适用的系统级进程监控工具（`initd`、`upstart`和`runit`）下运行Circus，特别是如果它是从系统软件包存储库安装的。为了简单起见，我们将在虚拟环境内本地运行。允许我们在Circus中运行应用程序的最小配置文件（这里命名为`circus.ini`）如下所示：
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, the `circus` process can be run with this configuration file as the execution
    argument:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`circus`进程可以使用这个配置文件作为执行参数来运行：
- en: '[PRE11]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now you can use the `circusctl` command to run an interactive session and control
    all managed processes using simple commands. Here is an example of such a session:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用`circusctl`命令来运行一个交互式会话，并使用简单的命令来控制所有受管进程。以下是这样一个会话的示例：
- en: '[PRE12]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Of course, both of the mentioned tools have a lot more features available. All
    of them are explained in their documentation, so before making your choice, you
    should read them carefully.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，上述两种工具都有更多功能可用。它们的所有功能都在它们的文档中有解释，因此在做出选择之前，您应该仔细阅读它们。
- en: Application code should be run in user space
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用代码应该在用户空间中运行
- en: Your application code should be always run in user space. This means it must
    not be executed under super-user privileges. If you designed your application
    following Twelve-Factor App, it is possible to run your application under a user
    that has almost no privileges. The conventional name for a user that owns no files
    and is in no privileged groups is `nobody`, anyway the actual recommendation is
    to create a separate user for each application daemon. The reason for that is
    system security. It is to limit the damage that a malicious user can do if it
    gains control over your application process. In Linux, processes of the same user
    can interact with each other, so it is important to have different applications
    separated at the user level.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您的应用程序代码应始终在用户空间中运行。这意味着它不得以超级用户权限执行。如果您按照Twelve-Factor App设计应用程序，可以在几乎没有特权的用户下运行应用程序。拥有文件并且不属于特权组的用户的传统名称是`nobody`，但实际建议是为每个应用程序守护进程创建一个单独的用户。原因是系统安全性。这是为了限制恶意用户在控制应用程序进程后可能造成的损害。在Linux中，同一用户的进程可以相互交互，因此在用户级别上将不同的应用程序分开是很重要的。
- en: Using reverse HTTP proxies
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用反向HTTP代理
- en: 'Multiple Python WSGI-compliant web servers can easily serve HTTP traffic all
    by themselves without the need for any other web server on top of them. It is
    still very common to hide them behind a reverse proxy such as Nginx for various
    reasons:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 多个Python符合WSGI标准的Web服务器可以轻松地自行提供HTTP流量，无需在其上方使用任何其他Web服务器。然而，通常还是很常见将它们隐藏在Nginx等反向代理后面，原因有很多：
- en: TLS/SSL termination is usually better handled by top-level web servers such
    as Nginx and Apache. The Python application can then speak only simple HTTP protocol
    (instead of HTTPS), so complexity and configuration of secure communication channels
    is left for the reverse proxy.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TLS/SSL终止通常最好由顶级Web服务器（如Nginx和Apache）处理。然后，Python应用程序只能使用简单的HTTP协议（而不是HTTPS），因此安全通信通道的复杂性和配置留给了反向代理。
- en: Unprivileged users cannot bind low ports (in the range of 0-1000), but HTTP
    protocol should be served to the users on port 80, and HTTPS should be served
    on port 443\. To do this, you must run the process with super-user privileges.
    Usually, it is safer to have your application serving on high port or on Unix
    Domain Socket and use that as an upstream for a reverse proxy that is run under
    the more privileged user.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非特权用户无法绑定低端口（0-1000范围内），但HTTP协议应该在端口80上为用户提供服务，HTTPS应该在端口443上提供服务。为此，必须以超级用户权限运行进程。通常，更安全的做法是让应用程序在高端口上提供服务，或者在Unix域套接字上提供服务，并将其用作在更特权用户下运行的反向代理的上游。
- en: Usually, Nginx can serve static assets (images, JS, CSS, and other media) more
    efficiently than Python code. If you configure it as a reverse proxy, then it
    is only few more lines of configuration to serve static files through it.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，Nginx可以比Python代码更有效地提供静态资产（图像、JS、CSS和其他媒体）。如果将其配置为反向代理，那么只需几行配置就可以通过它提供静态文件。
- en: When single host needs to serve multiple applications from different domains,
    Apache or Nginx are indispensable for creating virtual hosts for different domains
    served on the same port.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当单个主机需要从不同域中的多个应用程序提供服务时，Apache或Nginx是不可或缺的，用于为在同一端口上提供服务的不同域创建虚拟主机。
- en: Reverse proxies can improve performance by adding an additional caching layer
    or can be configured as simple load-balancers.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反向代理可以通过添加额外的缓存层来提高性能，也可以配置为简单的负载均衡器。
- en: Some of the web servers actually are recommended to be run behind a proxy, such
    as Nginx. For example, `gunicorn` is a very robust WSGI-based server that can
    give exceptional performance results if its clients are fast as well. On the other
    hand, it does not handle slow clients well, so it is easily susceptible to denial-of-service
    attacks based on slow client connection. Using a proxy server that is able to
    buffer slow clients is the best way to solve this problem.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一些Web服务器实际上建议在代理后运行，例如Nginx。例如，`gunicorn`是一个非常强大的基于WSGI的服务器，如果其客户端速度很快，可以提供出色的性能结果。另一方面，它不能很好地处理慢速客户端，因此很容易受到基于慢速客户端连接的拒绝服务攻击的影响。使用能够缓冲慢速客户端的代理服务器是解决这个问题的最佳方法。
- en: Reloading processes gracefully
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优雅地重新加载进程
- en: The ninth rule of the Twelve-Factor App methodology deals with process disposability
    and says that you should maximize robustness with fast startup times and graceful
    shutdowns. While a fast startup time is quite self-explanatory, graceful shutdowns
    require some additional discussion.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Twelve-Factor App方法论的第九条规则涉及进程的可处置性，并指出您应该通过快速启动时间和优雅的关闭来最大程度地提高鲁棒性。虽然快速启动时间相当不言自明，但优雅的关闭需要一些额外的讨论。
- en: In the scope of web applications, if you terminate the server process in a nongraceful
    way, it will quit immediately without time to finish processing requests and reply
    with the proper responses to connected clients. In the best case scenario, if
    you use some kind of reverse proxy, then the proxy might reply to the connected
    clients with some generic error response (for example, 502 Bad Gateway), even
    though it is not the right way to notify users that you have restarted your application
    and have deployed a new release.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web应用程序范围内，如果以非优雅的方式终止服务器进程，它将立即退出，没有时间完成处理请求并向连接的客户端回复适当的响应。在最佳情况下，如果使用某种反向代理，那么代理可能会向连接的客户端回复一些通用的错误响应（例如502
    Bad Gateway），即使这并不是通知用户您已重新启动应用程序并部署新版本的正确方式。
- en: According to the Twelve-Factor App, the web serving process should be able to
    quit gracefully upon receiving Unix `SIGTERM` signal (for example, `kill -TERM
    <process-id>`). This means the server should stop accepting new connections, finish
    processing all the pending requests, and then quit with some exit code when there
    is nothing more to do.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Twelve-Factor App，Web服务器进程应能够在接收到Unix `SIGTERM`信号（例如`kill -TERM <process-id>`）时优雅地退出。这意味着服务器应停止接受新连接，完成处理所有挂起的请求，然后在没有其他事情可做时以某种退出代码退出。
- en: 'Obviously, when all of the serving processes quit or start their shutdown procedure,
    you are not able to process new requests any longer. This means your service will
    still experience an outage, so there is an additional step you need to perform—start
    new workers that will be able to accept new connections while the old ones are
    gracefully quitting. Various Python WSGI-compliant web server implementations
    allow reloading the service gracefully without any downtime. The most popular
    are Gunicorn and uWSGI:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，当所有服务进程退出或开始其关闭过程时，您将无法再处理新请求。这意味着您的服务仍然会经历停机，因此您需要执行额外的步骤-启动新的工作进程，这些工作进程将能够在旧的工作进程优雅退出时接受新的连接。各种Python
    WSGI兼容的Web服务器实现允许在没有任何停机时间的情况下优雅地重新加载服务。最流行的是Gunicorn和uWSGI：
- en: Gunicorn's master process, upon receiving the `SIGHUP` signal (`kill -HUP <process-pid>`),
    will start new workers (with new code and configuration) and attempt a graceful
    shutdown on the old ones.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gunicorn的主进程在接收到`SIGHUP`信号（`kill -HUP <process-pid>`）后，将启动新的工作进程（带有新的代码和配置），并尝试在旧的工作进程上进行优雅的关闭。
- en: uWSGI has at least three independent schemes for doing graceful reloads. Each
    of them is too complex to explain briefly, but its official documentation provides
    full information on all the possible options.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: uWSGI至少有三种独立的方案来进行优雅的重新加载。每一种都太复杂，无法简要解释，但它的官方文档提供了所有可能选项的完整信息。
- en: 'Graceful reloads are today a standard in deploying web applications. Gunicorn
    seems to have an approach that is the easiest to use but also leaves you with
    the least flexibility. Graceful reloads in uWSGI on the other hand allow much
    better control on reloads but require more effort to automate and setup. Also,
    how you handle graceful reloads in your automated deploys is also affected on
    what supervision tools you use and how they are configured. For instance, in Gunicorn,
    graceful reloads are as simple as:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅的重新加载在部署Web应用程序中已经成为标准。Gunicorn似乎有一种最容易使用但也给您留下最少灵活性的方法。另一方面，uWSGI中的优雅重新加载允许更好地控制重新加载，但需要更多的努力来自动化和设置。此外，您如何处理自动部署中的优雅重新加载也受到您使用的监视工具以及其配置方式的影响。例如，在Gunicorn中，优雅的重新加载就像这样简单：
- en: '[PRE13]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: But if you want to properly isolate project distributions by separating virtual
    environments for each release and configure process supervision using symbolic
    links (as presented in the `fabfile` example earlier), you will shortly notice
    that this does not work as expected. For more complex deployments, there is still
    no solution available that will just work for you out-of-the-box. You will always
    need to do a bit of hacking and sometimes this will require a substantial level
    of knowledge about low-level system implementation details.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您想通过为每个发布分离虚拟环境并使用符号链接配置进程监视来正确隔离项目分发（如之前在`fabfile`示例中提出的），您很快会注意到这并不像预期的那样工作。对于更复杂的部署，目前还没有可用的解决方案可以直接为您解决问题。您总是需要进行一些黑客攻击，有时这将需要对低级系统实现细节有相当高的了解。
- en: Code instrumentation and monitoring
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码仪器和监控
- en: Our work does not end with writing an application and deploying it to the target
    execution environment. It is possible to write an application that after deployment
    will not require any further maintenance, although it is very unlikely. In reality,
    we need to ensure that it is properly observed for errors and performance.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作并不仅仅是编写应用程序并将其部署到目标执行环境。可能编写一个应用程序后，部署后将不需要任何进一步的维护，尽管这是非常不太可能的。实际上，我们需要确保它被正确地观察以发现错误和性能问题。
- en: 'To be sure that our product works as expected, we need to properly handle application
    logs and monitor the necessary application metrics. This often includes:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们的产品按预期工作，我们需要正确处理应用程序日志并监视必要的应用程序指标。这通常包括：
- en: Monitoring web application access logs for various HTTP status codes
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控Web应用程序访问日志以获取各种HTTP状态代码
- en: A collection of process logs that may contain information about runtime errors
    and various warnings
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能包含有关运行时错误和各种警告的进程日志的收集
- en: Monitoring system resources (CPU load, memory, and network traffic) on remote
    hosts where the application is run
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控远程主机上的系统资源（CPU负载、内存和网络流量），应用程序运行的地方
- en: Monitoring application-level performance and metrics that are business performance
    indicators (customer acquisition, revenue, and so on)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控业务绩效和指标的应用级性能（客户获取、收入等）
- en: Luckily there are a lot of free tools available for instrumenting your code
    and monitoring its performance. Most of them are very easy to integrate.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有很多免费的工具可用于仪器化您的代码并监视其性能。其中大多数都很容易集成。
- en: Logging errors – sentry/raven
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录错误-哨兵/乌鸦
- en: No matter how precisely your application is tested, the truth is painful. Your
    code will eventually fail at some point. This can be anything—unexpected exception,
    resource exhaustion, some backing service crashing, network outage, or simply
    an issue in the external library. Some of the possible issues, such as resource
    exhaustion, can be predicted and prevented with proper monitoring, but there will
    be always something that passes your defences no matter how much you try.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您的应用程序经过多么精确的测试，事实是痛苦的。您的代码最终会在某个时候失败。这可能是任何事情-意外的异常、资源耗尽、某些后台服务崩溃、网络中断，或者只是外部库中的问题。一些可能的问题，如资源耗尽，可以通过适当的监控来预测和防止，但无论您如何努力，总会有一些事情会越过您的防线。
- en: What you can do is be well prepared for such scenarios and make sure that no
    error passes unnoticed. In most cases, any unexpected failure scenario results
    in an exception raised by the application and logged through the logging system.
    This can be `stdout`, `sderr`, file, or whatever output you have configured for
    logging. Depending on your implementation, this may or may not result in the application
    quitting with some system exit code.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以做的是为这种情况做好充分准备，并确保没有错误被忽视。在大多数情况下，应用程序引发的任何意外故障场景都会导致异常，并通过日志系统记录。这可以是“stdout”、“sderr”、“文件”或您为日志记录配置的任何输出。根据您的实现，这可能会导致应用程序退出并带有一些系统退出代码，也可能不会。
- en: You could, of course, depend only on such logs stored in files for finding and
    monitoring your application errors. Unfortunately, observing errors in textual
    logs is quite painful and does not scale well beyond anything more complex than
    running code in development. You will eventually be forced to use some services
    designed for log collection and analysis. Proper log processing is very important
    for other reasons that will be explained a bit later but does not work well for
    tracking and debugging production errors. The reason is simple. The most common
    form of error logs is just Python stack trace. If you stop only on that, you will
    soon realize that it is not enough to find the root cause of your issues—especially
    when errors occur in unknown patterns or in certain load conditions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以仅依赖于存储在文件中的这些日志来查找和监视应用程序错误。不幸的是，观察文本日志中的错误非常痛苦，并且在除了在开发中运行代码之外的任何更复杂的情况下都无法很好地扩展。您最终将被迫使用一些专为日志收集和分析而设计的服务。适当的日志处理对于稍后将要解释的其他原因非常重要，但对于跟踪和调试生产错误并不起作用。原因很简单。错误日志的最常见形式只是Python堆栈跟踪。如果您仅停留在那里，您很快就会意识到这不足以找到问题的根本原因-特别是当错误以未知模式或在某些负载条件下发生时。
- en: What you really need is as much context information about error occurrence as
    possible. It is also very useful to have a full history of errors that have occurred
    in the production environment that you can browse and search in some convenient
    way. One of the most common tools that gives such capabilities is Sentry ([https://getsentry.com](https://getsentry.com)).
    It is a battle-tested service for tracking exceptions and collecting crash reports.
    It is available as open source, is written in Python, and originated as a tool
    for backend web developers. Now it has outgrown its initial ambitions and has
    support for many more languages, including PHP, Ruby, and JavaScript, but still
    stays the most popular tool of choice for most Python web developers.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 您真正需要的是尽可能多的关于错误发生的上下文信息。拥有在生产环境中发生的错误的完整历史记录，并且可以以某种便捷的方式浏览和搜索，也非常有用。提供这种功能的最常见工具之一是Sentry（[https://getsentry.com](https://getsentry.com)）。它是一个经过实战考验的用于跟踪异常和收集崩溃报告的服务。它作为开源软件提供，是用Python编写的，并起源于用于后端Web开发人员的工具。现在它已经超出了最初的野心，并支持了许多其他语言，包括PHP、Ruby和JavaScript，但仍然是大多数Python
    Web开发人员的首选工具。
- en: Tip
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Exception stack tracebacks in web applications**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**Web应用程序中的异常堆栈跟踪**'
- en: It is common that web applications do not exit on unhandled exceptions because
    HTTP servers are obliged to return an error response with a status code from the
    5XX group if any server error occurs. Most Python web frameworks do such things
    by default. In such cases, the exception is in fact handled but on a lower framework-level.
    Anyway, this, in most cases, will still result in the exception stack trace being
    printed (usually on standard output).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Web应用程序不会在未处理的异常上退出，因为HTTP服务器有义务在发生任何服务器错误时返回一个5XX组的状态代码的错误响应。大多数Python Web框架默认情况下都会这样做。在这种情况下，实际上是在较低的框架级别处理异常。无论如何，在大多数情况下，这仍将导致异常堆栈跟踪被打印（通常在标准输出上）。
- en: 'Sentry is available in a paid software-as-a-service model, but it is open source,
    so it can be hosted for free on your own infrastructure. The library that provides
    integration with Sentry is `raven` (available on PyPI). If you haven''t worked
    with it yet, want to test it but have no access to your own Sentry server, then
    you can easily signup for a free trial on Sentry''s on-premise service site. Once
    you have access to a Sentry server and have created a new project, you will obtain
    a string called DSN, or Data Source Name. This DSN string is the minimal configuration
    setting needed to integrate your application with sentry. It contains protocol,
    credentials, server location, and your organization/project identifier in the
    following form:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Sentry以付费软件即服务模式提供，但它是开源的，因此可以免费托管在您自己的基础设施上。提供与Sentry集成的库是“raven”（可在PyPI上获得）。如果您尚未使用过它，想要测试它但无法访问自己的Sentry服务器，那么您可以轻松在Sentry的本地服务站点上注册免费试用。一旦您可以访问Sentry服务器并创建了一个新项目，您将获得一个称为DSN或数据源名称的字符串。这个DSN字符串是集成应用程序与sentry所需的最小配置设置。它以以下形式包含协议、凭据、服务器位置和您的组织/项目标识符：
- en: '[PRE14]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once you have DSN, the integration is pretty straightforward:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您获得了DSN，集成就非常简单：
- en: '[PRE15]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Raven has numerous integrations with the most popular Python frameworks, such
    as Django, Flask, Celery, and Pyramid, to make integration easier. These integrations
    will automatically provide additional context that is specific to the given framework.
    If your web framework of choice does not have dedicated support, the `raven` package
    provides generic WSGI middleware that makes it compatible with any WSGI-based
    web servers:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Raven与最流行的Python框架（如Django，Flask，Celery和Pyramid）有许多集成，以使集成更容易。这些集成将自动提供特定于给定框架的附加上下文。如果您选择的Web框架没有专门的支持，“raven”软件包提供了通用的WSGI中间件，使其与任何基于WSGI的Web服务器兼容：
- en: '[PRE16]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The other notable integration is the ability to track messages logged through
    Python''s built-in `logging` module. Enabling such support requires only a few
    additional lines of code:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的集成是跟踪通过Python内置的“logging”模块记录的消息的能力。启用此类支持仅需要几行额外的代码：
- en: '[PRE17]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Capturing `logging` messages may have some not obvious caveats, so make sure
    to read the official documentation on that topic if you are interested in such
    a feature. This should save you from unpleasant surprises.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获`logging`消息可能会有一些不明显的注意事项，因此，如果您对此功能感兴趣，请确保阅读官方文档。这应该可以避免令人不快的惊喜。
- en: The last note is about running your own Sentry as a way to save some money.
    "There ain't no such thing as a free lunch." You will eventually pay additional
    infrastructure costs and Sentry will be just another service to maintain. *Maintenance
    = additional work = costs*! As your application grows, the number of exceptions
    grow, so you will be forced to scale Sentry as you scale your product. Fortunately,
    this is a very robust project, but will not give you any value if overwhelmed
    with too much load. Also, keeping Sentry prepared for a catastrophic failure scenario
    where thousands of crash reports per second can be sent is a real challenge. So
    you must decide which option is really cheaper for you, and whether you have enough
    resources and wit to do all of this by yourself. There is of course no such dilemma
    if security policies in your organization deny sending any data to third parties.
    If so, just host it on your own infrastructure. There are costs of course, but
    ones that are definitely worth paying.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点是关于运行自己的Sentry以节省一些钱的方法。 "没有免费的午餐。"最终，您将支付额外的基础设施成本，而Sentry将只是另一个需要维护的服务。*维护=额外工作=成本*！随着您的应用程序增长，异常的数量也会增长，因此您将被迫在扩展产品的同时扩展Sentry。幸运的是，这是一个非常强大的项目，但如果负载过重，它将无法为您提供任何价值。此外，保持Sentry准备好应对灾难性故障场景，其中可能会发送数千个崩溃报告，是一个真正的挑战。因此，您必须决定哪个选项对您来说真正更便宜，以及您是否有足够的资源和智慧来自己完成所有这些。当然，如果您的组织的安全政策禁止向第三方发送任何数据，那么就在自己的基础设施上托管它。当然会有成本，但这绝对是值得支付的成本。
- en: Monitoring system and application metrics
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控系统和应用程序指标
- en: When it comes to monitoring performance, the amount of tools to choose from
    may be overwhelming. If you have high expectations, then it is possible that you
    will need to use a few of them at the same time.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控性能方面，可供选择的工具数量可能令人不知所措。如果您期望很高，那么可能需要同时使用其中的几个。
- en: '**Munin** ([http://munin-monitoring.org](http://munin-monitoring.org)) is one
    of the popular choices used by many organizations regardless of the technology
    stack they use. It is a great tool for analyzing resource trends and provides
    a lot of useful information even with default installation without additional
    configuration. Its installation consists of two main components:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Munin（[http://munin-monitoring.org](http://munin-monitoring.org)）是许多组织使用的热门选择之一，无论它们使用什么技术栈。它是一个很好的工具，用于分析资源趋势，并且即使在默认安装时也提供了许多有用的信息，而无需额外配置。它的安装包括两个主要组件：
- en: The Munin master that collects metrics from other nodes and serves metrics graphs
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Munin主机从其他节点收集指标并提供指标图
- en: The Munin node that is installed on a monitored host, which gathers local metrics
    and sends it to the Munin master
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Munin节点安装在受监视的主机上，它收集本地指标并将其发送到Munin主机
- en: 'Master, node, and most of the plugins are written in Perl. There are also node
    implementations in other languages: `munin-node-c` is written in C ([https://github.com/munin-monitoring/munin-c](https://github.com/munin-monitoring/munin-c))
    and `munin-node-python` is written in Python ([https://github.com/agroszer/munin-node-python](https://github.com/agroszer/munin-node-python)).
    Munin comes with a huge number of plugins available in its `contrib` repository.
    This means it provides out-of-the-box support for most of the popular databases
    and system services. There are even plugins for monitoring popular Python web
    servers such as uWSGI, and Gunicorn.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 主机、节点和大多数插件都是用Perl编写的。还有其他语言的节点实现：`munin-node-c`是用C编写的（[https://github.com/munin-monitoring/munin-c](https://github.com/munin-monitoring/munin-c)），`munin-node-python`是用Python编写的（[https://github.com/agroszer/munin-node-python](https://github.com/agroszer/munin-node-python)）。Munin附带了大量插件，可在其`contrib`存储库中使用。这意味着它提供了对大多数流行的数据库和系统服务的开箱即用支持。甚至还有用于监视流行的Python
    Web服务器（如uWSGI和Gunicorn）的插件。
- en: The main drawback of Munin is the fact it serves graphs as static images and
    actual plotting configuration is included in specific plugin configurations. This
    does not help in creating flexible monitoring dashboards and comparing metric
    values from different sources at the same graph. But this is the price we need
    to pay for simple installation and versatility. Writing your own plugins is quite
    simple. There is the `munin-python` package ([http://python-munin.readthedocs.org/en/latest/](http://python-munin.readthedocs.org/en/latest/))
    that helps writing Munin plugins in Python.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Munin的主要缺点是它将图形呈现为静态图像，并且实际的绘图配置包含在特定插件配置中。这并不利于创建灵活的监控仪表板，并在同一图表中比较来自不同来源的度量值。但这是我们为简单安装和多功能性所付出的代价。编写自己的插件非常简单。有一个`munin-python`包（[http://python-munin.readthedocs.org/en/latest/](http://python-munin.readthedocs.org/en/latest/)），它可以帮助用Python编写Munin插件。
- en: Unfortunately, the architecture of Munin that assumes that there is always a
    separate monitoring daemon process on every host that is responsible for collection
    of metrics may not be the best solution for monitoring custom application performance
    metrics. It is indeed very easy to write your own Munin plugins, but under the
    assumption that the monitoring process can already report its performance statistics
    in some way. If you want to collect some custom application-level metrics, it
    might be necessary to aggregate and store them in some temporary storage until
    reporting to a custom Munin plugin. It makes creation of custom metrics more complicated,
    so you might want to consider other solutions for this purpose.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，Munin的架构假设每个主机上都有一个单独的监控守护进程负责收集指标，这可能不是监控自定义应用程序性能指标的最佳解决方案。编写自己的Munin插件确实非常容易，但前提是监控进程已经以某种方式报告其性能统计数据。如果您想收集一些自定义应用程序级别的指标，可能需要将它们聚合并存储在某些临时存储中，直到报告给自定义的Munin插件。这使得创建自定义指标变得更加复杂，因此您可能需要考虑其他解决方案。
- en: 'The other popular solution that makes it especially easy to collect custom
    metrics is StatsD ([https://github.com/etsy/statsd](https://github.com/etsy/statsd)).
    It''s a network daemon written in Node.js that listens to various statistics such
    as counters, timers, and gauges. It is very easy to integrate, thanks to the simple
    protocol based on UDP. It is also easy to use the Python package named `statsd`
    for sending metrics to the StatsD daemon:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特别容易收集自定义指标的流行解决方案是StatsD（[https://github.com/etsy/statsd](https://github.com/etsy/statsd)）。它是一个用Node.js编写的网络守护程序，监听各种统计数据，如计数器、计时器和量规。由于基于UDP的简单协议，它非常容易集成。还可以使用名为`statsd`的Python包将指标发送到StatsD守护程序：
- en: '[PRE18]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Because UDP is connectionless, it has a very low performance overhead on the
    application code so it is very suitable for tracking and measuring custom events
    inside the application code.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 由于UDP是无连接的，它对应用程序代码的性能开销非常低，因此非常适合跟踪和测量应用程序代码内的自定义事件。
- en: 'Unfortunately, StatsD is the only metrics collection daemon, so it does not
    provide any reporting features. You need other processes that are able to process
    data from StatsD in order to see the actual metrics graphs. The most popular choice
    is Graphite ([http://graphite.readthedocs.org](http://graphite.readthedocs.org)).
    It does mainly two things:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，StatsD是唯一的指标收集守护程序，因此它不提供任何报告功能。您需要其他进程能够处理来自StatsD的数据，以查看实际的指标图。最受欢迎的选择是Graphite（[http://graphite.readthedocs.org](http://graphite.readthedocs.org)）。它主要做两件事：
- en: Stores numeric time-series data
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储数字时间序列数据
- en: Renders graphs of this data on demand
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要呈现此数据的图形
- en: Graphite provides you with the ability to save graph presets that are highly
    customizable. You can also group many graphs into thematic dashboards. Graphs
    are, similarly to Munin, rendered as static images, but there is also the JSON
    API that allows other frontends to read graph data and render it by other means.
    One of the great dashboard plugins integrated with Graphite is Grafana ([http://grafana.org](http://grafana.org)).
    It is really worth trying because it has way better usability than plain Graphite
    dashboards. Graphs provided in Grafana are fully interactive and easier to manage.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Graphite提供了保存高度可定制的图形预设的功能。您还可以将许多图形分组到主题仪表板中。与Munin类似，图形呈现为静态图像，但还有JSON API允许其他前端读取图形数据并以其他方式呈现。与Graphite集成的一个很棒的仪表板插件是Grafana（[http://grafana.org](http://grafana.org)）。它真的值得一试，因为它比普通的Graphite仪表板具有更好的可用性。Grafana提供的图形是完全交互式的，更容易管理。
- en: 'Graphite is unfortunately a bit of a complex project. It is not a monolithic
    service and consists of three separate components:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Graphite是一个有点复杂的项目。它不是一个单一的服务，而是由三个独立的组件组成：
- en: '**Carbon**: This is a daemon written using Twisted that listens for time-series
    data'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Carbon**：这是一个使用Twisted编写的守护程序，用于监听时间序列数据'
- en: '**whisper**: This is a simple database library for storing time-series data'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**whisper**：这是一个简单的数据库库，用于存储时间序列数据'
- en: '**graphite webapp**: This is a Django web application that renders graphs on-demand
    as static images (using Cairo library) or as JSON data'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**graphite webapp**：这是一个Django Web应用程序，根据需要呈现静态图像（使用Cairo库）或JSON数据'
- en: When used with the StatsD project, the `statsd` daemon sends its data to `carbon`
    daemon. This makes the full solution a rather complex stack of various applications,
    where each of them is written using a completely different technology. Also, there
    are no preconfigured graphs, plugins, and dashboards available, so you will need
    to configure everything by yourself. This is a lot of work at the beginning and
    it is very easy to miss something important. This is the reason why it might be
    a good idea to use Munin as a monitoring backup even if you decide to have Graphite
    as your core monitoring service.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当与StatsD项目一起使用时，`statsd`守护程序将其数据发送到`carbon`守护程序。这使得整个解决方案成为一个相当复杂的各种应用程序堆栈，每个应用程序都是使用完全不同的技术编写的。此外，没有预配置的图形、插件和仪表板可用，因此您需要自己配置所有内容。这在开始时需要很多工作，很容易忽略一些重要的东西。这就是为什么即使决定将Graphite作为核心监控服务，使用Munin作为监控备份也可能是一个好主意。
- en: Dealing with application logs
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理应用程序日志
- en: While solutions such as Sentry are usually way more powerful than ordinary textual
    output stored in files, logs will never die. Writing some information to a standard
    output or file is one of the simplest things that an application can do and this
    should never be underestimated. There is a risk that messages sent to Sentry by
    raven will not get delivered. The network can fail. Sentry's storage can get exhausted
    or may not be able to handle incoming load. Your application might crash before
    any message is sent (with segmentation fault, for example). These are only a few
    of the possible scenarios. What is less likely is your application won't be able
    to log messages that are going to be written to the filesystem. It is still possible,
    but let's be honest. If you face such a condition where logging fails, probably
    you have a lot more burning issues than some missing log messages.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像Sentry这样的解决方案通常比存储在文件中的普通文本输出更强大，但日志永远不会消失。向标准输出或文件写入一些信息是应用程序可以做的最简单的事情之一，这绝对不应被低估。有可能raven发送到Sentry的消息不会被传递。网络可能会失败。Sentry的存储可能会耗尽，或者可能无法处理传入的负载。在任何消息被发送之前，您的应用程序可能会崩溃（例如，出现分段错误）。这只是可能的情况之一。不太可能的是您的应用程序无法记录将要写入文件系统的消息。这仍然是可能的，但让我们诚实一点。如果您面临日志记录失败的情况，可能您有更多紧迫的问题，而不仅仅是一些丢失的日志消息。
- en: Remember that logs are not only about errors. Many developers used to think
    about logs only as a source of data that is useful when debugging issues and/or
    which can be used to perform some kind of forensics. Definitely, less of them
    try to use it as a source for generating application metrics or to do some statistical
    analysis. But logs may be a lot more useful than that. They can be even the core
    of the product implementation. A great example of building a product with logs
    is the Amazon article presenting an example architecture for a real-time bidding
    service, where everything is centered around access log collection and processing.
    See [https://aws.amazon.com/blogs/aws/real-time-ad-impression-bids-using-dynamodb/](https://aws.amazon.com/blogs/aws/real-time-ad-impression-bids-using-dynamodb/).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，日志不仅仅是关于错误。许多开发人员过去认为日志只是在调试问题时有用的数据来源，或者可以用来进行某种取证。肯定有更少的人尝试将其用作生成应用程序指标的来源或进行一些统计分析。但是日志可能比这更有用。它们甚至可以成为产品实现的核心。一个很好的例子是亚马逊的一篇文章，介绍了一个实时竞价服务的示例架构，其中一切都围绕访问日志收集和处理。请参阅[https://aws.amazon.com/blogs/aws/real-time-ad-impression-bids-using-dynamodb/](https://aws.amazon.com/blogs/aws/real-time-ad-impression-bids-using-dynamodb/)。
- en: Basic low-level log practices
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本的低级日志实践
- en: The Twelve-Factor App says that logs should be treated as event streams. So
    a log file is not a log per se, but only an output format. The fact that they
    are streams means they represent time ordered events. In raw, they are typically
    in a text format with one line per event, although in some cases they may span
    multiple lines. This is typical for any backtraces related to run-time errors.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 十二要素应用程序表示日志应被视为事件流。因此，日志文件本身并不是日志，而只是一种输出格式。它们是流的事实意味着它们代表按时间顺序排列的事件。在原始状态下，它们通常以文本格式呈现，每个事件一行，尽管在某些情况下它们可能跨越多行。这对于与运行时错误相关的任何回溯都是典型的。
- en: According to the Twelve-Factor App methodology, the application should never
    be aware of the format in which logs are stored. This means that writing to the
    file, or log rotation and retention should never be maintained by the application
    code. These are the responsibilities of the environment in which applications
    are run. This may be confusing because a lot of frameworks provide functions and
    classes for managing log files as well as rotation, compression, and retention
    utilities. It is tempting to use them because everything can be contained in your
    application codebase, but actually it is an anti-pattern that should be really
    avoided.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 根据十二要素应用程序方法论，应用程序不应知道日志存储的格式。这意味着写入文件，或者日志轮换和保留不应由应用程序代码维护。这些是应用程序运行的环境的责任。这可能令人困惑，因为许多框架提供了用于管理日志文件以及轮换、压缩和保留实用程序的函数和类。诱人的是使用它们，因为一切都可以包含在应用程序代码库中，但实际上这是一个应该真正避免的反模式。
- en: 'The best conventions for dealing with logs can be closed in a few rules:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 处理日志的最佳约定可以归结为几条规则：
- en: The application should always write logs unbuffered to the standard output (`stdout`)
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序应始终将日志无缓冲地写入标准输出（`stdout`）
- en: The execution environment should be responsible for the collection and routing
    of logs to the final destination
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行环境应负责将日志收集和路由到最终目的地
- en: The main part of the mentioned execution environment is usually some kind of
    process supervision tool. The popular Python solutions, such as Supervisor or
    Circus, are the first ones responsible for dealing with log collection and routing.
    If logs are to be stored in the local filesystem, then only they should write
    to actual log files.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 所提到的执行环境的主要部分通常是某种进程监控工具。流行的Python解决方案，如Supervisor或Circus，是处理日志收集和路由的第一责任方。如果日志要存储在本地文件系统中，那么只有它们应该写入实际的日志文件。
- en: Both Supervisor and Circus are also capable of handling log rotation and retention
    for managed processes but you should really consider whether this is a path that
    you want to go. Successful operations are mostly about simplicity and consistency.
    Logs of your own application are probably not the only ones that you want to process
    and archive. If you use Apache or Nginx as a reverse proxy, you might want to
    collect their access logs. You might also want to store and process logs for caches
    and databases. If you are running some popular Linux distribution, then the chances
    are very high that each of these services have their own log files processed (rotated,
    compressed, and so on) by the popular utility named `logrotate`. My strong recommendation
    is to forget about Supervisor's and Circus' log rotation capabilities for the
    sake of consistency with other system services. `logrotate` is way more configurable
    and also supports compression.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Supervisor和Circus也能够处理受管进程的日志轮换和保留，但您确实应该考虑是否要走这条路。成功的操作大多是关于简单性和一致性。您自己应用程序的日志可能不是您想要处理和存档的唯一日志。如果您使用Apache或Nginx作为反向代理，您可能希望收集它们的访问日志。您可能还希望存储和处理缓存和数据库的日志。如果您正在运行一些流行的Linux发行版，那么每个这些服务都有它们自己的日志文件被名为`logrotate`的流行实用程序处理（轮换、压缩等）。我强烈建议您忘记Supervisor和Circus的日志轮换能力，以便与其他系统服务保持一致。`logrotate`更加可配置，还支持压缩。
- en: Tip
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**logrotate and Supervisor/Circus**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**logrotate和Supervisor/Circus**'
- en: There is an important thing to know when using `logrotate` with Supervisor or
    Circus. The rotation of logs will always happen while the process Supervisor still
    has an open descriptor to rotated logs. If you don't take proper countermeasures,
    then new events will be still written to file descriptor that was already deleted
    by `logrotate`. As a result, nothing more will be stored in a filesystem. Solutions
    to this problem are quite simple. Configure `logrotate` for log files of processes
    managed by Supervisor or Circus with the `copytruncate` option. Instead of moving
    the log file after rotation, it will copy it and truncate the original file to
    zero size in-place. This approach does not invalidate any of existing file descriptors
    and processes that are already running can write to log files uninterrupted. The
    Supervisor can also accept the `SIGUSR2` signal that will make it reopen all the
    file descriptors. It may be included as the `postrotate` script in the `logrotate`
    configuration. This second approach is more economical in the terms of I/O operations
    but is also less reliable and harder to maintain.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`logrotate`与Supervisor或Circus时，有一件重要的事情需要知道。日志的轮换将始终发生在Supervisor仍然具有对已轮换日志的打开描述符时。如果您不采取适当的对策，那么新事件仍将被写入已被`logrotate`删除的文件描述符。结果，文件系统中将不再存储任何内容。解决这个问题的方法非常简单。使用`copytruncate`选项为Supervisor或Circus管理的进程的日志文件配置`logrotate`。在旋转后，它将复制日志文件并在原地将原始文件截断为零大小。这种方法不会使任何现有的文件描述符无效，已经运行的进程可以不间断地写入日志文件。Supervisor还可以接受`SIGUSR2`信号，这将使其重新打开所有文件描述符。它可以作为`logrotate`配置中的`postrotate`脚本包含在内。这种第二种方法在I/O操作方面更经济，但也更不可靠，更难维护。
- en: Tools for log processing
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志处理工具
- en: If you have no experience of working with large amounts of logs, you will eventually
    gain it when working with a product that has some substantial load. You will shortly
    notice that a simple approach based on storing them in files and backing in some
    persistent storage for later retrieval is not enough. Without proper tools, this
    will become crude and expensive. Simple utilities such as `logrotate` help you
    only to ensure that the hard disk is not overflown by the ever-increasing amount
    of new events, but splitting and compressing log files only helps in the data
    archival process but does not make data retrieval or analysis simpler.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有处理大量日志的经验，那么当使用具有实质负载的产品时，您最终会获得这种经验。您很快会注意到，基于将它们存储在文件中并在某些持久存储中备份的简单方法是不够的。没有适当的工具，这将变得粗糙和昂贵。像`logrotate`这样的简单实用程序只能确保硬盘不会被不断增加的新事件所溢出，但是拆分和压缩日志文件只有在数据归档过程中才有帮助，但并不会使数据检索或分析变得更简单。
- en: When working with distributed systems that span multiple nodes, it is nice to
    have a single central point from which all logs can be retrieved and analyzed.
    This requires a log processing flow that goes way beyond simple compression and
    backing up. Fortunately this is a well-known problem so there are many tools available
    that aim to solve it.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理跨多个节点的分布式系统时，很好地拥有一个单一的中心点，从中可以检索和分析所有日志。这需要一个远远超出简单压缩和备份的日志处理流程。幸运的是，这是一个众所周知的问题，因此有许多可用的工具旨在解决它。
- en: One of the popular choices among many developers is **Logstash**. This is the
    log collection daemon that can observe active log files, parse log entries and
    send them to the backing service in a structured form. The choice of backing stays
    almost always the same—**Elasticsearch**. Elasticsearch is the search engine built
    on top of Lucene. Among text search capabilities, it has a unique data aggregation
    framework that fits extremely well into the purpose of log analysis.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发人员中的一个受欢迎的选择是**Logstash**。这是一个日志收集守护程序，可以观察活动日志文件，解析日志条目并以结构化形式将它们发送到后端服务。后端的选择几乎总是相同的——**Elasticsearch**。Elasticsearch是建立在Lucene之上的搜索引擎。除了文本搜索功能外，它还具有一个独特的数据聚合框架，非常适合用于日志分析的目的。
- en: The other addition to this pair of tools is **Kibana**. It is a very versatile
    monitoring, analysis, and visualization platform for Elasticsearch. The way how
    these three tools complement each other is the reason why they are almost always
    used together as a single stack for log processing.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这对工具的另一个补充是**Kibana**。它是一个非常多才多艺的监控、分析和可视化平台，适用于Elasticsearch。这三种工具如何相互补充的方式，是它们几乎总是作为单一堆栈一起用于日志处理的原因。
- en: The integration of existing services with Logstash is very simple because it
    can listen on existing log files changes for the new events with only minimal
    changes in your logging configuration. It parses logs in textual form and has
    preconfigured support for some of the popular log formats, such as Apache/Nginx
    access logs. The only problem with Logstash is that it does not handle log rotation
    well, and this is a bit surprising. Forcing a process to reopen its file descriptors
    by sending one of the defined Unix signals (usually `SIGHUP` or `SIGUSR1`) is
    a pretty well-established pattern. It seems that every application that deals
    with logs (exclusively) should know that and be able to process various log file
    rotation scenarios. Sadly, Logstash is not one of them, so if you want to manage
    log retention with the `logrotate` utility, remember to rely heavily on its `copytruncate`
    option. The Logstash process can't handle situations when the original log file
    was moved or deleted, so without the `copytruncate` option it wouldn't be able
    to receive new events after log rotation. Logstash can of course handle different
    inputs of log streams such as UDP packets, TCP connections, or HTTP requests.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现有服务与Logstash的集成非常简单，因为它可以监听现有日志文件的更改，以便通过最小的日志配置更改获取新事件。它以文本形式解析日志，并且预先配置了对一些流行日志格式（如Apache/Nginx访问日志）的支持。Logstash唯一的问题是它不能很好地处理日志轮换，这有点令人惊讶。通过发送已定义的Unix信号（通常是`SIGHUP`或`SIGUSR1`）来强制进程重新打开其文件描述符是一个非常成熟的模式。似乎每个处理日志的应用程序都应该知道这一点，并且能够处理各种日志文件轮换场景。遗憾的是，Logstash不是其中之一，因此如果您想使用`logrotate`实用程序管理日志保留，请记住要大量依赖其`copytruncate`选项。Logstash进程无法处理原始日志文件被移动或删除的情况，因此在没有`copytruncate`选项的情况下，它将无法在日志轮换后接收新事件。当然，Logstash可以处理不同的日志流输入，例如UDP数据包、TCP连接或HTTP请求。
- en: The other solution that seems to fill some of Logstash gaps is Fluentd. It is
    an alternative log collection daemon that can be used interchangeably with Logstash
    in the mentioned log monitoring stack. It also has an option to listen and parse
    log events directly in log files, so minimal integration requires only a little
    effort. In contrast to Logstash, it handles reloads very well and does not even
    need to be signaled if log files were rotated. Anyway, the biggest advantage comes
    from using one of its alternative log collection options that will require some
    substantial changes to logging configuration in your application.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个似乎填补了一些Logstash空白的解决方案是Fluentd。它是一种替代的日志收集守护程序，可以与Logstash在提到的日志监控堆栈中互换使用。它还有一个选项，可以直接监听和解析日志事件，所以最小的集成只需要一点点努力。与Logstash相比，它处理重新加载非常出色，甚至在日志文件轮换时也不需要信号。无论如何，最大的优势来自于使用其替代的日志收集选项，这将需要对应用程序中的日志配置进行一些重大更改。
- en: 'Fluentd really treats logs as event streams (as recommended by the Twelve-Factor
    App). The file-based integration is still possible but it is only kind of backward
    compatibility for legacy applications that treat logs mainly as files. Every log
    entry is an event and it should be structured. Fluentd can parse textual logs
    and has multiple plugin options to handle:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd真的将日志视为事件流（正如《十二要素应用程序》所推荐的）。基于文件的集成仍然是可能的，但它只是对将日志主要视为文件的传统应用程序的向后兼容性。每个日志条目都是一个事件，应该是结构化的。Fluentd可以解析文本日志，并具有多个插件选项来处理：
- en: Common formats (Apache, Nginx, and syslog)
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见格式（Apache、Nginx和syslog）
- en: Arbitrary formats specified using regular expressions or handled with custom
    parsing plugins
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则表达式指定的任意格式，或者使用自定义解析插件处理
- en: Generic formats for structured messages such as JSON
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化消息的通用格式，例如JSON
- en: The best event format for Fluentd is JSON because it adds the least amount of
    overhead. Messages in JSON can be also passed almost without any change to the
    backing service like Elasticsearch or the database.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd的最佳事件格式是JSON，因为它增加的开销最少。 JSON中的消息也可以几乎不经过任何更改地传递到Elasticsearch或数据库等后端服务。
- en: 'The other very useful feature of Fluentd is the ability to pass event streams
    using transports other than a log file written to the disk. Most notable built-in
    input plugins are:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd的另一个非常有用的功能是能够使用除了写入磁盘的日志文件之外的其他传输方式传递事件流。最值得注意的内置输入插件有：
- en: '`in_udp`: With this plugin every log event is sent as UDP packets'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_udp`：使用此插件，每个日志事件都作为UDP数据包发送'
- en: '`in_tcp`: With this plugin events are sent through TCP connection'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_tcp`：使用此插件，事件通过TCP连接发送'
- en: '`in_unix`: With this plugin events are sent through Unix Domain Socket (names
    socket)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_unix`：使用此插件，事件通过Unix域套接字（命名套接字）发送'
- en: '`in_http`: With this plugin events are sent as HTTP POST requests'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_http`：使用此插件，事件作为HTTP POST请求发送'
- en: '`in_exec`: With this plugin Fluentd process executes an external command periodically
    to pull events in the JSON or MessagePack format'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_exec`：使用此插件，Fluentd进程会定期执行外部命令，以JSON或MessagePack格式获取事件'
- en: '`in_tail`: With this plugin Fluentd process listens for an event in a textual
    file'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`in_tail`：使用此插件，Fluentd进程会监听文本文件中的事件'
- en: Alternative transports for log events may be especially useful in situations
    where you need to deal with poor I/O performance of machine storage. It is very
    often on cloud computing services that the default disk storage has a very low
    number of **IOPS** (**Input Output Operations Per Second**) and you need to pay
    a lot of money for better disk performance. If your application outputs large
    amount of log messages, you can easily saturate your I/O capabilities even if
    the data size is not very high. With alternate transports, you can use your hardware
    more efficiently because you leave the responsibility of data buffering only to
    a single process—log collector. When configured to buffer messages in memory instead
    of disk, you can even completely get rid of disk writes for logs, although this
    may greatly reduce the consistency guarantees of collected logs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 对于日志事件的替代传输可能在需要处理机器存储的I/O性能较差的情况下特别有用。在云计算服务中，通常默认磁盘存储的IOPS（每秒输入/输出操作次数）非常低，您需要花费大量资金以获得更好的磁盘性能。如果您的应用程序输出大量日志消息，即使数据量不是很大，也可能轻松饱和您的I/O能力。通过替代传输，您可以更有效地使用硬件，因为您只需将数据缓冲的责任留给单个进程——日志收集器。当配置为在内存中缓冲消息而不是磁盘时，甚至可以完全摆脱日志的磁盘写入，尽管这可能会大大降低收集日志的一致性保证。
- en: Using different transports seems to be slightly against the 11th rule of the
    Twelve-Factor App methodology. Treat logs as event streams when explained in detail
    suggests that the application should always log only through a single standard
    output stream (`stdout`). It is still possible to use alternate transports without
    breaking this rule. Writing to `stdout` does not necessarily mean that this stream
    must be written to file. You can leave your application logging that way and wrap
    it with an external process that will capture this stream and pass it directly
    to Logstash or Fluentd without engaging the filesystem. This is an advanced pattern
    that may not be suitable for every project. It has an obvious disadvantage of
    higher complexity, so you need to consider by yourself whether it is really worth
    doing.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的传输方式似乎略微违反了十二要素应用程序方法的第11条规则。详细解释时，将日志视为事件流表明应用程序应始终仅通过单个标准输出流（`stdout`）记录日志。仍然可以在不违反此规则的情况下使用替代传输方式。写入`stdout`并不一定意味着必须将此流写入文件。您可以保留应用程序以这种方式记录日志，并使用外部进程将其捕获并直接传递给Logstash或Fluentd，而无需涉及文件系统。这是一种高级模式，可能并不适用于每个项目。它具有更高复杂性的明显缺点，因此您需要自行考虑是否真的值得这样做。
- en: Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Code deployment is not a simple topic and you should already know that after
    reading this chapter. Extensive discussion of this problem could easily take a
    few books. Even though we limited our scope exclusively to web application, we
    have barely scratched the surface. This chapter takes as a basis the Twelve-Factor
    App methodology. We discussed in detail only a few of them: log treatment, managing
    dependencies, and separating build/run stages.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 代码部署并不是一个简单的话题，阅读本章后您应该已经知道这一点。对这个问题的广泛讨论很容易占据几本书。即使我们的范围仅限于Web应用程序，我们也只是触及了表面。本章以十二要素应用程序方法为基础。我们只详细讨论了其中的一些内容：日志处理、管理依赖关系和分离构建/运行阶段。
- en: After reading this chapter, you should know how to properly automate your deployment
    process, taking into consideration best practices, and be able to add proper instrumentation
    and monitoring for code that is run on your remote hosts.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本章后，您应该知道如何正确自动化部署过程，考虑最佳实践，并能够为在远程主机上运行的代码添加适当的仪器和监视。
