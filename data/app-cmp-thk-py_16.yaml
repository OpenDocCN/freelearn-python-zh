- en: '*Chapter 13*: Using Classification and Clusters'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第13章*：使用分类和聚类'
- en: In this chapter, we will use the classification and clustering capabilities
    of the Python programming language. We will use the computational thinking elements
    to define the necessary components for problems when working with clusters and
    classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Python编程语言的分类和聚类能力。我们将使用计算思维元素来定义处理聚类和分类问题时所需的组件。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Defining training and testing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义训练和测试
- en: Implementing data clustering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施数据聚类
- en: By the end of this chapter, you will be able to design algorithms that are the
    best fit for the scenarios presented. You will also be able to identify the Python
    functions that are the most aligned with the problems presented and generalize
    your solutions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章的学习，您将能够设计最适合所提出场景的算法。您还将能够识别与所提出问题最符合的Python函数，并概括您的解决方案。
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We will need the latest version of Python and **Scikit-Learn** to execute the
    code in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要最新版本的Python和**Scikit-Learn**来执行本章中的代码。
- en: 'You will find the code used in this chapter here: [https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter13](https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter13)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里找到本章中使用的代码：[https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter13](https://github.com/PacktPublishing/Applied-Computational-Thinking-with-Python/tree/master/Chapter13)
- en: 'You will find the **Pima Indians Diabetes Database** from **Kaggle** here:
    [https://www.kaggle.com/uciml/pima-indians-diabetes-database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里找到**Pima Indians Diabetes Database**：[https://www.kaggle.com/uciml/pima-indians-diabetes-database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)
- en: Data training and testing
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据训练和测试
- en: 'In this section, we''re going to learn how to create models for training and
    testing data using Python tools and libraries. When working with data and data
    science, we sometimes want to train the algorithm to continue gathering and learning
    from the data. Data training is then used for data mining and machine learning.
    First, let''s define the **training dataset**:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用Python工具和库为训练和测试数据创建模型。在处理数据和数据科学时，有时我们希望训练算法继续从数据中收集和学习。然后数据训练用于数据挖掘和机器学习。首先，让我们定义**训练数据集**：
- en: It is a sample of data used to fit the model.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是用来拟合模型的数据样本。
- en: It is an actual dataset that is used to train the model (weights and biases,
    in the case of a **neural network**). The training model *sees* and *learns* from
    this data.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个实际数据集，用于训练模型（在神经网络的情况下是权重和偏差）。训练模型从这些数据中“看到”和“学习”。
- en: In computing, a neural network is a system of computing that is created using
    biological neural networks in human and animal brains as inspiration. When using
    training datasets, such as when we are creating machine learning models, the models
    depend heavily on the data. *But what is machine learning?* **Machine learning**,
    or **ML**, is an application of **artificial intelligence** (**AI**) that allows
    a machine to learn automatically using a program without explicitly being programmed
    to do so.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机领域，神经网络是使用人类和动物大脑中的生物神经网络作为灵感创造的计算系统。当使用训练数据集时，例如在创建机器学习模型时，模型严重依赖数据。*但是什么是机器学习？*
    **机器学习**，或**ML**，是**人工智能**（**AI**）的一种应用，允许机器在没有明确编程的情况下自动学习使用程序。
- en: 'Without a top-quality foundation of data training, an algorithm is useless.
    Data training in ML refers to the initial data used to develop models. They find
    relationships and develop understanding and discover patterns and trends. Input
    data is fed into the ML algorithm and also to all the techniques associated to
    produce an output. That output is also fed back into the models as updated feedback,
    which in turn provides feedback data that is used as input again. The process
    is cyclical, continuously adapting and learning. The following diagram shows a
    simple ML graphic with the processes that happen:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 没有高质量的数据训练基础，算法就是无用的。ML中的数据训练是指用于开发模型的初始数据。它们发现关系，发展理解，发现模式和趋势。输入数据被馈送到ML算法和所有相关的技术中，以产生输出。该输出也被反馈到模型中作为更新的反馈，进而提供用作再次输入的反馈数据。这个过程是循环的，不断地适应和学习。下图显示了一个简单的ML图形，展示了发生的过程：
- en: '![Figure 13.1 – Machine Learning and its relationships with input and output'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.1 - 机器学习及其与输入和输出的关系'
- en: '](image/Figure_13.01_B15413.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.01_B15413.jpg)'
- en: Figure 13.1 – Machine Learning and its relationships with input and output
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 - 机器学习及其与输入和输出的关系
- en: In ML, data is combined with statistical tools to predict an output. The machines
    receive input data and use an algorithm to construct answers. This is similar
    to **data mining**, where large datasets are used to find anomalies, correlations,
    patterns, and so on to predict an outcome.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML中，数据与统计工具结合起来预测输出。机器接收输入数据并使用算法构建答案。这类似于**数据挖掘**，其中使用大型数据集来发现异常、相关性、模式等，以预测结果。
- en: In data mining, we extract information but using methods that pull the necessary,
    relevant, error-free data points. That is, with data mining, we extract what we
    need from the dataset without extracting those anomalies while also looking at
    correlations and patterns within our data. The difference between data mining
    and ML is that ML analyzes both input data and output data. So once the output
    is processed, it goes back to the algorithm, where it's fed back to the input
    data, and reprocessed. The cycle is ongoing, as you can see from the preceding
    diagram.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据挖掘中，我们提取信息，但使用方法提取必要的、相关的、无误的数据点。也就是说，通过数据挖掘，我们从数据集中提取我们需要的内容，而不提取那些异常值，同时还要查看数据中的相关性和模式。数据挖掘和ML之间的区别在于ML分析输入数据和输出数据。因此，一旦输出被处理，它就会回到算法中，被馈送回输入数据，并重新处理。这个循环是持续的，正如您可以从前面的图表中看到的那样。
- en: 'Important Note:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：
- en: There are four groups of ML algorithms, but in this book, we are only going
    to introduce two. While this is not an ML book, Python's applications in the ML
    arena continue to grow, so it is relevant to our goal of understanding the applications
    of the programming language and how we use computational thinking to solve problems.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 有四组ML算法，但在本书中，我们只会介绍其中两种。虽然这不是一本ML书，但Python在ML领域的应用仍在不断增长，因此了解编程语言的应用以及如何使用计算思维来解决问题与我们的目标相关。
- en: 'In ML, we use two types of important techniques:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML中，我们使用两种重要的技术：
- en: '**Supervised learning** maps data pairs, using input data and expected output
    (training data) so that the model can find underlying patterns.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**映射数据对，使用输入数据和期望输出（训练数据），以便模型可以找到潜在的模式。'
- en: '**Unsupervised learning** uses unlabeled training data to make conclusions.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**使用无标签的训练数据进行结论。'
- en: 'In addition, there are two other techniques we won''t go into in this book:
    semi-supervised learning and reinforcement learning.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有两种我们不会在本书中介绍的技术：半监督学习和强化学习。
- en: In supervised learning, the learning algorithm is presented with a set of inputs
    along with their desired outputs (also called labels). The goal is to discover
    a rule that enables the computer to re-create the outputs, or in other words,
    map the input and output. On the other hand, unsupervised learning allows us to
    approach problems with little or no idea what our results should look like. The
    output variables are unlabeled. With unsupervised learning, an algorithm is presented
    with a set of inputs but no desired outputs, which means the algorithm must find
    structures and patterns on its own.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，学习算法被提供一组输入以及它们的期望输出（也称为标签）。目标是发现一条规则，使计算机能够重新创建输出，或者换句话说，映射输入和输出。另一方面，无监督学习允许我们在几乎不知道我们的结果应该是什么的情况下解决问题。输出变量是无标签的。使用无监督学习，算法被提供一组输入，但没有期望的输出，这意味着算法必须自行找到结构和模式。
- en: 'The following diagram shows a roadmap to follow for supervised and unsupervised
    learning:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了监督学习和无监督学习的路线图：
- en: '![Figure 13.2 – Types of machine learning'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.2 - 机器学习类型'
- en: '](image/Figure_13.02_B15413.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.02_B15413.jpg)'
- en: Figure 13.2 – Types of machine learning
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 - 机器学习类型
- en: As you can see from the preceding figure, we have two types of **supervised
    learning**. When we are given the training data and desired outputs, we use **regression**
    or **classification**. With **regression**, we predict a continuous-valued output.
    With **classification**, we get a discrete-valued output (0 or 1). An example
    of regression would be predicting how much rainfall we'd get on a given day, while
    with classification, we'd be looking to know whether it would rain or not.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中可以看出，我们有两种**监督学习**。当我们获得训练数据和期望的输出时，我们使用**回归**或**分类**。使用**回归**，我们预测连续值输出。使用**分类**，我们得到离散值输出（0或1）。回归的一个例子是预测某一天会有多少降雨，而分类则是想知道是否会下雨。
- en: For **unsupervised learning**, the preceding figure contains the example of
    **clustering**. In **clustering**, we get the training data, but only a few desired
    outputs. An example of clustering is **grouping**, which would take items from
    large collections of data and group them.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**无监督学习**，前面的图包含了**聚类**的示例。在**聚类**中，我们获得训练数据，但只有少量期望的输出。聚类的一个例子是**分组**，它会从大量数据中获取项目并对其进行分组。
- en: We can apply these types of learning styles to **artificial neural networks**.
    The training of a neural network is usually conducted by determining the difference
    between the processed output of the network (often a prediction) and a target
    output. This is the error, so the network then adjusts its weighted associations
    according to a learning rule and using this error value to adapt. Neural networks
    are typically organized in layers. Layers are made up of several interconnected
    nodes that contain an activation function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些类型的学习风格应用于**人工神经网络**。神经网络的训练通常是通过确定网络的处理输出（通常是预测）与目标输出之间的差异来进行的。这就是错误，因此网络根据学习规则调整其加权关联，并使用此错误值进行调整。神经网络通常组织成层。层由包含激活函数的多个相互连接的节点组成。
- en: 'An activation function is used to make decisions about whether a neuron is
    activated or not. To do so, a weighted sum is calculated and further bias is added.
    We use activation functions to provide outputs of a neuron with non-linearity.
    The three most common activation functions are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数用于决定神经元是否被激活。为此，计算加权和，然后添加偏差。我们使用激活函数为神经元提供非线性的输出。最常见的三种激活函数如下：
- en: '**Sigmoid** can be formulated as ![](image/Formula_B15413_13_001.png), where
    the input of the real number is *x*. It returns a value between –1 and 1.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sigmoid**可以表示为![](image/Formula_B15413_13_001.png)，其中实数的输入为*x*。它返回一个在-1和1之间的值。'
- en: '**Tanh** is given by *tanh(x)*. It is a hyperbolic tangent function with real
    number input *x*; it returns a value between –1 and 1.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tanh**由*tanh(x)*给出。它是一个具有实数输入*x*的双曲正切函数；它返回一个在-1和1之间的值。'
- en: '**Rectified Linear Unit** (**ReLU**) is a piecewise linear function. Its output
    is the same as the input if the input is positive or 0 otherwise.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修正线性单元**（**ReLU**）是一个分段线性函数。如果输入是正数，则输出与输入相同，否则为0。'
- en: 'The following diagram shows the graphs associated with each of the aforementioned
    activation functions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了与上述每个激活函数相关的图表：
- en: '![Figure 13.3 – Activation functions'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.3 - 激活函数'
- en: '](image/Figure_13.03_B15413.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.03_B15413.jpg)'
- en: Figure 13.3 – Activation functions
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 - 激活函数
- en: 'Patterns are presented to the network via the **input layer**, which communicates
    to one or more **hidden layers**, where the actual processing is done via a system
    of weighted **connections**. The hidden layers then link to an **output layer**
    where the answer is output as shown in the following diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 模式通过**输入层**呈现给网络，该层与一个或多个**隐藏层**通信，实际处理是通过一组加权**连接**完成的。隐藏层然后链接到一个**输出层**，答案作为下图所示的输出输出：
- en: '![Figure 13.4 – Artificial Neural Network (ANN) model'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.4 – 人工神经网络（ANN）模型'
- en: '](image/Figure_13.04_B15413.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.04_B15413.jpg)'
- en: Figure 13.4 – Artificial Neural Network (ANN) model
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – 人工神经网络（ANN）模型
- en: As you can see, the summation operator (![](image/Formula_B15413_13_002.png))
    takes the input values and moves through the network and creates an output. They
    must be summed and return a single value when entering a new node. An activation
    function essentially *squashes* the input and transforms it into an output value
    that represents how much a node should contribute (that is, when a node should
    fire). A node is considered to be *fired up* when it is activated. It takes the
    output value and converts it so the next node can take it as input. This is called
    **firing up**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，求和运算符（![](image/Formula_B15413_13_002.png)）接受输入值并通过网络创建输出。它们必须被求和，并在进入新节点时返回单个值。激活函数本质上是*压缩*输入并将其转换为表示节点应该贡献多少的输出值（即节点何时应该触发）。当节点被激活时，节点被认为是*激活的*。它获取输出值并将其转换，以便下一个节点可以将其作为输入。这称为**激活**。
- en: Now let's take a look at how we classify data using pandas.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用pandas对数据进行分类。
- en: Classifying data example
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类数据示例
- en: 'Now let''s take a look at an example where we are classifying data. The following
    screenshot shows an example of using supervised learning. To produce the output
    that can be seen in the screenshot, we used an existing dataset from [www.kaggle.com](http://www.kaggle.com).
    The dataset is called **Pima Indians Diabetes Database**. It describes whether
    or not a Pima Indian patient was diagnosed with diabetes:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个分类数据的例子。以下屏幕截图显示了使用监督学习的示例。为了生成屏幕截图中可以看到的输出，我们使用了来自[www.kaggle.com](http://www.kaggle.com)的现有数据集。该数据集称为**皮马印第安人糖尿病数据库**。它描述了皮马印第安患者是否被诊断出患有糖尿病：
- en: '![Figure 13.5 – Sample of unsupervised learning'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.5 – 无监督学习示例'
- en: '](image/Figure_13.05_B15413.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.05_B15413.jpg)'
- en: Figure 13.5 – Sample of unsupervised learning
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5 – 无监督学习示例
- en: 'As you can see, the attributes from the table, also known as the *input variables*
    (*x*), are as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，表格中的属性，也称为*输入变量*（*x*），如下所示：
- en: Number of times pregnant
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 怀孕次数
- en: Plasma glucose concentration for 2 hours in an oral glucose tolerance test
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 口服葡萄糖耐量试验2小时后的血浆葡萄糖浓度
- en: Diastolic blood pressure (mm Hg)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 舒张压（mm Hg）
- en: Triceps skinfold thickness (mm)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三头肌皮褶厚度（mm）
- en: 2-hour serum insulin (mu U/ml)
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2小时血清胰岛素（mu U/ml）
- en: Body mass index ![](image/Formula_B15413_13_003.png)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 体重指数![](image/Formula_B15413_13_003.png)
- en: Diabetes pedigree function
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 糖尿病谱系功能
- en: Age (years)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄（年）
- en: For the *output variable* (*y*), we have the class variable (0 or 1). From the
    dataset, each row represents a patient and whether or not that person received
    a diagnosis of diabetes in the past 5 years. As you can see, there are eight input
    variables and one output variable (the last column) as shown in the preceding
    figure.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*输出变量*（*y*），我们有类变量（0或1）。从数据集中，每一行代表一个患者，以及该人在过去5年内是否被诊断出患有糖尿病。正如您所见，有八个输入变量和一个输出变量（如前图所示的最后一列）。
- en: 'We will be using the binary classification model (1 or 0), which maps the rows
    of input variables (*x*) to the output variable (*y*). This will summarize *y
    = f(x)*. The following code snippet uses this information to get our outputs.
    Please note we will be discussing the full file in snippets throughout this example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用二元分类模型（1或0），将输入变量（*x*）的行映射到输出变量（*y*）。这将总结为*y = f(x)*。以下代码片段使用此信息来获取我们的输出。请注意，我们将在整个示例中逐步讨论完整的文件：
- en: ch13_diabetesA.py
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ch13_diabetesA.py
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see from the preceding snippet, we are uploading the dataset called
    `diabetes.csv` (from Kaggle). If you need a reminder of how to save the file and
    locate the path needed, take a look at [*Chapter 12*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159),
    *Using Python in Experimental and Data Analysis Problems*, in the *Understanding
    data analysis with Python* section. There are many ways to upload datasets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您从前面的片段中所看到的，我们正在上传名为`diabetes.csv`的数据集（来自Kaggle）。如果您需要提醒如何保存文件并找到所需的路径，请参阅[*第12章*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159)，*在*使用Python进行实验和数据分析问题*中，*了解使用Python进行数据分析*部分。有许多上传数据集的方法。
- en: As we did in [*Chapter 12*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159),
    *Using Python in Experimental and Data Analysis Problems*, we are using the very
    popular **pandas** and importing it as `pd`. Pandas is used for data manipulation
    and analysis. It offers data structures and operations for manipulating numerical
    tables and time series. The `read_csv()` function from pandas deals with importing
    data from **Comma-Separated Values** (**CSV**) values.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在[*第12章*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159)中所做的那样，我们使用非常流行的**pandas**并将其导入为`pd`。Pandas用于数据操作和分析。它提供了用于操作数值表和时间序列的数据结构和操作。来自pandas的`read_csv()`函数处理从**逗号分隔值**（**CSV**）中导入数据的值。
- en: 'Important Note:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：
- en: We need to find the correct directory. When you're calling the `.csv` file make
    sure you're in the correct directory (where the `.csv` file is located) to avoid
    error codes. Use `os.chdir()` after using `import os`, then use `print('Current
    directory', os.getcwd())`. See [*Chapter 12*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159),
    *Using Python in Experimental and Data Analysis Problems*, for more information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要找到正确的目录。当您调用`.csv`文件时，请确保您在正确的目录中（即`.csv`文件所在的位置），以避免错误代码。在使用`import os`后使用`os.chdir()`，然后使用`print('Current
    directory', os.getcwd())`。有关更多信息，请参见[*第12章*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159)，*在实验和数据分析问题中使用Python*。
- en: 'Once you run the preceding snippet of code, you can look at your variable explorer
    to see the item shown in the following screenshot. Note that the **variable explorer**
    is a tool that allows you to browse and manage objects associated with and used
    in your code. This tool is part of the **Spyder** environment, which runs Python
    with additional functionalities and editing tools, such as the variable explorer.
    The variable explorer is found in Spyder at the top on the right-hand side of
    our environment. The following screenshot shows the view of our database in the
    variable explorer:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码片段后，您可以查看变量资源管理器，以查看以下截图中显示的项目。请注意，**变量资源管理器**是一个工具，允许您浏览和管理与您的代码相关的对象。该工具是**Spyder**环境的一部分，它运行Python并具有附加功能和编辑工具，如变量资源管理器。变量资源管理器位于我们环境的右上方。以下截图显示了变量资源管理器中我们数据库的视图：
- en: '![Figure 13.6 – Variable explorer sample'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.6 - 变量资源管理器示例'
- en: '](image/Figure_13.06_B15413.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.06_B15413.jpg)'
- en: Figure 13.6 – Variable explorer sample
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6 - 变量资源管理器示例
- en: As you can see, **Size** describes the dataset. It shows the number of patients,
    **786**, and the total number of variables, **9**. Now we have a better understanding
    of our dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，**Size**描述了数据集。它显示了患者数量**786**和变量总数**9**。现在我们对数据集有了更好的理解。
- en: 'But let''s say you don''t know what type of learning you will be needing. You
    can type this function in the console to get a full picture of the data and outputs:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但是假设你不知道你将需要什么类型的学习。您可以在控制台中键入此函数，以获得数据和输出的完整图片：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following screenshot shows the information we receive after using the preceding
    line of code in our algorithm:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们在算法中使用上述代码行后收到的信息：
- en: '![Figure 13.7 – Display of information after running a description algorithm'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.7 - 运行描述算法后的信息显示'
- en: '](image/Figure_13.07_B15413.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.07_B15413.jpg)'
- en: Figure 13.7 – Display of information after running a description algorithm
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.7 - 运行描述算法后的信息显示
- en: 'As you can see from the preceding figure, we are able to get all the numerical
    features and know that there is no categorical data. We want that information,
    so the following line of code can be used to see the correlation between the variables:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从上图可以看出，我们能够获得所有数值特征，并知道没有分类数据。我们希望获得这些信息，因此可以使用以下代码行来查看变量之间的相关性：
- en: '[PRE2]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This simple line of code helps us get the information shown in the following
    screenshot. Please note that the following screenshot may look different depending
    on the environment you are using. When running this code, using environments like
    **Spyder** or **Jupyter**, depending on your theme settings and choices, the table
    may look different, with different color schemes (or no color schemes):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行简单的代码帮助我们获得以下截图中显示的信息。请注意，以下截图可能会因您使用的环境而有所不同。在运行此代码时，使用**Spyder**或**Jupyter**等环境时，根据您的主题设置和选择，表格可能会有所不同，具有不同的颜色方案（或没有颜色方案）：
- en: '![Figure 13.8 – Dataset correlation graphic'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.8 - 数据集相关图'
- en: '](image/Figure_13.08_B15413.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.08_B15413.jpg)'
- en: Figure 13.8 – Dataset correlation graphic
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8 - 数据集相关图
- en: We can see the correlation between all the variables with the outcome (output
    (*y*)). The preceding screenshot shows us that plasma glucose has the strongest
    correlation with the outcome, and insulin has the lowest.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到所有变量与结果（输出（*y*））之间的相关性。前面的截图显示了血浆葡萄糖与结果的最强相关性，胰岛素的相关性最低。
- en: 'Now that we have a better understanding of the dataset, let''s separate the
    input variables and output variables to put in the model. Let''s take a look at
    the following code snippet from our `ch13_diabetesA.py` file, which exemplifies
    this for us:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对数据集有了更好的理解，让我们将输入变量和输出变量分开放入模型。让我们看一下我们的`ch13_diabetesA.py`文件中的以下代码片段，这为我们提供了示例：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We use the `print` function to check our values:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`print`函数来检查我们的值：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once you have run the preceding snippet of code, the output data will look
    as shown in the following screenshot. Note that the result shows what we''ve defined
    as the variables `x_variables` and `y_variable`, which are in turn defined as
    parts of the dataset, as noted in the preceding code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码片段后，输出数据将如下截图所示。请注意，结果显示了我们定义为变量`x_variables`和`y_variable`，这些变量又被定义为数据集的一部分，如前面的代码中所述：
- en: '![Figure 13.9 – Training the dataset output for algorithm printing input and
    output values'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.9 - 用于算法打印输入和输出值的训练数据集输出'
- en: '](image/Figure_13.09_B15413.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.09_B15413.jpg)'
- en: Figure 13.9 – Training the dataset output for algorithm printing input and output
    values
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 - 用于算法打印输入和输出值的训练数据集输出
- en: Now we have to split the data into a training dataset and a test dataset. The
    purpose of the split technique is to evaluate the performance of an ML algorithm.
    It is only meant for any type of supervised learning algorithm. The first set
    (the training dataset) is used for the purpose of fitting the model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将数据分割成训练数据集和测试数据集。分割技术的目的是评估ML算法的性能。它仅适用于任何类型的监督学习算法。第一组（训练数据集）用于拟合模型。
- en: The main goal is to fit it on available data with known inputs and outputs,
    then make predictions on new examples in the future where we do not have the expected
    output or target values.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 主要目标是将其拟合到具有已知输入和输出的可用数据上，然后对将来的新示例进行预测，在那里我们没有预期的输出或目标值。
- en: Using the Scikit-Learn library
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Scikit-Learn库
- en: 'Another important library when working with data and ML is the `scikit-learn`
    (`sklearn`) library. This library is particularly useful for classification, regression,
    clustering, model selection, dimensionality reduction, and more. You may recall
    from [*Chapter 12*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159), *Using Python
    in Experimental and Data Analysis Problems*, under the *Using data libraries in
    Python section*, that you can use `pip install` from your **Command Prompt** window
    to install the required libraries. Once you have the library, you can import it
    into the code, as shown in the following snippet, which uses `sklearn` to split
    the data. As a note, this snippet is part of the larger `ch13_diabetesA.py` file:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据和机器学习时，另一个重要的库是`scikit-learn`（`sklearn`）库。该库特别适用于分类、回归、聚类、模型选择、降维等。您可能还记得[*第12章*](B15413_12_Final_SK_ePub.xhtml#_idTextAnchor159)，*在实验和数据分析问题中使用Python*，在*在Python中使用数据库*部分中，您可以使用**命令提示符**窗口中的`pip
    install`来安装所需的库。一旦您有了库，就可以将其导入到代码中，如下面的代码片段所示，该代码片段使用`sklearn`来拆分数据。需要注意的是，此代码片段是较大的`ch13_diabetesA.py`文件的一部分：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here are the known parameters:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是已知的参数：
- en: '`x_variable` and `y_variable` as previously defined.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_variable`和`y_variable`如前所定义。'
- en: '`test_size`: The test size will be 20% of the dataset.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_size`：测试大小将占数据集的20%。'
- en: '`random_state`: It sets a seed to the random generator so your train and test
    splits are always deterministic. If it is set to none, then a randomly initialized
    `RandomState` object is returned.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_state`：它设置了随机生成器的种子，因此您的训练和测试拆分始终是确定性的。如果设置为none，则返回一个随机初始化的`RandomState`对象。'
- en: 'The following diagram shows the process and how each element interacts with
    others in the cycle:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了该过程以及每个元素如何在循环中相互作用：
- en: '![Figure 13.10 – Data cycle in ML'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.10 - 机器学习中的数据循环'
- en: '](image/Figure_13.10_B15413.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.10_B15413.jpg)'
- en: Figure 13.10 – Data cycle in ML
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10 - 机器学习中的数据循环
- en: Note that we'll use a sequential model in the algorithm. In addition, we are
    using the `keras` library, which is used with Python so we can run deep learning
    models with our algorithms. Make sure you have the `keras` library available to
    use for this algorithm. If you have TensorFlow installed, you should already have
    access to the Keras library.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将在算法中使用顺序模型。此外，我们使用`keras`库，它与Python一起使用，因此我们可以运行我们的算法与深度学习模型。确保您有`keras`库可用于此算法。如果您已安装了TensorFlow，则应该已经可以访问Keras库。
- en: When working with machine learning problems and algorithms, you'll have a choice
    of libraries. We chose Keras for this particular problem. Keras is open source,
    and is useful in creating artificial neural networks. TensorFlow is a platform
    that contains many machine learning components and tasks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理机器学习问题和算法时，您可以选择使用不同的库。我们选择了Keras来解决这个特定的问题。Keras是开源的，用于创建人工神经网络。TensorFlow是一个包含许多机器学习组件和任务的平台。
- en: Keras works on top of TensorFlow and makes it easier to interact with it in
    the Python programming language. Keras is a higher-level API, which we'll discuss
    further. Because of its capacity, it can sometimes be slower than usual. **PyTorch**
    is another library used for artificial neural networks. It's a lower-level API,
    and therefore runs faster. Keras is supported by **Google**, while PyTorch is
    supported by **Facebook**. Both are helpful, so deciding on which to use is typically
    a developer's preference. Personally, I prefer the Keras library.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Keras建立在TensorFlow之上，并使其更容易与Python编程语言交互。Keras是一个更高级的API，我们将进一步讨论。由于其容量，它有时可能比平常慢。**PyTorch**是另一个用于人工神经网络的库。它是一个较低级别的API，因此运行速度更快。Keras由**Google**支持，而PyTorch由**Facebook**支持。两者都很有帮助，因此决定使用哪一个通常是开发人员的偏好。就我个人而言，我更喜欢Keras库。
- en: The sequential API allows you to create models layer by layer in a step-by-step
    fashion. There are two other available models, the **functional API** and **model
    sub-classing**. We'll use the sequential API because it's the easiest architecture,
    while the functional API is used for deep learning (complex models) and model
    sub-classing.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序API允许您逐步创建模型层。还有另外两个可用的模型，**功能API**和**模型子类化**。我们将使用顺序API，因为它是最简单的架构，而功能API用于深度学习（复杂模型）和模型子类化。
- en: 'There are a few things we should note about using Keras:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有几件事情我们应该注意使用Keras：
- en: The model class is the root class and is used to define the architecture for
    the model.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型类是根类，用于定义模型的架构。
- en: Like Python itself, Keras uses object-oriented programming, which means we can
    add subclasses.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像Python本身一样，Keras使用面向对象的编程，这意味着我们可以添加子类。
- en: The subclasses in the model are customizable.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型中的子类是可定制的。
- en: 'All that said, it should also be noted that sub-classing is more challenging
    than if we were to use the sequential or functional API. Now let''s take a look
    at an updated algorithm using our Keras library. Remember to include the directory
    of your file or save the `.csv` file to the necessary directory to run the algorithm
    correctly:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，还应该注意到，与使用顺序或功能API相比，子类化更具挑战性。现在让我们看一下使用我们的Keras库更新的算法。记得包括你的文件目录或将`.csv`文件保存到必要的目录以正确运行算法：
- en: ch13_diabetesB.py
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ch13_diabetesB.py
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From the preceding snippet, we can see that we added four layers that are densely
    connected.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码片段中，我们可以看到我们添加了四个密集连接的层。
- en: 'The first layer is built as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 第一层建立如下：
- en: 12 neurons
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 12个神经元
- en: '`input_dim = 8` (that is, input values that are coming into the network)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_dim = 8`（即，输入进入网络的输入值）'
- en: '`activation ''relu''`'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`激活''relu''`'
- en: 'As you can see, we have added multiple models and defined them. To compile
    the model, we use the following snippet of code, contained in the same code file.
    We can also set `model.fit` to use our libraries and the following code, which
    is part of our `ch13_diabetesB.py` file:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们已经添加了多个模型并对其进行了定义。为了编译模型，我们使用了同一代码文件中包含的以下代码片段。我们还可以设置`model.fit`来使用我们的库和以下代码，这是我们的`ch13_diabetesB.py`文件的一部分：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code compiles the Adam optimizer. The Adam optimizer is used
    for stochastic gradient descent and updates network weights iteratively using
    the training data. Once we run our code, our output provides the information shown
    as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码编译了Adam优化器。Adam优化器用于随机梯度下降，并使用训练数据迭代更新网络权重。一旦我们运行我们的代码，输出会提供以下信息：
- en: '![Figure 13.11 – Output of model run using the Keras library'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.11 - 使用Keras库运行模型的输出'
- en: '](image/Figure_13.11_B15413.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.11_B15413.jpg)'
- en: Figure 13.11 – Output of model run using the Keras library
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11 - 使用Keras库运行模型的输出
- en: 'Note that the accuracy may be different as you run the algorithm. Test the
    algorithm a few times to see changes in your window. After we''ve run our accuracy
    model, we print the model summary using `model.summary()`, shown as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当您运行算法时，准确性可能会有所不同。多次测试算法以查看窗口中的变化。在运行准确性模型后，我们打印模型摘要，使用`model.summary()`，如下所示：
- en: '![Figure 13.12 – Model summary of the algorithm'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.12 - 算法的模型摘要'
- en: '](image/Figure_13.12_B15413.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.12_B15413.jpg)'
- en: Figure 13.12 – Model summary of the algorithm
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12 - 算法的模型摘要
- en: Now that we've seen how to run our algorithms using the diabetes data file,
    let's look briefly at some optimization models that will help us evaluate the
    algorithm. We will not be going into these algorithms, but we do want to mention
    a few of the various tools available to us. When we are working with modeling,
    we use optimization models, such as **binary cross-entropy**, the **Adam optimization
    algorithm**, and **gradient descent**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到如何使用糖尿病数据文件运行我们的算法，让我们简要地看一下一些优化模型，这将帮助我们评估算法。我们不会深入研究这些算法，但我们想提到一些可用于我们的各种工具。在建模时，我们使用优化模型，如**二元交叉熵**、**Adam优化算法**和**梯度下降**。
- en: Defining optimization models
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义优化模型
- en: Let's take a look at the types of models. Note that we are not diving deep into
    the use of these models, but further exploration into their application to our
    algorithm is recommended.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型的类型。请注意，我们并没有深入研究这些模型的使用，但建议进一步探索它们在我们算法中的应用。
- en: The binary cross-entropy model
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二元交叉熵模型
- en: In binary classification, we use cross-entropy as the default **loss function**.
    The loss function is a method that helps us evaluate how our algorithm models
    the data. With the loss function, we can use optimization in order to produce
    more accurate results, that is, it helps reduce the **prediction error**. We use
    the loss function when target values are in the binary set.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元分类中，我们使用交叉熵作为默认的**损失函数**。损失函数是一种帮助我们评估算法如何对数据建模的方法。有了损失函数，我们可以使用优化来产生更准确的结果，即它有助于减少**预测误差**。当目标值在二进制集中时，我们使用损失函数。
- en: Cross-entropy is a loss function that calculates the difference between two
    probability distributions. We can use cross-entropy when optimizing classification
    models using **logistic regression** and **artificial neural networks**.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵是一种损失函数，用于计算两个概率分布之间的差异。在使用**逻辑回归**和**人工神经网络**优化分类模型时，我们可以使用交叉熵。
- en: The Adam optimization algorithm
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Adam优化算法
- en: The Adam algorithm is a method for **stochastic optimization**. Stochastic optimization
    is used when there is randomness in a function, to maximize or minimize the value
    of the function. The Adam optimization algorithm is appropriate for some simple
    optimization problems that are *non-convex*. It is efficient and uses little memory
    but can be applied to large datasets.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Adam算法是一种**随机优化**方法。当函数中存在随机性以最大化或最小化函数的值时，使用随机优化。Adam优化算法适用于一些*非凸*的简单优化问题。它高效且占用内存少，但可以应用于大型数据集。
- en: The gradient descent model
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降模型
- en: The gradient descent algorithm is a first-order optimization algorithm. First-order
    refers to linear local errors. We use gradient descent on functions that can be
    differentiated to find a local minimum.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降算法是一种一阶优化算法。一阶指的是线性局部误差。我们在可微分的函数上使用梯度下降来找到局部最小值。
- en: The confusion matrix model
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆矩阵模型
- en: The confusion matrix is also known as the **error matrix**. The confusion matrix
    is visually helpful, as it presents the performance of the algorithm in a table
    format, which allows better visualization of that performance. It is typically
    used in supervised learning.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵也被称为**错误矩阵**。混淆矩阵在视觉上很有帮助，因为它以表格形式呈现算法的性能，这样可以更好地可视化性能。它通常用于监督学习。
- en: As stated, this is just some base information as you start working on the optimization
    of your algorithms. Additional information on ML can be found in other Packt books,
    such as *Python Machine Learning* and *Exploratory Data Analysis with Python*.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所述，这只是一些基本信息，当您开始优化算法时。关于ML的更多信息可以在其他Packt图书中找到，例如*Python机器学习*和*Python探索性数据分析*。
- en: 'Before we move on to an introduction to clusters, let''s do a quick recap of
    what we learned in this section on using the Keras package and model:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入对聚类的介绍之前，让我们快速回顾一下在本节中使用Keras包和模型学到的内容：
- en: Loading data
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据
- en: Defining a neural network in Keras
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Keras中定义神经网络
- en: Compiling a Keras model using the efficient numerical backend
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高效的数值后端编译Keras模型
- en: Training a model on data
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据上训练模型
- en: Evaluating a model on data
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据上评估模型
- en: Making predictions with the model
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型进行预测
- en: Now let's move on to data clusters.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向数据聚类。
- en: Implementing data clustering
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施数据聚类
- en: In this section, we're going to take a look at how to approach data clustering.
    First, let's define what we mean by **data clustering**. Data clustering refers
    to how we partition data into groups or clusters. Clusters can be meaningful if
    they provide an expanded understanding of domain knowledge. We use clustering
    for many applications, such as medicine, where clustering can help identify how
    a group of patients responds to treatment, or market research, where clustering
    is used to group consumers in order to appeal to that group based on that particular
    group's characteristics.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看一下如何处理数据聚类。首先，让我们定义一下我们所说的**数据聚类**。数据聚类是指我们如何将数据分成组或簇。如果簇能够提供对领域知识的扩展理解，那么簇就是有意义的。我们在许多应用中使用聚类，比如医学领域，聚类可以帮助识别一组患者对治疗的反应，或者市场研究，聚类用于根据特定群体的特征来对消费者进行分组以吸引该群体。
- en: 'For the purpose of this discussion, we are going to look at synthetic clusters
    rather than applied clusters. In [*Chapter 16*](B15413_16_Final_SK_ePub.xhtml#_idTextAnchor219),
    *Advanced Applied Computational Thinking Problems*, you''ll see some examples
    of clusters in context. A **synthetic cluster** is made from a synthetic dataset.
    That is, we generate the dataset using an algorithm. Let''s take a look at the
    following code snippet:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讨论中，我们将看一下合成簇而不是应用簇。在[*第16章*](B15413_16_Final_SK_ePub.xhtml#_idTextAnchor219)，*高级应用计算思维问题*中，你将看到一些上下文中的簇的例子。**合成簇**是由合成数据集生成的。也就是说，我们使用算法生成数据集。让我们看一下下面的代码片段：
- en: ch13_syntheticDataset.py
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ch13_syntheticDataset.py
- en: '[PRE8]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Notice from the preceding snippet that we establish the number of samples,
    the number of features, and the number of clusters, among other things. In addition,
    we then create a scatterplot of the synthetic data and plot the result. The following
    graph shows the results of our synthetic dataset plotted as a scatterplot:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码片段中可以看到，我们确定了样本数量、特征数量和簇的数量等等。此外，我们还创建了合成数据的散点图并绘制了结果。下面的图展示了我们的合成数据集作为散点图的结果：
- en: '![Figure 13.13 – Synthetic dataset scatterplot'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.13 – 合成数据集散点图'
- en: '](image/Figure_13.13_B15413.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.13_B15413.jpg)'
- en: Figure 13.13 – Synthetic dataset scatterplot
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13 – 合成数据集散点图
- en: 'Note that the number of samples for this synthetic dataset was `1800`. Try
    to change the number of samples to see the changes in the scatterplot. Now that
    we have a dataset, we can start applying clustering algorithms. Here are some
    of the more common clustering algorithms:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个合成数据集的样本数量为`1800`。尝试改变样本数量来看看散点图的变化。现在我们有了数据集，我们可以开始应用聚类算法。以下是一些常见的聚类算法：
- en: '**The BIRCH algorithm**'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BIRCH算法**'
- en: '**The K-means clustering algorithm**'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K均值聚类算法**'
- en: We will look at the aforementioned algorithms in the following sections.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中看到上述的算法。
- en: Using the BIRCH algorithm
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用BIRCH算法
- en: '**Balanced Iterative Reducing and Clustering using Hierarchies** (**BIRCH**)
    is a clustering algorithm that uses the cluster centroids as long as there is
    enough available memory and time. For the BIRCH and K-means clustering algorithms,
    we will share an algorithm and the corresponding plot in order to better understand
    them.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**平衡迭代减少和层次聚类**（**BIRCH**）是一种聚类算法，只要有足够的可用内存和时间，就可以使用聚类中心。对于BIRCH和K均值聚类算法，我们将分享一个算法和相应的图表，以便更好地理解它们。'
- en: 'The following snippet shows us the BIRCH algorithm:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了BIRCH算法：
- en: ch13_BIRCH.py
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ch13_BIRCH.py
- en: '[PRE9]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that we arbitrarily chose two clusters in this sample, as you can see in
    the line `model = Birch(threshold = 0.01, n_clusters = 2)`. We are sticking with
    our sample of 1800 so that we can compare our output figures. The following screenshot
    shows two sample BIRCH models. The first (*on the left*) shows the algorithm run
    as provided in the preceding snippet. The second (*on the right*) shows the same
    algorithm run but for three clusters.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个示例中我们任意选择了两个簇，就像你在代码行`model = Birch(threshold = 0.01, n_clusters = 2)`中看到的一样。我们坚持使用我们的1800个样本，这样我们可以比较我们的输出图。下面的截图展示了两个样本的BIRCH模型。第一个（*左侧*）展示了前面代码片段中提供的算法运行的情况。第二个（*右侧*）展示了相同的算法运行，但是为了三个簇。
- en: 'To run the second graph, we changed the model line code to the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行第二个图，我们将模型行代码更改为以下内容：
- en: '[PRE10]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Take a look at the following figure with both plots shown, `n_clusters = 2`
    and `n_clusters = 3`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面的图，显示了`n_clusters = 2`和`n_clusters = 3`的情况：
- en: '![Figure 13.14 – BIRCH models using 2 and 3 clusters, respectively'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.14 – 分别使用2和3个簇的BIRCH模型'
- en: '](image/Figure_13.14_B15413.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.14_B15413.jpg)'
- en: Figure 13.14 – BIRCH models using 2 and 3 clusters, respectively
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.14 – 分别使用2和3个簇的BIRCH模型
- en: Notice that on the *left* of the preceding screenshot, two clusters are clearly
    shown. When compared to *Figure 13.13*, you can see some data points have been
    converted to fit each of the clusters identified. The scatterplot on the *right*
    of the preceding screenshot divides the data into three distinct clusters. To
    get more familiar with the clustering algorithms, change the parameters to see
    what happens when you change the number of clusters, the sample size, and other
    parameters.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面截图的*左侧*，清楚地显示了两个簇。与*图13.13*相比，你可以看到一些数据点已经被转换以适应每个被识别的簇。前面截图的*右侧*的散点图将数据分成了三个不同的簇。为了更加熟悉聚类算法，改变参数来看看当你改变簇的数量、样本大小和其他参数时会发生什么。
- en: Now let's take a look at the K-means clustering algorithm.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下K均值聚类算法。
- en: Using the K-means clustering algorithm
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用K均值聚类算法
- en: 'The K-means clustering algorithm is one of the most widely used clustering
    algorithms. The algorithm assigns examples so that the variance is minimized in
    each of the identified clusters. Much like with the BIRCH algorithm, we set the
    number of clusters within the algorithm. Let''s take a look at the K-means code
    snippet:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: K均值聚类算法是最常用的聚类算法之一。该算法将示例分配到每个识别的聚类中以最小化方差。与BIRCH算法类似，我们在算法中设置了聚类的数量。让我们看一下K均值代码片段：
- en: ch13_KMeans.py
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ch13_KMeans.py
- en: '[PRE11]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Again, notice that we''re using the same number of clusters (`2`) and the number
    of samples (`1800`) so that we can compare our displays. The following screenshot
    shows the K-means scatterplot output resulting from the preceding algorithm:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，我们使用相同数量的聚类（`2`）和样本数量（`1800`），以便进行比较。以下屏幕截图显示了前述算法产生的K均值散点图输出：
- en: '![Figure 13.15 – K-means algorithm output'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.15 – K均值算法输出'
- en: '](image/Figure_13.15_B15413.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Figure_13.15_B15413.jpg)'
- en: Figure 13.15 – K-means algorithm output
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.15 – K均值算法输出
- en: Notice that the data is still exactly the same, however, when we compare the
    displays we got from the BIRCH algorithm and the K-means algorithm, you can see
    that our algorithms produced very different results for our clusters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，数据仍然完全相同，然而，当我们比较从BIRCH算法和K均值算法得到的显示时，您会发现我们的算法为我们的聚类产生了非常不同的结果。
- en: There are many other clustering algorithms we can use and test. Learning about
    them and comparing the results is imperative in determining which ones to use
    based on real datasets. The results from the K-means algorithm, in this case,
    do not really fit the model well. The BIRCH model seems more suited when using
    two clusters because the variance in the K-means algorithm is unequal.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用和测试许多其他的聚类算法。了解它们并比较结果对于确定基于真实数据集使用哪些算法是至关重要的。在这种情况下，K均值算法的结果并不真正适合模型。当使用两个聚类时，BIRCH模型似乎更合适，因为K均值算法中的方差是不均等的。
- en: As we move on from the clustering examples, please note that, as for much of
    data science and ML, the more we use the models and algorithms, the more we understand
    their uses and when the models are appropriate, and we can learn to visually identify
    whether an algorithm fits our data or not.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们从聚类示例中继续前进，请注意，对于大部分数据科学和机器学习而言，我们使用模型和算法的越多，我们就越了解它们的用途，以及何时使用这些模型是合适的，我们可以学会通过视觉识别算法是否适合我们的数据。
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to use some of the packages available for the
    Python programming language to create models of large sets of data. We used packages,
    such as Keras, to upload data and define neural networks. We trained the model
    and evaluated the model. We used the model to make predictions. We also learned
    about the classification and testing of data and how to work with data clusters.
    After reading this chapter, you can now define data training and how Python is
    used in data training. You can also define and use a clustering algorithm.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用Python编程语言中可用的一些包来创建大型数据集的模型。我们使用了Keras等包来上传数据和定义神经网络。我们训练了模型并评估了模型。我们使用模型进行预测。我们还学习了数据的分类和测试以及如何处理数据聚类。阅读完本章后，您现在可以定义数据训练以及Python在数据训练中的用途。您还可以定义和使用聚类算法。
- en: We will continue to explore some of the topics discussed here in the next chapter.
    We will also see some of these applications in the examples provided in [*Chapter
    16*](B15413_16_Final_SK_ePub.xhtml#_idTextAnchor219), *Advanced* *Applied Computational
    Thinking Problems*.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章继续探讨这里讨论的一些主题。我们还将在[*第16章*](B15413_16_Final_SK_ePub.xhtml#_idTextAnchor219)中提供的示例中看到一些这些应用，*高级*
    *应用计算思维问题*。
