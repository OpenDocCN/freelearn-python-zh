- en: '6'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '6'
- en: Recursions and Reductions
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 递归和归约
- en: Many functional programming language compilers will optimize a recursive function
    to transform a recursive call in the tail of the function to an iteration. This
    tail-call optimization will dramatically improve performance. Python doesn’t do
    this automatic tail-call optimization. One consequence is pure recursion suffers
    from limitations. Lacking an automated optimization, we need to do the tail-call
    optimization manually. This means rewriting recursion to use an explicit iteration.
    There are two common ways to do this, and we’ll consider them both in this chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 许多函数式编程语言编译器会将递归函数优化，将函数尾部的递归调用转换为迭代。这种尾调用优化将显著提高性能。Python 不进行这种自动尾调用优化。一个后果是纯递归受到限制。缺乏自动优化，我们需要手动进行尾调用优化。这意味着重写递归以使用显式迭代。有两种常见的方法来做这件事，我们将在本章中考虑它们。
- en: 'In previous chapters, we’ve looked at several related kinds of processing design
    patterns; some of them are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们探讨了多种相关的处理设计模式；其中一些如下：
- en: Mapping and filtering, which create collections from collections
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射和过滤，它们从集合创建集合
- en: Reductions that create a scalar value from a collection
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从集合创建标量值的归约
- en: The distinction is exemplified by functions such as `map()` and `filter()` that
    accomplish the first kind of collection processing. There are some more specialized
    reduction functions, which include `min()`, `max()`, `len()`, and `sum()`. There’s
    a general-purpose reduction function as well, `functools.reduce()`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别可以通过像 `map()` 和 `filter()` 这样的函数来体现，这些函数完成了第一种集合处理。还有一些更专业的归约函数，包括 `min()`、`max()`、`len()`
    和 `sum()`。还有一个通用归约函数，`functools.reduce()`。
- en: We’ll also consider creating a `collections.Counter()` object as a kind of reduction
    operator. It doesn’t produce a single scalar value per se, but it does create
    a new organization of the data that eliminates some of the original structure.
    At heart, it’s a kind of count-group-by operation that has more in common with
    a counting reduction than with a mapping.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将考虑创建一个 `collections.Counter()` 对象作为归约操作符的一种。它本身并不产生单个标量值，但它确实创建了一种新的数据组织方式，消除了原始结构的一些部分。本质上，它是一种计数分组操作，与计数归约比与映射有更多的共同点。
- en: In this chapter, we’ll look at reduction functions in more detail. From a purely
    functional perspective, a reduction can be defined recursively. The tail-call
    optimization techniques available in Python apply elegantly to reductions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更详细地探讨归约函数。从纯函数的角度来看，归约可以递归地定义。Python 中可用的尾调用优化技术非常适合归约。
- en: We’ll review a number of built-in reduction algorithms including `sum()`, `count()`,
    `max()`, and `min()`. We’ll look at the `collections.Counter()` creation and related
    `itertools.groupby()` reductions. We’ll also look at how parsing (and lexical
    scanning) are proper reductions since they transform sequences of tokens (or sequences
    of characters) into higher-order collections with more complex properties.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回顾一些内置的归约算法，包括 `sum()`、`count()`、`max()` 和 `min()`。我们将探讨 `collections.Counter()`
    的创建和相关 `itertools.groupby()` 归约。我们还将探讨解析（和词法扫描）是如何作为适当的归约的，因为它们将标记序列（或字符序列）转换为具有更复杂属性的更高阶集合。
- en: 6.1 Simple numerical recursions
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 简单数值递归
- en: We can consider all numeric operations to be defined by recursions. For more
    details, read about the Peano axioms that define the essential features of numbers
    at [https://www.britannica.com/science/Peano-axioms](https://www.britannica.com/science/Peano-axioms).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将所有数值运算都定义为递归。有关更多详细信息，请阅读定义数字基本特征的佩亚诺公理，见[https://www.britannica.com/science/Peano-axioms](https://www.britannica.com/science/Peano-axioms)。
- en: From these axioms, we can see that addition is defined recursively using more
    primitive notions of the next number, or the successor of a number n, S(n).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些公理中，我们可以看到加法是通过使用更原始的下一个数的概念，即数 n 的后继，S(n) 来递归定义的。
- en: To simplify the presentation, we’ll assume that we can define a predecessor
    function, P(n), such that n = S(P(n)) = P(S(n)), as long as n≠0\. This formalizes
    the idea that a number is the successor of the number’s predecessor.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化说明，我们假设我们可以定义一个前驱函数，P(n)，使得 n = S(P(n)) = P(S(n))，只要 n≠0。这形式化了这样一个观点：一个数是它前驱数的后继。
- en: 'Addition between two natural numbers could be defined recursively as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 两个自然数之间的加法可以递归地定义为如下：
- en: '![ ( |{ add(a,b) = b if a = 0 |( add(P(a),S(b)) if a ⁄= 0 ](img/file48.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ add(a,b) = b if a = 0 |( add(P(a),S(b)) if a ⁄= 0 ](img/file48.jpg)'
- en: If we use the more typical notations of n + 1 and n− 1 instead of S(n) and P(n),
    we can more easily see how the rule add(a,b) = add(a − 1,b + 1) when a≠0 works.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用更典型的n + 1和n− 1的表示法，而不是S(n)和P(n)，我们可以更容易地看到当a≠0时，add(a,b) = add(a − 1,b
    + 1)的规则是如何工作的。
- en: 'This translates neatly into Python, as shown in the following function definition:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这在以下函数定义中得到了很好的体现：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We’ve rearranged the abstract mathematical notation into concrete Python.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将抽象的数学符号重新排列成了具体的Python代码。
- en: There’s no good reason to provide our own functions in Python to do simple addition.
    We rely on Python’s underlying implementation to properly handle arithmetic of
    various kinds. Our point here is that fundamental scalar arithmetic can be defined
    recursively, and the definition translates to Python.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中提供我们自己的函数来进行简单的加法没有很好的理由。我们依赖于Python的底层实现来正确处理各种算术运算。我们在这里的要点是，基本标量算术可以递归定义，并且定义可以翻译成Python。
- en: This suggests that more complicated operations, defined recursively, can also
    be translated to Python. The translation can be manually optimized to create working
    code that matches the abstract definitions, reducing questions about possible
    bugs in the implementation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明更复杂的递归定义的操作也可以翻译成Python。这种翻译可以通过手动优化来创建与抽象定义相匹配的运行代码，从而减少关于实现中可能出现的错误的问题。
- en: 'A recursive definition must include at least two cases: a non-recursive (or
    base) case where the value of the function is defined directly, and the recursive
    case where the value of the function is computed from a recursive evaluation of
    the function with different argument values.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 递归定义必须至少包括两种情况：一个非递归（或基本）情况，其中函数的值直接定义，以及递归情况，其中函数的值是通过递归评估具有不同参数值的函数来计算的。
- en: In order to be sure the recursion will terminate, it’s important to see how
    the recursive case computes values that approach the defined non-recursive base
    case. Pragmatically, there are often constraints on the argument values that we’ve
    omitted from the functions here. For example, the `add()` function in the preceding
    command snippet could be expanded to include `assert`` a>=0`` and`` b>=0` to establish
    two necessary constraints on the input values.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保递归能够终止，重要的是要看到递归情况是如何计算接近定义的非递归基本情况的值的。从实用角度来看，我们通常省略了函数中的参数值约束。例如，前面命令片段中的`add()`函数可以扩展以包括`assert
    a>=0 and b>=0`，以建立对输入值的两个必要约束。
- en: Without these constraints, starting with `a` equal to -1 won’t approach the
    non-recursive case of `a`` ==`` 0` as we keep subtracting 1 from `a`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 没有这些限制，从`a`等于-1开始，当我们不断从`a`中减去1时，不会接近`a == 0`的非递归情况。
- en: 6.1.1 Implementing manual tail-call optimization
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 实现手动尾调用优化
- en: For some functions, the recursive definition is the most succinct and expressive.
    A common example is the `factorial()` function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些函数，递归定义是最简洁和表达性最强的。一个常见的例子是`factorial()`函数。
- en: 'We can see how this is rewritten as a simple recursive function in Python from
    the following formula:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从以下公式中看到，这如何被重写为Python中的一个简单递归函数：
- en: '![ ( | { 1 if n = 0 n! = |( n × (n− 1)! if n ⁄= 0 ](img/file49.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![ ( | { 1 if n = 0 n! = |( n × (n− 1)! if n ⁄= 0 ](img/file49.jpg)'
- en: 'The preceding formula can be implemented in Python by using the following function
    definition:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述公式可以通过以下函数定义在Python中实现：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This implementation has the advantage of simplicity. The recursion limits in
    Python artificially constrain us; we can’t do anything larger than about `fact(997)`.
    The value of 1000! has 2,568 digits and generally exceeds our floating-point capacity;
    on some systems the floating-point limit is near 10^(300). Pragmatically, it’s
    common to switch to a log gamma function instead of working with immense numbers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实现具有简单性的优势。Python中的递归限制人为地限制了我们的能力；我们无法进行大于约`fact(997)`的操作。1000!的值有2,568位数字，通常超过了我们的浮点数容量；在某些系统中，浮点数限制接近10^(300)。从实用角度来看，通常切换到对数伽马函数而不是处理巨大的数字。
- en: See [https://functions.wolfram.com/GammaBetaErf/LogGamma/introductions/Gammas/ShowAll.html](https://functions.wolfram.com/GammaBetaErf/LogGamma/introductions/Gammas/ShowAll.html)
    for more on log gamma functions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有关对数伽马函数的更多信息，请参阅[https://functions.wolfram.com/GammaBetaErf/LogGamma/introductions/Gammas/ShowAll.html](https://functions.wolfram.com/GammaBetaErf/LogGamma/introductions/Gammas/ShowAll.html)。
- en: We can expand Python’s call stack limit to stretch this to the limits of memory.
    It’s better, however, to manually optimize these kinds of functions to eliminate
    the recursion.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将Python的调用栈限制扩展到内存的极限。然而，手动优化这些函数以消除递归是更好的选择。
- en: This function demonstrates a typical tail recursion. The last expression in
    the function is a call to the function with a new argument value. An optimizing
    compiler can replace the function call stack management with a loop that executes
    very quickly.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数演示了一个典型的尾递归。函数中的最后一个表达式是对具有新参数值的函数的调用。优化编译器可以用执行非常快的循环来替换函数调用栈管理。
- en: In this example, the function involves an incremental change from n to n − 1\.
    This means that we’re generating a sequence of numbers and then doing a reduction
    to compute their product.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，函数涉及从 n 到 n - 1 的增量变化。这意味着我们在生成一系列数字后，再进行归约以计算它们的乘积。
- en: 'Stepping outside purely functional processing, we can define an imperative
    `facti()` calculation as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 超出纯粹函数式处理，我们可以定义一个命令式的 `facti()` 计算如下：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This version of the factorial function will compute values beyond 1000! (2000!,
    for example, has 5,736 digits). This example isn’t purely functional. We’ve optimized
    the tail recursion into a stateful `for` statement depending on the `i` variable
    to maintain the state of the computation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶乘函数版本将计算超过1000!（例如，2000!有5,736位）。这个例子并不纯粹是函数式的。我们将尾递归优化为一个依赖于 `i` 变量的状态 `for`
    语句，以保持计算状态。
- en: In general, we’re obliged to do this in Python because Python can’t automatically
    do the tail-call optimization. There are situations, however, where this kind
    of optimization isn’t actually helpful. We’ll look at a few of them.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们不得不在Python中这样做，因为Python无法自动进行尾调用优化。然而，在某些情况下，这种优化实际上并不 helpful。我们将探讨其中的一些情况。
- en: 6.1.2 Leaving recursion in place
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 保持递归不变
- en: 'In some cases, the recursive definition is actually optimal. Some recursions
    involve a divide and conquer strategy that minimizes the work. One example of
    this is the algorithm for doing exponentiation by squaring. This works for computing
    values that have a positive integer exponent, like 2^(64). We can state it formally
    as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，递归定义实际上是最佳的。一些递归涉及分治策略，这可以最小化工作量。其中一个例子是平方幂的指数算法。这适用于计算具有正整数指数的值，如 2^(64)。我们可以如下形式化地陈述它：
- en: '![ (| ||| 1 if n = 0 n { (n−1) a = || a × a if a is odd ||( n2 2 (a ) if a
    is even ](img/file50.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![ (| ||| 1 if n = 0 n { (n−1) a = || a × a if a is odd ||( n2 2 (a ) if a
    is even ](img/file50.jpg)'
- en: 'We’ve broken the process into three cases, easily written in Python as a recursion.
    Look at the following function definition:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将过程分解为三个情况，可以很容易地用Python作为递归编写。看看以下函数定义：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For odd numbers, the `fastexp()` method is defined recursively. The exponent
    `n` is reduced by 1\. A simple tail-recursion optimization would work for this
    case. It would not work for the even case, however.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于奇数，`fastexp()` 方法定义为递归。指数 `n` 减少了1。对于这种情况，简单的尾递归优化是可行的。然而，对于偶数情况，则不可行。
- en: For even numbers, the `fastexp()` recursion uses `n`` //`` 2`, chopping the
    problem into half of its original size. Since the problem size is reduced by a
    factor of 2, this case results in a significant speed-up of the processing.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于偶数，`fastexp()` 递归使用 `n // 2`，将问题规模减半。由于问题规模减少了2倍，这种情况会导致处理速度显著提升。
- en: We can’t trivially reframe this kind of function into a tail-call optimization
    loop. Since it’s already optimal, we don’t really need to optimize it further.
    The recursion limit in Python would impose the constraint of n ≤ 2^(1000), a generous
    upper bound.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能简单地重构这种函数为尾调用优化循环。由于它已经是最优的，我们实际上不需要进一步优化它。Python中的递归限制将导致 n ≤ 2^(1000)，这是一个相当宽松的上限。
- en: 6.1.3 Handling difficult tail-call optimization
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3 处理困难的尾调用优化
- en: 'We can look at the definition of Fibonacci numbers recursively. The following
    is one widely used definition for the n^(th) Fibonacci number, F[n]:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以递归地查看斐波那契数的定义。以下是对第 n 个斐波那契数 F[n] 的一个广泛使用的定义：
- en: '![ (| ||| 0 if n = 0 { Fn = | 1 if n = 1 |||( Fn− 1 + Fn− 2 if n ≥ 2 ](img/file51.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![ (| ||| 0 if n = 0 { Fn = | 1 if n = 1 |||( Fn− 1 + Fn− 2 if n ≥ 2 ](img/file51.jpg)'
- en: 'A given Fibonacci number, F[n], is defined as the sum of the previous two numbers,
    F[n−1] + F[n−2]. This is an example of multiple recursion: it can’t be trivially
    optimized as a simple tail recursion. However, if we don’t optimize it to a tail
    recursion, we’ll find it to be too slow to be useful.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个给定的斐波那契数F[n]定义为前两个数的和，即F[n−1] + F[n−2]。这是一个多次递归的例子：它不能简单地作为简单的尾递归进行优化。然而，如果我们不将其优化为尾递归，我们会发现它太慢而无法使用。
- en: 'The following is a naïve implementation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单的实现：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This suffers from a terrible multiple recursion problem. When computing the
    `fib(n)` value, we must compute the `fib(n-1)` and `fib(n-2)` values. The computation
    of the `fib(n-1)` value involves a duplicate calculation of the `fib(n-2)` value.
    The two recursive uses of the `fib()` function will more than duplicate the amount
    of computation being done.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这存在一个可怕的多次递归问题。在计算`fib(n)`值时，我们必须计算`fib(n-1)`和`fib(n-2)`的值。`fib(n-1)`值的计算涉及到`fib(n-2)`值的重复计算。`fib()`函数的两次递归使用将超过重复计算的工作量。
- en: Because of the left-to-right Python evaluation rules, we can evaluate values
    up to about `fib(1000)`. However, we have to be patient. Very patient. (Trying
    to find the actual upper bound with the default stack size means waiting a long
    time before the `RecursionError` is raised.)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python从左到右的评估规则，我们可以评估到大约`fib(1000)`的值。然而，我们必须有耐心。非常耐心。（尝试使用默认的栈大小找到实际的界限意味着在`RecursionError`被抛出之前要等待很长时间。）
- en: 'The following is one alternative, which restates the entire algorithm to use
    stateful variables instead of a simple recursion:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个替代方案，它重新表述了整个算法，使用有状态变量而不是简单的递归：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Our stateful version of this function counts up from 0, unlike the recursion,
    which counts down from the initial value of `n`. This version is considerably
    faster than the recursive version.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这个有状态版本的函数从0开始计数，与递归从初始值`n`开始计数不同。这个版本比递归版本快得多。
- en: What’s important here is that we couldn’t trivially optimize the `fib()` function
    recursion with an obvious rewrite. In order to replace the recursion with an imperative
    version, we had to look closely at the algorithm to determine how many stateful
    intermediate variables were required.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里重要的是，我们无法简单地通过明显的重写来优化`fib()`函数的递归。为了用命令式版本替换递归，我们必须仔细查看算法，以确定需要多少个有状态的中间变量。
- en: As an exercise for the reader, try using the `@cache` decorator from the `functools`
    module. What impact does this have?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对读者的练习，尝试使用`functools`模块中的`@cache`装饰器。这会产生什么影响？
- en: 6.1.4 Processing collections through recursion
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.4 通过递归处理集合
- en: 'When working with a collection, we can also define the processing recursively.
    We can, for example, define the `map()` function recursively. The formalism could
    be stated as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理集合时，我们也可以递归地定义处理。例如，我们可以递归地定义`map()`函数。形式化可以表述如下：
- en: '![ ( |{ [] if len(C ) = 0 map (f,C ) = | ( map(f,C [:−1]) + [f (C −1)] if len(C
    ) > 0 ](img/file52.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{ [] if len(C ) = 0 map (f,C ) = | ( map(f,C [:−1]) + [f (C −1)] if len(C
    ) > 0 ](img/file52.jpg)'
- en: We’ve defined the mapping of a function, f, to an empty collection as an empty
    sequence, `[]`. We’ve also specified that applying a function to a collection
    can be defined recursively with a three-step expression. First, recursively perform
    the mapping of the function to all of the collection except the last element,
    creating a sequence object. Then apply the function to the last element. Finally,
    append the last calculation to the previously built sequence.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将函数f映射到空集合定义为空序列`[]`。我们还指定了将函数应用于集合可以通过一个三步表达式递归定义。首先，递归地对函数应用于除最后一个元素之外的所有集合元素进行映射，创建一个序列对象。然后对最后一个元素应用函数。最后，将最后的计算结果追加到之前构建的序列中。
- en: 'Following is a purely recursive function version of this `map()` function:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这个`map()`函数的纯递归函数版本：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The value of the `mapr(f,[])` method is defined to be an empty list object.
    The value of the `mapr()` function with a non-empty list will apply the function
    to the last element in the list and append this to the list built recursively
    from the `mapr()` function applied to the head of the list.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapr(f,[])`方法定义的值是一个空列表对象。对于非空列表的`mapr()`函数，将应用函数到列表的最后一个元素，并将其追加到由应用于列表头的`mapr()`函数递归构建的列表中。'
- en: We have to emphasize that this `mapr()` function actually creates a list object.
    The built-in `map()` function is an iterator; it doesn’t create a list object.
    It yields the result values as they are computed. Also, the work is done in right-to-left
    order, which is not the way Python normally works. This is only observable when
    using a function that has side effects, something we’d like to avoid doing.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须强调，这个`mapr()`函数实际上创建了一个列表对象。内置的`map()`函数是一个迭代器；它不会创建列表对象。它按计算顺序产生结果值。此外，工作是在从右到左的顺序中完成的，这不是Python通常的工作方式。这只有在使用具有副作用的功能时才会观察到，这是我们希望避免做的事情。
- en: While this is an elegant formalism, it still lacks the tail-call optimization
    required. An optimization will allow us to exceed the default recursion limit
    of 1,000 and also performs much more quickly than this naïve recursion.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个优雅的形式主义，但它仍然缺乏所需的尾调用优化。优化将使我们能够超过默认的递归限制1,000，并且比这种原始递归快得多。
- en: The use of `Callable[[Any],`` Any]` is a weak type hint. To be more clear, it
    can help to define a domain type variable and a range type variable. We’ll include
    this detail in the optimized example.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Callable[[Any], Any]`是一种弱类型提示。为了更清楚，可以定义一个域类型变量和一个范围类型变量。我们将在优化示例中包含这个细节。
- en: 6.1.5 Tail-call optimization for collections
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.5 集合的尾调用优化
- en: 'We have two general ways to handle collections: we can use a higher-order function
    that returns a generator expression, or we can create a function that uses a `for`
    statement to process each item in a collection. These two patterns are very similar.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两种处理集合的一般方法：我们可以使用返回生成器表达式的高阶函数，或者我们可以创建一个使用`for`语句处理集合中每个项的函数。这两种模式非常相似。
- en: 'Following is a higher-order function that behaves like the built-in `map()`
    function:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个类似于内置`map()`函数的高阶函数：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We’ve returned a generator expression that produces the required mapping. This
    uses the explicit `for` in the generator expression as a kind of tail-call optimization.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们返回了一个生成器表达式，它产生了所需的映射。这使用了生成器表达式中的显式`for`作为尾调用优化的一种形式。
- en: The source of data, `C`, has a type hint of `Iterable[DomT]` to emphasize that
    some type, `DomT`, will form the domain for the mapping. The transformation function
    has a hint of `Callable[[DomT],`` RngT]` to make it clear that it transforms from
    some domain type to a range type. The function `float()`, for example, can transform
    values from the string domain to the float range. The result has the hint of `Iterator[RngT]`
    to show that it iterates over the range type, `RngT`; the result type of the callable
    function.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源`C`有一个类型提示`Iterable[DomT]`，以强调某些类型`DomT`将形成映射的域。转换函数有一个提示`Callable[[DomT],
    RngT]`，以使其明确地从某个域类型转换到范围类型。例如，`float()`函数可以将值从字符串域转换为浮点数范围。结果有一个提示`Iterator[RngT]`，以表明它遍历范围类型`RngT`；可调用函数的结果类型。
- en: 'The following is a generator function with the same signature and result:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个具有相同签名和结果的生成器函数：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This uses a complete `for` statement for the tail-call optimization. The results
    are identical. This version is slightly slower because it involves multiple statements.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用了完整的`for`语句进行尾调用优化。结果相同。这个版本稍微慢一些，因为它涉及多个语句。
- en: 'In both cases, the result is an iterator over the results. We must do something
    else to materialize a sequence object from an iterable source. For example, here
    is the `list()` function being used to create a sequence from the iterator:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，结果是对结果的一个迭代器。我们必须做些别的事情，才能从一个可迭代源中创建一个序列对象。例如，这里使用`list()`函数从迭代器创建序列：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For performance and scalability, this kind of tail-call optimization is required
    in Python programs. It makes the code less than purely functional. However, the
    benefit far outweighs the lack of purity. In order to reap the benefits of succinct
    and expressive functional design, it is helpful to treat these less-than-pure
    functions as if they were proper recursions.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了性能和可扩展性，Python程序中需要这种尾调用优化。这使得代码不如纯函数。然而，好处远远超过了纯度的缺乏。为了获得简洁和表达性强的函数式设计的益处，将这些非纯函数视为适当的递归是有帮助的。
- en: What this means, pragmatically, is that we must avoid cluttering up a collection
    processing function with additional stateful processing. The central tenets of
    functional programming are still valid even if some elements of our programs are
    less than purely functional.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这在实用意义上意味着我们必须避免在集合处理函数中添加额外的状态化处理。即使我们程序的一些元素不是完全函数式的，函数式编程的核心原则仍然有效。
- en: 6.1.6 Using the assignment (sometimes called the ”walrus”) operator in recursions
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.6 在递归中使用赋值（有时称为“walrus”）运算符
- en: In some cases, recursions involve conditional processing that can be optimized
    using the ”walrus” or assignment operator, `:=`. The use of assignment means that
    we’re introducing stateful variables. If we’re careful of the scope of those variables,
    the possibility of terribly complex algorithms is reduced.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，递归涉及可以使用“walrus”或赋值运算符`:=`进行优化的条件处理。使用赋值意味着我们正在引入状态变量。如果我们小心这些变量的作用域，那么产生极其复杂算法的可能性就会降低。
- en: 'We reviewed the `fast_exp()` function shown below in the [Leaving recursion
    in place](#x1-1290002) section. This function used three separate cases to implement
    a divide and conquer strategy. In the case of raising a number, `a`, to an even
    power, we can use t = a^(![n 2](img/file53.jpg)) to compute t × t = a^n:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[保留递归](#x1-1290002)部分回顾了下面的`fast_exp()`函数。这个函数使用了三个不同的案例来实现分而治之的策略。在将数字`a`提升到偶数次幂的情况下，我们可以使用`t
    = a^![n 2](img/file53.jpg)`来计算`t × t = a^n`：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This uses the `:=` walrus operator to compute a partial answer, `fastexp_w(a,`` q)`,
    and save it into a temporary variable, `t`. This is used later in the same statement
    to compute `t`` *`` t`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`:=` walrus运算符来计算部分答案`fastexp_w(a, q)`并将其保存到临时变量`t`中。这将在同一语句的稍后部分用于计算`t *
    t`。
- en: For the most part, when we perform tail-call optimization on a recursion, the
    body of the `for` statement will have ordinary assignment statements. It isn’t
    often necessary to exploit the walrus operator.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于递归的大部分情况，当我们对递归进行尾调用优化时，`for`语句的主体将包含普通赋值语句。通常没有必要利用walrus运算符。
- en: The assignment operator is often used in situations like regular expression
    matching, where we want to save the match object as well as make a decision. It’s
    very common to see `if`` (match`` :=`` pattern.match(text)):` as a way to both
    attempt a regular expression match, save the resulting match object, and confirm
    it’s not a `None` object.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 赋值运算符常用于正则表达式匹配等场景，我们希望保存匹配对象并做出决策。`if(match := pattern.match(text)):`作为尝试正则表达式匹配、保存结果匹配对象并确认它不是`None`对象的一种常见方式。
- en: 6.2 Reductions and folding a collection from many items to one
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 从多个项目折叠集合到单个项目
- en: 'We can consider the `sum()` function to have the following kind of definition.
    We could say that the sum of a collection is 0 for an empty collection. For a
    non-empty collection, the sum is the first element plus the sum of the remaining
    elements:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`sum()`函数考虑为以下类型的定义。我们可以说，对于空集合，集合的和为0。对于非空集合，和是第一个元素加上剩余元素的和：
- en: '![ (| { 0 if n = 0 sum ([c0,c1,c2,...,cn]) = | ( c0 + sum ([c1,c2,...,cn])
    if n > 0 ](img/file54.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![ (| { 0 if n = 0 sum ([c0,c1,c2,...,cn]) = | ( c0 + sum ([c1,c2,...,cn])
    if n > 0 ](img/file54.jpg)'
- en: 'We can use a slightly simplified notation called the Bird-Meertens Formalism.
    This uses ⊕∕[c[0],c[1],...c[n]] to show how some arbitrary binary operator, ⊕,
    can be applied to a sequence of values. It’s used as follows to summarize a recursive
    definition into something a little easier to work with:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一种稍微简化的符号，称为Bird-Meertens形式主义。它使用⊕∕[c[0],c[1],...c[n]]来显示某些任意二元运算符⊕如何应用于一系列值。它如下所示，将递归定义总结为更容易处理的东西：
- en: '![sum ([c0,c1,c2,...,cn]) = + ∕[c0,c1,c2,...,cn] = 0+ c0 + c1 + ...+ cn ](img/file55.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![sum ([c0,c1,c2,...,cn]) = + ∕[c0,c1,c2,...,cn] = 0+ c0 + c1 + ...+ cn ](img/file55.jpg)'
- en: We’ve effectively folded the + operator between each item of the sequence. Implicitly,
    the processing will be done left to right. This could be called a ”fold left”
    way of reducing a collection to a single value. We could also imagine grouping
    the operators from right to left, calling this a ”fold right.” While some compiled
    languages will perform this optimization, Python works strictly from left to right
    when given a sequence of similar precedence operators.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有效地将序列中每个项目之间的加法运算符折叠起来。隐式地，处理将按从左到右的顺序进行。这可以称为将集合折叠为单个值的“fold left”方式。我们也可以想象从右到左分组运算符，称之为“fold
    right”。虽然一些编译型语言会执行这种优化，但Python在给定一系列具有相同优先级的运算符时，会严格从左到右工作。
- en: 'In Python, a product function can be defined recursively as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，乘积函数可以递归地定义为以下内容：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This is a tiny rewrite from a mathematical notation to Python. However, it is
    less than optimal because all of the slices will create a large number of intermediate
    list objects. It’s also limited to only working with explicit collections; it
    can’t work easily with iterable objects.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对数学符号到Python的微小重写。然而，它并不理想，因为所有的切片都会创建大量中间列表对象。它也仅限于与显式集合一起工作；它不能容易地与可迭代对象一起工作。
- en: 'We can revise this slightly to work with an iterable, which avoids creating
    any intermediate collection objects. The following is a properly recursive product
    function that works with any iterator as a source of data:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍作修改以适应可迭代对象，这样可以避免创建任何中间集合对象。以下是一个正确递归的乘积函数，它可以与任何迭代器作为数据源一起工作：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This doesn’t work with iterable collections. We can’t interrogate an iterator
    with the `len()` function to see how many elements it has. All we can do is attempt
    to extract the head of the iterator. If there are no items in the iterator, then
    any attempt to get the head will raise the `StopIteration` exception. If there
    is an item, then we can multiply this item by the product of the remaining items
    in the sequence.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这不适用于可迭代集合。我们无法使用`len()`函数来查询迭代器有多少元素。我们所能做的就是尝试提取迭代器的头部。如果没有元素在迭代器中，那么任何获取头部尝试都会引发`StopIteration`异常。如果有元素，那么我们可以将这个元素乘以序列中剩余元素的乘积。
- en: 'Note that we must explicitly create an iterator from a materialized sequence
    object, using the `iter()` function. In other contexts, we might have an iterable
    result that we can use. Following is an example:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们必须显式地使用`iter()`函数从一个具体化的序列对象创建一个迭代器。在其他上下文中，我们可能有一个可迭代的输出结果可以使用。以下是一个示例：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This recursive definition does not rely on explicit state or other imperative
    features of Python. While it’s more purely functional, it is still limited to
    working with collections of under 1,000 items. (While we can extend the stack
    size, it’s far better to optimize this properly.) Pragmatically, we can use the
    following kind of imperative structure for reduction functions:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个递归定义不依赖于显式状态或Python的其他命令式特性。虽然它更纯粹是函数式的，但它仍然限制在处理小于1,000个项目的集合。（虽然我们可以扩展栈的大小，但正确优化这一点要好得多。）从实用主义的角度来看，我们可以使用以下类型的命令式结构来处理归约函数：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This avoids any recursion limits. It includes the required tail-call optimization.
    Furthermore, this will work equally well with any iterable. This means a `Sequence`
    object, or an iterator.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这避免了任何递归限制。它包括所需的尾调用优化。此外，这将以相同的方式与任何可迭代对象一起工作。这意味着一个`Sequence`对象，或者一个迭代器。
- en: 6.2.1 Tail-call optimization using deques
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 使用双端队列进行尾调用优化
- en: The heart of recursion is a stack of function calls. Evaluating `fact(5)`, for
    example, is `5*fact(4)`. The value of `fact(4)` is `5*fact(3)`. There is a stack
    of pending computations until `fact(0)` has a value of 1\. Then the stack of computations
    is completed, revealing the final result.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 递归的核心是函数调用的栈。例如，评估`fact(5)`是`5*fact(4)`。`fact(4)`的值是`5*fact(3)`。直到`fact(0)`的值为1，才会有一系列待处理的计算。然后计算栈完成，揭示最终结果。
- en: Python manages the stack of calls for us. It imposes an arbitrary default limit
    of 1,000 calls on the stack, to prevent a program with a bug in the recursion
    from running forever.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Python为我们管理调用栈。它对栈强加了一个任意默认限制，即1,000次调用，以防止具有递归错误的程序无限期地运行。
- en: We can manage the stack manually, also. This gives us another way to optimize
    recursions. We can—explicitly—create a stack of pending work. We can then do a
    final summarization of the pending work, emptying the items from the stack.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以手动管理栈。这为我们提供了优化递归的另一种方法。我们可以——明确地——创建一个待处理工作的栈。然后我们可以对待处理工作进行最终总结，从栈中清空项目。
- en: For something as simple as computing a factorial value, the stacking and unstacking
    can seem like needless overhead. For more complex applications, like examining
    the hierarchical file system, it seems more appropriate to mix processing files
    with putting directories onto a stack for later consideration.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像计算阶乘值这样简单的事情，堆栈的压入和弹出可能看起来像是无用的开销。对于更复杂的应用，如检查分层文件系统，将文件处理与将目录放入堆栈以供以后考虑混合起来似乎更合适。
- en: We need a function to traverse a directory hierarchy without an explicit recursion.
    The core concept is that a directory is a collection of entries, and each entry
    is either a file, a sub-directory, or some other filesystem object we don’t want
    to touch (e.g., a mount point, symbolic link, etc.).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个函数来遍历目录层次结构而不使用显式递归。核心概念是目录是一系列条目，每个条目要么是一个文件，要么是一个子目录，或者是我们不想接触的其他文件系统对象（例如，挂载点、符号链接等）。
- en: 'We can say a node in the directory tree is a collection of entries: N = e[0],e[1],e[2],...,e[n].
    Each entry is either another directory, e ∈𝔻, or a file, e ∈𝔽.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说目录树中的一个节点是一系列条目：N = e[0],e[1],e[2],...,e[n]。每个条目要么是另一个目录，e ∈𝔻，要么是一个文件，e
    ∈𝔽。
- en: We can perform mappings on each file in the tree to process each file’s content.
    We might perform a filter operation to create an iterator over files with a specific
    property. We can also perform a reduction to count the number of files with a
    property. In this example, we’ll count the occurrences of a specific substring
    throughout the contents of files in a directory tree.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在树中的每个文件上执行映射以处理每个文件的内容。我们可能执行一个过滤操作来创建具有特定属性的文件迭代器。我们还可以执行归约操作来计算具有属性的文件数量。在这个例子中，我们将计算目录树中文件内容中特定子字符串的出现次数。
- en: 'Formally, we want a function p(f) that will provide the count of `"print"`
    in a node of the directory tree. It could be defined like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，我们希望有一个函数p(f)，它将为目录树节点中的“打印”提供计数。它可以定义如下：
- en: '![ ( |{|“print” ∈ N | if N ∈ 𝔽 p(N ) = ∑ |( e∈N p(e) if N ∈ 𝔻 ](img/file56.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![ ( |{|“打印” ∈ N | 如果 N ∈ 𝔽 p(N ) = ∑ |( e∈N p(e) if N ∈ 𝔻 ](img/file56.jpg)'
- en: This shows how to apply the p(N) function to each element of a directory tree.
    When the element is a file, e ∈𝔽, we can count instances of ”print”. When the
    element is a directory, e ∈𝔻, we need to apply the p(N) function recursively to
    each entry, e[x], in the directory. While directory trees can’t be deep enough
    to break Python’s stack size limit, this kind of algorithm reveals an alternative
    tail-call optimization. It is an opportunity to use an explicit stack.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了如何将p(N)函数应用于目录树中的每个元素。当元素是文件，e ∈𝔽，时，我们可以计算“打印”的实例。当元素是目录，e ∈𝔻，时，我们需要递归地应用p(N)函数到目录中的每个条目，e[x]。虽然目录树可能不够深以打破Python的栈大小限制，但这种算法揭示了尾调用优化的替代方案。这是一个使用显式栈的机会。
- en: The `collections.deque` class is a marvelous way to build stacks and queues.
    The name comes from ”double-ended queue,” sometimes spelled dequeue. The data
    structure can be used as either a last-in-first-out (LIFO) stack or a first-in-first-out
    (FIFO). In this example, we use the `append()` and `pop()` methods, which enforce
    LIFO stack behavior. While this is much like a list, there are some optimizations
    in the `deque` implementation that can make it slightly faster than the generic
    list.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`collections.deque`类是构建栈和队列的奇妙方式。这个名字来自“双端队列”，有时拼写为dequeue。这种数据结构可以用作后进先出（LIFO）栈或先进先出（FIFO）。在这个例子中，我们使用`append()`和`pop()`方法，这些方法强制执行LIFO栈行为。虽然这很像列表，但在`deque`实现中还有一些优化，可以使其比通用列表略快。'
- en: 'Using a stack data structure lets us work with a hierarchy of indefinite size
    without running into Python’s internal stack depth limitation and raising `RecursionError`
    exceptions. The following function will traverse a file hierarchy looking at Python
    source files (with a suffix of `.py`):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用栈数据结构让我们能够在不遇到Python内部栈深度限制并引发`RecursionError`异常的情况下处理不定大小的层次结构。以下函数将遍历文件层次结构，查看Python源文件（后缀为`.py`）：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We seeded the stack of pending tasks with the initial directory. The essential
    algorithm is to unstack a directory and visit each entry in the directory. For
    entries that are files with the proper suffix, the processing is performed: counting
    the occurrences of ”print”. For entries that are directories, the directory is
    put into the stack as a pending task. Note that directories with a leading dot
    in their name need to be ignored. For the code in this book, those directories
    include caches used by tools like mypy, pytest, and tox. We want to skip over
    those cache directories.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用初始目录填充了待处理任务的栈。基本算法是从栈中弹出目录并访问目录中的每个条目。对于具有正确后缀的文件条目，执行处理：计算“打印”的出现次数。对于目录条目，将目录作为待处理任务放入栈中。注意，名称中带有点的目录需要被忽略。对于本书中的代码，这些目录包括mypy、pytest和tox等工具使用的缓存。我们希望跳过这些缓存目录。
- en: The processing performed on each file is part of the `all_print()` function.
    This can be refactored as a separate function that’s applied to each node as part
    of a reduction. Rewriting the `all_print()` function to be a proper higher-order
    function is left as an exercise for the reader.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个文件执行的处理是`all_print()`函数的一部分。这可以重构为一个单独的函数，作为减少的一部分应用于每个节点。将`all_print()`函数重写为适当的更高阶函数作为练习留给读者。
- en: The idea here is we have two strategies for transforming a formal recursion
    into a usefully optimized function. We can reframe the recursion into an iteration,
    or we can introduce an explicit stack.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的想法是我们有两种将形式化递归转换为有用优化函数的策略。我们可以将递归重构成迭代，或者我们可以引入一个显式的栈。
- en: In the next section, we will apply the idea of a reduction (and the associated
    tail-call optimizations) to creating groups of items and computing a reduction
    for the groups.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将应用减少（以及相关的尾调用优化）的概念来创建项目组并计算组的减少。
- en: 6.3 Group-by reduction from many items to fewer
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 从多个项目到较少项目的分组减少
- en: The idea of a reduction can apply in many ways. We’ve looked at the essential
    recursive definition of a reduction that produces a single value from a collection
    of values. This leads us to optimizing the recursion so we have the ability to
    compute summaries without the overheads of a naive Pythonic implementation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 减少的想法可以以多种方式应用。我们已经看到了减少的基本递归定义，它从值集合中生成单个值。这导致我们优化递归，以便我们能够在没有原始Python实现开销的情况下计算摘要。
- en: Creating subgroups in Python isn’t difficult, but it can help to understand
    the formalisms that support it. This understanding can help to avoid implementations
    that perform extremely poorly.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中创建子组并不困难，但了解支持它的形式化方法可能会有所帮助。这种理解可以帮助避免性能极差的实现。
- en: A very common operation is a reduction that groups values by some key or indicator.
    The raw data is grouped by some column’s value, and reductions (sometimes called
    aggregate functions) are applied to other columns.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常常见的操作是按某些键或指标对值进行分组。原始数据按某些列的值进行分组，并将减少（有时称为聚合函数）应用于其他列。
- en: In SQL, this is often called the `GROUP`` BY` clause of the `SELECT` statement.
    The SQL aggregate functions include `SUM`, `COUNT`, `MAX`, and `MIN`, and often
    many more.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在SQL中，这通常称为`SELECT`语句的`GROUP BY`子句。SQL聚合函数包括`SUM`、`COUNT`、`MAX`和`MIN`，以及许多其他函数。
- en: Python offers us several ways to group data before computing a reduction of
    the grouped values. We’ll start by looking at two ways to get simple counts of
    grouped data. Then we’ll look at ways to compute different summaries of grouped
    data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Python为我们提供了多种在计算分组值的减少之前对数据进行分组的方法。我们将从查看获取分组数据的简单计数方法开始。然后我们将探讨计算分组数据不同摘要的方法。
- en: 'We’ll use the trip data that we computed in [Chapter 4](Chapter_04.xhtml#x1-740004),
    [Working with Collections](Chapter_04.xhtml#x1-740004). This data started as a
    sequence of latitude-longitude waypoints. We restructured it to create legs represented
    by three-tuples of start, end, and distance for each leg. The data looks as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们在[第4章](Chapter_04.xhtml#x1-740004)，[处理集合](Chapter_04.xhtml#x1-740004)中计算的三次数据。这些数据最初是一系列纬度-经度航点。我们将其重构为表示每条腿的起点、终点和距离的三元组。数据看起来如下：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We’d like to know the most common distance. Since the data is real-valued, and
    continuous, each distance is a unique value. We need to constrain these values
    from the continuous domain to a discrete set of distances. For example, quantizing
    each leg to the nearest multiple of five nautical miles. This creates bands of
    0 to 5 miles, over 5 to 10 miles, etc. Once we’ve created discrete integer values,
    we can count the number of legs in each of these bands.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想知道最常见的距离。由于数据是实值且连续的，每个距离都是一个独特的值。我们需要将这些值从连续域约束到一组离散的距离。例如，将每条腿量化到最接近的五海里倍数。这创建了从0到5英里，超过5到10英里等的波段。一旦我们创建了离散的整数值，我们就可以计算每个波段中的腿的数量。
- en: 'These quantized distances can be produced with a generator expression:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这些量子化的距离可以通过生成器表达式来生成：
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will divide each distance by 5—discarding any fractions—then multiply the
    truncated result by 5 to compute a number that represents the distance rounded
    down to the nearest 5 nautical miles.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把每个距离除以5——丢弃任何分数——然后将截断的结果乘以5来计算一个表示距离向下舍入到最接近5海里的数字。
- en: 'We don’t use the values assigned to the `start` and `stop` variables. It’s
    common practice to assign these values to the `_` variable. This can lead to some
    confusion because this can obscure the structure of the triple. It would look
    like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有使用分配给 `start` 和 `stop` 变量的值。将它们分配给 `_` 变量是一种常见的做法。这可能会导致一些混淆，因为这可能会掩盖三元组的结构。它看起来会是这样：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This approach can be helpful for removing some visual clutter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法对于去除一些视觉杂乱是有帮助的。
- en: 6.3.1 Building a mapping with Counter
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1 使用 Counter 构建映射
- en: 'A mapping like the `collections.Counter` class is a great optimization for
    doing reductions that create counts (or totals) grouped by some value in the collection.
    The following expression creates a mapping from distance to frequency:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `collections.Counter` 类的映射是进行按集合中某些值创建计数的归约的优化。以下表达式创建了一个从距离到频率的映射：
- en: '[PRE19]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The resulting `summary` object is stateful; it can be updated. The expression
    to create the groups, `Counter()`, looks like a function, making it a good fit
    for a design based on functional programming ideas.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 `summary` 对象是状态的；它可以被更新。创建组的表达式 `Counter()` 看起来像一个函数，这使得它非常适合基于函数编程思想的架构。
- en: 'If we print the `summary.most_common()` value, we’ll see the following results:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印 `summary.most_common()` 的值，我们将看到以下结果：
- en: '[PRE20]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The most common distance was about 30 nautical miles. We can also apply functions
    like `min()` and `max()` to find the shortest recorded and longest legs as well.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的距离大约是 30 海里。我们还可以应用 `min()` 和 `max()` 等函数来找到记录的最短和最长的腿。
- en: 'Note that your output may vary slightly from what’s shown. The results of the
    `most_common()` function are in order of frequency; equal-frequency bins may be
    in any order. These five lengths may not always be in the order shown:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你的输出可能与显示的略有不同。`most_common()` 函数的结果按频率排序；频率相等的桶可能以任何顺序排列。这五个长度不一定总是按显示的顺序排列：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This slight variability makes testing with the doctest tool a little bit more
    complex. One helpful trick for testing with counters is to use a dictionary to
    validate the results in general; the comparison between actual and expected no
    longer relies on the vagaries of internal hash computations.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这种轻微的变化使得使用 doctest 工具进行测试稍微复杂一些。对于计数器测试的一个有用技巧是使用字典来验证结果；实际值与预期值之间的比较不再依赖于内部哈希计算的随意性。
- en: 6.3.2 Building a mapping by sorting
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2 通过排序构建映射
- en: An alternative to `Counter` is to sort the original collection, and then use
    a recursive loop to identify when each group begins. This involves materializing
    the raw data, performing a sort that could—at worst—do O(nlog n) operations, and
    then doing a reduction to get the sums or counts for each key.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`Counter` 的一个替代方案是对原始集合进行排序，然后使用递归循环来识别每个组开始的位置。这涉及到将原始数据实体化，执行一个可能最坏情况下进行
    O(nlog n) 操作的排序，然后进行归约以获取每个键的求和或计数。'
- en: In order to work in a general way with Python objects that can be sorted, we
    need to define the protocol required for sorting. We’ll call the protocol `SupportsRichComparisonT`
    because we can sort any kinds of objects that implement the rich comparison operators,
    `<` and `>`. This isn’t a particular class of objects; it’s a protocol that any
    number of classes might implement. We formalize the idea of a protocol that classes
    must support using the `typing.Protocol` type definition. It could be also be
    called an interface that a class must implement. Python’s flexibility stems from
    having a fairly large number of protocols that many different classes support.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以通用方式与可以排序的 Python 对象一起工作，我们需要定义排序所需的协议。我们将此协议称为 `SupportsRichComparisonT`，因为我们可以排序任何实现了丰富比较运算符
    `<` 和 `>` 的对象。这不是一个特定的对象类；这是一个任何数量的类都可能实现的协议。我们使用 `typing.Protocol` 类型定义正式化类必须支持的协议概念。它也可以被称为一个类必须实现的接口。Python
    的灵活性源于拥有相当多的协议，许多不同的类都支持这些协议。
- en: 'The following is a common algorithm for creating groups from sorted data:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从排序数据创建组的一个常见算法：
- en: '[PRE22]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The internal `group()` function steps through the sorted sequence of legs.
    If a given item key has already been seen—it matches the value in `previous`—then
    the `counter` variable is incremented. If a given item does not match the previous
    value, then there’s been a change in value: emit the previous value and the count,
    and begin a new accumulation of counts for the new value.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 内部 `group()` 函数遍历腿的排序序列。如果给定的项目键已经出现过——它与 `previous` 中的值匹配——则 `counter` 变量递增。如果给定的项目不匹配前一个值，那么值发生了变化：输出前一个值和计数，并开始为新值积累计数。
- en: The definition of `group()` provides two important type hints. The source data
    is an iterable over some type, shown with the type variable `SupportsRichComparisonT`.
    In this specific case, it’s pretty clear that the values in use will be of type
    `int`; however, the algorithm will work for any Python type. The resulting iterable
    from the `group()` function will preserve the type of the source data, and this
    is made explicit by using the same type variable, `SupportsRichComparisonT`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`group()` 函数的定义提供了两个重要的类型提示。源数据是一些类型的可迭代对象，用类型变量 `SupportsRichComparisonT`
    表示。在这个特定的情况下，很明显，使用的值将是 `int` 类型；然而，算法对任何 Python 类型都适用。`group()` 函数的结果可迭代对象将保留源数据的类型，并且通过使用相同的类型变量
    `SupportsRichComparisonT` 来明确这一点。'
- en: The final line of the `group_sort()` function creates a dictionary from the
    grouped items. This dictionary will be similar to a `Counter` dictionary. The
    primary difference is that a `Counter()` function will have a `most_common()`
    method function, which a default dictionary lacks.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`group_sort()` 函数的最后一行从分组项创建一个字典。这个字典将与 `Counter` 字典类似。主要区别是 `Counter()` 函数将有一个
    `most_common()` 方法函数，而默认字典没有。'
- en: We can also do this with `itertools.groupby()`. We’ll look at this function
    closely in [Chapter 8](Chapter_08.xhtml#x1-1700008), [The Itertools Module](Chapter_08.xhtml#x1-1700008).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用 `itertools.groupby()` 来做这件事。我们将在[第8章](Chapter_08.xhtml#x1-1700008)，[Itertools
    模块](Chapter_08.xhtml#x1-1700008)中详细探讨这个函数。
- en: 6.3.3 Grouping or partitioning data by key values
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.3 按键值分组或分区数据
- en: There are no limits to the kinds of reductions we might want to apply to grouped
    data. We might have data with a number of independent and dependent variables.
    We can consider partitioning the data by an independent variable and computing
    summaries such as the maximum, minimum, average, and standard deviation of the
    values in each partition.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想要应用于分组数据的归约类型没有限制。我们可能有具有多个独立和依赖变量的数据。我们可以考虑按独立变量分区数据，并计算每个分区中值的最大值、最小值、平均值和标准差等摘要。
- en: The essential trick to doing more sophisticated reductions is to collect all
    of the data values into each group. The `Counter()` function merely collects counts
    of identical items. For deeper analysis, we want to create sequences of the original
    members of the group.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 进行更复杂归约的基本技巧是将所有数据值收集到每个组中。`Counter()` 函数仅收集相同项的计数。对于更深入的分析，我们希望创建包含组原始成员的序列。
- en: Looking back at our trip data, each five-mile bin could contain the entire collection
    of legs of that distance, not merely a count of the legs. We can consider the
    partitioning as a recursion or as a stateful application of `defaultdict(list)`
    objects. We’ll look at the recursive definition of a `groupby()` function, since
    it’s easy to design.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们的行程数据，每个五英里区间可能包含该距离的所有腿的整个集合，而不仅仅是腿的数量。我们可以将分区视为递归或作为 `defaultdict(list)`
    对象的状态化应用。我们将探讨 `groupby()` 函数的递归定义，因为它很容易设计。
- en: Clearly, the `groupby(C,`` key)` computation for an empty collection, `[]`,
    is the empty dictionary, `dict()`. Or, more usefully, the empty `defaultdict(list)`
    object.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，对于空集合 `[]` 的 `groupby(C,` `key)` 计算结果是空字典 `dict()`。或者更有用，空 `defaultdict(list)`
    对象。
- en: 'For a non-empty collection, we need to work with item `C[0]`, the head, and
    recursively process sequence `C[1:]`, the tail. We can use slice expressions,
    or we can use the `head,` `*tail`` =`` C` statement to do this parsing of the
    collection, as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非空集合，我们需要处理项 `C[0]`，即头部，并递归地处理序列 `C[1:]`，即尾部。我们可以使用切片表达式，或者我们可以使用 `head,`
    `*tail`` =`` C` 语句来解析这个集合，如下所示：
- en: '[PRE23]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If we have a `defaultdict` object named `groups`, we need to use the expression
    `groups[key(head)].append(head)` to include the head element in the `groups` dictionary.
    After this, we need to evaluate the `groupby(tail,`` key)` expression to process
    the remaining elements.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个名为 `groups` 的 `defaultdict` 对象，我们需要使用表达式 `groups[key(head)].append(head)`
    将头部元素包含在 `groups` 字典中。之后，我们需要评估 `groupby(tail, key)` 表达式来处理剩余的元素。
- en: 'We can create a function as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个如下所示的函数：
- en: '[PRE24]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The interior function `group_into()` handles the essential recursive definition.
    An empty value for `collection` returns the provided dictionary, `group_dict`.
    A non-empty collection is partitioned into a head and tail. The head is used to
    update the `group_dict` dictionary. The tail is then used, recursively, to update
    the dictionary with all remaining elements.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 内部函数 `group_into()` 处理基本的递归定义。对于 `collection` 的空值返回提供的字典 `group_dict`。非空集合被分割成头部和尾部。头部用于更新
    `group_dict` 字典。然后递归地使用尾部更新字典中的所有剩余元素。
- en: The type hints make an explicit distinction between the type of the source objects
    `SeqItemT` and the type of the key `ItemKeyT`. The function provided as the `key`
    parameter must be a callable that returns a value of the key type `ItemKeyT`,
    given an object of the source type `SeqItemT`. In many of the examples, a function
    to extract the distance from a `Leg` object will be be shown. This is a `Callable[[SeqItemT],`` ItemKeyT]`
    where the source type `SeqItemT` is the `Leg` object and the key type `ItemKeyT`
    is the float value.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 类型提示在源对象 `SeqItemT` 的类型和键 `ItemKeyT` 的类型之间做出了明确的区分。作为 `key` 参数提供的函数必须是一个可调用的函数，它返回一个键类型
    `ItemKeyT` 的值，给定一个源类型 `SeqItemT` 的对象。在许多示例中，将展示一个从 `Leg` 对象中提取距离的函数。这是一个 `Callable[[SeqItemT],
    ItemKeyT]`，其中源类型 `SeqItemT` 是 `Leg` 对象，键类型 `ItemKeyT` 是浮点值。
- en: '`bound=Hashable` is an additional constraint. This defines an ”upper bound”
    on the possible types, alerting mypy that any type that could be assigned to this
    type variable must implement the protocol for `Hashable`. The essential, immutable
    Python types of numbers, strings, and tuples all meet this bound. A mutable object
    like a dictionary, set, or list, will not meet the upper bound, leading to warnings
    from mypy.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`bound=Hashable` 是一个额外的约束。这定义了可能类型的“上限”，并提醒mypy任何可以分配给此类型变量的类型都必须实现 `Hashable`
    协议。基本、不可变的Python类型，如数字、字符串和元组都满足这个限制。像字典、集合或列表这样的可变对象将不会满足上限，从而导致mypy发出警告。'
- en: 'We can’t easily use Python’s default values to collapse this into a single
    function. We explicitly cannot use the following incorrect command snippet:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能轻易使用Python的默认值将此合并为一个单一函数。我们明确不能使用以下错误的命令片段：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If we try this, all uses of the `group_by()` function share one common `defaultdict(list)`
    object. This does not work because Python builds the default value just once.
    Mutable objects as default values rarely do what we want. The common practice
    is to provide a `None` value, and use an explicit `if` statement to create each
    unique, empty instance of `defaultdict(list)` as needed. We’ve shown how to use
    a wrapper function definition to avoid the `if` statement.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试这样做，`group_by()` 函数的所有使用都共享一个共同的 `defaultdict(list)` 对象。这不起作用，因为Python只构建一次默认值。作为默认值的可变对象很少能做我们想要的事情。常见的做法是提供一个
    `None` 值，并使用显式的 `if` 语句根据需要创建每个唯一的空 `defaultdict(list)` 实例。我们已经展示了如何使用包装函数定义来避免
    `if` 语句。
- en: 'We can group the data by distance as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下按距离对数据进行分组：
- en: '[PRE26]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We’ve defined a reusable lambda that puts our distances into bins, each of which
    is 5 nautical miles in size. We then grouped the data using the provided lambda.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个可重用的lambda，将我们的距离放入大小为5海里一个的箱子中。然后我们使用提供的lambda对数据进行分组。
- en: 'We can examine the binned data as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下检查分组后的数据：
- en: '[PRE27]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following is what the output looks like:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 以下就是输出看起来像什么：
- en: '[PRE28]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Having looked at a recursive definition, we can turn to looking at making a
    tail-call optimization to build a group-by algorithm using iteration. This will
    work with larger collections of data, because it can exceed the internal stack
    size limitation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看递归定义之后，我们可以转向查看如何通过迭代来构建一个分组算法的尾调用优化。这将适用于更大的数据集，因为它可以超过内部栈大小限制。
- en: We’ll start with doing tail-call optimization on the `group_into()` function.
    We’ll rename this to `partition()` because partitioning is another way of looking
    at grouping.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从对 `group_into()` 函数进行尾调用优化开始。我们将将其重命名为 `partition()`，因为分割是另一种看待分组的方式。
- en: 'The `partition()` function can be written as an iteration as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`partition()`函数可以写成如下迭代形式：'
- en: '[PRE29]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: When doing the tail-call optimization, the essential line of the code in the
    imperative version will match the recursive definition. We’ve put a comment under
    the changed line to emphasize the rewrite is intended to have the same outcome.
    The rest of the structure represents the tail-call optimization we’ve adopted
    as a common way to work around the Python limitations.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行尾调用优化时，命令式版本中的关键代码行将与递归定义匹配。我们在更改的行下面添加了注释，以强调重写是为了达到相同的结果。其余的结构代表了作为绕过Python限制的常用方法所采用的尾调用优化。
- en: The type hints emphasize the distinction between the source type `SeqT` and
    the key type `KeyT`. The source data can be anything, but the keys are limited
    to types that have proper hash values.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 类型提示强调了源类型`SeqT`和键类型`KeyT`之间的区别。源数据可以是任何东西，但键限于具有适当哈希值的类型。
- en: 6.3.4 Writing more general group-by reductions
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.4 编写更通用的按组减少
- en: Once we have partitioned the raw data, we can compute various kinds of reductions
    on the data elements in each partition. We might, for example, want the northernmost
    point for the start of each leg in the distance bins.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对原始数据进行分区，我们就可以对每个分区中的数据元素进行各种类型的减少计算。例如，我们可能想要距离bin中每一段的北部最远点。
- en: 'We’ll introduce some helper functions to decompose the tuple as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将引入一些辅助函数来分解元组，如下所示：
- en: '[PRE30]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Each of these helper functions expects a tuple object to be provided using the
    `*` operator to map each element of the tuple to a separate parameter of the lambda.
    Once the tuple is expanded into the `s`, `e`, and `p` parameters, it’s reasonably
    obvious to return the proper parameter by name. It’s much clearer than trying
    to interpret the `tuple_arg[2]` value.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这些辅助函数中的每一个都期望提供一个使用`*`运算符提供的元组对象，将元组的每个元素映射到lambda的单独参数。一旦元组展开为`s`、`e`和`p`参数，通过名称返回适当的参数就相当明显了。这比尝试解释`tuple_arg[2]`值要清晰得多。
- en: 'The following is how we use these helper functions:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何使用这些辅助函数：
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Our initial `point` object is a nested three tuple with (0)—a starting position,
    (1)—the ending position, and (2)—the distance. We extracted various fields using
    our helper functions.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初的`point`对象是一个嵌套的三元组，包含（0）起始位置，（1）结束位置，和（2）距离。我们使用辅助函数提取了各种字段。
- en: 'Given these helpers, we can locate the northernmost starting position for the
    legs in each bin:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这些辅助函数，我们可以定位每个bin中路段的北部最起始位置：
- en: '[PRE32]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The data that we grouped by distance included each leg of the given distance.
    We supplied all of the legs in each bin to the `max()` function. The `key` function
    we provided to the `max()` function extracted just the latitude of the starting
    point of the leg.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按距离分组的数据包括给定距离的每一段。我们将每个bin中的所有段都提供给`max()`函数。我们提供给`max()`函数的`key`函数仅提取路段起点的纬度。
- en: 'This gives us a short list of the northernmost legs of each distance, as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个北部最远路段的简短列表，如下所示：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 6.3.5 Writing higher-order reductions
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.5 编写高阶减少
- en: We’ll look at an example of a higher-order reduction algorithm here. This will
    introduce a rather complex topic. The simplest kind of reduction develops a single
    value from a collection of values. Python has a number of built-in reductions,
    including `any()`, `all()`, `max()`, `min()`, `sum()`, and `len()`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里查看一个高阶减少算法的示例。这将引入一个相当复杂的话题。最简单的减少类型是从值集合中发展出一个单一值。Python有几个内置的减少，包括`any()`、`all()`、`max()`、`min()`、`sum()`和`len()`。
- en: 'As we noted in [Chapter 4](Chapter_04.xhtml#x1-740004), [Working with Collections](Chapter_04.xhtml#x1-740004),
    we can do a great deal of statistical calculation if we start with a few reductions
    such as the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第4章](Chapter_04.xhtml#x1-740004)中提到的[使用集合](Chapter_04.xhtml#x1-740004)，如果我们从以下几种减少开始，我们可以进行大量的统计计算：
- en: '[PRE34]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This allows us to define mean, standard deviation, normalized values, correction,
    and even least-squares linear regression, building on these base reduction functions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许我们定义平均值、标准差、归一化值、校正，甚至最小二乘线性回归，基于这些基础减少函数。
- en: 'The last of our reductions, `sum_x2()`, shows how we can apply existing reductions
    to create higher-order functions. We might change our approach to be more like
    the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后的减少`sum_x2()`展示了我们如何应用现有的减少来创建高阶函数。我们可能会改变我们的方法，使其更接近以下内容：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We’ve added a function, `function()`, as a parameter; the function can transform
    the data. This overall function, `sum_f()`, computes the sum of the transformed
    values.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了一个函数，`function()`，作为参数；该函数可以转换数据。这个整体函数，`sum_f()`，计算转换值的总和。
- en: 'Now we can apply this function in three different ways to compute the three
    essential sums as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以以三种不同的方式应用此函数来计算三个基本求和如下：
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We’ve plugged in a small lambda to compute ∑ [x∈X]x⁰ = ∑ [x∈X]1, which is the
    count, ∑ [x∈X]x¹ = ∑ [x∈X]x, the sum, and ∑ [x∈X]x², the sum of the squares, which
    we can use to compute standard deviation.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们插入了一个小的lambda来计算 ∑ [x∈X]x⁰ = ∑ [x∈X]1，这是计数，∑ [x∈X]x¹ = ∑ [x∈X]x，求和，以及 ∑ [x∈X]x²，平方和，我们可以使用这些来计算标准差。
- en: 'A common extension to this includes a filter to reject raw data that is unknown
    or unsuitable in some way. We might use the following function to reject bad data:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对此的一个常见扩展包括一个过滤器来拒绝某些方式未知或不合适的原始数据。我们可能使用以下函数来拒绝不良数据：
- en: '[PRE37]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following function definition for computing a mean will reject `None` values
    in a simple way:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下用于计算平均值的函数定义将以简单的方式拒绝`None`值：
- en: '[PRE38]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This shows how we can provide two distinct combinations of lambdas to our `sum_filter_f()`
    function. The filter argument is a lambda that rejects `None` values; we’ve called
    it `valid` to emphasize its meaning. The function argument is a lambda that implements
    a count or a sum operation. We can easily add a lambda to compute a sum of squares.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了我们可以向`sum_filter_f()`函数提供两种不同的lambda组合。过滤器参数是一个拒绝`None`值的lambda；我们将其称为`valid`以强调其含义。函数参数是一个实现计数或求和操作的lambda。我们可以轻松地添加一个lambda来计算平方和。
- en: The reuse of a common `valid` rule assures that the various computations are
    all identical in applying any filters to the source data. This can be combined
    with a user-selected filter criteria to provide a tidy plug-in to compute a number
    of statistics related to a user’s requested subset of the data.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 重复使用一个常见的`valid`规则确保在应用任何过滤器到源数据时，各种计算都是相同的。这可以与用户选择的过滤器标准相结合，提供一个整洁的插件来计算与用户请求的数据子集相关的多个统计数据。
- en: 6.3.6 Writing file parsers
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.6 编写文件解析器
- en: 'We can often consider a file parser to be a kind of reduction. Many languages
    have two levels of definition: the lower-level tokens in the language and the
    higher-level structures built from those tokens. When looking at an XML file,
    the tags, tag names, and attribute names form this lower-level syntax; the structures
    which are described by XML form a higher-level syntax.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常可以将文件解析器视为一种还原。许多语言有两个级别的定义：语言中的低级标记和由这些标记构建的高级结构。当我们查看XML文件时，标签、标签名称和属性名称形成这种低级语法；由XML描述的结构形成一个高级语法。
- en: 'The lower-level lexical scanning is a kind of reduction that takes individual
    characters and groups them into tokens. This fits well with Python’s generator
    function design pattern. We can often write functions that look as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 低级词法扫描是一种将单个字符分组为标记的还原过程。这与Python的生成器函数设计模式非常契合。我们经常可以编写如下所示的功能：
- en: '[PRE39]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: For well-known file formats, we’ll use existing file parsers. For data in CSV,
    JSON, XML, or TOML format, we don’t need to write file parsers. Most of these
    modules have a `load()` method that produces useful Python objects.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于众所周知的文件格式，我们将使用现有的文件解析器。对于CSV、JSON、XML或TOML格式的数据，我们不需要编写文件解析器。这些模块中的大多数都有一个`load()`方法，该方法生成有用的Python对象。
- en: In some cases, we’ll need to combine the results of this parsing into higher-level
    objects, useful for our specific application. While the CSV parser provides individual
    rows, these might need to be used to create `NamedTuple` instances, or perhaps
    some other class of immutable Python objects. Our examples of trip data, starting
    in [Chapter 4](Chapter_04.xhtml#x1-740004), [Working with Collections](Chapter_04.xhtml#x1-740004),
    are combined into higher-level objects, legs of a journey, by an algorithm that
    combines waypoints into pairs. When we introduce more complex decision-making,
    we make a transition from restructuring into parsing.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们需要将此解析的结果组合成更高层次的对象，这些对象对我们特定的应用是有用的。虽然CSV解析器提供单个行，但这些可能需要用于创建`NamedTuple`实例，或者可能是其他不可变Python对象。我们的行程数据示例，从[第4章](Chapter_04.xhtml#x1-740004)
    [使用集合](Chapter_04.xhtml#x1-740004)开始，通过将航点组合成对的一个算法组合成更高层次的对象，即旅程的段落。当我们引入更复杂的决策时，我们就从重构过渡到解析。
- en: 'In order to provide useful waypoints in the first place, we needed to parse
    a source file. In these examples, the input was a KML file; KML is an XML representation
    of geographic information. The essential features of the parser look similar to
    the following definition:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了首先提供有用的航点，我们需要解析源文件。在这些示例中，输入是一个 KML 文件；KML 是地理信息的 XML 表示。解析器的基本功能看起来类似于以下定义：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The bulk of the `row_iter_kml()` function is the XML parsing that allows us
    to use the `doc.findall()` function to iterate through the `<ns0:coordinates>`
    tags in the document. We’ve used a function named `comma_split()` to parse the
    text of this tag into a three-tuple of values.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`row_iter_kml()` 函数的主体是 XML 解析，这使得我们可以使用 `doc.findall()` 函数遍历文档中的 `<ns0:coordinates>`
    标签。我们使用了一个名为 `comma_split()` 的函数来解析这个标签的文本内容，将其解析为包含三个值的元组。'
- en: The `cast()` function is only present to provide evidence to mypy that the value
    of `coordinates.text` is a `str` object. The default definition of the text attribute
    is `Union[str,` `bytes]`; in this application, the data will be `str` exclusively.
    The `cast()` function doesn’t do any runtime processing.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`cast()` 函数仅存在以向 mypy 提供证据，表明 `coordinates.text` 的值是一个 `str` 对象。文本属性的默认定义是
    `Union[str, bytes]`；在此应用中，数据将是 `str` 独有的。`cast()` 函数不执行任何运行时处理。'
- en: 'This function focused on working with the normalized XML structure. The document
    is close to the database designer’s definitions of first normal form: each attribute
    is atomic (a single value), and each row in the XML data has the same columns
    with data of a consistent type. The data values aren’t fully atomic, however:
    we have to split the points on the , to separate longitude, latitude, and altitude
    into atomic string values. However, the text value for these XML tags is internally
    consistent, making it a close fit with first normal form.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数专注于与规范化的 XML 结构一起工作。文档接近数据库设计者对第一范式定义的描述：每个属性都是原子的（单个值），XML 数据中的每一行都具有相同的列，并且数据类型一致。然而，数据值并非完全原子：我们必须在逗号处拆分点，以将经度、纬度和海拔分离成原子的字符串值。然而，这些
    XML 标签的文本值在内部是一致的，这使得它与第一范式非常契合。
- en: A large volume of data—XML tags, attributes, and other punctuation—is reduced
    to a somewhat smaller volume, including just floating-point latitude and longitude
    values. For this reason, we can think of parsers as a kind of reduction.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 大量的数据——XML 标签、属性和其他标点符号——被减少到相对较小的体积，包括仅包含浮点纬度和经度值。因此，我们可以将解析器视为一种简化。
- en: 'We’ll need a higher-level set of conversions to map the tuples of text into
    floating-point numbers. Also, we’d like to discard altitude, and reorder longitude
    and latitude. This will produce the application-specific tuple we need. We can
    use functions as follows for this conversion:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一组高级转换来将文本元组映射到浮点数。此外，我们希望丢弃海拔，并重新排序经度和纬度。这将生成我们需要的特定于应用的元组。我们可以使用以下函数进行此转换：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The essential tool is the `float_lat_lon()` function. This is a higher-order
    function that returns a generator expression. The generator uses the `map()` function
    to apply the `float()` function conversion to the results of the `pick_lat_lon()`
    function, and the `*row` argument to assign each member of the row tuple to a
    different parameter of the `pick_lat_lon()` function. This only works when each
    row is a three-tuple. The `pick_lat_lon()` function then returns a two-tuple of
    the selected items in the required order.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的工具是 `float_lat_lon()` 函数。这是一个高阶函数，它返回一个生成器表达式。生成器使用 `map()` 函数将 `float()`
    函数转换应用于 `pick_lat_lon()` 函数的结果，并使用 `*row` 参数将行元组的每个成员分配给 `pick_lat_lon()` 函数的不同参数。这仅在每一行是三个元组时才有效。然后
    `pick_lat_lon()` 函数返回一个所需顺序的选定项的两元组。
- en: 'The source includes XML that looks like this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 源文件包含如下所示的 XML：
- en: '[PRE42]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can use this parser as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样使用这个解析器：
- en: '[PRE43]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This will build a tuple-of-tuples representation of each waypoint along the
    path in the original KML file. The result will be a flat sequence of pairs that
    looks like this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这将构建原始 KML 文件中每个航点的元组表示。结果将是一个看起来像这样的平坦序列对：
- en: '[PRE44]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `float_lat_lon()` function uses a low-level XML parser to extract rows of
    text data from the original representation. It uses a higher-level parser to transform
    the text items into more useful tuples of floating-point values suitable for the
    target application.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`float_lat_lon()` 函数使用低级 XML 解析器从原始表示中提取文本数据行。它使用高级解析器将文本项转换为更有用的浮点数值元组，这些值适用于目标应用。'
- en: Parsing CSV files
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 解析 CSV 文件
- en: 'In [Chapter 3](Chapter_03.xhtml#x1-510003), [Functions, Iterators, and Generators](Chapter_03.xhtml#x1-510003),
    we saw another example where we parsed a CSV file that was not in a normalized
    form: we had to discard header rows to make it useful. To do this, we used a function
    that extracted the header and returned an iterator over the remaining rows.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](Chapter_03.xhtml#x1-510003)，[函数、迭代器和生成器](Chapter_03.xhtml#x1-510003)中，我们看到了另一个示例，其中我们解析了一个非规范化的CSV文件：我们必须丢弃标题行以使其有用。为此，我们使用了一个提取标题并返回剩余行迭代器的函数。
- en: 'The data looks as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下所示：
- en: '[PRE45]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The columns are separated by tab characters. Plus, there are three rows of headers
    that we can discard.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 列由制表符分隔。此外，还有三行标题，我们可以丢弃。
- en: 'Here’s another version of that CSV-based parser. We’ve broken it into three
    functions. The first, `row_iter_csv()` function, returns the iterator over the
    rows in a tab-delimited file. The function looks as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这个基于CSV的解析器的另一个版本。我们将其分解为三个函数。第一个函数是`row_iter_csv()`，它返回一个制表符分隔的文件中行的迭代器。该函数如下所示：
- en: '[PRE46]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This is a small wrapper around the CSV parsing process. When we look back at
    the previous parsers for XML and plain text, this was the kind of thing that was
    missing from those parsers. Producing an iterable over row tuples can be a common
    feature of parsers for normalized data.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个围绕CSV解析过程的小型包装器。当我们回顾之前的XML和纯文本解析器时，这就是那些解析器所缺少的东西。生成行元组的可迭代对象可以是规范化数据解析器的常见功能。
- en: Once we have a row of tuples, we can pass rows that contain usable data and
    reject rows that contain other metadata, such as titles and column names. We’ll
    introduce a helper function that we can use to do some of the parsing, plus a
    `filter()` function to validate a row of data.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一行元组，我们就可以传递包含可用数据的行，并拒绝包含其他元数据（如标题和列名）的行。我们将介绍一个辅助函数，我们可以用它来进行一些解析，以及一个`filter()`函数来验证数据行。
- en: 'Following is the conversion:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是转换：
- en: '[PRE47]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This function handles the conversion of a single string to float values, converting
    bad data to a `None` value. The type hint of `float`` |`` None` expresses the
    idea of having a value of the given type or having a value of the same type as
    `None`. This can also be stated as `Union[float,`` None]` to show how the result
    is a union of different alternative types.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数处理将单个字符串转换为浮点值，将不良数据转换为`None`值。`float` | `None`的类型提示表达了具有给定类型值或具有与`None`相同类型的值的想法。这也可以表述为`Union[float,
    None]`，以显示结果是如何成为不同替代类型的联合。
- en: 'We can embed the `float_none()` function in a mapping so that we convert all
    columns of a row to a float or `None` value. A lambda for this looks as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`float_none()`函数嵌入映射中，以便将行的所有列转换为浮点数或`None`值。这个lambda表达式如下所示：
- en: '[PRE48]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Two type hints are used to make the definition of the `float_row()` function
    explicit. The `R_Float` hint defines the floating-point version of a row of data
    that may include `None` values.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义`float_row()`函数时使用了两个类型提示，以使其定义明确。`R_Float`提示定义了可能包含`None`值的行的浮点数版本。
- en: 'Following is a row-level validator based on the use of the `all()` function
    to ensure that all values are `float` (or none of the values are `None`):'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个基于`all()`函数的行级验证器，用于确保所有值都是`float`（或者没有值是`None`）：
- en: '[PRE49]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This lambda is a kind of reduction, transforming a row of floating-point values
    to a Boolean value if all values are not ”falsy” (that is, neither `None` nor
    zero) and there are exactly eight values.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这个lambda表达式是一种归约，如果所有值都不是“假值”（即，既不是`None`也不是零）并且恰好有八个值，则将浮点值行转换为布尔值。
- en: The simplistic `all_numeric()` function conflates zero and `None`. A more sophisticated
    test would rely on something such as `not`` any(item`` is`` None`` for`` item`` in`` row)`.
    The rewrite is left as an exercise for the reader.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的`all_numeric()`函数将零和`None`混淆。一个更复杂的测试将依赖于类似`not any(item is None for item
    in row)`的东西。重写留给读者作为练习。
- en: The essential design is to create row-based elements that can be combined to
    create more complete algorithms for parsing an input file. The foundational functions
    iterate over tuples of text. These are combined to convert and validate the converted
    data. For the cases where files are either in first normal form (all rows are
    the same) or a simple validator can reject the extraneous rows, this design pattern
    works out nicely.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 基本设计是创建基于行的元素，可以组合起来创建解析输入文件的更完整的算法。基础函数遍历文本元组。这些被组合起来以转换和验证转换后的数据。对于文件要么是第一范式（所有行都相同）或者简单验证器可以拒绝额外行的情况，这种设计模式运作得很好。
- en: All parsing problems aren’t quite this simple, however. Some files have important
    data in header or trailer rows that must be preserved, even though it doesn’t
    match the format of the rest of the file. These non-normalized files will require
    a more sophisticated parser design.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有解析问题都这么简单。一些文件在标题或尾部行中有重要数据必须保留，即使它不匹配文件其余部分的格式。这些非标准化文件将需要一个更复杂的解析器设计。
- en: Parsing plain text files with headers
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 解析带有标题的纯文本文件
- en: 'In [Chapter 3](Chapter_03.xhtml#x1-510003), [Functions, Iterators, and Generators](Chapter_03.xhtml#x1-510003),
    the `Crayola.GPL` file was presented without showing the parser. This file looks
    as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 3 章](Chapter_03.xhtml#x1-510003)，[函数、迭代器和生成器](Chapter_03.xhtml#x1-510003)
    中，`Crayola.GPL` 文件被展示出来，但没有显示解析器。这个文件看起来如下：
- en: '[PRE50]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We can parse a text file using regular expressions. We need to use a filter
    to read (and parse) header rows. We also want to return an iterable sequence of
    data rows. This rather complex two-part parsing is based entirely on the two-part—head
    and tail—file structure.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用正则表达式解析文本文件。我们需要使用过滤器来读取（并解析）标题行。我们还希望返回一个数据行的可迭代序列。这个相当复杂的两步解析完全基于两步——头部和尾部——文件结构。
- en: 'Following is a low-level parser that handles both the four lines of the header
    and the long tail:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个低级解析器，它处理标题的四行和长尾：
- en: '[PRE51]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `Head_Body` type definition summarizes the overall goal of the row iterator.
    The result is a two-tuple. The first item is a two-tuple with details from the
    file header. The second item is an iterator that provides the text items for a
    color definition. This `Head_Body` type hint is used in two places in this function
    definition.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '`Head_Body` 类型定义总结了行迭代器的总体目标。结果是两个元组。第一个元素是一个包含文件标题详细信息的两个元组。第二个元素是一个迭代器，提供颜色定义的文本项。这个
    `Head_Body` 类型提示在这个函数定义中使用了两个地方。'
- en: The `header_pat` regular expression parses all four lines of the header. There
    are instances of `()` in the expression to extract the name and column information
    from the header.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`header_pat` 正则表达式解析标题的所有四行。表达式中存在 `()` 的情况，用于从标题中提取名称和列信息。'
- en: There are two internal functions for parsing different parts of the file. The
    `read_head()` function parses the header lines and returns interesting text and
    a `TextIO` object that can be used for the rest of the parsing. It does this by
    reading four lines and merging them into a single long string. This is then parsed
    with the `header_pat` regular expression.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 文件解析有两个内部函数用于解析文件的不同部分。`read_head()` 函数解析标题行，并返回有趣的文本和一个可以用于其余解析的 `TextIO` 对象。它是通过读取四行并将它们合并成一个长字符串来做到这一点的。然后使用
    `header_pat` 正则表达式进行解析。
- en: The idea of returning the iterator from one function to be used in another function
    is a pattern for passing an explicitly stateful object from one function to another.
    It seems helpful to make sure all of the arguments for the `read_tail()` function
    are the results from the `read_head()` function.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个函数返回迭代器以在另一个函数中使用是一种将显式状态对象从一个函数传递到另一个函数的模式。确保 `read_tail()` 函数的所有参数都是 `read_head()`
    函数的结果似乎是有帮助的。
- en: The `read_tail()` function parses the iterator over the remaining lines. These
    lines are merely split on spaces, since that fits the description of the GPL file
    format.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_tail()` 函数解析剩余行的迭代器。这些行仅按空格分割，因为这与 GPL 文件格式的描述相符。'
- en: 'For more information, visit the following link: [https://code.google.com/p/grafx2/issues/detail?id=518](https://code.google.com/p/grafx2/issues/detail?id=518).'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请访问以下链接：[https://code.google.com/p/grafx2/issues/detail?id=518](https://code.google.com/p/grafx2/issues/detail?id=518)。
- en: Once we’ve transformed each line of the file into a canonical tuple-of-strings
    format, we can apply the higher level of parsing to this data. This involves conversion
    and (if necessary) validation.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将文件的每一行转换成规范化的字符串元组格式，我们就可以对这份数据应用高级解析。这涉及到转换（如果需要）和验证。
- en: 'The following is a higher-level parser command snippet:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个高级解析器命令片段：
- en: '[PRE52]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This function will work with the output of the lower-level `row_iter_gpl()`
    parser: it requires the headers and the iterator over individual rows. This function
    will use the multiple assignment feature of the `for` clause in the generator
    to separate the color numbers and the remaining words into four variables, `r`,
    `g`, `b`, and `name`. The use of the `*name` parameter ensures that all remaining
    values will be assigned to the `name` variable as a tuple. The `"`` ".join(name)`
    expression then concatenates the words into a single space-separated string.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将与低级`row_iter_gpl()`解析器的输出一起工作：它需要标题和单个行的迭代器。此函数将使用生成器中`for`子句的多个赋值功能，将颜色数字和剩余的单词分别分配到四个变量`r`、`g`、`b`和`name`中。使用`*name`参数确保所有剩余的值都将作为一个元组分配给`name`变量。然后`"`` ".join(name)`表达式将单词连接成一个空格分隔的字符串。
- en: 'The following is how we can use this two-tier parser:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用这个双层解析器的说明：
- en: '[PRE53]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We’ve applied the higher-level parser to the results of the lower-level parser.
    This will return the headers and a tuple built from the sequence of `Color` objects.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将高级解析器应用于低级解析器的结果。这将返回标题和一个由`Color`对象序列构建的元组。
- en: 6.4 Summary
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 摘要
- en: In this chapter, we’ve looked at two significant functional programming topics.
    We’ve looked at recursions in some detail. Many functional programming language
    compilers will optimize a recursive function to transform a call in the tail of
    the function to a loop. This is sometimes called tail recursion elimination. More
    commonly, it’s known as tail-call optimization. In Python, we must do the tail-call
    optimization manually by using an explicit `for` statement, replacing a purely
    functional recursion.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了两个重要的函数式编程主题。我们详细研究了递归。许多函数式编程语言编译器会优化递归函数，将函数尾部的调用转换为循环。这有时被称为尾递归消除。更常见的是，它被称为尾调用优化。在Python中，我们必须通过使用显式的`for`语句手动进行尾调用优化，以替换纯函数式递归。
- en: We’ve also looked at reduction algorithms, including `sum()`, `count()`, `max()`,
    and `min()` functions. We looked at the `collections.Counter()` function and related
    `groupby()` reductions.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了包括`sum()`、`count()`、`max()`和`min()`函数在内的简化算法。我们研究了`collections.Counter()`函数和相关`groupby()`简化。
- en: We’ve also looked at how parsing (and lexical scanning) are similar to reductions
    since they transform sequences of tokens (or sequences of characters) into higher-order
    collections with more complex properties. We’ve examined a design pattern that
    decomposes parsing into a lower level and tries to produce tuples of raw strings,
    and a higher level that creates more useful application objects.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了解析（和词法扫描）如何与简化相似，因为它们将标记序列（或字符序列）转换为具有更复杂属性的更高阶集合。我们检查了一个将解析分解为低级并尝试生成原始字符串元组的模式，以及一个创建更有用应用对象的更高级模式。
- en: In the next chapter, we’ll look at some techniques appropriate to working with
    named tuples and other immutable data structures. We’ll look at techniques that
    make stateful objects unnecessary. While stateful objects aren’t purely functional,
    the idea of a class hierarchy can be used to package related method definitions.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨适用于处理命名元组和其它不可变数据结构的技巧。我们将探讨使状态对象变得不必要的技巧。虽然状态对象不是纯函数式的，但类层次结构的概念可以用来封装相关的方法定义。
- en: 6.5 Exercises
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5 练习
- en: This chapter’s exercises are based on code available from Packt Publishing on
    GitHub. See [https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition](https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的练习基于GitHub上Packt Publishing提供的代码。请参阅[https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition](https://github.com/PacktPublishing/Functional-Python-Programming-3rd-Edition)。
- en: In some cases, the reader will notice that the code provided on GitHub includes
    partial solutions to some of the exercises. These serve as hints, allowing the
    reader to explore alternative solutions.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，读者会注意到GitHub上提供的代码包含了一些练习的部分解决方案。这些解决方案作为提示，允许读者探索替代方案。
- en: In many cases, exercises will need unit test cases to confirm they actually
    solve the problem. These are often identical to the unit test cases already provided
    in the GitHub repository. The reader should replace the book’s example function
    name with their own solution to confirm that it works.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，练习需要单元测试用例来确认它们确实解决了问题。这些通常与GitHub仓库中已提供的单元测试用例相同。读者应将书籍中的示例函数名称替换为自己的解决方案以确认其工作。
- en: 6.5.1 Multiple recursion and caching
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.1 多重递归和缓存
- en: In [Handling difficult tail-call optimization](#x1-1300003), we looked at a
    naive definition of a function to compute Fibonacci numbers, the `fib()` function.
    The `functools.cache` decorator can have a profound impact on the performance
    of this algorithm.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在[处理困难的尾调用优化](#x1-1300003)中，我们查看了一个计算斐波那契数的函数的原始定义，即`fib()`函数。`functools.cache`装饰器可以对算法的性能产生深远的影响。
- en: Implement both versions and describe the impact of caching on the time required
    to compute large Fibonacci numbers.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 实现两种版本，并描述缓存对计算大斐波那契数所需时间的影响。
- en: 6.5.2 Refactor the all_print() function
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.2 重构all_print()函数
- en: In [Tail-call optimization using deques](#x1-1350001), we showed a function
    that used a `collections.deque` to visit all nodes in a directory tree, summing
    the value for each node that is a proper file. This can be done with a list as
    well as a `deque`, with some minor code changes.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在[使用deque进行尾调用优化](#x1-1350001)中，我们展示了一个使用`collections.deque`遍历目录树中所有节点并计算每个正确文件的值的函数。这也可以使用列表以及`deque`完成，只需进行一些小的代码更改。
- en: 'This function embedded a specific computation. This computation (finding all
    occurrences of ”print”) really should have been a separate function. The body
    of the `all_print()` function should be refactored into two functions:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数嵌入了一个特定的计算。这个计算（查找所有“print”的实例）实际上应该是一个单独的函数。`all_print()`函数的主体应该重构为两个函数：
- en: A generic directory traverse that applies a function to each text file with
    the expected suffix and sums the results.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个通用的目录遍历，将一个函数应用于具有预期后缀的每个文本文件并汇总结果。
- en: A function that counts instances of ”print” in a given Python file.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个统计给定Python文件中“print”实例数量的函数。
- en: 6.5.3 Parsing CSV files
  id: totrans-298
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.3 解析CSV文件
- en: See the [Parsing CSV files](#x1-1430006) section, earlier in this chapter. In
    that example, the simplistic `all_numeric()` function conflates zero and `None`.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅本章前面的[解析CSV文件](#x1-1430006)部分。在那个例子中，简单的`all_numeric()`函数将零和`None`混淆。
- en: Create a test case for this function that will show that it does not handle
    zero correctly, treating it as `None`. Once the test case is defined, rewrite
    the `all_numeric()` function to distinguish between zero and `None`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 为此函数创建一个测试用例，以显示它没有正确处理零，将其视为`None`。一旦测试用例定义好，重新编写`all_numeric()`函数以区分零和`None`。
- en: Note that it’s common practice in Python to use the `is` operator when comparing
    with `None`. This specifically avoids some subtle problems that can arise when
    a class has an implementation of `__eq__()` that doesn’t handle `None` as a properly
    distinct object.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在Python中，使用`is`运算符与`None`进行比较是一种常见做法。这特别避免了当类有一个不正确处理`None`作为独立对象的`__eq__()`实现时可能出现的微妙问题。
- en: 6.5.4 Classification of state, Part III
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.4 状态分类，第三部分
- en: See [Chapter 5](Chapter_05.xhtml#x1-1000005), [Higher-Order Functions](Chapter_05.xhtml#x1-1000005),
    the [Classification of state](Chapter_05.xhtml#x1-1220001) exercise.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[第5章](Chapter_05.xhtml#x1-1000005)，[高阶函数](Chapter_05.xhtml#x1-1000005)，[状态分类](Chapter_05.xhtml#x1-1220001)练习。
- en: There’s a third way to consume status details and summarize them.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 消费状态详情并总结的第三种方法。
- en: Write a reduce computation. This starts with an initial state of Running. As
    each service’s three-tuple is folded into the result, there is a comparison between
    the state and the three-tuple. If the three-tuple has a non-responsive service,
    the state advances to Stopped. If the three-tuple has a slow or not working service,
    the state advances to Degraded. If no problems are found, the initial value becomes
    the final health of the overall system.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个reduce计算。这从运行状态开始。随着每个服务的三元组折叠到结果中，状态与三元组之间进行比较。如果三元组包含一个无响应的服务，状态将前进到停止。如果三元组包含一个慢或无法工作的服务，状态将前进到降级。如果没有发现问题，初始值将成为整个系统的最终健康状态。
- en: The idea is to provide a `status_add(previous,`` this_service)` function. This
    can be used in the context of `status`` =`` reduce(status_add,`` service_status_sequence,`` "Running")`
    to compute the current status of the sequence of services.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 策略是提供一个 `status_add(previous, this_service)` 函数。这个函数可以在 `status = reduce(status_add,
    service_status_sequence, "Running")` 的上下文中使用，以计算服务序列的当前状态。
- en: 6.5.5 Diesel engine data
  id: totrans-307
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.5 柴油机数据
- en: A diesel engine has had some repairs that raised doubts about the accuracy of
    the tachometer. After some heroic effort, the following table of data was collected
    showing the observed reading on the engine’s tachometer, and the actual RPMs measured
    with an optical device on the engine.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 一台柴油发动机进行了一些维修，这引起了人们对转速表准确性的怀疑。经过一些英勇的努力，收集到了以下表格中的数据，显示了发动机转速表上的观察读数，以及使用发动机上的光学设备测量的实际
    RPM 值。
- en: '| Sample | Tach | Engine |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 样本 | 转速 | 发动机 |'
- en: '| 1 | 1000 | 883 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1000 | 883 |'
- en: '| 2 | 1500 | 1242 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1500 | 1242 |'
- en: '| 3 | 1500 | 1217 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1500 | 1217 |'
- en: '| 4 | 1600 | 1306 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1600 | 1306 |'
- en: '| 5 | 1750 | 1534 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1750 | 1534 |'
- en: '| 6 | 2000 | 1805 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 2000 | 1805 |'
- en: '| 7 | 2000 | 1720 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 2000 | 1720 |'
- en: '|  |  |  |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: If needed, create a CSV file with the data. If you have access to the GitHub
    repository for this book, this is available in the `engine.csv` file.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，创建一个包含数据的 CSV 文件。如果您有访问本书 GitHub 仓库的权限，这些数据可以在 `engine.csv` 文件中找到。
- en: Create a `NamedTuple` for each sample and write some functions to acquire this
    data in a useful form. Once the data is available, see the [Using sums and counts
    for statistics](Chapter_04.xhtml#x1-850001) section of [Chapter 4](Chapter_04.xhtml#x1-740004),
    [Working with Collections](Chapter_04.xhtml#x1-740004), for a definition of a
    correlation function.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个样本创建一个 `NamedTuple`，并编写一些函数以获取这些数据的有用形式。一旦数据可用，请参阅[第 4 章](Chapter_04.xhtml#x1-740004)，[使用集合](Chapter_04.xhtml#x1-740004)中的[使用总和和计数进行统计](Chapter_04.xhtml#x1-850001)部分，了解相关函数的定义。
- en: The objective is to apply this correlation function to the engine and tach values
    to see if the values correlate. If they do, it suggests that the engine’s instruments
    can be recalibrated. If they don’t correlate, something else is wrong with the
    engine.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是将此相关函数应用于发动机和转速值，以查看它们是否相关。如果它们相关，则表明发动机的仪表可以重新校准。如果不相关，则表明发动机存在其他问题。
- en: Note that the [Chapter 4](Chapter_04.xhtml#x1-740004), [Working with Collections](Chapter_04.xhtml#x1-740004),
    correlation example may have assumptions about data types that don’t necessarily
    apply to the `NamedTuple` defined earlier. If necessary, rewrite the type hints
    or your `NamedTuple` definition. Note that it can be difficult to write perfectly
    generic type hints, and it often takes a bit of work to resolve the differences.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，[第 4 章](Chapter_04.xhtml#x1-740004)，[使用集合](Chapter_04.xhtml#x1-740004)的相关示例可能对数据类型有一些假设，这些假设不一定适用于之前定义的
    `NamedTuple`。如果需要，请重写类型提示或您的 `NamedTuple` 定义。请注意，编写完全通用的类型提示可能很困难，通常需要一些工作来解决差异。
- en: Join our community Discord space
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间
- en: 'Join our Python Discord workspace to discuss and know more about the book:
    [https://packt.link/dHrHU](https://packt.link/dHrHU)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Python Discord 工作空间，讨论并了解更多关于本书的信息：[https://packt.link/dHrHU](https://packt.link/dHrHU)
- en: '![PIC](img/file1.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
