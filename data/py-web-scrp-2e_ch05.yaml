- en: Dynamic Content
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态内容
- en: According to a 2006 study by the United Nations, 73 percent of leading websites
    rely on JavaScript for important functionalities (refer to [http://www.un.org/esa/socdev/enable/documents/execsumnomensa.doc](http://www.un.org/esa/socdev/enable/documents/execsumnomensa.doc)).
    The growth and popularity of model-view-controller (or MVC) frameworks within
    JavaScript such as React, AngularJS, Ember, Node and many more have only increased
    the importance of JavaScript as the primary engine for web page content.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 根据联合国2006年的一项研究，73%的主要网站依赖于JavaScript来实现重要功能（参考[http://www.un.org/esa/socdev/enable/documents/execsumnomensa.doc](http://www.un.org/esa/socdev/enable/documents/execsumnomensa.doc)）。在JavaScript中，如React、AngularJS、Ember、Node等模型-视图-控制器（MVC）框架的增长和普及，进一步增加了JavaScript作为网页内容主要引擎的重要性。
- en: The use of JavaScript can vary from simple form events to single page apps that
    download the entire page content after loading. One consequence of this architecture
    is the content may not available in the original HTML, and the scraping techniques
    we've covered so far will not extract the important information on the site.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript的使用可以从简单的表单事件到单页应用，在加载后下载整个页面内容。这种架构的一个后果是内容可能不在原始HTML中，而我们之前介绍过的抓取技术将无法提取网站上的重要信息。
- en: 'This chapter will cover two approaches to scraping data from dynamic JavaScript
    websites. These are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍两种从动态JavaScript网站抓取数据的方法。具体如下：
- en: Reverse engineering JavaScript
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反向工程JavaScript
- en: Rendering JavaScript
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 渲染JavaScript
- en: An example dynamic web page
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个示例动态网页
- en: 'Let''s look at an example dynamic web page. The example website has a search
    form, which is available at [http://example.webscraping.com/search](http://example.webscraping.com/search),
    which is used to locate countries. Let''s say we want to find all the countries
    that begin with the letter A:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个示例动态网页。这个示例网站有一个搜索表单，位于[http://example.webscraping.com/search](http://example.webscraping.com/search)，用于定位国家。假设我们想找到所有以字母A开头的国家：
- en: '![](img/4364OS_05_02.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4364OS_05_02.png)'
- en: 'If we right-click on these results to inspect them with our browser tools (as
    covered in [Chapter 2](py-web-scrp-2e_ch02.html), *Scraping the Data*), we would
    find the results are stored within a `div` element with ID `"results"`:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们右键点击这些结果，并使用我们的浏览器工具（如[第2章](py-web-scrp-2e_ch02.html)，*抓取数据*中所述）检查它们，我们会发现结果存储在一个ID为`"results"`的`div`元素中：
- en: '![](img/4364OS_05_03.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4364OS_05_03.png)'
- en: 'Let''s try to extract these results using the `lxml` module, which was also
    covered in [Chapter 2](py-web-scrp-2e_ch02.html), *Scraping the Data*, and the
    `Downloader` class from [Chapter 3](py-web-scrp-2e_ch03.html), *Caching Downloads*:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用`lxml`模块来提取这些结果，这个模块在[第2章](py-web-scrp-2e_ch02.html)，*抓取数据*中也有介绍，以及来自[第3章](py-web-scrp-2e_ch03.html)，*缓存下载*的`Downloader`类：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The example scraper here has failed to extract results. Examining the source
    code of this web page (by using the right-click View Page Source option instead
    of using the browser tools) can help you understand why. Here, we find the `div`
    element we are trying to scrape is empty:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里示例的抓取器未能提取结果。通过检查这个网页的源代码（使用右键点击“查看页面源代码”选项而不是使用浏览器工具）可以帮助你理解原因。在这里，我们发现我们试图抓取的`div`元素是空的：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Our browser tools give us a view of the current state of the web page. In this
    case, it means the web page has used JavaScript to load search results dynamically.
    In the next section, we will use another feature of our browser tools to understand
    how these results are loaded.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的浏览器工具为我们提供了网页当前状态的一个视图。在这种情况下，这意味着网页使用了JavaScript动态加载搜索结果。在下一节中，我们将使用浏览器工具的另一个功能来了解这些结果是如何加载的。
- en: What is AJAX?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是AJAX？
- en: '**AJAX** stands for **Asynchronous JavaScript and XML** and was coined in 2005
    to describe the features available across web browsers that make dynamic web applications
    possible. Most importantly, the JavaScript `XMLHttpRequest` object, which was
    originally implemented by Microsoft for ActiveX, became available in many common
    web browsers. This allowed JavaScript to make HTTP requests to a remote server
    and receive responses, which meant that a web application could send and receive
    data.  The previous way to communicate between client and server was to refresh
    the entire web page, which resulted in a poor user experience and wasted bandwidth
    when only a small amount of data needed to be transmitted.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**AJAX**代表**异步JavaScript和XML**，于2005年提出，用于描述跨浏览器可用的功能，这些功能使得动态网络应用成为可能。最重要的是，原本由微软为ActiveX实现的JavaScript
    `XMLHttpRequest`对象，在许多常见的网络浏览器中变得可用。这使得JavaScript能够向远程服务器发送HTTP请求并接收响应，这意味着网络应用可以发送和接收数据。之前客户端和服务器之间通信的方式是刷新整个网页，这导致当只需要传输少量数据时，用户体验不佳且带宽浪费。'
- en: Google's Gmail and Maps sites were early examples of the dynamic web applications
    and helped make AJAX mainstream.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的Gmail和地图网站是动态网络应用的早期例子，并帮助使AJAX成为主流。
- en: Reverse engineering a dynamic web page
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向工程动态网页
- en: 'So far, we tried to scrape data from a web page the same way as introduced
    in [Chapter 2](py-web-scrp-2e_ch02.html), *Scraping the Data*. This method did
    not work because the data is loaded dynamically using JavaScript. To scrape this
    data, we need to understand how the web page loads the data, a process which can
    be described as reverse engineering. Continuing the example from the preceding
    section, in our browser tools, if we click on the Network tab and then perform
    a search, we will see all of the requests made for a given page. There are a lot!
    If we scroll up through the requests, we see mainly photos (from loading country
    flags), and then we notice one with an interesting name: `search.json` with a
    path of `/ajax`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们尝试以与第2章中介绍的方法相同的方式从网页中抓取数据，*抓取数据*。这种方法没有奏效，因为数据是使用JavaScript动态加载的。为了抓取这些数据，我们需要了解网页如何加载数据，这个过程可以描述为反向工程。继续前一小节中的例子，在我们的浏览器工具中，如果我们点击“网络”标签并执行搜索，我们将看到针对给定页面的所有请求。请求非常多！如果我们滚动查看请求，我们看到主要是图片（来自加载国家标志），然后我们注意到一个有趣的名称：“search.json”，路径为`/ajax`：
- en: '![](img/network_view.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/network_view.png)'
- en: 'If we click on that URL using Chrome, we can see more details (there is similar
    functionality for this in all major browsers, so your view may vary; however the
    main features should function similarly). Once we click on the URL of interest,
    we can see more details, including a preview which shows us the response in parsed
    form. Here, similar to the Inspect Element view in our Elements tab, we use the
    carrots to expand the preview and see that each country of our results is included
    in JSON form:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用Chrome点击该URL，我们可以看到更多详细信息（所有主要浏览器都有类似的功能，所以你的视图可能会有所不同；然而，主要功能应该以类似的方式工作）。一旦我们点击感兴趣的URL，我们就可以看到更多详细信息，包括一个预览，它以解析形式显示给我们响应。在这里，类似于我们在元素标签页中的“检查元素”视图，我们使用胡萝卜来展开预览，并看到我们的结果中的每个国家都以JSON形式包含：
- en: '![](img/preview_ajax.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/preview_ajax.png)'
- en: 'We can also open the URL directly by right-clicking and opening the URL in
    a new tab. When you do so, you will see it as a simple JSON response. This AJAX
    data is not only accessible from within the Network tab or via a browser, but
    can also be downloaded directly, as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过右键单击并在新标签页中打开URL来直接打开该URL。当你这样做时，你会看到它是一个简单的JSON响应。这种AJAX数据不仅可以从“网络”标签或通过浏览器访问，还可以直接下载，如下所示：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As we can see from the previous code, the `requests` library allows us to access
    JSON responses as a Python dictionary by using the `json` method. We could also
    download the raw string response and load it using Python's `json.loads` method.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的代码所示，`requests`库允许我们通过使用`json`方法将JSON响应作为Python字典访问。我们也可以下载原始字符串响应，并使用Python的`json.loads`方法加载它。
- en: Our code gives us a simple way to scrape countries containing the letter `A`.
    To find the details of the countries requires calling the AJAX search with each
    letter of the alphabet. For each letter, the search results are split into pages,
    and the number of pages is indicated by `page_size` in the response.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码为我们提供了一个简单的方法来抓取包含字母“A”的国家。要找到这些国家的详细信息，需要调用带有字母表中每个字母的AJAX搜索。对于每个字母，搜索结果被分成页面，页数由响应中的`page_size`指示。
- en: Unfortunately, we cannot save all results returned because the same countries
    will be returned in multiple searches-for example, `Fiji` matches searches for
    `f`, `i`, and `j`. These duplicates are filtered here by storing results in a
    set before writing them to a text file-the set data structure ensures unique elements.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法保存所有返回的结果，因为相同的国家会在多次搜索中返回——例如，`Fiji`与对`f`、`i`和`j`的搜索匹配。这些重复的结果在这里通过在写入文本文件之前将结果存储在集合中来过滤——集合数据结构确保了唯一元素。
- en: Here is an example implementation that scrapes all of the countries by searching
    for each letter of the alphabet and then iterating the resulting pages of the
    JSON responses. The results are then stored in a simple text file.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个示例实现，通过搜索字母表中的每个字母并迭代JSON响应的结果页面来抓取所有国家。然后，结果存储在一个简单的文本文件中。
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you run the code, you will see progressive output:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行代码时，你会看到逐步的输出：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once the script is completed, the `countries.txt` file in the relative folder `../data/`
    will show a sorted list of the country names. You may also note the page length
    can be set using the `PAGE_SIZE` global variable. You may want to try toggling
    this to increase or decrease the number of requests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦脚本完成，相对文件夹`../data/`中的`countries.txt`文件将显示国家名称的排序列表。你也许会注意到页面长度可以通过`PAGE_SIZE`全局变量来设置。你可能想尝试切换这个值来增加或减少请求数量。
- en: 'This AJAX scraper provides a simpler way to extract the country details than
    the traditional page-by-page scraping approach covered in [Chapter 2](py-web-scrp-2e_ch02.html),
    *Scraping the Data*. This is a common experience: AJAX-dependent websites initially
    look more complex, however their structure encourages separating the data and
    presentation layers, which can actually make our job of extracting data easier.
    If you find a site with an open Application Programming Interface (or API) like
    this example site, you can simply scrape the API rather than using CSS selectors
    and XPath to load data from HTML.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个AJAX爬虫提供了一种比在[第2章](py-web-scrp-2e_ch02.html)“抓取数据”中介绍的逐页爬取方法更简单的方式来提取国家详情。这是一个常见的经验：依赖于AJAX的网站最初看起来更复杂，然而它们的结构鼓励分离数据层和表示层，这实际上可以使我们提取数据的工作更容易。如果你找到一个像这个示例网站一样有公开应用程序编程接口（或API）的网站，你可以简单地爬取API而不是使用CSS选择器和XPath从HTML中加载数据。
- en: Edge cases
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边界情况
- en: 'The AJAX search script is quite simple, but it can be simplified further by
    utilizing possible edge cases. So far, we have queried each letter, which means
    26 separate queries, and there are duplicate results between these queries. It
    would be ideal if a single search query could be used to match all results. We
    will try experimenting with different characters to see if this is possible. This
    is what happens if the search term is left empty:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: AJAX搜索脚本相当简单，但可以通过利用可能的边界情况进一步简化。到目前为止，我们已经查询了每个字母，这意味着有26个单独的查询，并且这些查询之间存在重复结果。如果可以使用单个搜索查询匹配所有结果将是非常理想的。我们将尝试用不同的字符进行实验，看看这是否可能。如果搜索词为空，会发生以下情况：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Unfortunately, this did not work-there are no results. Next we will check if
    ''*'' will match all results:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这并没有奏效——没有结果。接下来我们将检查是否“*”可以匹配所有结果：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Still no luck. Then we check `''.''`, which is a regular expression to match
    any character:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然没有成功。然后我们检查`'.'`，这是一个匹配任何字符的正则表达式：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Perfect! The server must be matching results using regular expressions. So,
    now searching each letter can be replaced with a single search for the dot character.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 完美！服务器必须是在使用正则表达式匹配结果。所以，现在搜索每个字母可以替换为对点字符的单次搜索。
- en: Furthermore, we can set the page size in the AJAX URLs using the `page_size`
    query string value. The web site search interface has options for setting this
    to 4, 10, and 20, with the default set to 10\. So, the number of pages to download
    could be halved by increasing the page size to the maximum.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以在AJAX URL中使用`page_size`查询字符串值来设置页面大小。网站搜索界面有设置此值为4、10和20的选项，默认设置为10。因此，通过将页面大小增加到最大值，可以减少下载的页面数量。
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, what if a much higher page size is used, a size higher than what the web
    interface select box supports?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果使用比网页界面选择框支持的更大的页面大小会怎样呢？
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Apparently, the server does not check whether the page size parameter matches
    the options allowed in the interface and now returns all the results in a single
    page. Many web applications do not check the page size parameter in their AJAX
    backend because they expect all API requests to only come via the web interface.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，服务器没有检查页面大小参数是否与接口中允许的选项匹配，现在在单页中返回所有结果。许多Web应用程序在其AJAX后端不检查页面大小参数，因为它们期望所有API请求都通过Web界面进行。
- en: 'Now, we have crafted a URL to download the data for all countries in a single
    request. Here is the updated and much simpler implementation which saves the data
    to a CSV file:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经构建了一个URL，以单次请求下载所有国家的数据。以下是更新后的、更简单的实现，它将数据保存到CSV文件中：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Rendering a dynamic web page
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渲染动态网页
- en: For the example search web page, we were able to quickly reverse engineer how
    the API worked and how to use it to retrieve the results in one request. However,
    websites can be very complex and difficult to understand, even with advanced browser
    tools. For example, if the website has been built with **Google Web Toolkit**
    (**GWT**), the resulting JavaScript code will be machine-generated and minified.
    This generated JavaScript code can be cleaned with a tool such as `JS beautifier`,
    but the result will be verbose and the original variable names will be lost, so
    it is difficult to understand and reverse engineer.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于示例搜索网页，我们能够快速逆向工程API的工作原理以及如何使用它来在一次请求中检索结果。然而，网站可能非常复杂且难以理解，即使有高级浏览器工具。例如，如果网站是用**Google
    Web Toolkit**（**GWT**）构建的，生成的JavaScript代码将是机器生成的和压缩的。可以使用像`JS beautifier`这样的工具清理生成的JavaScript代码，但结果将是冗长的，原始变量名将丢失，因此难以理解和逆向工程。
- en: Additionally, higher level frameworks like `React.js` and other Node.js-based
    tools can further abstract already complex JavaScript logic and obfuscate data
    and variable names and add more layers of API request security (by requiring cookies,
    browser sessions and timestamps or using other anti-scraper technologies).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，像`React.js`这样的高级框架以及其他基于Node.js的工具可以进一步抽象复杂的JavaScript逻辑，模糊数据变量名，并添加更多层API请求安全（通过要求cookies、浏览器会话和时间戳或使用其他反爬虫技术）。
- en: With enough effort, any website can be reverse engineered. However, this effort
    can be avoided by instead using a browser rendering engine, which is the part
    of the web browser that parses HTML, applies the CSS formatting, and executes
    JavaScript to display a web page. In this section, the WebKit rendering engine
    will be used, which has a convenient Python interface through the Qt framework.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 经过足够的努力，任何网站都可以被逆向工程。然而，可以通过使用浏览器渲染引擎来避免这种努力，这是网络浏览器解析HTML、应用CSS格式和执行JavaScript以显示网页的部分。在本节中，将使用WebKit渲染引擎，它通过Qt框架提供了一个方便的Python接口。
- en: What is WebKit?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: WebKit是什么？
- en: The code for WebKit started life as the KHTML project in 1998, which was the
    rendering engine for the Konqueror web browser. It was then forked by Apple as
    WebKit in 2001 for use in their Safari web browser. Google used WebKit up to Chrome
    Version 27 before forking their version from WebKit called **Blink** in 2013\.
    Opera originally used their internal rendering engine called **Presto** from 2003
    to 2012 before briefly switching to WebKit, and then followed Chrome to Blink.
    Other popular browser rendering engines are **Trident,** used by Internet Explorer,
    and **Gecko** by Firefox.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: WebKit的代码最初起源于1998年的KHTML项目，它是Konqueror网络浏览器的渲染引擎。随后，苹果公司在2001年将其分支为WebKit，用于其Safari网络浏览器。谷歌公司一直使用WebKit直到Chrome版本27，然后在2013年从WebKit分支出自己的版本，称为**Blink**。Opera最初从2003年到2012年使用其内部渲染引擎**Presto**，之后短暂切换到WebKit，然后跟随Chrome使用Blink。其他流行的浏览器渲染引擎包括由Internet
    Explorer使用的**Trident**和Firefox使用的**Gecko**。
- en: PyQt or PySide
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyQt或PySide
- en: There are two available Python bindings to the Qt framework, `PyQt` and `PySide`.
    `PyQt` was first released in 1998 but requires a license for commercial projects.
    Due to this licensing problem, the company developing Qt, then Nokia and now Digia,
    later developed Python bindings in 2009 called `PySide` and released it under
    the more permissive LGPL license.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种Python绑定到Qt框架，`PyQt`和`PySide`。`PyQt`于1998年首次发布，但商业项目需要许可证。由于这个许可问题，Qt的开发公司，当时是诺基亚，现在是Digia，后来在2009年开发了名为`PySide`的Python绑定，并在更宽松的LGPL许可证下发布。
- en: 'There are minor differences between the two bindings but the examples developed
    here will work with either. The following snippet can be used to import whichever
    Qt binding is installed:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个绑定之间有一些细微的差异，但这里开发的示例可以与任一绑定一起工作。以下代码片段可以用来导入已安装的任何Qt绑定：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, if `PySide` is not available, an `ImportError` exception will be raised
    and `PyQt` will be imported. If `PyQt` is also unavailable, another `ImportError`
    will be raised and the script will exit.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，如果`PySide`不可用，将引发`ImportError`异常，并导入`PyQt`。如果`PyQt`也不可用，将再次引发`ImportError`异常，脚本将退出。
- en: The instructions to download and install each of the Python bindings for Qt
    are available at [http://qt-project.org/wiki/Setting_up_PySide](http://qt-project.org/wiki/Setting_up_PySide)
    and [http://pyqt.sourceforge.net/Docs/PyQt4/installation.html](http://pyqt.sourceforge.net/Docs/PyQt4/installation.html).
    Depending on the version of Python 3 you are using, there might not be availability
    yet for the library, but releases are somewhat frequent so you can always check
    back soon.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下载和安装Qt每个Python绑定的说明可在[http://qt-project.org/wiki/Setting_up_PySide](http://qt-project.org/wiki/Setting_up_PySide)和[http://pyqt.sourceforge.net/Docs/PyQt4/installation.html](http://pyqt.sourceforge.net/Docs/PyQt4/installation.html)找到。根据您使用的Python
    3版本，可能还没有提供该库，但发布频率相对较高，所以您可以随时检查。
- en: Debugging with Qt
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Qt进行调试
- en: Whether you are using PySide or PyQt, you will likely run into sites where you
    need to debug the application or script. We have already covered one way to do
    so, by utilizing the `QWebView` GUI `show()` method to "see" what is being rendered
    on the page you've loaded. You can also use the `page().mainFrame().toHtml()`
    chain (easily referenced when using the `BrowserRender` class via the `html` method
    to pull the HTML at any point, write it to a file and save and then open it in
    your browser.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用PySide还是PyQt，您都可能遇到需要调试应用程序或脚本的网站。我们已经介绍了一种方法，即通过利用`QWebView` GUI `show()`方法来“查看”您已加载的页面上的渲染内容。您还可以使用`page().mainFrame().toHtml()`链（当通过`BrowserRender`类使用`html`方法时很容易引用）在任何点提取HTML，将其写入文件并保存，然后在浏览器中打开。
- en: In addition, there are several useful Python debuggers, such as `pdb` which
    you can integrate into your script and then use breakpoints to step through the
    code where the error, issue or bug is expressed. There are several different ways
    to set this up and specific to whichever library and Qt version you have installed,
    so we recommend searching for the exact setup you have and reviewing implementation
    to allow setting breakpoints or trace.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有几个有用的Python调试器，例如`pdb`，您可以将它集成到脚本中，然后使用断点逐步执行代码，以找到错误、问题或错误所在的位置。设置此环境有几种不同的方法，具体取决于您安装的库和Qt版本，所以我们建议搜索您确切的环境设置，并审查实现以允许设置断点或跟踪。
- en: Executing JavaScript
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行JavaScript
- en: To confirm your WebKit installation can execute JavaScript, there is a simple
    example available at [http://example.webscraping.com/dynamic](http://example.webscraping.com/dynamic).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要确认您的WebKit安装可以执行JavaScript，有一个简单的示例可在[http://example.webscraping.com/dynamic](http://example.webscraping.com/dynamic)找到。
- en: 'This web page simply uses JavaScript to write `Hello World` to a `div` element.
    Here is the source code:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网页简单地使用JavaScript将`Hello World`写入`div`元素。以下是源代码：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the traditional approach of downloading the original HTML and parsing
    the result, the `div` element will be empty, as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统的下载原始HTML并解析结果的方法，`div`元素将是空的，如下所示：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here is an initial example with WebKit, which needs to follow the `PyQt` or
    `PySide` imports shown in the previous section:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个使用WebKit的初始示例，它需要遵循上一节中显示的`PyQt`或`PySide`导入：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There is quite a lot going on here, so we will step through the code line by
    line:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多事情要做，所以我们将逐行分析代码：
- en: The first line instantiates the `QApplication` object that the Qt framework
    requires before other Qt objects can be initialized.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行实例化了Qt框架在初始化其他Qt对象之前所需的`QApplication`对象。
- en: Next, a `QWebView` object is created, which is a widget for the web documents.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，创建了一个`QWebView`对象，这是一个用于网页文档的小部件。
- en: A `QEventLoop` object is created, which is used to create a local event loop.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个`QEventLoop`对象，用于创建本地事件循环。
- en: The `loadFinished` callback of the `QwebView` object is linked to the `quit`
    method of `QEventLoop` so when a web page finishes loading, the event loop will
    stop.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`QwebView`对象的`loadFinished`回调与`QEventLoop`的`quit`方法相连接，因此当网页加载完成时，事件循环将停止。'
- en: The URL to load is then passed to `QWebView`. `PyQt` requires this URL string
    to be wrapped in a `QUrl` object, but for `PySide`, this is optional.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后将要加载的URL传递给`QWebView`。`PyQt`要求这个URL字符串被包裹在一个`QUrl`对象中，但对于`PySide`来说这是可选的。
- en: The `QWebView` loads asynchronously, so execution immediately passes to the
    next line while the web page is loading-however, we want to wait until this web
    page is loaded, so `loop.exec_()` is called to start the event loop.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`QWebView`异步加载，因此执行立即传递到下一行，同时网页正在加载——然而，我们希望等待此网页加载完成，所以调用`loop.exec_()`来启动事件循环。'
- en: When the web page completes loading, the event loop will exit and code execution
    continues. The resulting HTML from the loaded web page is extracted using the
    `toHTML` method.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网页完成加载后，事件循环将退出，代码执行继续。使用`toHTML`方法从加载的网页中提取生成的HTML。
- en: The final line shows the JavaScript has been successfully executed and the `div`
    element contains `Hello World`.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后的行显示JavaScript已成功执行，`div`元素包含`Hello World`。
- en: The classes and methods used here are all excellently documented in the C++
    Qt framework website at [http://qt-project.org/doc/qt-4.8/](http://qt-project.org/doc/qt-4.8/).
    `PyQt` and `PySide` have their own documentation, however, the descriptions and
    formatting for the original C++ version is superior, and, generally Python developers
    use it instead.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的类和方法在C++ Qt框架网站上都有出色的文档，网址为[http://qt-project.org/doc/qt-4.8/](http://qt-project.org/doc/qt-4.8/)。`PyQt`和`PySide`都有自己的文档，然而，原始C++版本的描述和格式更好，并且通常Python开发者会使用它。
- en: Website interaction with WebKit
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用WebKit进行网站交互
- en: The search web page we have been examining requires the user to modify and submit
    a search form, and then click on the page links. However, so far, our browser
    renderer can only execute JavaScript and access the resulting HTML. Scraping the
    search page requires extending the browser renderer to support these interactions.
    Fortunately, Qt has an excellent API to select and manipulate the HTML elements,
    which makes implementation straightforward.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在检查的搜索网页要求用户修改并提交搜索表单，然后点击页面链接。然而，到目前为止，我们的浏览器渲染器只能执行JavaScript和访问生成的HTML。抓取搜索页面需要扩展浏览器渲染器以支持这些交互。幸运的是，Qt有一个出色的API来选择和操作HTML元素，这使得实现变得简单。
- en: 'Here is an alternative version to the earlier AJAX search example, which sets
    the search term to `''.''` and page size to `''1000''` and loads all results in
    a single query:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是之前AJAX搜索示例的替代版本，将搜索词设置为`'.'`，页面大小设置为`'1000'`，并在单个查询中加载所有结果：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The first few lines instantiate the Qt objects required to render a web page,
    the same as in the previous `Hello World` example. Next, the `QWebView` GUI `show()`
    method is called so that the render window is displayed, which is useful for debugging.
    Then, a reference to the frame is created to make the following lines shorter.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前几行实例化了渲染网页所需的Qt对象，与之前的`Hello World`示例相同。接下来，调用`QWebView` GUI的`show()`方法，以便显示渲染窗口，这对于调试很有用。然后，创建对框架的引用，以便使下面的行更短。
- en: The `QWebFrame` class has many useful methods to interact with web pages. The
    three lines containing `findFirstElement` use the CSS selectors to locate an element
    in the frame, and set the search parameters. Then, the form is submitted with
    the `evaluateJavaScript()` method which simulates the click event. This method
    is very convenient because it allows insertion and execution of any JavaScript
    code we submit, including calling JavaScript methods defined in the web page directly.
    Then, the final line enters the application event loop so we can review what is happening
    in the form. Without this, the script would exit immediately.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`QWebFrame`类有许多用于与网页交互的有用方法。包含`findFirstElement`的三个行使用CSS选择器在框架中定位元素，并设置搜索参数。然后，使用`evaluateJavaScript()`方法提交表单，该方法模拟点击事件。这个方法非常方便，因为它允许插入和执行我们提交的任何JavaScript代码，包括直接调用网页中定义的JavaScript方法。然后，最后一行进入应用程序事件循环，这样我们就可以查看表单中的发生情况。如果没有这个，脚本将立即退出。'
- en: 'This is displayed when this script is run:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当此脚本运行时，会显示以下内容：
- en: '![](img/pyqt_search.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![pyqt_search](img/pyqt_search.png)'
- en: The final line of code we ran `app._exec()` is a blocking call and will prevent
    any more lines of code in this particular thread from executing. Having a view
    of how your code is functioning by using `webkit.show()` is a great way to debug
    your application and determine what is really happening on the web page.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行的最后一行代码`app._exec()`是一个阻塞调用，将阻止此特定线程中的任何更多代码执行。通过使用`webkit.show()`来查看代码的运行情况是调试应用程序和确定网页上实际发生情况的好方法。
- en: To stop the running application, you can simply close the Qt window (or the
    Python interpreter).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 要停止运行的应用程序，你可以简单地关闭Qt窗口（或Python解释器）。
- en: Waiting for results
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等待结果
- en: 'The final part of implementing our WebKit crawler is scraping the search results,
    which turns out to be the most difficult part because it isn''t obvious when the
    AJAX event is complete and the country data is loaded. There are three possible
    approaches to deal with this conundrum:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 实现我们的WebKit爬虫的最后一部分是抓取搜索结果，这证明是最困难的部分，因为不清楚AJAX事件何时完成以及国家数据何时加载。有三种可能的方法来处理这个难题：
- en: Wait a set amount of time and hope the AJAX event is complete
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待设定的时间并希望AJAX事件完成
- en: Override Qt's network manager to track when URL requests are complete
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖Qt的网络管理器以跟踪URL请求何时完成
- en: Poll the web page for the expected content to appear
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮询网页以查找预期内容的出现
- en: 'The first option is the simplest to implement but it''s inefficient, since if
    a safe timeout is set, usually the script spends too much time waiting. Also,
    when the network is slower than usual, a fixed timeout could fail. The second
    option is more efficient but cannot be applied when there are client-side delays;
    for example, if the download is complete, but a button needs to be pressed before
    content is displayed. The third option is more reliable and straightforward to
    implement; though there is the minor drawback of wasting CPU cycles when checking
    whether the content has loaded. Here is an implementation for the third option:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法实现起来最简单，但效率不高，因为如果设置了安全的超时，通常脚本会花费太多时间等待。此外，当网络速度比平时慢时，固定的超时可能会失败。第二种方法更高效，但不能应用于存在客户端延迟的情况；例如，如果下载已完成，但需要在内容显示之前按下按钮。第三种方法更可靠且易于实现；尽管检查内容是否已加载时会有浪费CPU周期的微小缺点。以下是第三种方法的实现：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, the code will remain in the `while` loop until the country links are present
    in the `results` div. For each loop, `app.processEvents()` is called to give the
    Qt event loop time to perform tasks, such as responding to click events and updating
    the GUI. We could additionally add a `sleep` for a short period of seconds in
    this loop to give the CPU intermittent breaks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，代码将保持在`while`循环中，直到国家链接出现在`results` div中。对于每个循环，都会调用`app.processEvents()`以给Qt事件循环时间来执行任务，例如响应用户点击事件和更新GUI。我们还可以在这个循环中添加一个短暂的秒数`sleep`，以给CPU间歇性的休息时间。
- en: A full example of the code so far can be found at [https://github.com/kjam/wswp/blob/master/code/chp5/pyqt_search.py](https://github.com/kjam/wswp/blob/master/code/chp5/pyqt_search.py).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止的代码完整示例可以在[https://github.com/kjam/wswp/blob/master/code/chp5/pyqt_search.py](https://github.com/kjam/wswp/blob/master/code/chp5/pyqt_search.py)找到。
- en: The Render class
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渲染类
- en: 'To help make this functionality easier to use in future, here are the methods
    used and packaged into a class, whose source code is also available at [https://github.com/kjam/wswp/blob/master/code/chp5/browser_render.py](https://github.com/kjam/wswp/blob/master/code/chp5/browser_render.py):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助使此功能在未来更容易使用，以下是使用的方法，这些方法被包装成一个类，其源代码也可在[https://github.com/kjam/wswp/blob/master/code/chp5/browser_render.py](https://github.com/kjam/wswp/blob/master/code/chp5/browser_render.py)找到。
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You may have noticed the `download()` and `wait_load()` methods have some additional
    code involving a timer. This timer tracks how long is spent waiting and cancels
    the event loop if the deadline is reached. Otherwise, when a network problem is
    encountered, the event loop would run indefinitely.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到`download()`和`wait_load()`方法涉及一些额外的代码，包括计时器。这个计时器跟踪等待花费的时间，并在达到截止日期时取消事件循环。否则，当遇到网络问题时，事件循环将无限期运行。
- en: 'Here is how to scrape the search page using this new class:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用这个新类抓取搜索页面的方法：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Selenium
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Selenium
- en: 'With the WebKit library used in the previous section, we have full control
    to customize the browser renderer to behave as we need it to. If this level of
    flexibility is not needed, a good and easier-to-install alternative is Selenium,
    which provides an API to automate several popular web browsers. Selenium can be
    installed using `pip` with the following command:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个部分中使用的WebKit库，我们可以完全控制自定义浏览器渲染器以按需行为。如果不需要这种级别的灵活性，一个好的且易于安装的替代方案是Selenium，它提供了一个API来自动化几个流行的网络浏览器。可以使用以下命令使用`pip`安装Selenium：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To demonstrate how Selenium works, we will rewrite the previous search example
    in Selenium. The first step is to create a connection to the web browser:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示Selenium的工作原理，我们将使用Selenium重写之前的搜索示例。第一步是创建与网络浏览器的连接：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When this command is run, an empty browser window will pop up. If you received
    an error instead, you likely need to install `geckodriver` ([https://github.com/mozilla/geckodriver/releases](py-web-scrp-2e_ch04.html))
    and ensure it is available via your `PATH` variables.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行此命令时，将弹出一个空浏览器窗口。如果您收到错误，则可能需要安装`geckodriver` ([https://github.com/mozilla/geckodriver/releases](py-web-scrp-2e_ch04.html))
    并确保它通过您的`PATH`变量可用。
- en: Using a browser you can see and interact with (rather than a Qt widget) is handy
    because with each command, the browser window can be checked to see if the script worked
    as expected. Here, we used Firefox, but Selenium also provides interfaces to other
    common web browsers, such as Chrome and Internet Explorer. Note that you can only
    use a Selenium interface for a web browser that is installed on your system.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可以查看和与之交互的浏览器（而不是Qt小部件）很方便，因为每次执行命令时，都可以检查浏览器窗口以查看脚本是否按预期工作。在这里，我们使用了Firefox，但Selenium还提供了与其他常见网络浏览器的接口，例如Chrome和Internet
    Explorer。请注意，您只能使用安装在系统上的网络浏览器的Selenium接口。
- en: To see if your system's browser is supported and what other dependencies or
    drivers you may need to install to use Selenium, check the Selenium documentation
    on supported platforms: [http://www.seleniumhq.org/about/platforms.jsp](http://www.seleniumhq.org/about/platforms.jsp).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看您的系统浏览器是否受支持以及您可能需要安装的其他依赖项或驱动程序以使用Selenium，请检查Selenium关于支持平台的文档：[http://www.seleniumhq.org/about/platforms.jsp](http://www.seleniumhq.org/about/platforms.jsp)。
- en: 'To load a web page in the chosen web browser, the `get()` method is called:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要在所选网络浏览器中加载网页，请调用`get()`方法：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, to set which element to select, the ID of the search textbox can be used.
    Selenium also supports selecting elements with a CSS selector or XPath. When the
    search textbox is found, we can enter content with the `send_keys()` method, which
    simulates typing:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了设置要选择的元素，可以使用搜索文本框的ID。Selenium还支持使用CSS选择器或XPath选择元素。当找到搜索文本框时，我们可以使用`send_keys()`方法输入内容，该方法模拟键入：
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To return all results in a single search, we want to set the page size to 1000\.
    However, this is not straightforward because Selenium is designed to interact
    with the browser, rather than to modify the web page content. To get around this
    limitation, we can use JavaScript to set the select box content:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在单个搜索中返回所有结果，我们希望将页面大小设置为1000。然而，这并不简单，因为Selenium旨在与浏览器交互，而不是修改网页内容。为了克服这一限制，我们可以使用JavaScript来设置下拉框内容：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now the form inputs are ready, so the search button can be clicked on to perform
    the search:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在表单输入已准备就绪，因此可以点击搜索按钮以执行搜索：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We need to wait for the AJAX request to complete before loading the results,
    which was the hardest part of the script in the previous WebKit implementation.
    Fortunately, Selenium provides a simple solution to this problem by setting a
    timeout with the `implicitly_wait()` method:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载结果之前，我们需要等待AJAX请求完成，这是之前WebKit实现中脚本最困难的部分。幸运的是，Selenium通过使用`implicitly_wait()`方法设置超时，提供了一个简单的解决方案：
- en: '[PRE25]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, a delay of 30 seconds was used. Now, if we search for elements that are
    not yet available, Selenium will wait up to 30 seconds before raising an exception.
    Selenium also allows for more detailed polling control using explicit waits (which
    are well-documented at [http://www.seleniumhq.org/docs/04_webdriver_advanced.jsp](http://www.seleniumhq.org/docs/04_webdriver_advanced.jsp)).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用了30秒的延迟。现在，如果我们搜索尚未可用的元素，Selenium会在抛出异常之前等待最多30秒。Selenium还允许使用显式等待进行更详细的轮询控制（有关详细信息，请参阅[http://www.seleniumhq.org/docs/04_webdriver_advanced.jsp](http://www.seleniumhq.org/docs/04_webdriver_advanced.jsp)）。
- en: 'To select the country links, we use the same CSS selector that we used in the
    WebKit example:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择国家链接，我们使用与WebKit示例中相同的CSS选择器：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, the text of each link can be extracted to create a list of countries:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以提取每个链接的文本以创建国家列表：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Finally, the browser can be shut down by calling the `close()` method:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以通过调用 `close()` 方法关闭浏览器：
- en: '[PRE28]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The source code for this example is available at [https://github.com/kjam/wswp/blob/master/code/chp5/selenium_search.py](https://github.com/kjam/wswp/blob/master/code/chp5/selenium_search.py).
    For further details about Selenium, the Python bindings are documented at [https://selenium-python.readthedocs.org/](https://selenium-python.readthedocs.org/).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本例的源代码可在[https://github.com/kjam/wswp/blob/master/code/chp5/selenium_search.py](https://github.com/kjam/wswp/blob/master/code/chp5/selenium_search.py)找到。有关
    Selenium 的更多详细信息，Python 绑定在[https://selenium-python.readthedocs.org/](https://selenium-python.readthedocs.org/)有文档说明。
- en: Selenium and Headless Browsers
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Selenium 和无头浏览器
- en: Although it's convenient and fairly easy to install and use Selenium with common
    browsers; this can present problems when running these scripts on servers. For
    servers, it's more common to use headless browsers. They also tend to be faster
    and more configurable than fully-functional web browsers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用常见浏览器安装和配置 Selenium 很方便且相对简单；但在服务器上运行这些脚本时可能会出现问题。对于服务器来说，更常见的是使用无头浏览器。它们通常比功能完整的网络浏览器更快且更可配置。
- en: The most popular headless browser at the time of this publication is PhantomJS.
    It runs via its own JavaScript-based webkit engine. PhantomJS can be installed
    easily on most servers, and can be installed locally by following the latest download
    instructions ([http://phantomjs.org/download.html](http://phantomjs.org/download.html)).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本出版物发布时，最受欢迎的无头浏览器是 PhantomJS。它通过自己的基于 JavaScript 的 webkit 引擎运行。PhantomJS 可以轻松安装在大多数服务器上，并且可以通过遵循最新的下载说明在本地安装（[http://phantomjs.org/download.html](http://phantomjs.org/download.html)）。
- en: 'Using PhantomJS with Selenium merely requires a different initialization:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Selenium 与 PhantomJS 仅需要不同的初始化：
- en: '[PRE29]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first difference you notice is no browser window is opened, but there is
    a PhantomJS instance running. To test our code, we can visit a page and take a
    screenshot.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您首先注意到的是没有打开浏览器窗口，但有一个 PhantomJS 实例正在运行。为了测试我们的代码，我们可以访问一个页面并截图。
- en: '[PRE30]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now if you open that saved PNG file, you can see what the PhantomJS browser
    has rendered:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果您打开那个保存的 PNG 文件，您可以看到 PhantomJS 浏览器渲染的内容：
- en: '![](img/python_website.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/python_website.png)'
- en: We notice it is a long window. We could change this by using `maximize_window`
    or setting a window size with `set_window_size`, both of which are documented
    in the [Selenium Python documentation on the WebDriver API](http://selenium-python.readthedocs.io/api.html).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到窗口很大。我们可以通过使用 `maximize_window` 或使用 `set_window_size` 设置窗口大小来改变这一点，这两个方法都在[Selenium
    Python WebDriver API 文档](http://selenium-python.readthedocs.io/api.html)中有说明。
- en: Screenshot options are great for debugging any Selenium issues you have, even
    if you are using Selenium with a real browser -- since there are times the script
    may fail to work due to a slow-loading page or changes in the page structure or
    JavaScript on the site. Having a screenshot of the page exactly as it was at the
    time of the error can be very helpful. Additionally, you can use the driver's
    `page_source` attribute to save or inspect the current page source.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 截图选项非常适合调试任何 Selenium 问题，即使您在使用真实浏览器时也是如此——因为有时脚本可能因为页面加载缓慢或页面结构或网站上的 JavaScript
    变化而无法正常工作。拥有错误发生时页面的截图可以非常有帮助。此外，您还可以使用驱动程序的 `page_source` 属性来保存或检查当前页面源代码。
- en: Another reason to utilize a browser-based parser like Selenium is it makes it
    more difficult to act like a scraper. Some sites use scraper-avoidance techniques
    like Honeypots, where the site might include a hidden toxic link on a page, which
    will get your scraper banned if your script clicks it. For these types of problems,
    Selenium acts as a great scraper because of its browser-based architecture. If
    you cannot click or see a link in the browser, you also cannot interact with it
    via Selenium. Additionally, your headers will include whichever browser you are
    using and you'll have access to normal browser features like cookies, sessions
    as well as loading images and interactive elements, which are sometimes required
    to load particular forms or pages. If your scraper must interact with the page
    and seem "human-like", Selenium is a great choice.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 利用基于浏览器的解析器如Selenium的另一个原因是它使得表现得像爬虫更困难。一些网站使用像Honeypots这样的爬虫避免技术，其中网站可能在页面上包含一个隐藏的有毒链接，如果你的脚本点击它，你的爬虫就会被禁止。对于这类问题，Selenium由于其基于浏览器的架构而成为一个出色的爬虫。如果你在浏览器中不能点击或看到链接，你也不能通过Selenium与之交互。此外，你的头部信息将包括你使用的浏览器，你将能够访问正常的浏览器功能，如cookies、会话以及加载图像和交互元素，这些有时是加载特定表单或页面所必需的。如果你的爬虫必须与页面交互并表现得“像人一样”，Selenium是一个很好的选择。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered two approaches to scraping data from dynamic web pages.
    It started with reverse engineering a dynamic web page using browser tools, and
    then moved on to using a browser renderer to trigger JavaScript events for us.
    We first used WebKit to build our own custom browser, and then reimplemented this
    scraper with the high-level Selenium framework.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了从动态网页中抓取数据的两种方法。它从使用浏览器工具逆向工程一个动态网页开始，然后转向使用浏览器渲染器为我们触发JavaScript事件。我们首先使用WebKit构建了自己的自定义浏览器，然后使用高级的Selenium框架重新实现了这个抓取器。
- en: A browser renderer can save the time needed to understand how the backend of
    a website works; however, there are some disadvantages. Rendering a web page adds
    overhead and is much slower than just downloading the HTML or using API calls.
    Additionally, solutions using a browser renderer often require polling the web
    page to check whether the resulting HTML has loaded, which is brittle and can
    fail when the network is slow.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览器渲染器可以节省理解网站后端工作原理所需的时间；然而，也有一些缺点。渲染网页会增加开销，并且比仅下载HTML或使用API调用要慢得多。此外，使用浏览器渲染器的解决方案通常需要轮询网页以检查生成的HTML是否已加载，这很脆弱，在网络速度慢时可能会失败。
- en: I typically use a browser renderer for short-term solutions where the long-term
    performance and reliability is less important; for long-term solutions, I attempt to
    reverse engineer the website. Of course, some sites may require "human-like" interactions
    or have closed APIs, meaning a browser rendered implementation will likely be
    the only way to acquire content.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常在短期解决方案中使用浏览器渲染器，因为在这种情况下长期性能和可靠性不太重要；对于长期解决方案，我尝试逆向工程网站。当然，一些网站可能需要“像人一样”的交互或已关闭API，这意味着浏览器渲染的实现可能是获取内容的唯一方式。
- en: In the next chapter, we will cover how to interact with forms and cookies to
    log into a website and edit content.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何与表单和cookies交互以登录网站并编辑内容。
