- en: Chapter 9. Creating Asynchronous Tasks with Celery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。使用Celery创建异步任务
- en: While creating web apps, it is vital to keep the time that a request takes to
    process below or around 50 ms. As the majority of response times are occupied
    by waiting for users' connection, and extra processing time may hang the server.
    Any extra processing on the server that can be avoided should be avoided. However,
    it is quite common for several operations in a web app to take longer than a couple
    of seconds, especially when complex database operations or image processing are
    involved. To save our user experience, a task queue named Celery will be used
    to move these operations out of the Flask process.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建Web应用程序时，保持请求处理时间在50毫秒左右以下是至关重要的。由于大部分响应时间都被等待用户连接所占据，额外的处理时间可能会挂起服务器。应该避免服务器上的任何额外处理。然而，在Web应用程序中，有几个操作可能需要花费超过几秒钟的时间，特别是涉及复杂的数据库操作或图像处理时。为了保护用户体验，将使用名为Celery的任务队列将这些操作移出Flask进程。
- en: What is Celery?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Celery是什么？
- en: '**Celery** is an asynchronous task queue written in Python. Celery runs tasks,
    which are user-defined functions, *concurrently*—multiple tasks at once—through
    the Python multiprocessing library. Celery receives messages that tell it to start
    a task from a **broker**, which is usually called a message queue as shown in
    the following diagram:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**Celery**是用Python编写的异步任务队列。Celery通过Python多进程库*并发*运行任务，这些任务是用户定义的函数。Celery接收消息，告诉它从**代理**开始任务，通常称为消息队列，如下图所示：'
- en: '![What is Celery?](img/B03929_09_01.jpg)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Celery是什么？](img/B03929_09_01.jpg)'
- en: A **message queue** is a system specifically designed to send data between producer
    processes and consumer processes. **Producer processes** are any programs that
    create messages to be sent in the queue, and **consumer processes** are any programs
    that take the messages out of the queue. Messages sent from a producer are stored
    in a **First In First Out** (**FIFO**) queue, where the oldest items are retrieved
    first. Messages are stored until a consumer receives the message, after which
    it is deleted. Message queues provide real-time messaging without relying on polling,
    the process of continuously checking the status of a process. When messages are
    sent from producers, consumers are *listening* on their connection to the message
    queue for new messages; the consumer is not constantly contacting the queue. This
    difference is like the difference between **AJAX** and **WebSockets**; AJAX requires
    constant contact with the server while WebSockets are just a continuous stream.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**消息队列**是一个专门设计用于在生产者进程和消费者进程之间发送数据的系统。**生产者进程**是创建要发送到队列中的消息的任何程序，**消费者进程**是从队列中取出消息的任何程序。从生产者发送的消息存储在**先进先出**（**FIFO**）队列中，最旧的项目首先被检索。消息存储直到消费者接收消息，之后消息被删除。消息队列提供实时消息传递，而不依赖于轮询，即持续检查进程状态的过程。当消息从生产者发送时，消费者正在其连接到消息队列上*监听*新消息；消费者不会不断地联系队列。这种差异就像**AJAX**和**WebSockets**之间的差异；AJAX需要与服务器保持不断的联系，而WebSockets只是一个持续的流。'
- en: It is possible to replace the message queue with a traditional database. Celery
    even comes with built-in support for SQLAlchemy to allow this. However, using
    a database as a broker for Celery is highly discouraged. Using a database in place
    of a message queue requires the consumer to constantly poll the database for updates.
    Also, because Celery uses multiprocessing for concurrency, the number of connections
    making lots of reads goes up quickly. Under medium loads, using a database requires
    the producer to make lots of writes to the database at the same time as the consumer
    is reading. Databases cannot have too many connections making reads, writes, and
    updates at the same time on the same data. When this happens, tables are often
    locked and all other connections are left waiting for each write to finish before
    anything can read the data, and vice versa. Even worse, it can lead to race conditions,
    which are situations where concurrent events change and read the same resource,
    and each concurrent operation started using a stale version of the data. Specific
    to Celery, this can lead to the same operation being run multiple times for the
    same message.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用传统数据库替换消息队列。Celery甚至内置了对SQLAlchemy的支持以实现这一点。然而，强烈不建议使用数据库作为Celery的代理。使用数据库代替消息队列需要消费者不断地轮询数据库以获取更新。此外，由于Celery使用多进程进行并发处理，大量读取的连接数量会迅速增加。在中等负载下，使用数据库需要生产者同时向数据库进行大量写入，而消费者正在读取。数据库不能有太多的连接同时进行读取、写入和更新相同的数据。当这种情况发生时，表通常会被锁定，所有其他连接都在等待每次写入完成后才能读取数据，反之亦然。更糟糕的是，这可能导致竞争条件，即并发事件更改和读取相同的资源，并且每个并发操作都使用过时版本的数据。特定于Celery，这可能导致相同的操作针对相同的消息多次运行。
- en: It is also possible to use a message queue as a broker and a database to store
    the results of the tasks. In the preceding diagram, the message queue was used
    for sending task requests and task results.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用消息队列作为代理和数据库来存储任务的结果。在前面的图表中，消息队列用于发送任务请求和任务结果。
- en: 'However, using a database to store the end result of the task allows the final
    product to be stored indefinitely, whereas the message queue will throw out the
    data as soon as the producer receives the data as shown in the following diagram:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用数据库存储任务的最终结果允许最终产品无限期地存储，而消息队列将在生产者接收数据后立即丢弃数据，如下图所示：
- en: '![What is Celery?](img/B03929_09_02.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Celery是什么？](img/B03929_09_02.jpg)'
- en: This database is often a key-value NoSQL store to help handle the load. This
    is useful if you plan on doing analytics on previously run tasks; otherwise, it's
    safer to just stick with the message queue.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据库通常是一个键值NoSQL存储，以帮助处理负载。如果您计划对先前运行的任务进行分析，这将非常有用；否则，最好只使用消息队列。
- en: There is even an option to drop the results of tasks entirely and not have the
    results of tasks returned. This has the downside that the producer has no way
    of knowing if a task was successful or not, but often this is enough in smaller
    projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至有一个选项可以完全丢弃任务的结果，而不返回任务的结果。这样做的缺点是生产者无法知道任务是否成功，但在较小的项目中通常足够。
- en: For our stack, we will use **RabbitMQ** as the message broker. RabbitMQ runs
    on all major OSes and is very simple to set up and run. Celery also supports RabbitMQ
    without any extra libraries and is the recommended message queue in the Celery
    documentation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的堆栈，我们将使用**RabbitMQ**作为消息代理。RabbitMQ在所有主要操作系统上运行，并且非常简单设置和运行。Celery还支持RabbitMQ，无需任何额外的库，并且是Celery文档中推荐的消息队列。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing, there is no way to use RabbitMQ with Celery in Python
    3\. You can use Redis instead of RabbitMQ. The only difference will be the connection
    strings. For more information, see [http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html](http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，尚无法在Python 3中使用RabbitMQ与Celery。您可以使用Redis代替RabbitMQ。唯一的区别将是连接字符串。有关更多信息，请参见[http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html](http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html)。
- en: Setting up Celery and RabbitMQ
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Celery和RabbitMQ
- en: 'To install Celery with `pip`, run the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`pip`安装Celery，请运行以下命令：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will also need a Flask extension to help handle initializing Celery:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个Flask扩展来帮助处理初始化Celery：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The Flask documentation states that Flask extensions for Celery are unnecessary.
    However, getting the Celery server to work with Flask's application context when
    your app is organized with an application factory is significant. So, we will
    use **Flask-Celery-Helper** to do the heavy lifting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Flask文档指出，Flask对Celery的扩展是不必要的。但是，在使用应用程序工厂组织应用程序时，使Celery服务器能够与Flask的应用程序上下文一起工作是很重要的。因此，我们将使用**Flask-Celery-Helper**来完成大部分工作。
- en: Next, RabbitMQ needs to be installed. RabbitMQ is not written in Python; therefore,
    installation instructions will be different for every OS. Thankfully, RabbitMQ
    maintains a detailed list of instructions for each OS at [https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，需要安装RabbitMQ。RabbitMQ不是用Python编写的；因此，每个操作系统的安装说明都将不同。幸运的是，RabbitMQ在[https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html)上为每个操作系统维护了详细的说明列表。
- en: 'After RabbitMQ is installed, go to a terminal window and run the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 安装RabbitMQ后，打开终端窗口并运行以下命令：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will start a RabbitMQ server with a user of guest and a password of guest.
    By default, RabbitMQ only accepts connections on localhost, so this setup is okay
    for the development.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个带有用户名为guest和密码为guest的RabbitMQ服务器。默认情况下，RabbitMQ只接受本地主机上的连接，因此这种设置对开发来说是可以的。
- en: Creating tasks in Celery
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Celery中创建任务
- en: As stated before, Celery tasks are just user-defined functions that perform
    some operations. But before any tasks can be written, our Celery object needs
    to be created. This is the object that the Celery server will import to handle
    running and scheduling all of the tasks.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Celery任务只是执行一些操作的用户定义函数。但在编写任何任务之前，需要创建我们的Celery对象。这是Celery服务器将导入以处理运行和调度所有任务的对象。
- en: 'At a bare minimum, Celery needs one configuration variable to run: the connection
    to the message broker. The connection is defined like the SQLAlchemy connection,
    as a URL. The backend, what stores our tasks'' results, is also defined as a URL
    as shown in the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，Celery需要一个配置变量才能运行：与消息代理的连接。连接被定义为URL，就像SQLAlchemy连接一样。后端，用于存储我们任务结果的地方，也被定义为URL，如下面的代码所示：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So, in order for our Celery process to work with the database and any other
    Flask extensions, it needs to work within our application context. In order to
    do so, Celery will need to create a new instance of our application for each process.
    Unlike most Celery apps, we need a Celery factory to create an application instance
    and register our Celery instance on it. In a new file in the top-level directory,
    the same location where `manage.py` resides, named `celery_runner.py`, add the
    following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了使我们的Celery进程能够与数据库和任何其他Flask扩展一起工作，它需要在我们的应用程序上下文中工作。为了做到这一点，Celery需要为每个进程创建我们应用程序的新实例。与大多数Celery应用程序不同，我们需要一个Celery工厂来创建应用程序实例并在其上注册我们的Celery实例。在顶级目录中的一个新文件中，与`manage.py`位于同一位置，命名为`celery_runner.py`，添加以下内容：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What the `make_celery` function does is wraps every call to each Celery task
    in a Python `with` block. This makes sure that every call to any Flask extension
    will work as it is working with our app. Also, make sure not to name the Flask
    app instance `app`, as Celery tries to import any object named `app` or `celery`
    as the Celery application instance. So, naming your Flask object `app` will cause
    Celery to try to use it as a Celery object.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`make_celery`函数的作用是在Python的`with`块中包装对每个Celery任务的每次调用。这确保了对任何Flask扩展的每次调用都可以正常工作，因为它正在与我们的应用程序一起工作。还要确保不要将Flask应用程序实例命名为`app`，因为Celery会尝试导入任何名为`app`或`celery`的对象作为Celery应用程序实例。因此，将您的Flask对象命名为`app`将导致Celery尝试将其用作Celery对象。'
- en: 'Now, we can write our first task. It will be a simple task to start with, one
    that just returns any string passed to it. In a new file in the application directory
    named `tasks.py`, add the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以编写我们的第一个任务。这将是一个简单的任务，只是返回传递给它的任何字符串。在应用程序目录中的一个新文件中命名为`tasks.py`，添加以下内容：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, the final piece of the puzzle is to run the Celery process, which is called
    a **worker**, in a new terminal window. Again, this is the process that will be
    listening to our message broker for commands to start new tasks:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，谜题的最后一部分是在新的终端窗口中运行Celery进程，称为**worker**。再次强调，这是将监听我们的消息代理以启动新任务的进程：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `loglevel` flag is there, so you can see the confirmation that a task was
    received and its output was available in the terminal window.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`loglevel`标志存在的原因是，您可以在终端窗口中看到任务已收到的确认以及其输出的可用性。'
- en: 'Now, we can send commands to our Celery worker. Open the `manage.py` shell
    and import the `log` task:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以向 Celery 工作进程发送命令。打开 `manage.py` shell 并导入 `log` 任务：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The function can be called as if it were any other function; doing so will execute
    the function in the current process. However, calling the `delay` method on the
    task will send a message to the worker process to execute the function with the
    given arguments.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数可以像调用其他函数一样调用；这样做将在当前进程中执行该函数。但是，在任务上调用 `delay` 方法将向工作进程发送消息，以使用给定的参数执行该函数。
- en: 'In the terminal window that is running the Celery worker, you should see something
    like the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 Celery 工作进程的终端窗口中，您应该看到类似以下内容：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: With any asynchronous task, the `ready` method can be used to tell if the task
    has successfully completed. If true, the `get` method can be used to retrieve
    the result of the tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何异步任务，`ready` 方法可用于判断任务是否成功完成。如果为真，则可以使用 `get` 方法来检索任务的结果。
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `get` method causes the current process to wait until the `ready` function
    returns `True` to retrieve the result. So, calling `get` immediately after calling
    the task essentially makes the task synchronous. Because of this, it's rather
    rare for tasks to actually return a value to the producer. The vast majority of
    tasks perform some operation and then exit.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`get` 方法会导致当前进程等待，直到 `ready` 函数返回 `True` 以检索结果。因此，在调用任务后立即调用 `get` 实质上使任务同步。因此，任务实际上很少返回值给生产者。绝大多数任务执行某些操作然后退出。'
- en: 'When a task is run on the Celery worker, the state of the task can be accessed
    via the `state` attribute. This allows for a more fine-grained understanding of
    what the task is currently doing in the worker process. The available states are
    as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 Celery 工作进程上运行任务时，可以通过 `state` 属性访问任务的状态。这允许更细粒度地了解任务在工作进程中当前正在执行的操作。可用的状态如下：
- en: '`FAILURE`: The task failed and all of the retries failed as well'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FAILURE`：任务失败，所有重试也失败'
- en: '`PENDING`: The task has not yet been received by the worker'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PENDING`：任务尚未被工作进程接收'
- en: '`RECEIVED`: The task has been received by the worker and is not yet processing'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RECEIVED`：任务已被工作进程接收，但尚未处理'
- en: '`RETRY`: The task failed and is waiting to be retried'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RETRY`：任务失败，正在等待重试'
- en: '`REVOKED`: The task was stopped'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`REVOKED`：任务已停止'
- en: '`STARTED`: The worker has started processing the task'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`STARTED`：工作进程已开始处理任务'
- en: '`SUCCESS`: The task completed successfully'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SUCCESS`：任务成功完成'
- en: 'In Celery, if a task fails, then the task can recall itself with the `retry`
    method as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Celery 中，如果任务失败，则任务可以使用 `retry` 方法重新调用自身，如下所示：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `bind` parameter in the decorator function tells Celery to pass a reference
    to the task object as the first parameter in the function. Using the `self` parameter,
    the `retry` method can be called, which will rerun the task with the same parameters.
    There are several other parameters that can be passed to the function decorator
    to change the behavior of the task:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 装饰器函数中的 `bind` 参数告诉 Celery 将任务对象的引用作为函数的第一个参数传递。使用 `self` 参数，可以调用 `retry` 方法，该方法将使用相同的参数重新运行任务。可以将其他参数传递给函数装饰器，以更改任务的行为：
- en: '`max_retries`: This is the maximum number of times the task can be retried
    before it is declared as failed.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_retries`：这是任务在被声明为失败之前可以重试的最大次数。'
- en: '`default_retry_delay`: This is the time in seconds to wait before running the
    task again. It''s a good idea to keep this at somewhere around a minute or so
    if you expect that the conditions that led to the task failing are transitory—for
    example, network errors.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default_retry_delay`：这是在再次运行任务之前等待的时间（以秒为单位）。如果您预期导致任务失败的条件是短暂的，例如网络错误，那么最好将其保持在大约一分钟左右。'
- en: '`rate_limit`: This specifies the total number of unique calls to this task
    that are allowed to run in a given interval. If the value is an integer, it is
    the total number of this task that is allowed to run per second. The value can
    also be a string in the form of *x/m* for *x* number of tasks per minute or *x/h*
    for *x* number of tasks per hour. For example, passing in *5/m* will only allow
    this task to be called five times a minute.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rate_limit`：这指定在给定间隔内允许运行此任务的唯一调用总数。如果值是整数，则是每秒允许运行此任务的总数。该值也可以是形式为 *x/m*
    的字符串，表示每分钟 *x* 个任务，或形式为 *x/h* 的字符串，表示每小时 *x* 个任务。例如，传入 *5/m* 将只允许每分钟调用此任务五次。'
- en: '`time_limit`: If specified, the task will be killed if it runs longer than
    this number of seconds.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_limit`：如果指定，任务将在运行时间超过此秒数时被终止。'
- en: '`ignore_result`: If the task''s return value isn''t used, then don''t send
    it back.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignore_result`：如果不使用任务的返回值，则不要将其发送回。'
- en: It's a good idea to specify all of these for each task to avoid any chance that
    a task will not be run.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最好为每个任务指定所有这些内容，以避免任务不会运行的任何机会。
- en: Running Celery tasks
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Celery 任务
- en: 'The `delay` method is a shorthand version of the `apply_async` method, which
    is called in this format:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`delay` 方法是 `apply_async` 方法的简写版本，格式如下所示：'
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'However, the `args` keyword can be implicit:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，`args` 关键字可以是隐式的：
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Calling `apply_async` allows you to define some extra functionality in the
    task call that you cannot specify in the `delay` method. First, the `countdown`
    option specifies the amount of time in seconds the worker should wait to run the
    task after receiving it:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `apply_async` 允许您在任务调用中定义一些额外的功能，这些功能在 `delay` 方法中无法指定。首先，`countdown` 选项指定工作进程在接收到任务后等待运行任务的时间（以秒为单位）：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`countdown` is not a guarantee that the task will be run after `600` seconds.
    `countdown` only says that the task is up for processing after *x* number of seconds.
    If all of the worker processes are busy with the other tasks, then it will not
    be run immediately.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`countdown` 不能保证任务将在 `600` 秒后运行。`countdown` 只表示任务在 *x* 秒后准备处理。如果所有工作进程都忙于处理其他任务，则任务将不会立即运行。'
- en: Another keyword argument that `apply_async` gives is the `eta` argument. `eta`
    is passed through a Python `datetime` object that specifies exactly when the task
    should be run. Again, `eta` is not reliable.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply_async` 提供的另一个关键字参数是 `eta` 参数。`eta` 通过一个指定任务应该运行的确切时间的 Python `datetime`
    对象传递。同样，`eta` 不可靠。'
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Celery workflows
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Celery 工作流
- en: 'Celery provides many ways to group multiple, dependent tasks together or to
    execute many tasks in parallel. These methods take a large amount of influence
    from language features found in functional programming languages. However, to
    understand how this works, we first need to understand signatures. Consider the
    following task:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Celery 提供了许多方法来将多个依赖任务分组在一起，或者并行执行多个任务。这些方法受到函数式编程语言中的语言特性的很大影响。然而，要理解这是如何工作的，我们首先需要了解签名。考虑以下任务：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let''s see a **signature** in action to understand it. Open up the `manage.py`
    shell:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个**签名**的实际操作以理解它。打开 `manage.py` shell：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Calling a signature, or sometimes called a **subtask**, of a task creates a
    function that can be passed to the other functions to be executed. Executing the
    signature, like the third-to-last line in the example, executes the function in
    the current process and not in the worker.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 调用任务的签名，有时称为任务的**子任务**，会创建一个可以传递给其他函数以执行的函数。执行签名，就像示例中倒数第三行那样，会在当前进程中执行函数，而不是在工作进程中执行。
- en: Partials
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部分
- en: 'The first application of task signatures is functional programming style partials.
    **Partials** are functions that originally take many arguments; however an operation
    is applied to the original function to return a new function, so the first *n*
    arguments are always the same. An example would be a `multiply` function that
    is not a task:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 任务签名的第一个应用是函数式编程风格的部分。**部分**是最初接受许多参数的函数；然而，对原始函数应用操作以返回一个新函数，因此前 *n* 个参数始终相同。一个例子是一个不是任务的
    `multiply` 函数：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This is a fictional API, but this is very close to the Celery version:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个虚构的 API，但这与 Celery 版本非常接近：
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output in the worker window should show **16**. Basically, we created a
    new function that was saved to partial and that will always multiply its input
    by four.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 工作窗口中的输出应该显示 **16**。基本上，我们创建了一个新函数，保存到部分中，它将始终将其输入乘以四。
- en: Callbacks
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回调
- en: 'Once a task is completed, it is very common to have another task run based
    on the output of the previous tasks. To achieve this, the `apply_async` function
    has a `link` method:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦任务完成，根据前一个任务的输出运行另一个任务是非常常见的。为了实现这一点，`apply_async` 函数有一个 `link` 方法：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The worker output should show that both the `multiply` task and the `log` task
    returned **16**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 工作器输出应该显示 `multiply` 任务和 `log` 任务都返回 **16**。
- en: 'If you have a function that does not take input, or your callback does not
    need the result of the original method, the task signature must be marked as immutable
    with the `si` method:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有一个不需要输入的函数，或者您的回调不需要原始方法的结果，则必须使用 `si` 方法将任务签名标记为不可变：
- en: '[PRE21]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Callbacks** can be used to solve real-world problems. If we wanted to send
    a welcome e-mail every time a task created a new user, then we could produce that
    effect with the following call:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**回调**可以用来解决现实世界的问题。如果我们想要在每次任务创建新用户时发送欢迎电子邮件，那么我们可以通过以下调用产生该效果：'
- en: '[PRE22]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Partials and callbacks can be combined to produce some powerful effects:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 部分和回调可以结合产生一些强大的效果：
- en: '[PRE23]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It's important to note that if this call was saved and the `get` method was
    called on it, the result would be **16** rather than **64**. This is because the
    `get` method does not return the results for callback methods. This will be solved
    with later methods.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，如果保存了此调用并在其上调用了 `get` 方法，则结果将是 **16** 而不是 **64**。这是因为 `get` 方法不会返回回调方法的结果。这将在以后的方法中解决。
- en: Group
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组
- en: 'The `group` function takes a list of signatures and creates a callable function
    to execute all of the signatures in parallel and then return a list of all of
    the results:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`group` 函数接受一个签名列表，并创建一个可调用函数来并行执行所有签名，然后返回所有结果的列表：'
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Chain
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 链
- en: 'The `chain` function takes task signatures and passes the value of each result
    to the next value in the chain, returning one result as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`chain` 函数接受任务签名，并将每个结果的值传递给链中的下一个值，返回一个结果如下：'
- en: '[PRE25]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Chains and partials can be taken a bit further. Chains can be used to create
    new functions when using partials, and chains can be nested as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 链和部分可以进一步发展。链可以用于在使用部分时创建新函数，并且链可以嵌套如下：
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Chord
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 和弦
- en: 'The `chord` function creates a signature that will execute a `group` of signatures
    and pass the final result to a callback:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`chord` 函数创建一个签名，将执行一组签名，并将最终结果传递给回调：'
- en: '[PRE27]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Just like the link argument, the callback is not returned with the `get` method.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 就像链接参数一样，回调不会随着 `get` 方法返回。
- en: 'Using the `chain` syntax with a group and a callback automatically creates
    a chord signature:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `chain` 语法与组和回调自动创建一个和弦签名：
- en: '[PRE28]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Running tasks periodically
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定期运行任务
- en: Celery also has the ability to call tasks periodically. For those familiar with
    ***nix** OSes, this system is a lot like the command-line utility `cron`, but
    it has the added benefit of being defined in our source code rather than on some
    system file. As such, it will be much easier to update when our code is ready
    for publishing to production in [Chapter 13](ch13.html "Chapter 13. Deploying
    Flask Apps"), *Deploying Flask Apps*,. In addition, all of the tasks are run within
    the application context, whereas a Python script called by `cron` would not be.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Celery 还有能力定期调用任务。对于熟悉 ***nix** 操作系统的人来说，这个系统很像命令行实用程序 `cron`，但它的额外好处是在我们的源代码中定义，而不是在某个系统文件中。因此，当我们的代码准备发布到
    [第 13 章](ch13.html "第 13 章。部署 Flask 应用") *部署 Flask 应用* 中时，更新将更容易。此外，所有任务都在应用上下文中运行，而由
    `cron` 调用的 Python 脚本则不会。
- en: 'To add periodic tasks, add the following to the `DevConfig` configuration object:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加定期任务，请将以下内容添加到 `DevConfig` 配置对象中：
- en: '[PRE29]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This `configuration` variable defines that the `log` task should be run every
    30 seconds with the `args` tuple passed as the parameters. Any `timedelta` object
    can be used to define the interval to run the task on.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此`configuration`变量定义了`log`任务应该每30秒运行一次，并将`args`元组作为参数传递。任何`timedelta`对象都可以用来定义运行任务的间隔。
- en: 'To run periodic tasks, another specialized worker named a `beat` worker is
    needed. In another terminal window, run the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行周期性任务，需要另一个名为`beat`工作程序的专门工作程序。在另一个终端窗口中，运行以下命令：
- en: '[PRE30]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If you now watch the terminal output in the main `Celery` worker, you should
    now see a log event every 30 seconds.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在观看主要的`Celery`工作程序中的终端输出，您应该每30秒看到一个日志事件。
- en: What if your task needs to run at much more specific intervals, for example,
    every Tuesday in June at 3 am and 5 pm? For very specific intervals, there is
    the Celery `crontab` object.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的任务需要以更具体的间隔运行，例如，每周二在6月的凌晨3点和下午5点？对于非常具体的间隔，有`Celery` `crontab`对象。
- en: 'To illustrate how the `crontab` object represents intervals, here are some
    examples:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明`crontab`对象如何表示间隔，以下是一些示例：
- en: '[PRE31]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The object has the following arguments:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 该对象具有以下参数：
- en: '`minute`'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`分钟`'
- en: '`hour`'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小时
- en: day_of_week
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`星期几`'
- en: '`day_of_month`'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`每月的日期`'
- en: '`month_of_year`'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`月份`'
- en: Each of these arguments can take various inputs. With plain integers, they operate
    much like the `timedelta` object, but they can also take strings and lists. When
    passed a list, the task will execute on every moment that is in the list. When
    passed a string in the form of **/x*, the task will execute every moment that
    the modulo operation returns zero. Also, the two forms can be combined to form
    a comma-separated string of integers and divisions.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数中的每一个都可以接受各种输入。使用纯整数时，它们的操作方式与`timedelta`对象类似，但它们也可以接受字符串和列表。当传递一个列表时，任务将在列表中的每个时刻执行。当传递一个形式为**/x*的字符串时，任务将在模运算返回零的每个时刻执行。此外，这两种形式可以组合成逗号分隔的整数和除法的字符串。
- en: Monitoring Celery
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控Celery
- en: 'When our code is pushed to the server, our `Celery` worker will not be run
    in the terminal window, it will be run as a background task. Because of this,
    Celery provides many command-line arguments to monitor the status of your `Celery`
    worker and tasks. These commands take the following form:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的代码被推送到服务器时，我们的`Celery`工作程序将不会在终端窗口中运行，它将作为后台任务运行。因此，Celery提供了许多命令行参数来监视您的`Celery`工作程序和任务的状态。这些命令采用以下形式：
- en: '[PRE32]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The main tasks to view the status of your workers are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 查看工作程序状态的主要任务如下：
- en: '`status`: This prints the running workers and if they are up'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`状态`：这会打印运行的工作程序以及它们是否正常运行'
- en: '`result`: When passed a task id, this shows the return value and final status
    of the task'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`结果`：当传递一个任务id时，这显示任务的返回值和最终状态'
- en: '`purge`: Using this, all messages in the broker will be deleted'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`清除`：使用此命令，代理中的所有消息将被删除'
- en: '`inspect active`: This lists all active tasks'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`检查活动`：这将列出所有活动任务'
- en: '`inspect scheduled`: This lists all tasks that have been scheduled with the
    `eta` argument'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`检查已安排`：这将列出所有已使用`eta`参数安排的任务'
- en: '`inspect registered`: This lists all of the tasks waiting to be processed'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`检查已注册`：这将列出所有等待处理的任务'
- en: '`inspect stats`: This returns a dictionary full of statistics on the currently
    running workers and the broker'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`检查统计`：这将返回一个字典，其中包含有关当前运行的工作程序和代理的统计信息'
- en: Web-based monitoring with Flower
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flower进行基于Web的监控
- en: '**Flower** is a web-based, real-time management tool for Celery. In Flower,
    all active, queued, and completed tasks can be monitored. Flower also provides
    graphs and stats on how long each graph has been sitting in the queue versus how
    long its execution took and the arguments to each of those tasks.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**Flower**是一个基于Web的实时管理工具，用于Celery。在Flower中，可以监视所有活动的，排队的和已完成的任务。Flower还提供了关于每个图表在队列中停留的时间以及执行所需的时间和每个任务的参数的图表和统计信息。'
- en: 'To install Flower, use `pip` as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Flower，请使用以下`pip`：
- en: '[PRE33]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To run it, just treat `flower` as a Celery command as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行它，只需将`flower`视为`Celery`命令，如下所示：
- en: '[PRE34]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, open your browser to `http://localhost:5555`. It''s best to familiarize
    yourself with the interface while tasks are running, so go to the command line
    and type the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，打开浏览器到`http://localhost:5555`。最好在任务运行时熟悉界面，因此转到命令行并输入以下内容：
- en: '[PRE35]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Your worker process will now start processing 10,000 tasks. Browse around the
    different pages while the tasks are running to see how Flower interacts with your
    worker while it is really churning.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您的工作程序现在将开始处理10,000个任务。在任务运行时浏览不同的页面，看看Flower在工作程序真正忙碌时如何与其交互。
- en: Creating a reminder app
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个提醒应用
- en: Let's get into some real-world examples in Celery. Suppose another page on our
    site now requires a reminder feature. Users can create reminders that will send
    an e-mail to a specified location at the time specified. We will need a model,
    a task, and a way to call our task automatically every time a model is created.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些Celery中的真实例子。假设我们网站上的另一页现在需要一个提醒功能。用户可以创建提醒，将在指定时间发送电子邮件到指定位置。我们需要一个模型，一个任务，以及一种在每次创建模型时自动调用我们的任务的方法。
- en: 'Let''s start with the following basic SQLAlchemy model:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从以下基本的SQLAlchemy模型开始：
- en: '[PRE36]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now we need a task that will send an e-mail to the location in the model. In
    our `tasks.py` file, add the following task:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一个任务，将发送电子邮件到模型中的位置。在我们的`tasks.py`文件中，添加以下任务：
- en: '[PRE37]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note that our task takes a primary key rather than a model. This is a hedge
    against a race condition, as a passed model could be stale by the time the worker
    finally gets around to processing it. You will also have to replace the placeholder
    e-mails and login with your own login info.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们的任务接受的是主键而不是模型。这是对抗竞争条件的一种保护，因为传递的模型可能在工作程序最终处理它时已经过时。您还需要用自己的登录信息替换占位符电子邮件和登录。
- en: How do we have our task called when the user creates a reminder model? We will
    use a SQLAlchemy feature named `events`. SQLAlchemy allows us to register callbacks
    on our models that will be called when specific changes are made to our models.
    Our task will use the `after_insert` event, which is called after new data is
    entered into the database, whether the model is brand new or being updated.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户创建提醒模型时，我们如何调用我们的任务？我们将使用一个名为`events`的SQLAlchemy功能。SQLAlchemy允许我们在我们的模型上注册回调，当对我们的模型进行特定更改时将被调用。我们的任务将使用`after_insert`事件，在新数据输入到数据库后被调用，无论模型是全新的还是正在更新。
- en: 'We need a callback in `tasks.py`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在`tasks.py`中的回调：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, in `__init__.py`, we will register our callback on our model:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`__init__.py`中，我们将在我们的模型上注册我们的回调：
- en: '[PRE39]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, every time a model is saved, a task is registered that will send an e-mail
    to our user.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当模型被保存时，都会注册一个任务，该任务将向我们的用户发送一封电子邮件。
- en: Creating a weekly digest
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建每周摘要
- en: Say our blog has a lot of people who don't use RSS and prefer mailing lists,
    which is a large number of users. We need some way to create a list of new posts
    at the end of every week to increase our site's traffic. To solve this problem,
    we will create a digest task that will be called by a beat worker at 10 am every
    Saturday.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的博客有很多不使用RSS而更喜欢邮件列表的人，这是大量的用户。我们需要一种方法，在每周末结束时创建一个新帖子列表，以增加我们网站的流量。为了解决这个问题，我们将创建一个摘要任务，该任务将由一个beat
    worker在每个星期六的上午10点调用。
- en: 'First, in `tasks.py`, let''s create our task as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在`tasks.py`中，让我们创建我们的任务如下：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We will also need to add a periodic schedule to our configuration object in
    `config.py` to manage our task:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在`config.py`的配置对象中添加一个周期性计划来管理我们的任务：
- en: '[PRE41]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, we need our e-mail template. Unfortunately, HTML in e-mail clients
    is terribly outdated. Every single e-mail client has different rendering bugs
    and quirks, and the only way to find them is to open your e-mail in all the clients.
    Many e-mail clients don''t even support CSS, and those that do support a very
    small amount of selectors and attributes. In order to compensate, we have to use
    the web development methods of 10 years ago, that is, designing with tables with
    inline styles. Here is our `digest.html`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要我们的电子邮件模板。不幸的是，电子邮件客户端中的HTML已经非常过时。每个电子邮件客户端都有不同的渲染错误和怪癖，找到它们的唯一方法就是在所有客户端中打开您的电子邮件。许多电子邮件客户端甚至不支持CSS，而那些支持的也只支持很少的选择器和属性。为了弥补这一点，我们不得不使用10年前的网页开发方法，也就是使用带有内联样式的表进行设计。这是我们的`digest.html`：
- en: '[PRE42]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Now, at the end of every week, our digest task will be called and it will send
    an e-mail to all the users present in our mailing list.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每周末，我们的摘要任务将被调用，并且会向我们邮件列表中的所有用户发送一封电子邮件。
- en: Summary
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Celery is a very powerful task queue that allows programmers to defer the processing
    of slower tasks to another process. Now that you understand how to move complex
    tasks out of the Flask process, we will take a look at a collection of Flask extensions
    that simplify some common tasks seen in Flask apps.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Celery是一个非常强大的任务队列，允许程序员将较慢的任务的处理推迟到另一个进程中。现在您了解了如何将复杂的任务移出Flask进程，我们将看一下一系列简化Flask应用程序中一些常见任务的Flask扩展。
