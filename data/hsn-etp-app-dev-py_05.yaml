- en: Building for Large-Scale Request Handling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建大规模请求处理
- en: In an enterprise environment, as the number of users grow, it is normal for
    the number of users who try to access the web application at the same time to
    also grow. This presents us with the interesting problem of how to scale the web
    application to handle a large number of concurrent requests by the users.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业环境中，随着用户数量的增长，同时尝试访问Web应用程序的用户数量也会增长是正常的。这给我们带来了一个有趣的问题，即如何扩展Web应用程序以处理大量用户的并发请求。
- en: Scaling up a web application to handle a large number of users is a task that
    can be achieved in multiple ways where one of the simplest ways can be adding
    more infrastructure and running more instances of the application. However, this
    technique, though simple, is highly burdensome on the economics of application
    scalability, since the infrastructure costs associated with running the application
    at scale can be huge. We certainly need to craft our application in such a way
    that it is easily able to handle a lot of concurrent requests without really requiring
    frequent infrastructure scaling.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 将Web应用程序扩展以处理大量用户是可以通过多种方式实现的任务，其中最简单的方式之一可以是增加更多基础设施并运行应用程序的更多实例。然而，尽管这种技术简单，但对应用程序可扩展性的经济影响很大，因为运行规模化应用程序的基础设施成本可能是巨大的。我们当然需要以这样的方式设计我们的应用程序，以便它能够轻松处理大量并发请求，而不需要频繁地扩展基础设施。
- en: Building on the foundation laid out in the previous chapter, we will see how
    we can apply these techniques to build a scalable application that can handle
    a large number of concurrent requests, while also learning a few other techniques
    that will help us scale the application in an effortless manner.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章奠定的基础上，我们将看到如何应用这些技术来构建一个可扩展的应用程序，可以处理大量并发请求，同时学习一些其他技术，将帮助我们轻松地扩展应用程序。
- en: 'Over the course of the chapter, we will be taking a look at the following techniques
    to scale our web application for large-scale request handling:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到以下技术来扩展我们的Web应用程序，以处理大规模的请求处理：
- en: Utilizing reverse proxies in web application deployment
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Web应用部署中利用反向代理
- en: Using thread pools to scale up request processing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程池来扩展请求处理
- en: Understanding the concept of single-threaded concurrent code with Python AsyncIO
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解使用Python AsyncIO的单线程并发代码的概念
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code listings in this book can be found under `chapter05` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码清单可以在[https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)的`chapter05`目录下找到。
- en: 'The code samples can be cloned by running the following command:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过运行以下命令克隆代码示例：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For successful execution of the code sample, the python-`virtualenv` package
    needs to be present.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功执行代码示例，需要安装python-`virtualenv`包。
- en: The problems of accommodating increased concurrency
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容纳增加的并发问题
- en: Over the years, in the time the internet has been around, one of the most common
    problems that web application architects have commonly faced is how to deal with
    the increasing concurrency. As more and more users are coming online and utilizing
    web applications, there is a huge need to scale up infrastructures to manage all
    these requests.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，互联网存在的时间里，Web应用架构师常常面临的最常见问题之一是如何处理不断增加的并发。随着越来越多的用户上线并使用Web应用程序，迫切需要扩展基础设施来管理所有这些请求。
- en: This stands true even for our enterprise web applications. Even though we can
    make an estimate of how many users could be concurrently accessing these web applications
    inside an enterprise, there is no hard and fast rule that will be true for the
    time to come. As the enterprise grows, the number of clients accessing the application
    will also increase, putting more stress upon the infrastructure and increasing
    the need to scale it out. But what options do we have, while trying to scale out
    the application to accommodate the increasing number of clients? Let's take a
    look.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 即使对于我们的企业Web应用程序也是如此。尽管我们可以估计企业内可能有多少用户同时访问这些Web应用程序，但没有硬性规定适用于未来的时间。随着企业的发展，访问应用程序的客户数量也会增加，给基础设施增加更多压力，并增加扩展的需求。但是，在尝试扩展应用程序以适应不断增加的客户数量时，我们有哪些选择？让我们来看看。
- en: The multiple options to scale up
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多种扩展选项
- en: 'The world of technology provides a lot of options to scale up the application
    to accommodate the ever increasing user base; some of these options simply ask
    for increasing the hardware resources whereas the other options require the application
    to be built around dealing with multiple requests internally itself. Most of the
    time, the options of scaling fall into two major categories, vertical scaling,
    and horizontal scaling:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 技术世界提供了许多选项，以扩展应用程序以适应不断增长的用户群体；其中一些选项只是要求增加硬件资源，而其他选项则要求应用程序围绕处理内部的多个请求来构建。大多数情况下，扩展选项分为两大类，即垂直扩展和水平扩展：
- en: '![](Images/093dd96f-4d4a-4e41-984c-d15d16a27c21.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/093dd96f-4d4a-4e41-984c-d15d16a27c21.png)'
- en: 'Let''s take a look at both of them and figure out their pros and cons:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它们，找出它们的利弊：
- en: '**Vertical scaling**: The whole concept of vertical scaling is based upon the
    fact of adding more resources to the existing ...'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直扩展**：垂直扩展的整个概念基于向现有资源添加更多资源的事实...'
- en: Engineering the application for scalability
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为可扩展性工程应用
- en: At a time when most of the enterprise projects resort to using one framework
    or another, which usually decides how the application will be served during the
    production phase, it is still a good idea to take a look beneath the surface and
    understand how to develop the application while keeping the scalability of the
    application in perspective.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数企业项目在生产阶段通常使用一个框架或另一个框架来决定应用程序的服务方式的时候，仍然有必要深入了解如何在开发应用程序时保持应用程序的可扩展性。
- en: In this section, we will take a look at the different techniques that can help
    us build a scalable application, even when we are not using some per-built framework
    which can do it for us. During the course of this section, we will see how we
    can use thread/process pooling to handle multiple clients at the same time, and
    why the pooling of resources is necessary and what prevents us from starting a
    separate thread or process for dealing with every other incoming request.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看看不使用一些预先构建的框架，如何构建可扩展的应用程序的不同技术。在本节课程中，我们将看到如何使用线程/进程池来同时处理多个客户端，以及资源池化为什么是必要的，以及是什么阻止我们为处理每个其他传入请求启动单独的线程或进程。
- en: But before we dive into the concepts of how we can utilize the thread pooling
    or process pooling in the application development, let's first take a look at
    a simple way through which we can hand-off the processing of the incoming requests
    to a background thread.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们深入探讨如何在应用程序开发中利用线程池或进程池之前，让我们首先看一下通过哪种简单的方式我们可以将传入请求的处理交给后台线程。
- en: 'The following code implements a simple socket server which first accepts an
    incoming connection and then hands it off to a background thread for reads and
    writes, hence freeing the main thread to accept the other incoming connections:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码实现了一个简单的套接字服务器，首先接受传入的连接，然后将其交给后台线程进行读写，从而释放主线程以接受其他传入连接：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this code, we have implemented a simple `Server` class which initializes
    a TCP-based server on the machine, ready to accept the incoming connections. Without
    diverting too much, let's try to focus on the important aspect of this code, where
    we start the listening loop of the server under the `listen()` method.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们实现了一个简单的`Server`类，它在机器上初始化了一个基于TCP的服务器，准备接受传入的连接。在不偏离太多的情况下，让我们试着专注于这段代码的重要方面，在这里我们在`listen()`方法下启动了服务器的监听循环。
- en: Under the `listen()` method, we first call the `listen()` method of the socket
    and tell it that it can queue up, at most, 10 connections which have not been
    accepted. Once this limit is reached, any further client connection will be rejected
    by the server. Now, moving on from here, we start an infinite loop where the first
    call is made to the `accept()` method of the socket. The call to the `accept()` method
    blocks until a client attempts to make a connection. On a successful attempt,
    the `accept()` call returns the client connection socket and the client address.
    The client connection socket can be used to perform I/O operations with the client.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在`listen()`方法下，我们首先调用套接字的`listen()`方法，并告诉它最多可以排队10个尚未被接受的连接。一旦达到这个限制，服务器将拒绝任何进一步的客户端连接。接下来，我们开始一个无限循环，在循环中首先调用套接字的`accept()`方法。对`accept()`方法的调用将阻塞，直到客户端尝试建立连接。成功尝试后，`accept()`调用将返回客户端连接套接字和客户端地址。客户端连接套接字可用于与客户端执行I/O操作。
- en: 'The fun part happens next: as soon as the client connection is accepted, we
    launch a daemon thread responsible for handling the communication with the client
    and hand-off the client connection socket to the thread. This essentially frees
    up our main thread from dealing with the I/O of the client socket, and hence,
    our main thread can now accept more clients. This process continues for every
    other client that connects to our server.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来发生的有趣部分是：一旦客户端连接被接受，我们就启动一个负责处理与客户端通信的守护线程，并将客户端连接套接字交给线程处理。这实质上使我们的主线程从处理客户端套接字的I/O中解放出来，因此，我们的主线程现在可以接受更多的客户端。这个过程对于连接到我们服务器的每个其他客户端都会继续进行。
- en: So far so good; we have a nice way through which we can handle the incoming
    clients and our service can scale up gradually as the number of clients increases.
    That was an easy solution, wasn't it? Well, apparently during the course of coming
    up with this solution, we have ignored a major flaw in the process. The flaw lies
    in the fact that we have not implemented any kind of control related to how many
    threads can be launched by the application for dealing with the incoming clients.
    Imagine what will happen if a million clients try to connect to our server? Will
    we be really running a million threads at the same time? The answer is a big NO.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止一切都很好；我们有了一个很好的方法来处理传入的客户端，我们的服务可以随着客户端数量的增加逐渐扩展。这是一个简单的解决方案，不是吗？嗯，在提出这个解决方案的过程中，显然我们忽略了一个主要缺陷。缺陷在于我们没有实现任何与应用程序可以启动多少个线程来处理传入客户端相关的控制。想象一下，如果一百万个客户端尝试连接到我们的服务器会发生什么？我们真的会同时运行一百万个线程吗？答案是否定的。
- en: But why isn't it possible? Let's take a look.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么不可能呢？让我们来看看。
- en: Controlling the concurrency
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制并发
- en: 'In the previous example, we came up with a problem of why can''t we have a
    million threads, each dealing with an individual client? That should provide us
    with a lot of concurrency and scalability. But, there are a number of reasons
    that really prevent us from running a million threads at the same time. Let''s
    try to take a look at the possible reasons preventing us from scaling our application
    infinitely:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们遇到了一个问题，为什么我们不能有一百万个线程，每个线程处理一个单独的客户端？这应该为我们提供了大量的并发性和可扩展性。但是，有许多原因实际上阻止我们同时运行一百万个线程。让我们试着看看可能阻止我们无限扩展应用程序的原因：
- en: '**Resource limitations**: Every single client connection that is being handled
    by the server doesn''t come free of cost. With every new connected client, we
    are expending some of the resources of the machine. These may include file descriptors
    that map to a socket, some amount of memory that is used to hold the information
    ...'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源限制**：服务器处理的每个客户端连接都不是免费的。随着每个新连接的客户端，我们都在消耗机器的一些资源。这些资源可能包括映射到套接字的文件描述符，用于保存信息的一些内存...'
- en: Using thread pools for handling incoming connections
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程池处理传入的连接
- en: As we saw in the previous section, we do not need an infinite number of threads
    to handle the incoming clients. We can manage with a limited number of threads
    to handle a large number of clients. But, how do we implement this thread pooling
    in our application. As it turns out, it is quite easy to implement the thread
    pool functionality with Python 3 and the `concurrent.futures` module.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中看到的，我们不需要无限数量的线程来处理传入的客户端。我们可以通过有限数量的线程来处理大量的客户端。但是，我们如何在我们的应用程序中实现这个线程池呢？事实证明，使用Python
    3和`concurrent.futures`模块实现线程池功能是相当容易的。
- en: 'The following code sample modifies our existing TCP server example to use a
    thread pool, instead of arbitrarily launching an infinite number of threads to
    handle the incoming client connections:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例修改了我们现有的TCP服务器示例，以使用线程池来处理传入的客户端连接，而不是任意启动无限数量的线程：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, we modified our TCP server code to utilize a thread pool instead
    of launching an arbitrary number of threads. Let's take a look at how we made
    it possible.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们修改了我们的TCP服务器代码，以利用线程池来处理客户端连接，而不是启动任意数量的线程。让我们看看我们是如何做到的。
- en: 'First, to utilize the thread pool, we need to initialize an instance of the
    thread pool executor. Under the `__init__` method of the `Server` class, we first
    initialize the thread pool executor by calling its constructor:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，要使用线程池，我们需要初始化线程池执行器的实例。在`Server`类的`__init__`方法中，我们首先通过调用其构造函数来初始化线程池执行器：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `ThreadPoolExecutor` constructor takes a `max_workers` parameter that defines
    how many concurrent threads are possible inside the `ThreadPool`. But, what will
    be an optimal value for the `max_workers` parameter?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`ThreadPoolExecutor`构造函数接受一个`max_workers`参数，该参数定义了`ThreadPool`内可能有多少并发线程。但是，`max_workers`参数的最佳值是多少呢？'
- en: A general rule of thumb will be to have `max_workers` = *(5 x Total number of
    CPU cores)*. The reasoning behind this formula is that inside a web application,
    most of the threads are generally waiting for the I/O to complete, whereas a few
    threads are busy doing CPU-bound operations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经验法则是将`max_workers` = *(5 x CPU核心总数)*。这个公式背后的原因是，在Web应用程序中，大多数线程通常在等待I/O完成，而少数线程正在忙于执行CPU绑定的操作。
- en: 'The next thing after we have created a `ThreadPoolExecutor` is to submit jobs
    to it so that they can be processed by the threads inside the Executor Pool. This
    can be achieved through the use of the submit method of the `ThreadPoolExecutor`
    class. This can be seen under the `listen()` method of the `Server` class:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了`ThreadPoolExecutor`之后，下一步是提交作业，以便它们可以由执行器池内的线程处理。这可以通过`Server`类的`listen()` 方法来实现：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `submit()` method of the `ThreadPoolExecutor` takes in, as the first parameter,
    the name of the method to execute inside a thread and the parameters that need
    to be passed to the executing method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`ThreadPoolExecutor`的`submit()` 方法的第一个参数是要在线程内执行的方法的名称，第二个参数是要传递给执行方法的参数。'
- en: 'That was quite simple to implement and provides us with lots of benefits, such
    as:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做非常简单，而且给我们带来了很多好处，比如：
- en: Optimal usage of resources provided by the underlying infrastructure
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 充分利用底层基础设施提供的资源
- en: Ability to handle multiple requests
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理多个请求的能力
- en: Increased scalability and reduced wait times for the clients
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加了可扩展性，减少了客户端的等待时间
- en: One important thing to take a note of here is, since the `ThreadPoolExecutor`
    utilizes the threads, the CPython implementation might not provide the maximum
    performance due to the presence of GIL, which doesn't allow the execution of more
    than one thread at a time. Hence, the performance of the application may vary
    depending upon the underlying Python implementation being used.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一点是，由于`ThreadPoolExecutor`利用了线程，CPython实现可能由于GIL的存在而无法提供最大性能，GIL不允许同时执行多个线程。因此，应用程序的性能可能会因所使用的底层Python实现而异。
- en: Now, the question that arises is, what if we wanted to sidestep the Global Interpreter
    Lock? Is there some mechanism while still using the CPython implementation of
    Python? We discussed this scenario in the previous chapter and settled with the
    use of Python's multiprocessing module in place of the threading library.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在出现的问题是，如果我们想要规避全局解释器锁，那该怎么办呢？在仍然使用Python的CPython实现的情况下，有没有一些机制？我们在上一章讨论了这种情况，并决定使用Python的多进程模块来代替线程库。
- en: 'Also, as it turns out, using a `ProcessPoolExecutor` is quite a simple feat
    to achieve. The underlying implementation inside the concurrent.futures package
    takes care of most of the necessities and provides the programmer with a simple-to-use
    abstraction. To see this in action, let''s modify our previous example to swap
    in `ProcessPoolExecutor` in place of the `ThreadPoolExecutor`. To do this, all
    we need to do is first import the correct implementation from the concurrent.futures
    package as described by the following line:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，事实证明，使用`ProcessPoolExecutor`是一件相当简单的事情。并发.futures包中的底层实现处理了大部分必要性，并为程序员提供了一个简单易用的抽象。为了看到这一点，让我们修改我们之前的例子，将`ProcessPoolExecutor`替换为`ThreadPoolExecutor`。要做到这一点，我们只需要首先从concurrent.futures包中导入正确的实现，如下行所述：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The next thing we need to do is to modify our `__init__` method to create a
    process pool instead of a thread pool. The following implementation of the `__init__`
    method shows how we can achieve this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的下一件事是修改我们的`__init__`方法，以创建一个进程池而不是线程池。下面的`__init__`方法的实现显示了我们如何做到这一点：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Indeed, that was a simple process to carry out and now our application can use
    the multiprocess model instead of the multithread model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，这是一个简单的过程，现在我们的应用程序可以使用多进程模型而不是多线程模型。
- en: But, can we keep the pool size the same or does it also need to change?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们可以保持池大小不变，还是它也需要改变？
- en: Every process has its own memory space and internal pointers that it needs to
    maintain, which makes the process heavier in comparison to the use of threads
    for achieving concurrency. This provides a reason to reduce the pool size so as
    to allow for the heavier usage of the underlying system resources. As a general
    rule, for a `ProcessPoolExecutor`, the `max_workers` can be calculated by the
    formula `max_workers` = *(2 x Number of CPU Cores + 1)*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 每个进程都有自己的内存空间和需要维护的内部指针，这使得进程比使用线程实现并发更重。这提供了减少池大小的理由，以便允许更重的底层系统资源的使用。作为一个一般规则，对于`ProcessPoolExecutor`，`max_workers`可以通过公式`max_workers`
    = *(2 x CPU核心数 + 1)*来计算。
- en: The reasoning behind this formula can be attributed to the fact that, at any
    given time, we can assume that half of the processes will be busy in performing
    network I/O while the others might be busy doing CPU-intensive tasks.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式背后的推理可以归因于这样一个事实，即在任何给定时间，我们可以假设一半的进程将忙于执行网络I/O，而另一半可能忙于执行CPU密集型任务。
- en: So, now we have a fair enough idea about how we can use a resource pool and
    why it is a better approach in comparison to launching an arbitrary number of
    threads. But, this approach still requires a lot of context switches and is also
    highly dependent upon the underlying Python implementation being used. But there
    should be something better than this, for sure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们对如何使用资源池以及为什么这是一个比启动任意数量的线程更好的方法有了一个相当清楚的想法。但是，这种方法仍然需要大量的上下文切换，并且也高度依赖于所使用的底层Python实现。但肯定有比这更好的东西。
- en: With this in mind, let's try to venture into another territory in the kingdom
    of Python, the territory of asynchronous programming.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们尝试进入Python王国的另一个领域，即异步编程领域。
- en: Asynchronous programming with AsyncIO
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AsyncIO进行异步编程
- en: Before we dive into this unknown territory of asynchronous programming, let's
    first try to recall why we used threads or multiple processes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨异步编程这个未知领域之前，让我们首先回顾一下为什么我们使用线程或多个进程。
- en: One of the main reasons to use threads or multiple processes was to increase
    the concurrency and, as a result, the ability of the application to handle a higher
    number of concurrent requests. But this came at a cost of increased resource utilization,
    and the limited ability to run multiple threads or the launching of heavier processes
    to accommodate higher concurrency with complex mechanisms of implementing locks
    between the shared data structures.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程或多个进程的主要原因之一是增加并发性，从而使应用程序能够处理更多的并发请求。但这是以增加资源利用率为代价的，而且使用多线程或启动更重的进程来适应更高的并发性，需要复杂的实现在共享数据结构之间实现锁定。
- en: Now, in the context of building a scalable web application, we also have a few
    major differences from a general purpose ...
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在构建可扩展的Web应用程序的背景下，我们还有一些与一般用途不同的主要区别...
- en: AsyncIO terminology
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AsyncIO术语
- en: 'As we recently discussed, the support for asynchronous programming in Python
    is implemented through the use of an event loop and co-routines. But what exactly
    are they? Let''s take a look:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们最近讨论的，Python中对异步编程的支持是通过事件循环和协程来实现的。但它们究竟是什么？让我们来看一下：
- en: '![](Images/da23e7db-4f0e-46af-b4c4-77f78570c732.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/da23e7db-4f0e-46af-b4c4-77f78570c732.png)'
- en: Event loop
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件循环
- en: An event loop, as its name implies, is a loop. What this loop does is, when
    a new task is supposed to be executed, the event loop queues this task. Now from
    here, the control shifts to the event loop. When the event loop runs, it checks
    whether there is some task in its queue or not. If there is a task present, the
    control switches to the task.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 事件循环，顾名思义，就是一个循环。这个循环的作用是，当一个新任务应该被执行时，事件循环会将这个任务排队。现在，控制权转移到了事件循环。当事件循环运行时，它会检查它的队列中是否有任务。如果有任务存在，控制权就会转移到这个任务上。
- en: Now, here is the interesting part in the context of the asynchronous execution
    of tasks. Suppose there are two tasks, namely Task A and Task B, in the queue
    of the event loop. When the event loop starts executing, it checks the status
    of the task queue it has. The event queue finds out that there are tasks in its
    queue. So, the event queue picks up Task A. Now a context switch happens ...
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在异步执行任务的上下文中，这是一个有趣的部分。假设事件循环的队列中有两个任务，即任务A和任务B。当事件循环开始执行时，它会检查它的任务队列的状态。事件队列发现它的队列中有任务。因此，事件队列选择了任务A。现在发生了上下文切换...
- en: Co-routines
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协程
- en: Co-routines in Python AsyncIO provide a lightweight mechanism of executing multiple
    simultaneous operations. The co-routines are implemented as a special use case
    of generators in Python. So, before we dive into understanding what co-routines
    are, let's spend a little time on understanding the generators.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Python AsyncIO中的协程提供了执行多个同时操作的轻量级机制。协程在Python中作为生成器的特殊用例实现。因此，在我们深入理解协程之前，让我们花一点时间来理解生成器。
- en: In general terms, generators are those functions which generate some value.
    However, that is what every other function does, so how does a generator differ
    from a regular function. The difference lies in how the life cycle of a general
    function differs from a generator. When we call a function, it produces some value,
    returns it, and the scope of the function is destroyed once the call moves out
    of the function body. When we call the function again, a new scope is generated
    and executed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，生成器是那些生成一些值的函数。然而，这是每个其他函数所做的，那么生成器与常规函数有何不同。区别在于一般函数的生命周期与生成器的生命周期不同。当我们调用一个函数时，它产生一些值，返回它，一旦调用移出函数体，函数的作用域就被销毁。当我们再次调用函数时，会生成并执行一个新的作用域。
- en: In contrast to this, when we call a generator, the generator can return a value
    and then goes into a paused state and the control transfers back to the caller.
    At this time, the scope of the generator is not destroyed and it can pick up the
    generation of values from where it previously left. This basically provides us
    with a function through which we can pull or yield some values.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，当我们调用一个生成器时，生成器可以返回一个值，然后进入暂停状态，控制权转移到调用者。此时，生成器的作用域不会被销毁，它可以从之前离开的地方继续生成值。这基本上为我们提供了一个通过它可以拉取或产生一些值的函数。
- en: 'The following code sample shows how to write a simple generator function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例显示了如何编写一个简单的生成器函数：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The interesting part here is that a generator won't continue to provide you
    with the next result by simply calling the generator again and again. For yielding
    new results, we need to use the `next()` method on the generator. This allows
    us to yield new results from the generator.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有趣的部分是，通过简单地一次又一次地调用生成器，生成器不会继续提供下一个结果。为了产生新的结果，我们需要在生成器上使用`next()`方法。这允许我们从生成器中产生新的结果。
- en: Now, co-routines implement a special use case of generator in which they can
    not only yield new results, but can also take in some data. This is made possible
    with a combination of yield and the `send()` method of the generators.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，协程实现了生成器的一个特殊用例，在这个用例中，它不仅可以产生新的结果，还可以接收一些数据。这是通过yield和生成器的`send()`方法的组合实现的。
- en: 'The following code sample shows the implementation of a simple co-routine:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例显示了一个简单协程的实现：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Since co-routines allow for the pausing and resuming of functions, and hence
    the lazy generation of the results, that makes it a good option for the use case
    of asynchronous programming, where the tasks are frequently sent into the blocking
    state and are then resumed from there once their operation completes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于协程允许函数暂停和恢复，因此可以懒惰地生成结果，这使得它成为异步编程的一个很好的选择，其中任务经常进入阻塞状态，一旦它们的操作完成，就会从那里恢复。
- en: Tasks
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务
- en: A task in Python AsyncIO is a mechanism to wrap the co-routines. Every task
    has a result associated with it, that may be generated immediately or may be deferred
    depending upon the kind of task. This result is known as the Future.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Python AsyncIO中的任务是包装协程的机制。每个任务都有与之关联的结果，可能会立即生成，也可能会延迟，这取决于任务的类型。这个结果被称为Future。
- en: In AsyncIO, a task is a subclass of the Future which wraps around a co-routine.
    When a co-routine has finished generating the values, the task returns and is
    marked as complete by the event loop and is hence removed from the task queue
    of the event queue.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在AsyncIO中，任务是Future的一个子类，它包装了一个协程。当协程完成生成值时，任务返回并被事件循环标记为完成，因此从事件队列的任务队列中移除。
- en: Now, we have a fair enough idea of the terminology associated with the use of
    Python AsyncIO. Let's now dive into some action and write a simple program to
    understand how the Python AsyncIO really works.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对与Python AsyncIO相关的术语有了相当清楚的概念。现在让我们深入一些行动，并编写一个简单的程序来了解Python AsyncIO的工作原理。
- en: Writing a simple Python AsyncIO program
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写一个简单的Python AsyncIO程序
- en: It's time to buckle up and start taking a dive into the world of asynchronous
    programming with Python and to understand how the AsyncIO really works.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候做好准备，开始深入了解Python异步编程的世界，了解AsyncIO是如何工作的。
- en: 'The following code implements a simple URL fetcher using the Python requests
    library and AsyncIO:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用Python请求库和AsyncIO实现了一个简单的URL获取器：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: That was a small and a nice asynchronous program implementing the Python AsyncIO
    library. Now, let's spend some time understanding what we did here.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个小而不错的异步程序，实现了Python AsyncIO库。现在，让我们花一些时间来理解我们在这里做了什么。
- en: Starting from the top, we have imported the Python requests library to make
    web requests from our Python code and have also imported the Python's AsyncIO
    library.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始，我们已经导入了Python请求库来从我们的Python代码中进行网络请求，并且还导入了Python的AsyncIO库。
- en: 'Next, we define a co-routine named `fetch_url`. The general syntax of defining
    a co-routine for AsyncIO requires the use of the `async` keyword:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义了一个名为`fetch_url`的协程。在AsyncIO中定义协程的一般语法需要使用`async`关键字：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The next in line is the definition of another co-routine named `get_url`. What
    we do inside the `get_url` routine is make a call to our other co-routine, `fetch_url`,
    which does the actual fetch of the URL.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是另一个名为`get_url`的协程的定义。在`get_url`例程中，我们调用另一个协程`fetch_url`，它执行实际的URL获取。
- en: 'Since `fetch_url` is a blocking co-routine, we proceed the call to `fetch_url`
    with the `await` keyword. This signifies that this method can be suspended until
    the results are obtained:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`fetch_url`是一个阻塞协程，我们在调用`fetch_url`之前使用`await`关键字。这表示这个方法可以被暂停，直到结果被获取：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next in the program is the definition of the `process_results` method. We use
    this method as a callback to process the results from the `get_url` method once
    they arrive. This method takes a single parameter, a `future` object, which will
    contain the results of the function call to the `get_url`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 程序中的下一个部分是`process_results`方法的定义。我们使用这个方法作为一个回调来处理`get_url`方法的结果一旦它们到达。这个方法接受一个参数，一个`future`对象，它将包含`get_url`函数调用的结果。
- en: 'Inside the method, the results of the future can be accessed through the use
    of the `results()` method of the `future` object:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在方法内部，可以通过`future`对象的`results()`方法访问future的结果：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With this, we have all the basic machinery set up for the execution of the AsyncIO
    event loop. Now, it's time to implement a real event loop and submit a few tasks
    to it.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们已经为执行AsyncIO事件循环设置了所有基本的机制。现在，是时候实现一个真正的事件循环并向其提交一些任务了。
- en: We start this by first fetching an AsyncIO event loop by making a call to the `get_event_loop()`
    method. The `get_event_loop()` method returns the optimal event loop implementation
    of AsyncIO for the platform on which the code is running.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过调用`get_event_loop()`方法获取AsyncIO事件循环。`get_event_loop()`方法返回在代码运行的平台上的AsyncIO的最佳事件循环实现。
- en: AsyncIO implements multiple event loops which a programmer can use. Usually
    a simple call to `get_event_loop()` will return the best event loop implementation
    for the system the interpreter is running on.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO实现了多个事件循环，程序员可以使用。通常，对`get_event_loop()`的简单调用将返回系统解释器正在运行的最佳事件循环实现。
- en: 'Once we have the loop created, we now submit a few tasks to the event loop
    through the use of the `create_task()` method. This adds the tasks to the queue
    of the event loop to execute. Now, since these tasks are asynchronous and we don''t
    have a clue about which task will produce the results first, we need to provide
    a callback to handle the results of the task. To achieve this, we add a callback
    to the tasks with the help of the tasks `add_done_callback()` method:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了循环，现在我们通过使用`create_task()`方法向事件循环提交了一些任务。这将任务添加到事件循环的队列中以执行。现在，由于这些任务是异步的，我们不知道哪个任务会首先产生结果，因此我们需要提供一个回调来处理任务的结果。为了实现这一点，我们使用任务的`add_done_callback()`方法向任务添加回调：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once everything here is set, we start the event loop into a `run_forever` mode
    so that the event loop keeps on running and dealing with the new tasks.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这里的一切都设置好了，我们就开始进入“run_forever”模式的事件循环，这样事件循环就会继续运行并处理新的任务。
- en: With this, we have completed the implementation of a simple AsyncIO program.
    But hey, we are trying to build a enterprise scale application. What if I wanted
    to build an enterprise web application with AsyncIO?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们已经完成了一个简单的AsyncIO程序的实现。但是，嘿，我们正在尝试构建一个企业规模的应用程序。如果我想用AsyncIO构建一个企业级Web应用程序呢？
- en: So, now let's take a look at how we can use AsyncIO to implement a simple asynchronous
    socket server.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在让我们看看如何使用AsyncIO来实现一个简单的异步套接字服务器。
- en: Implementing a simple socket server with AsyncIO
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AsyncIO实现简单的套接字服务器
- en: The AsyncIO library provided by the Python implementation provides a lot of
    powerful functionality. One of these many functionalities is the ability to interface
    and manage socket communication. This provides the programmer with the ability
    to implement asynchronous socket handling and, hence, allows for a higher number
    of clients to connect to the server.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Python实现提供的AsyncIO库提供了许多强大的功能。其中之一是能够接口和管理套接字通信。这为程序员提供了实现异步套接字处理的能力，因此允许更多的客户端连接到服务器。
- en: 'The following code sample builds a simple socket handler with the callback-based
    mechanism to handle the communication with the clients:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例构建了一个简单的套接字处理程序，使用基于回调的机制来处理与客户端的通信：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Boosting the application concurrency
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增加应用程序的并发性
- en: Most of the time when we are building some web application through a framework,
    the frameworks usually provide a small and easy to run web server. Although these
    servers are good for use in the development environment to quickly realize the
    changes and debug through the issues inside the application during the development
    stage, these servers are not capable of handling the production workloads.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们通过框架构建Web应用程序时，大多数情况下，框架通常会提供一个小巧易用的Web服务器。尽管这些服务器在开发环境中用于快速实现更改并在开发阶段内部调试应用程序中的问题，但这些服务器无法处理生产工作负载。
- en: 'Even in the case when the whole application has been developed from scratch,
    it is generally a good idea to proxy the communication to the web application
    through use of a reverse proxy. But the question arises is, why do we need to
    do so? Why shouldn''t we just run the web application directly and let it handle
    the incoming requests. Let''s quickly go through all the responsibilities the
    web application serves:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 即使整个应用程序是从头开始开发的情况下，通常也是一个好主意通过使用反向代理来代理与Web应用程序的通信。但问题是，为什么我们需要这样做？为什么我们不直接运行Web应用程序并让它处理传入的请求。让我们快速浏览一下Web应用程序的所有职责：
- en: '**Handling of incoming requests**: When a new request arrives at the web application,
    the web application might need to decide what to do with that request. If the
    web application has workers that can process the request, the application will
    accept the request, hand it over to a worker, and return the response for the
    request, once the worker finishes processing. If there is no worker, then the
    web application has to queue this request for later processing. In the worst case,
    when the queue backlog has exceeded the threshold of the maximum number of queued
    clients, then the web application has to reject the request.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理传入请求**：当一个新的请求到达Web应用程序时，Web应用程序可能需要决定如何处理该请求。如果Web应用程序有可以处理请求的工作进程，应用程序将接受请求，将其交给工作进程，并在工作进程完成处理后返回请求的响应。如果没有工作进程，那么Web应用程序必须将此请求排队以供以后处理。在最坏的情况下，当队列积压超过最大排队客户端数量的阈值时，Web应用程序必须拒绝请求。'
- en: '**Serving static resources**: If the web application needs to generate dynamic
    HTML pages, it may also double up as a server to send across the static resources
    such as CSS, Javascript, images, and so on, hence increasing the load.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供静态资源**：如果Web应用程序需要生成动态HTML页面，它也可以兼作服务器发送静态资源，如CSS、Javascript、图像等，从而增加负载。'
- en: '**Handling encryption**: Most of the web applications now come up with the
    encryption turned on. In this case, our web application will also require us to
    manage the parsing of the encrypted data and provide a secure connection.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理加密**：现在大多数网络应用程序都启用了加密。在这种情况下，我们的网络应用程序还需要我们来管理加密数据的解析并提供安全连接。'
- en: Those are quite some responsibilities to be handled by a simple web application
    server. What we rather need is a mechanism through which we can offload quite
    a lot of these responsibilities from the web application server and let it handle
    only the essential work that it is supposed to do and where it really shines.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是由一个简单的网络应用程序服务器处理的相当多的责任。我们实际上需要的是一种机制，通过这种机制，我们可以从网络应用程序服务器中卸载很多这些责任，让它只处理它应该处理的基本工作，并且真正发挥其作用。
- en: Running behind a reverse proxy
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在反向代理后运行
- en: 'So, our first line of action to improve the ability of our web application
    to handle a lot of clients, is to first take a few responsibilities off its shoulders.
    A simple option that comes to mind in order to achieve this, is to first start
    running the web application behind a **Reverse Proxy**:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们改进网络应用程序处理大量客户端的第一步行动是，首先从它的肩上卸下一些责任。为了实现这一点，首先要做的简单选择是将网络应用程序放在**反向代理**后面运行：
- en: '![](Images/86e65d54-88df-4f22-a6f3-ae0ed9b7e2a1.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/86e65d54-88df-4f22-a6f3-ae0ed9b7e2a1.png)'
- en: So, what essentially does a **Reverse Proxy** do? The way the reverse proxy
    works is, when a **Client** request arrives at the **Web Application Server**,
    the **Reverse Proxy** intercepts the request. Based on the rules defined to match
    the request to the appropriate backend application, the **Reverse Proxy** then
    forwards this request to the ...
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，**反向代理**到底是做什么的呢？反向代理的工作方式是，当**客户端**请求到达**网络应用程序服务器**时，**反向代理**会拦截该请求。根据定义的规则将请求匹配到适当的后端应用程序，**反向代理**然后将该请求转发到...
- en: Improved security
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高安全性
- en: One of the first advantages that comes to the mind when considering the use
    of a reverse proxy is the improved security. This happens because now we can run
    our web application behind the firewall so that it cannot be accessed directly.
    The reverse proxy intercepts the request and forwards it to the application without
    letting the user know what is going on behind the scenes with the request that
    they made.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑使用反向代理时首先想到的一个优势是提高安全性。这是因为现在我们可以在防火墙后面运行我们的网络应用程序，因此无法直接访问。反向代理拦截请求并将其转发到应用程序，而不让用户知道他们所发出的请求在幕后发生了什么。
- en: This restricted access to the web application helps in reducing the attack surface
    that can be utilized by a malicious user to break into the web application, and
    access or modify the critical records.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对网络应用程序的受限访问有助于减少恶意用户可以利用的攻击面，从而破坏网络应用程序，并访问或修改关键记录。
- en: Improved connection handling
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进连接处理
- en: A reverse proxy server can also be used to improve the connection handling capability
    of the web application. Nowadays, to speed up the fetching of the remote content,
    the web browsers open multiple connections to a web server to increase the parallel
    download of the resources. The reverse proxy can queue up and serve the connection
    requests as the web application is processing the pending requests, hence improving
    the connection acceptance and reducing the load on the application to manage the
    connection states.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 反向代理服务器还可以用于改进网络应用程序的连接处理能力。如今，为了加快获取远程内容的速度，Web浏览器会打开多个连接到Web服务器，以增加资源的并行下载。反向代理可以排队并提供连接请求，同时网络应用程序正在处理待处理的请求，从而提高连接接受性并减少应用程序管理连接状态的负载。
- en: Resource caching
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源缓存
- en: When the web application generates a response to a particular client request,
    there is a chance that the same kind of request may arrive again, or the same
    resource may be requested again. For every similar request, using the web application
    to generate the response again and again may turn out to be a not so elegant solution.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络应用程序为特定客户端请求生成响应时，有可能会再次收到相同类型的请求，或者再次请求相同的资源。对于每个类似的请求，使用网络应用程序一遍又一遍地生成响应可能并不是一个优雅的解决方案。
- en: The reverse proxies can at times help understand the request and response patterns
    and implement caching for them. When caching is enabled, when the similar request
    arrives again or the same resource is requested again, the reverse proxy, instead
    of forwarding the request to the web application can send back the cached response
    directly, hence offloading a lot of overhead from the web application. This results
    in the improved performance of the web application and a shorter response time
    for the clients.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 反向代理有时可以帮助理解请求和响应模式，并为它们实施缓存。当启用缓存时，当再次收到类似的请求或再次请求相同的资源时，反向代理可以直接发送缓存的响应，而不是将请求转发到网络应用程序，从而卸载了网络应用程序的很多开销。这将提高网络应用程序的性能，并缩短客户端的响应时间。
- en: Serving static resources
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供静态资源
- en: Most of the web applications have two kind of resources that they serve. One
    is the dynamic responses generated in accordance to the external input and static
    content that remains the same, such as CSS files, Javascript files, images, and
    so on.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数网络应用程序提供两种资源。一种是根据外部输入生成的动态响应，另一种是保持不变的静态内容，例如CSS文件、Javascript文件、图像等。
- en: It provides a lot of performance gain as well as improved scalability if we
    can offload either one of these responsibilities from the web application.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们可以从网络应用程序中卸载这些责任中的任何一项，那么它将提供很大的性能增益和改进的可扩展性。
- en: The best possibility that we have here is to offload the serving of static resources
    to the clients. A reverse proxy can also double up as a server which can serve
    the static resources to the clients without forwarding these requests to the web
    application server, which dramatically reduces the number of requests waiting
    to ...
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里最好的可能性是将静态资源的提供转移到客户端。反向代理也可以充当服务器，为客户端提供静态资源，而无需将这些请求转发到Web应用程序服务器，从而大大减少了等待的请求数量...
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Through the course of this chapter, we got to learn about the different ways
    through which we can build our web application to handle a large number of concurrent
    requests. We started off by understanding and learning about the different scaling
    techniques, such as vertical scaling and horizontal scaling, and learned about
    the different pros and cons of each technique. We then further dived into the
    topics to help us improve the ability of the web application itself to process
    a higher number of requests. This led us to a journey into the use of resource
    pools and why it is a good idea to use resource pooling instead of arbitrarily
    allocating the resources for every new request that arrives at the web application.
    Further on in the journey, we got to know about the asynchronous way of dealing
    with the incoming requests and why the asynchronous mechanism is better suited
    for higher scalability in the case of web applications which are more I/O bound.
    We ended our discussion on scaling the applications for large numbers of clients
    by looking into the use of reverse proxies and what advantages a reverse proxy
    provides to help us scale our web application up.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的过程中，我们了解了构建我们的Web应用程序以处理大量并发请求的不同方式。我们首先了解并学习了不同的扩展技术，如垂直扩展和水平扩展，并了解了每种技术的不同优缺点。然后，我们进一步深入讨论了帮助我们提高Web应用程序本身处理更多请求的能力的主题。这使我们进入了使用资源池的旅程，以及为什么使用资源池而不是随意分配资源给每个到达Web应用程序的新请求是一个好主意。在旅程的进一步过程中，我们了解了处理传入请求的异步方式，以及为什么异步机制更适合于更I/O绑定的Web应用程序的更高可扩展性。我们通过研究反向代理的使用以及反向代理为我们扩展Web应用程序提供的优势来结束了我们关于为大量客户端扩展应用程序的讨论。
- en: Now with the understanding of how we can make our application handle a large
    number of concurrent requests, the next chapter will take us through the process
    of building a demo application taking advantage of the different concepts we have
    learned so far in the book so far.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过了解我们如何使我们的应用程序处理大量并发请求，下一章将带领我们通过构建演示应用程序的过程，利用到目前为止在本书中学到的不同概念。
- en: Questions
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How can we use multiple instances of the same application to serve the incoming
    requests?
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何使用同一应用程序的多个实例来处理传入请求？
- en: How do we implement process pools and distribute the client requests over them?
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何实现进程池并将客户端请求分发到它们之上？
- en: Can we implement an application which utilizes both process pooling and thread
    pooling? What are the issues we may face while implementing the same?
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们是否可以实现一个同时利用进程池和线程池的应用程序？在实施相同的过程中可能会遇到什么问题？
- en: How do we implement a basic web server with AsyncIO?
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何使用AsyncIO实现基本的Web服务器？
