- en: Concurrent Web Requests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发网络请求
- en: This chapter will focus on the application of concurrency in making web requests.
    Intuitively, making requests to a web page to collect information about it is
    independent to applying the same task to another web page. Concurrency, specifically
    threading in this case, therefore can be a powerful tool that provides a significant
    speedup in this process. In this chapter, we will learn the fundamentals of web
    requests and how to interact with websites using Python. We will also see how
    concurrency can help us make multiple requests in an efficient way. Finally, we
    will look at a number of good practices in web requests.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点介绍并发性在进行网络请求时的应用。直观地，向网页发出请求以收集有关其的信息与将相同任务应用于另一个网页是独立的。因此，在这种情况下，特别是线程，可以成为一个强大的工具，可以在这个过程中提供显著的加速。在本章中，我们将学习网络请求的基础知识以及如何使用Python与网站进行交互。我们还将看到并发性如何帮助我们以高效的方式进行多个请求。最后，我们将看一些网络请求的良好实践。
- en: 'In this chapter, we will cover the following concepts:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下概念：
- en: The basics of web requests
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络请求的基础知识
- en: The requests module
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求模块
- en: Concurrent web requests
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发网络请求
- en: The problem of timeout
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超时问题
- en: Good practices in making web requests
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行网络请求的良好实践
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following is a list of prerequisites for this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章的先决条件列表：
- en: Python 3 must be installed on your computer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须在计算机上安装Python 3
- en: Download the GitHub repository at [https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载GitHub存储库：[https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)
- en: During this chapter, we will be working with the subfolder named `Chapter05`
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用名为`Chapter05`的子文件夹进行工作。
- en: Check out the following video to see the Code in Action: [http://bit.ly/2Fy1ZcS](http://bit.ly/2Fy1ZcS)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际操作：[http://bit.ly/2Fy1ZcS](http://bit.ly/2Fy1ZcS)
- en: The basics of web requests
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络请求的基础知识
- en: The worldwide capacity to generate data is estimated to double in size every
    two years. Even though there is an interdisciplinary field known as data science
    that is entirely dedicated to the study of data, almost every programming task
    in software development also has something to do with collecting and analyzing
    data. A significant part of this is, of course, data collection. However, the
    data that we need for our applications is sometimes not stored nicely and cleanly
    in a database—sometimes, we need to collect the data we need from web pages.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 据估计，全球生成数据的能力每两年就会增加一倍。尽管有一个名为数据科学的跨学科领域专门致力于数据的研究，但几乎软件开发中的每个编程任务都与收集和分析数据有关。其中一个重要部分当然是数据收集。然而，我们应用程序所需的数据有时并没有以清晰和干净的方式存储在数据库中，有时我们需要从网页中收集我们需要的数据。
- en: For example, web scraping is a data extraction method that automatically makes
    requests to web pages and downloads specific information. Web scraping allows
    us to comb through numerous websites and collect any data we need in a systematic
    and consistent manner—the collected data can be analyzed later on by our applications
    or simply saved on our computers in various formats. An example of this would
    be Google, which programs and runs numerous web scrapers of its own to find and
    index web pages for the search engine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，网络爬虫是一种自动向网页发出请求并下载特定信息的数据提取方法。网络爬虫允许我们遍历许多网站，并以系统和一致的方式收集我们需要的任何数据，这些收集的数据可以由我们的应用程序稍后进行分析，或者简单地以各种格式保存在我们的计算机上。一个例子是谷歌，它编写并运行了许多自己的网络爬虫来查找和索引搜索引擎的网页。
- en: The Python language itself provides a number of good options for applications
    of this kind. In this chapter, we will mainly work with the `requests` module
    to make client-side web requests from our Python programs. However, before we
    look into this module in more detail, we need to understand some web terminology
    in order to be able to effectively design our applications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Python语言本身提供了许多适用于这种类型应用的好选择。在本章中，我们将主要使用`requests`模块从我们的Python程序中进行客户端网络请求。然而，在我们更详细地了解这个模块之前，我们需要了解一些网络术语，以便能够有效地设计我们的应用程序。
- en: HTML
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTML
- en: '**Hypertext Markup Language** (**HTML**) is the standard and most common markup
    language for developing web pages and web applications. An HTML file is simply
    a plaintext file with the `.html` file extension. In an HTML document, texts are
    surrounded and delimited by tags, written in angle brackets: `<p>`, `<img>`, `<i>`,
    and so on. These tags typically consist of pairs—an opening tag and a closing
    tag—indicating the styling or the'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**超文本标记语言**（**HTML**）是开发网页和Web应用程序的标准和最常见的标记语言。HTML文件只是一个扩展名为`.html`的纯文本文件。在HTML文档中，文本被标签包围和分隔，标签用尖括号括起来：`<p>`，`<img>`，`<i>`等。这些标签通常由一对组成，即开放标签和闭合标签，指示样式或数据的'
- en: nature of the data included inside.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的性质。
- en: It is also possible to include other forms of media in HTML code, such as images
    or videos. There are also numerous other tags that are used in common HTML documents.
    Some specify a group of elements that share some common characteristics, such
    as `<id></id>` and `<class></class>`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在HTML代码中还可以包括其他形式的媒体，如图像或视频。常见的HTML文档中还有许多其他标签。有些标签指定了一组具有共同特征的元素，例如`<id></id>`和`<class></class>`。
- en: 'The following is an example of HTML code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是HTML代码的示例：
- en: '![](assets/ce982a49-5538-4b5c-abee-b7580ca242dd.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ce982a49-5538-4b5c-abee-b7580ca242dd.png)'
- en: Sample HTML code
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 示例HTML代码
- en: Fortunately, detailed knowledge on what each HTML tag accomplishes is not required
    for us to be able to make effective web requests. As we will see later on in this
    chapter, the more essential part of making web requests is the ability to interact
    with web pages efficiently.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们不需要详细了解每个HTML标签的功能，就能够有效地进行网络请求。正如我们将在本章后面看到的那样，进行网络请求的更重要的部分是能够有效地与网页进行交互。
- en: HTTP requests
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP请求
- en: In a typical communication process on the web, HTML texts are the data that
    is to be saved and/or further processed. This data needs to be first collected
    from web pages, but how can we go about doing that? Most of the communication
    is done via the internet—more specifically, the World Wide Web—and this utilizes
    the **Hypertext Transfer Protocol** (**HTTP**). In HTTP, request methods are used
    to convey the information of what data is being requested and should be sent back
    from a server.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web上的典型通信过程中，HTML文本是要保存和/或进一步处理的数据。这些数据首先需要从网页中收集，但我们该如何做呢？大多数通信是通过互联网进行的——更具体地说，是通过万维网——这利用了**超文本传输协议**（**HTTP**）。在HTTP中，请求方法用于传达所请求的数据以及应该从服务器发送回来的信息。
- en: For example, when you type `packtpub.com` in your browser, the browser sends
    a request method via HTTP to the Packt website's main server asking for data from
    the website. Now, if both your internet connection and Packt's server are working
    well, then your browser will receive a response back from the server, as shown
    in the following diagram. This response will be in the form of an HTML document,
    which will be interpreted by your browser, and your browser will display the corresponding
    HTML output to the screen.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当您在浏览器中输入`packtpub.com`时，浏览器通过HTTP向Packt网站的主服务器发送请求方法，请求网站的数据。现在，如果您的互联网连接和Packt的服务器都正常工作，那么您的浏览器将从服务器接收到响应，如下图所示。此响应将以HTML文档的形式呈现，浏览器将解释相应的HTML输出并在屏幕上显示。
- en: '![](assets/a850443e-e2d2-47d3-b1ca-b498d390fb95.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a850443e-e2d2-47d3-b1ca-b498d390fb95.png)'
- en: Diagram of HTTP communication
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP通信图
- en: 'Generally, request methods are defined as verbs that indicate the desired action
    to be performed while the HTTP client (web browsers) and the server communicate
    with each other: `GET`, `HEAD`, `POST`, `PUT`, `DELETE`, and so on. Of these methods,
    `GET` and `POST` are two of the most common request methods used in web-scraping
    applications; their function is described in the following list:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，请求方法被定义为表示所需执行的操作的动词，而HTTP客户端（Web浏览器）和服务器相互通信：`GET`、`HEAD`、`POST`、`PUT`、`DELETE`等。在这些方法中，`GET`和`POST`是Web抓取应用程序中最常用的两种请求方法；它们的功能如下所述：
- en: The `GET` method makes a request for a specific data from the server. This method
    only retrieves data and has no other effect on the server and its databases.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GET方法从服务器请求特定数据。此方法仅检索数据，对服务器及其数据库没有其他影响。
- en: The `POST` method sends data in a specific form that is accepted by the server.
    This data could be, for example, a message to a bulletin board, mailing list,
    or a newsgroup; information to be submitted to a web form; or an item to be added
    to a database.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: POST方法以服务器接受的特定形式发送数据。例如，这些数据可能是发往公告板、邮件列表或新闻组的消息；要提交到Web表单的信息；或要添加到数据库的项目。
- en: All general-purpose HTTP servers that we commonly see on the internet are actually required
    to implement at least the `GET` (and `HEAD`) method, while the `POST` method is
    considered optional.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在互联网上常见的所有通用HTTP服务器实际上都必须至少实现GET（和HEAD）方法，而POST方法被视为可选。
- en: HTTP status code
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP状态代码
- en: It is not always the case that, when a web request is made and sent to a web
    server, the server will process the request and return the requested data without
    fail. Sometimes, the server might be completely down or already busy interacting
    with other clients and therefore unresponsive to a new request; sometimes, the
    client itself makes bad requests to a server (for example, incorrectly formatted
    or malicious requests).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 并非总是当发出Web请求并发送到Web服务器时，服务器会处理请求并无误地返回所请求的数据。有时，服务器可能完全关闭或已忙于与其他客户端交互，因此无法对新请求做出响应；有时，客户端本身向服务器发出错误请求（例如，格式不正确或恶意请求）。
- en: As a way to categorize these problems as well as provide the most information
    as possible during the communication resulting from a web request, HTTP requires
    servers to respond to each request from its clients an **HTTP response** **status
    code**. A status code is typically a three-digit number that indicates the specific
    characteristics of the response that the server sends back to a client.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这些问题归类并在Web请求引起的通信中提供尽可能多的信息，HTTP要求服务器对其客户端的每个请求做出**HTTP响应** **状态代码**的响应。状态代码通常是一个三位数，指示服务器发送回客户端的响应的具体特征。
- en: 'There are in total five large categories of HTTP response status codes, indicated
    by the first digit of the code. They are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP响应状态代码共有五个大类，由代码的第一位数字表示。它们如下所示：
- en: '**1xx (informational status code)**: The request was received and the server
    is processing it. For example, 100 means the request header has been received
    and the server is waiting for the request body; 102 indicates that the request
    is currently being processed (this is used for large requests and to prevent clients
    from timing out).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1xx（信息状态代码）**：请求已收到，服务器正在处理。例如，100表示已接收请求头，并且服务器正在等待请求正文；102表示请求当前正在处理中（用于大型请求和防止客户端超时）。'
- en: '**2xx (successful status code)**: The request was successfully received, understood,
    and processed by the server. For example, 200 means the request was successfully
    fulfilled; 202 indicates that the request has been accepted for processing, but
    the processing itself is not complete.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2xx（成功状态代码）**：请求已被服务器成功接收、理解和处理。例如，200表示请求已成功完成；202表示请求已被接受进行处理，但处理本身尚未完成。'
- en: '**3xx (redirectional status code)**: Additional actions need to be taken so
    that the request can be successfully processed. For example, 300 means that there
    are multiple options regarding how the response from the server should be processed
    (for example, giving the client multiple video format options when a video file
    is to be downloaded); 301 indicates that the server has been moved permanently
    and all requests should be directed to another address (provided in the response
    from the server).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3xx（重定向状态码）**：需要采取其他操作才能成功处理请求。例如，300表示关于如何处理来自服务器的响应有多个选项（例如，在下载视频文件时，为客户端提供多个视频格式选项）；301表示服务器已永久移动，所有请求应重定向到另一个地址（在服务器响应中提供）。'
- en: '**4xx (error status code for the client)**: The request was incorrectly formatted
    by the client and could not be processed. For example, 400 means that the client
    sent in a bad request (for example, syntax error or the size of the request is
    too large); 404 (arguably the most well-known status code) indicates that the
    request method is not supported by the server.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4xx（客户端的错误状态码）**：客户端错误地格式化了请求，无法处理。例如，400表示客户端发送了错误的请求（例如，语法错误或请求的大小太大）；404（可能是最知名的状态码）表示服务器不支持请求方法。'
- en: '**5xx (error status code for the server)**: The request, although valid, could
    not be processed by the server. For example, 500 means there is an internal server
    error in which an unexpected condition was encountered; 504 (Gateway Timeout)
    means that the server, which was acting as a gateway or a proxy, did not receive
    a response from the final server in time.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**5xx（服务器的错误状态码）**：请求虽然有效，但服务器无法处理。例如，500表示出现内部服务器错误，遇到了意外情况；504（网关超时）表示充当网关或代理的服务器未能及时从最终服务器接收响应。'
- en: A lot more can be said about these status codes, but it is already sufficient
    for us to keep in mind the big five categories previously mentioned when making
    web requests from Python. If you would like to find more specific information
    about the above or other status codes, the **Internet Assigned Numbers Authority**
    (**IANA**) maintains the official registry of HTTP status codes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些状态码还可以说很多，但对于我们来说，只需记住之前提到的五大类别就足够了。如果您想找到有关上述或其他状态码的更多具体信息，**互联网编号分配机构**（**IANA**）维护着HTTP状态码的官方注册表。
- en: The requests module
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请求模块
- en: The `requests` module allows its users to make and send HTTP request methods.
    In the applications that we will be considering, it is mainly used to make contact
    with the server of the web pages we want to extract data from and obtain the response
    for the server.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests`模块允许用户发出和发送HTTP请求方法。在我们考虑的应用程序中，它主要用于与我们想要提取数据的网页的服务器联系，并获取服务器的响应。'
- en: According to the official documentation of the module, the use of Python 3 is
    **highly recommended** over Python 2 for `requests`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据该模块的官方文档，**强烈建议**在`requests`中使用Python 3而不是Python 2。
- en: 'To install the module on your computer, run the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要在计算机上安装该模块，请运行以下命令：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should use this code if you are using `pip` as your package manager. If,
    however, you are using Anaconda instead, simply use the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用`pip`作为软件包管理器，请使用此代码。但如果您使用的是Anaconda，只需使用以下代码：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These commands should install `requests` and any other required dependencies
    (`idna`, `certifi`, `urllib3`, and so on) for you if your system does not have
    those already. After this, run `import requests` in a Python interpreter to confirm
    that the module has been installed successfully.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统尚未安装这些依赖项（`idna`、`certifi`、`urllib3`等），这些命令应该会为您安装`requests`和其他所需的依赖项。之后，在Python解释器中运行`import
    requests`以确认模块已成功安装。
- en: Making a request in Python
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中发出请求
- en: 'Let''s look at an example usage of the module. If you already have the code
    for this book downloaded from the GitHub page, go ahead and navigate to the `Chapter05`
    folder. Let''s take a look at the `example1.py` file, as shown in the following
    code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下该模块的一个示例用法。如果您已经从GitHub页面下载了本书的代码，请转到`Chapter05`文件夹。让我们看一下以下代码中显示的`example1.py`文件：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, we are using the `requests` module to download the HTML code
    of the web page, `www.google.com`. The `requests.get()` method sends a `GET` request
    method to `url` and we store the response to the `res` variable. After checking
    the status and headers of the response by printing them out, we create a file
    called `google.html` and write the HTML code, which is stored in the response
    text, to the file.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们使用`requests`模块下载网页`www.google.com`的HTML代码。`requests.get()`方法向`url`发送`GET`请求方法，并将响应存储在`res`变量中。在打印出响应的状态和标头后，我们创建一个名为`google.html`的文件，并将存储在响应文本中的HTML代码写入文件。
- en: 'After running the programming (assuming that your internet is working and the
    Google server is not down), you should get the following output:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序（假设您的互联网正常工作，Google服务器没有宕机），您应该会得到以下输出：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The response had a `200` status code, which we know means that the request has
    been successfully completed. The header of the response, stored in `res.headers`,
    additionally contains further specific information regarding the response. For
    example, we can see the date and time the request was made or that the content
    of the response is text and HTML and the total length of the content is `4958`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 响应的状态码为`200`，这意味着请求已成功完成。响应的标头存储在`res.headers`中，还包含有关响应的进一步具体信息。例如，我们可以看到请求的日期和时间，或者响应的内容是文本和HTML，内容的总长度为`4958`。
- en: The complete data sent from the server was also written to the `google.html`
    file. When you open the file in a text editor, you will be able to see the HTML
    code of the web page that we have downloaded using requests. On the other hand,
    if you use a web browser to open the file, you will see how **most** of the information
    from the original web page is now being displayed through a downloaded offline
    file.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器发送的完整数据也被写入了`google.html`文件。当您在文本编辑器中打开文件时，您将能够看到我们使用请求下载的网页的HTML代码。另一方面，如果您使用Web浏览器打开文件，您将看到原始网页的**大部分**信息现在通过下载的离线文件显示出来。
- en: 'For example, the following is how Google Chrome on my system interprets the
    HTML file:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是我的系统上Google Chrome如何解释HTML文件：
- en: '![](assets/ddbf9c3e-2633-4f3c-914b-a2d868e5155f.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ddbf9c3e-2633-4f3c-914b-a2d868e5155f.png)'
- en: Downloaded HTML opened offline
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 离线打开的下载HTML
- en: There is other information that is stored on the server that web pages of that
    server make reference to. This means that not all of the information that an online
    web page provides can be downloaded via a `GET` request, and this is why offline
    HTML code sometimes fails to contain all of the information available on the online
    web page that it was downloaded from. (For example, the downloaded HTML code in
    the preceding screenshot does not display the Google icon correctly.)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器上还存储着网页引用的其他信息。这意味着并非所有在线网页提供的信息都可以通过`GET`请求下载，这就是为什么离线HTML代码有时无法包含从中下载的在线网页上所有可用的信息的原因。（例如，前面截图中下载的HTML代码无法正确显示Google图标。）
- en: Running a ping test
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行ping测试
- en: 'With the basic knowledge of HTTP requests and the `requests` module in Python
    in mind, we will go through the rest of this chapter with a central problem: running
    a ping test. A ping test is a process in which you test the communication between
    your system and specific web servers, simply by making a request to each of the
    servers in question. By considering the HTTP response status code (potentially)
    returned by the server, the test is used to evaluate either the internet connection
    of your own system or the availability of the servers.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了HTTP请求和Python中的`requests`模块的基本知识后，我们将在本章的其余部分中解决一个核心问题：运行ping测试。Ping测试是一个过程，通过该过程您可以通过向每个相关服务器发出请求来测试系统与特定Web服务器之间的通信。通过考虑服务器（可能）返回的HTTP响应状态代码，该测试用于评估您自己系统的互联网连接或服务器的可用性。
- en: Ping tests are quite common among web administrators, who usually have to manage
    a large number of websites simultaneously. Ping tests are a good tool to quickly
    identify pages that are unexpectedly unresponsive or down. There are many tools
    that provide you with powerful options in ping tests and, in this chapter, we
    will be designing a ping test application that can concurrently send multiple
    web requests at the same time.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Ping测试在Web管理员中非常常见，他们通常需要同时管理大量网站。Ping测试是一个快速识别意外无响应或宕机页面的好工具。有许多工具可以为您提供强大的ping测试选项，在本章中，我们将设计一个可以同时发送多个Web请求的ping测试应用程序。
- en: To simulate different HTTP response status codes to be sent back to our program,
    we will be using [httpstat.us](http://www.httpstat.us), a website that can generate
    various status codes and is commonly used to test how applications that make web
    requests can handle varying response. Specifically, to use a request that will
    return a 200 status code in a program, we can simply make a request to [httpstat.us/200](http://www.httpstat.us/200) and
    the same applies for other status codes. In our ping test program, we will have
    a list of [httpstat.us](http://www.httpstat.us) URLs with different status codes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟不同的HTTP响应状态代码发送回我们的程序，我们将使用[httpstat.us](http://www.httpstat.us)，这是一个可以生成各种状态代码并常用于测试应用程序如何处理不同响应的网站。具体来说，要在程序中使用返回200状态代码的请求，我们可以简单地向[httpstat.us/200](http://www.httpstat.us/200)发出请求，其他状态代码也是如此。在我们的ping测试程序中，我们将有一个包含不同状态代码的[httpstat.us](http://www.httpstat.us)
    URL列表。
- en: 'Let''s now a take look at the `Chapter05/example2.py` file, as shown in the
    following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下`Chapter05/example2.py`文件，如下面的代码所示：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this program, the `ping()` function takes in a URL and attempts to make a
    `GET` request to the site. It will then print out the content of the response
    returned by the server. In our main program, we have a list of different status
    codes that we mentioned earlier, each of which we will go through and call the
    `ping()` function on.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个程序中，`ping()`函数接收一个URL，并尝试向站点发出`GET`请求。然后它将打印出服务器返回的响应内容。在我们的主程序中，我们有一个不同状态代码的列表，我们将逐个调用`ping()`函数。
- en: 'The final output after running the preceding example should be as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述示例后的最终输出应该如下：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We see that our ping test program was able to obtain corresponding responses
    from the server.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到我们的ping测试程序能够从服务器获得相应的响应。
- en: Concurrent web requests
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发网络请求
- en: In the context of concurrent programming, we can see that the process of making
    a request to a web server and obtaining the returned response is independent from
    the same procedure for a different web server. This is to say that we could apply
    concurrency and parallelism to our ping test application to speed up our execution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发编程的背景下，我们可以看到向Web服务器发出请求并获取返回的响应的过程与为不同的Web服务器执行相同的过程是独立的。这意味着我们可以将并发性和并行性应用于我们的ping测试应用程序，以加快执行速度。
- en: 'In the concurrent ping test applications that we are designing, multiple HTTP
    requests will be made to the server simultaneously and corresponding responses
    will be sent back to our program, as shown in the following figure. As discussed
    before, concurrency and parallelism have significant applications in web development,
    and most servers nowadays have the ability to handle a large amount of requests
    at the same time:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们设计的并发ping测试应用程序中，将同时向服务器发出多个HTTP请求，并将相应的响应发送回我们的程序，如下图所示。正如之前讨论的那样，并发性和并行性在Web开发中有重要的应用，大多数服务器现在都有能力同时处理大量的请求：
- en: '![](assets/82ff2bcf-4fcb-47fd-9b08-0c1ebbf9a7bf.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/82ff2bcf-4fcb-47fd-9b08-0c1ebbf9a7bf.png)'
- en: Parallel HTTP requests
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 并行HTTP请求
- en: Spawning multiple threads
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成多个线程
- en: 'To apply concurrency, we simply use the `threading` module that we have been
    discussing to create separate threads to handle different web requests. Let''s
    take a look at the `Chapter05/example3.py` file, as shown in the following code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用并发，我们只需使用我们一直在讨论的`threading`模块来创建单独的线程来处理不同的网络请求。让我们看一下`Chapter05/example3.py`文件，如下面的代码所示：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this example, we are including the sequential logic from the previous example
    to process our URL list, so that we can compare the improvement in speed when
    we apply threading to our ping test program. We are also creating a thread to
    ping each of the URLs in our URL list using the `threading` module; these threads
    will be executing independently from each other. Time taken to process the URLs
    sequentially and concurrently are also tracked using methods from the `time` module.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们包括了前一个例子中的顺序逻辑来处理我们的URL列表，以便我们可以比较当我们将线程应用到我们的ping测试程序时速度的提高。我们还使用`threading`模块为我们的URL列表中的每个URL创建一个线程来ping；这些线程将独立执行。使用`time`模块的方法还跟踪了顺序和并发处理URL所花费的时间。
- en: 'Run the program and your output should be similar to the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序，您的输出应该类似于以下内容：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: While the specific time that the sequential logic and threading logic take to
    process all the URLs might be different from system to system, there should still
    be a clear distinction between the two. Specifically, here we can see that the
    threading logic was almost six times faster than the sequential logic (which corresponds
    to the fact that we had six threads processing six URLs in parallel). There is
    no doubt, then, that concurrency can provide significant speedup for our ping
    test application specifically and for the process of making web requests in general.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管顺序逻辑和线程逻辑处理所有URL所花费的具体时间可能因系统而异，但两者之间仍应有明显的区别。具体来说，我们可以看到线程逻辑几乎比顺序逻辑快了六倍（这对应于我们有六个线程并行处理六个URL的事实）。毫无疑问，并发可以为我们的ping测试应用程序以及一般的Web请求处理过程提供显著的加速。
- en: Refactoring request logic
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重构请求逻辑
- en: 'The current version of our ping test application works as intended, but we
    can improve its readability by refactoring the logic where we make web requests
    into a thread class. Consider the `Chapter05/example4.py` file, specifically the
    `MyThread` class:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们ping测试应用程序的当前版本按预期工作，但我们可以通过重构我们的请求逻辑将Web请求的逻辑放入一个线程类中来提高其可读性。考虑`Chapter05/example4.py`文件，特别是`MyThread`类：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In this example, `MyThread` inherits from the `threading.Thread` class and
    contains two additional attributes: `url` and `result`. The `url` attribute holds
    the URL that the thread instance should process, and the response returned from
    the web server to that thread will be written to the `result` attribute (in the
    `run()` function).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`MyThread`继承自`threading.Thread`类，并包含两个额外的属性：`url`和`result`。`url`属性保存了线程实例应该处理的URL，来自Web服务器对该线程的响应将被写入`result`属性（在`run()`函数中）。
- en: 'Outside of this class, we now can simply loop through the URL list, and create
    and manage the threads accordingly while not having to worry about the request
    logic in the main program:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类之外，我们现在可以简单地循环遍历URL列表，并相应地创建和管理线程，而不必担心主程序中的请求逻辑：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note that we are now storing the responses in the `result` attribute of the
    `MyThread` class, instead of directly printing them out as in the old `ping()`
    function from the previous examples. This means that, after making sure that all
    threads have finished, we will need to loop through the threads one more time
    and print out those responses.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们现在将响应存储在`MyThread`类的`result`属性中，而不是像以前的示例中的旧`ping()`函数中直接打印出来。这意味着，在确保所有线程都已完成后，我们需要再次循环遍历这些线程并打印出这些响应。
- en: 'Refactoring the request logic should not greatly affect the performance of
    our current program; we are keeping track of the execution speed to see if this
    is actually the case. Execute the program and you will obtain the output similar
    to the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 重构请求逻辑不应该对我们当前的程序性能产生很大影响；我们正在跟踪执行速度，以查看是否实际情况如此。执行程序，您将获得类似以下的输出：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Just as we expected, we are still achieving a significant speedup from the sequential
    version of the program with this refactored request logic. Again, our main program
    is now more readable, and further adjustments of the request logic (as we will
    see in the next section) can simply be directed to the `MyThread` class, without
    affecting the rest of the program.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们预期的那样，通过重构的请求逻辑，我们仍然从程序的顺序版本中获得了显著的加速。同样，我们的主程序现在更易读，而对请求逻辑的进一步调整（正如我们将在下一节中看到的）可以简单地指向`MyThread`类，而不会影响程序的其余部分。
- en: The problem of timeout
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超时问题
- en: 'In this section, we will explore a potential improvement to be made to our
    ping test application: timeout handling. Timeouts typically occur when the server
    takes an unusually long time to process a specific request, and the connection
    between the server and its client is terminated.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨对我们的ping测试应用程序可以进行的一个潜在改进：超时处理。超时通常发生在服务器在处理特定请求时花费异常长的时间，并且服务器与其客户端之间的连接被终止。
- en: In the context of a ping test application, we will be implementing a customized
    threshold for the timeout. Recall that a ping test is used to determine whether
    specific servers are still responsive, so we can specify in our program that,
    if a request takes more than our timeout threshold for the server to response,
    we will categorize that specific server with a timeout.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在ping测试应用程序的上下文中，我们将实现一个定制的超时阈值。回想一下，ping测试用于确定特定服务器是否仍然响应，因此我们可以在程序中指定，如果请求花费的时间超过了服务器响应的超时阈值，我们将将该特定服务器归类为超时。
- en: Support from httpstat.us and simulation in Python
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来自httpstat.us和Python模拟的支持
- en: In addition to different options for status codes, the [httpstat.us](http://www.httpstat.us)
    website additionally provides a way to simulate a delay in its response when we
    send in requests. Specifically, we can customize the delay time (in milliseconds)
    with a query argument in our `GET` request. For example, [httpstat.us/200?sleep=5000](http://httpstat.us/200?sleep=5000)
    will return a response after five seconds of delay.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不同状态码的选项之外，[httpstat.us](http://www.httpstat.us)网站还提供了一种在发送请求时模拟响应延迟的方法。具体来说，我们可以使用`GET`请求中的查询参数来自定义延迟时间（以毫秒为单位）。例如，[httpstat.us/200?sleep=5000](http://httpstat.us/200?sleep=5000)将在延迟五秒后返回响应。
- en: 'Now, let us see how a delay like this would affect the execution of our program.
    Consider the `Chapter05/example5.py` file, which contains the current request
    logic of our ping test application but has a different URL list:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这样的延迟会如何影响我们程序的执行。考虑一下`Chapter05/example5.py`文件，其中包含我们ping测试应用程序的当前请求逻辑，但具有不同的URL列表：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here we have a URL that will take around 20 seconds to return a response. Considering
    that we will block the main program until all threads finish their execution (with
    the `join()` method), our program will most likely appear to be hanging for 20
    seconds before any response is printed out.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个URL，将花费大约20秒才能返回响应。考虑到我们将阻塞主程序直到所有线程完成执行（使用`join()`方法），我们的程序在打印出任何响应之前很可能会出现20秒的挂起状态。
- en: 'Run the program to experience this for yourself. A 20 second delay will occur
    (which will make the execution take significantly longer to finish) and we will
    obtain the following output:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序来亲身体验一下。将会发生20秒的延迟（这将使执行时间显著延长），我们将获得以下输出：
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Timeout specifications
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超时规范
- en: An efficient ping test application should not be waiting for responses from
    its websites for a long time; it should have a set threshold for timeout that,
    if a server fails to return a response under that threshold, the application will
    deem that server non-responsive. We therefore need to implement a way to keep
    track of how much time has passed since a request is sent to a server. We will
    do this by counting down from the timeout threshold and, once that threshold is
    passed, all responses (whether returned or not yet returned) will be printed out.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高效的ping测试应用程序不应该长时间等待来自网站的响应；它应该有一个超时的设定阈值，如果服务器在该阈值下未返回响应，应用程序将认为该服务器不响应。因此，我们需要实现一种方法来跟踪自从发送请求到服务器以来经过了多少时间。我们将通过从超时阈值倒计时来实现这一点，一旦超过该阈值，所有响应（无论是否已返回）都将被打印出来。
- en: 'Additionally, we will also be keeping track of how many requests are still
    pending and have not had their responses returned. We will be using the `isAlive()`
    method from the `threading.Thread` class to indirectly determine whether a response
    has been returned for a specific request: if, at one point, the thread processing
    a specific request is alive, we can conclude that that specific request is still
    pending.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将跟踪还有多少请求仍在等待并且还没有返回响应。我们将使用`threading.Thread`类中的`isAlive()`方法来间接确定特定请求是否已经返回响应：如果在某一时刻，处理特定请求的线程仍然存活，我们可以得出结论，该特定请求仍在等待。
- en: 'Navigate to the `Chapter05/example6.py` file and consider the `process_requests()`
    function first:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到`Chapter05/example6.py`文件，并首先考虑`process_requests()`函数：
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The function takes in a list of threads that we have been using to make web
    requests in the previous examples, as well as an optional argument specifying
    the timeout threshold. Inside this function, we have an inner function, `alive_count()`,
    which returns the count of the threads that are still alive at the time of the
    function call.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数接受一个线程列表，我们在之前的示例中一直在使用这些线程来进行网络请求，还有一个可选参数指定超时阈值。在这个函数内部，我们有一个内部函数`alive_count()`，它返回在函数调用时仍然存活的线程数。
- en: In the `process_requests()` function, as long as there are threads that are
    currently alive and processing requests, we will allow the threads to continue
    with their execution (this is done in the `while` loop with the double condition).
    The `UPDATE_INTERVAL` variable, as you can see, specifies how often we check for
    this condition. If either condition fails (if there are no alive threads left
    or if the threshold timeout is passed), then we will proceed with printing out
    the responses (even if some might have not been returned).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在`process_requests()`函数中，只要有线程仍然存活并处理请求，我们将允许线程继续执行（这是在`while`循环中完成的，具有双重条件）。正如你所看到的，`UPDATE_INTERVAL`变量指定了我们检查这个条件的频率。如果任一条件失败（如果没有存活的线程或者超时阈值已过），那么我们将继续打印出响应（即使有些可能尚未返回）。
- en: 'Let''s turn our attention to the new `MyThread` class:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把注意力转向新的`MyThread`类：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This class is almost identical to the one we considered in the previous example,
    except that the initial value for the `result` attribute is a message indicating
    a timeout. In the case that we discussed earlier where the timeout threshold specified
    in the `process_requests()` function is passed, this initial value will be used
    when the responses are printed out.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类几乎与我们在之前的示例中考虑的类相同，只是`result`属性的初始值是指示超时的消息。在我们之前讨论的情况中，超时阈值在`process_requests()`函数中指定，当打印出响应时，将使用这个初始值。
- en: 'Finally, let''s consider our main program:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们考虑一下我们的主程序：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, in our URL list, we have a request that would take 4 seconds and another
    that would take 20 seconds, aside from the ones that would respond immediately.
    As the timeout threshold that we are using is 5 seconds, theoretically we should
    be able to see that the 4-second-delay request will successfully obtain a response,
    while the 20-second-delay one will not.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的URL列表中，我们有一个请求需要4秒，另一个需要20秒，除了那些会立即响应的请求。由于我们使用的超时阈值是5秒，理论上我们应该能够看到4秒延迟的请求成功获得响应，而20秒延迟的请求则不会。
- en: 'There is another point to be made about this program: daemon threads. In the
    `process_requests()` function, if the timeout threshold is passed while there
    is still at least one thread processing, then the function will proceed to print
    out the `result` attribute of each thread:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个程序还有另一个要点：守护线程。在`process_requests()`函数中，如果超时阈值在至少有一个线程在处理时被触发，那么函数将继续打印出每个线程的`result`属性。
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This means that we do not block our program until all of the threads have finished
    their execution by using the `join()` function, and the program therefore can
    simply move forward if the timeout threshold is reached. However, this means that
    the threads themselves do not terminate at this point. The 20-second-delay request,
    specifically, will still most likely be running after our program exits out of
    the `process_requests()` function.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不会通过使用`join()`函数阻止程序直到所有线程都执行完毕，因此如果达到超时阈值，程序可以简单地继续前进。然而，这意味着线程本身在这一点上并不终止。特别是20秒延迟的请求，在我们的程序退出`process_requests()`函数后仍然很可能在运行。
- en: If the thread processing this request is not a daemon thread (as we know, daemon
    threads execute in the background and never terminate), it will block the main
    program from finishing until the thread itself finishes. By making this thread,
    and any other thread, a daemon thread, we allow the main program to finish as
    soon as it executes the last line of its instructions, even if there are threads
    still running.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理此请求的线程不是守护线程（如我们所知，守护线程在后台执行并且永远不会终止），它将阻止主程序完成，直到线程本身完成。通过将此线程和任何其他线程设置为守护线程，我们允许主程序在执行其指令的最后一行后立即完成，即使仍有线程在运行。
- en: 'Let us see this program in action. Execute the code and your output should
    be similar to the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个程序的运行情况。执行代码，您的输出应该类似于以下内容：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, it took around 5 seconds for our program to finish this time.
    This is because it spent 5 seconds waiting for the threads that were still running
    and, as soon as the 5-second threshold was passed, the program printed out the
    results. Here we see that the result from the 20-second-delay request was simply
    the default value of the `result` attribute of the `MyThread` class, while the
    rest of the requests were able to obtain the correct response from the server
    (including the 4-second-delay request, since it had enough time to obtain the
    response).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这次我们的程序花了大约5秒才完成。这是因为它花了5秒等待仍在运行的线程，一旦超过5秒的阈值，程序就会打印出结果。在这里，我们看到20秒延迟请求的结果只是`MyThread`类的`result`属性的默认值，而其他请求都能够从服务器获得正确的响应（包括4秒延迟的请求，因为它有足够的时间来获取响应）。
- en: 'If you would like to see the effect of non-daemon threads that we discussed
    earlier, simply comment out the corresponding line of code in our main program,
    as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想看到我们之前讨论的非守护线程的影响，只需注释掉主程序中相应的代码行，如下所示：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You will see that the main program will hang for around 20 seconds, as the non-daemon
    thread processing the 20-second-delay request is still running, before being able
    to finish its execution (even though the output produced will be identical).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到主程序将挂起大约20秒，因为处理20秒延迟请求的非守护线程仍在运行，然后才能完成执行（即使产生的输出将是相同的）。
- en: Good practices in making web requests
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制作网络请求的良好实践
- en: There are a few aspects of making concurrent web requests that require careful
    consideration and implementation. In this section, we will be going over those
    aspects and some of the best practices that you should use when developing your
    applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行并发网络请求时，有一些方面需要仔细考虑和实施。在本节中，我们将讨论这些方面以及在开发应用程序时应该使用的一些最佳实践。
- en: Consider the terms of service and data-collecting policies
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑服务条款和数据收集政策
- en: Unauthorized data collection has been the topic of discussion in the technology
    world for the past few years, and it will continue to be for a long time—and for
    good reason too. It is therefore extremely important for developers who are making
    automated web requests in their applications to look for websites' policies on
    data collecting. You can find these policies in their terms of service or similar
    documents. When in doubt, it is generally a good rule of thumb to contact the
    website directly to ask for more details.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 未经授权的数据收集已经成为技术世界的讨论话题，过去几年，它将继续存在很长一段时间，这也是有充分理由的。因此，对于在其应用程序中进行自动化网络请求的开发人员来说，查找网站的数据收集政策非常重要。您可以在其服务条款或类似文件中找到这些政策。如果有疑问，直接联系网站询问更多细节通常是一个很好的经验法则。
- en: Error handling
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误处理
- en: Error is something that no one can easily avoid in the field of programming,
    and this is especially true in making web requests. Errors in these programs can
    include making bad requests (invalid requests or even bad internet connections),
    mishandling downloaded HTML code, or unsuccessfully parsing HTML code. It is therefore
    important to make use of `try...except` blocks and other error-handling tools
    in Python to avoid crashing your application. Avoiding crashes is especially important
    if your code/applications are used in production and larger applications.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 编程领域中，错误是无法轻易避免的事情，特别是在进行网络请求时。这些程序中的错误可能包括发出错误的请求（无效请求或者是网络连接不佳），处理下载的HTML代码不当，或者解析HTML代码失败。因此，在Python中使用`try...except`块和其他错误处理工具以避免应用程序崩溃非常重要。如果您的代码/应用程序用于生产和大型应用程序中，避免崩溃尤为重要。
- en: Specifically in concurrent web scraping, it might be possible for some threads
    to collect data successfully, while others fail. By implementing error-handling
    functionalities in multithreaded parts of your program, you can make sure that
    a failed thread will not be able to crash the entirety of your program and ensure
    that successful threads can still return their results.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在并发网络爬虫中，一些线程可能成功收集数据，而其他线程可能失败。通过在程序的多线程部分实现错误处理功能，您可以确保失败的线程不会导致整个程序崩溃，并确保成功的线程仍然可以返回其结果。
- en: However, it is important to note that blind error-catching is still undesirable.
    This term indicates the practice where we have a large `try...expect` block in
    our program that will catch any and all errors that occur in the program execution,
    and no further information regarding the errors can be obtained; this practice
    might also be known as error swallowing. It's highly recommended to have specific
    error handling code in a program, so that not only appropriate actions can be
    taken with regards to that specific error, but other errors that have not been
    taken into account might also reveal themselves.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，盲目捕获错误仍然是不可取的。这个术语表示我们在程序中有一个大的`try...expect`块，它将捕获程序执行中发生的任何错误，而且无法获得有关错误的进一步信息；这种做法也可能被称为错误吞噬。强烈建议在程序中具有特定的错误处理代码，这样不仅可以针对特定错误采取适当的行动，而且还可以发现未考虑的其他错误。
- en: Update your program regularly
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定期更新您的程序
- en: It is quite common for websites to change their request-handling logic as well
    as their displayed data regularly. If a program that makes requests to a website
    has considerably inflexible logic to interact with the server of the website (for
    example, structuring its requests in a specific format, only handling one kind
    of response), then if and when the website alters the way it handles its client
    requests, the program will most likely stop functioning correctly. This situation
    happens frequently with web scraping programs that look for data in specific HTML
    tags; when the HTML tags are changed, these programs will fail to find their data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 网站定期更改其请求处理逻辑以及显示的数据是非常常见的。如果一个向网站发出请求的程序具有相当不灵活的逻辑来与网站的服务器交互（例如，以特定格式构造其请求，仅处理一种响应），那么当网站改变其处理客户端请求的方式时，该程序很可能会停止正常运行。这种情况经常发生在寻找特定HTML标签中的数据的网络爬虫程序中；当HTML标签发生变化时，这些程序将无法找到它们的数据。
- en: This practice is implemented to prevent automated data collecting programs from
    functioning. The only way to keep using a website that recently changed its request-handling
    logic is to analyze the updated protocols and alter our programs accordingly.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这种做法是为了防止自动数据收集程序的运行。要继续使用最近更改了请求处理逻辑的网站，唯一的方法是分析更新的协议并相应地修改我们的程序。
- en: Avoid making a large number of requests
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免发出大量请求
- en: Each time one of the programs that we have been discussing runs, it makes HTTP
    requests to a server that manages the site that you'd like to extract data from.
    This process happens significantly more frequently and over a shorter amount of
    time in a concurrent program, where multiple requests are being submitted to that
    server.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的每个程序运行时，都会向管理您想要提取数据的网站的服务器发出HTTP请求。在并发程序中，向该服务器提交多个请求的频率更高，时间更短。
- en: As mentioned before, servers nowadays have the ability to handle multiple requests
    simultaneously with ease. However, to avoid having to overwork and overconsume
    resources, servers are also designed to stop answering requests that come in too
    frequently. Websites of big tech companies, such as Amazon or Twitter, look for
    large amounts of automated requests that are made from the same IP address and
    implement different response protocols; some requests might be delayed, some might
    be refused a response, or the IP address might even be banned from making further
    requests for a specific amount of time.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，现在的服务器具有轻松处理多个请求的能力。然而，为了避免过度工作和过度消耗资源，服务器也设计为停止回应过于频繁的请求。大型科技公司的网站，如亚马逊或Twitter，会寻找来自同一IP地址的大量自动请求，并实施不同的响应协议；一些请求可能会延迟，一些可能会拒绝响应，甚至可能会禁止该IP地址在特定时间内继续发出请求。
- en: 'Interestingly, making repeated, heavy-duty requests to servers is actually
    a form of hacking a website. In **Denial of Service** (**DoS**) and **Distributed
    Denial of Service** (**DDoS**) attacks, a very large number of requests are made
    at the same time to the server, flooding the bandwidth of the targeted server
    with traffic, and as a result, normal, nonmalicious requests from other clients
    are denied because the servers are busy processing the concurrent requests, as
    illustrated in the following diagram:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，向服务器重复发送大量请求实际上是一种对网站进行黑客攻击的形式。在**拒绝服务**（**DoS**）和**分布式拒绝服务**（**DDoS**）攻击中，大量请求同时发送到服务器，使目标服务器的带宽被流量淹没，因此，其他客户端的正常、非恶意请求被拒绝，因为服务器正忙于处理并发请求，如下图所示：
- en: '![](assets/84cd0186-2860-4658-bc69-b0c6cf6a8fec.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/84cd0186-2860-4658-bc69-b0c6cf6a8fec.png)'
- en: A of a DDoS attack
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: DDoS攻击的一种
- en: It is therefore important to space out the concurrent requests that your application
    makes to a server so that the application would not be considered an attacker
    and be potentially banned or treated as a malicious client. This could be as simple
    as limiting the maximum number of threads/requests that can be implemented at
    a time in your program or pausing the threading for a specific amount of time
    (for example, using the `time.sleep()` function) before making a request to the
    server.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的是要分隔应用程序对服务器发出的并发请求，以便应用程序不被视为攻击者，并且可能被禁止或视为恶意客户端。这可以简单地限制程序中可以同时实施的最大线程/请求数量，或者在向服务器发出请求之前暂停线程一段特定时间（例如，使用`time.sleep()`函数）。
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned about the basics of HTML and web requests.
    The two most common web requests are `GET` and `POST` requests. There are five
    main categories for HTTP response status code, each indicating a different concept
    regarding the communication between the server and its client. By considering
    the status codes received from different websites, we can write a ping test application
    that effectively checks for the responsiveness of those websites.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经了解了HTML和网络请求的基础知识。最常见的网络请求是`GET`和`POST`请求。HTTP响应状态码有五个主要类别，每个类别表示关于服务器和其客户端之间通信的不同概念。通过考虑从不同网站接收的状态代码，我们可以编写一个ping测试应用程序，有效地检查这些网站的响应能力。
- en: Concurrency can be applied to the problem of making multiple web requests simultaneously
    via threading to provide a significant improvement in application speed. However,
    it is important to keep in mind a number of considerations when make concurrent
    web requests.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 并发可以应用于同时进行多个网络请求的问题，通过线程提供了应用程序速度的显着改进。但是，在进行并发网络请求时，需要牢记一些考虑因素。
- en: 'In the next chapter, we will start discussing another major player in concurrent
    programming: processes. We will be considering the concept of and the basic idea
    behind a process, and the options that Python provides for us to work with processes.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始讨论并发编程中的另一个重要角色：进程。我们将考虑进程的概念和基本思想，以及Python为我们提供的处理进程的选项。
- en: Questions
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is HTML?
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是HTML？
- en: What are HTTP requests?
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP请求是什么？
- en: What are HTTP response status codes?
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是HTTP响应状态码？
- en: How does the `requests` module help with making web requests?
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`模块如何帮助进行网络请求？'
- en: What is a ping test and how is one typically designed?
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是ping测试，通常如何设计？
- en: Why is concurrency applicable in making web requests?
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么并发适用于进行网络请求？
- en: What are the considerations that need to be made while developing applications
    that make concurrent web requests?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发进行并发网络请求的应用程序时需要考虑哪些因素？
- en: Further reading
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information, you can refer to the following links:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，您可以参考以下链接：
- en: '*Automate the boring stuff with Python: practical programming for total beginners*, Al.
    Sweigart, No Starch Press, 2015'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用Python自动化乏味的事情：面向完全初学者的实用编程*，Al. Sweigart，No Starch Press，2015'
- en: '*Web Scraping with Python*, Richard Lawson, Packt Publishing Ltd, 2015'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Python进行网络抓取*，Richard Lawson，Packt Publishing Ltd，2015'
- en: '*Instant Web Scraping with Java*, Ryan Mitchell, Packt Publishing Ltd, 2013'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Java进行即时网络抓取*，Ryan Mitchell，Packt Publishing Ltd，2013'
