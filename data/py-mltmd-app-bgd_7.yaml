- en: Chapter 7. Working with Videos
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 处理视频
- en: Photographs capture the moment, but it is the video that helps us relive that
    moment! Video has become a major part of our lives. We preserve our memories by
    capturing the family vacation on a camcorder. When it comes to digitally preserving
    those recorded memories, the digital video processing plays an important role.
    In the previous chapter, to learn various audio processing techniques, the GStreamer
    multimedia framework was used. We will continue to use GStreamer for learning
    the fundamentals of video processing.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 照片捕捉瞬间，但视频帮助我们重温那一刻！视频已成为我们生活的重要组成部分。我们通过在摄像机上记录家庭假期来保存我们的记忆。当涉及到数字保存这些记录的记忆时，数字视频处理起着重要作用。在前一章中，为了学习各种音频处理技术，我们使用了GStreamer多媒体框架。我们将继续使用GStreamer来学习视频处理的基础知识。
- en: 'In this chapter, we shall:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将：
- en: Develop a simple command-line video player
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个简单的命令行视频播放器
- en: Perform basic video manipulations such as cropping, resizing, and tweaking the
    parameters such as brightness, contrast, and saturation levels of a streaming
    video
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的视频操作，如裁剪、调整大小以及调整亮度、对比度和饱和度等参数。
- en: Add text string on top of a video stream
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在视频流上添加文本字符串
- en: Learn how to convert video between different video formats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何在不同视频格式之间转换视频
- en: Write a utility that separates audio and video tracks from an input video file
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个实用程序，从输入视频文件中分离音频和视频轨道
- en: Mix audio and video tracks to create a single video file
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将音频和视频轨道混合以创建单个视频文件
- en: Save one or more video frames as still images
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个或多个视频帧保存为静态图像
- en: So let's get on with it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧。
- en: Installation prerequisites
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装先决条件
- en: We will use Python bindings of GStreamer multimedia framework to process video
    data. See the installation instructions in [Chapter 5](ch05.html "Chapter 5. Working
    with Audios"), *Working with Audios* to install GStreamer and other dependencies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用GStreamer多媒体框架的Python绑定来处理视频数据。请参阅[第5章](ch05.html "第5章. 处理音频")，“处理音频”中的安装说明，以安装GStreamer和其他依赖项。
- en: For video processing, we will be using several GStreamer plugins not introduced
    earlier. Make sure that these plugins are available in your GStreamer installation
    by running the `gst-inspect-0.10` command from the console (gst-inspect-0.10.exe
    for Windows XP users). Otherwise, you will need to install these plugins or use
    an alternative if available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于视频处理，我们将使用一些之前未介绍过的GStreamer插件。请确保这些插件在您的GStreamer安装中可用，通过从控制台运行`gst-inspect-0.10`命令（Windows
    XP用户为gst-inspect-0.10.exe）。否则，您需要安装这些插件或使用可用的替代方案。
- en: 'Following is a list of additional plugins we will use in this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将在本章中使用的附加插件列表：
- en: '`autoconvert:` Determines an appropriate converter based on the capabilities.
    It will be used extensively used throughout this chapter.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autoconvert:` 根据能力确定合适的转换器。它将在本章中广泛使用。'
- en: '`autovideosink:` Automatically selects a video sink to display a streaming
    video.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autovideosink:` 自动选择视频输出设备以显示流媒体视频。'
- en: '`ffmpegcolorspace:` Transforms the color space into a color space format that
    can be displayed by the video sink.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ffmpegcolorspace:` 将颜色空间转换为视频输出设备可以显示的颜色空间格式。'
- en: '`capsfilter:` It''s the capabilities filter used to restrict the type of media
    data passing down stream, discussed extensively in this chapter.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`capsfilter:` 是用于限制流向下传递的媒体数据类型的特性过滤器，在本章中进行了详细讨论。'
- en: '`textoverlay:` Overlays a text string on the streaming video. Used in the *Adding
    text and time on a video stream* section.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`textoverlay:` 在流媒体视频上叠加文本字符串。用于“在视频流中添加文本和时间”部分。'
- en: '`timeoverlay:` Adds a timestamp on top of the video buffer.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoverlay:` 在视频缓冲区顶部添加时间戳。'
- en: '`clockoverlay:` Puts current clock time on the streaming video.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clockoverlay:` 在流媒体视频上显示当前时钟时间。'
- en: '`videobalance:` Used to adjust brightness, contrast, and saturation of the
    images. It is used in the *Video manipulations and effects* section.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videobalance:` 用于调整图像的亮度、对比度和饱和度。它在“视频操作和效果”部分中使用。'
- en: '`videobox:` Crops the video frames by specified number of pixels used in the
    *Cropping* section.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`videobox:` 通过指定像素数裁剪视频帧，用于“裁剪”部分。'
- en: '`ffmux_mp4:` Provides `muxer` element for MP4 video muxing.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ffmux_mp4:` 为MP4视频复用提供`muxer`元素。'
- en: '`ffenc_mpeg4:` Encodes data into MPEG4 format.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ffenc_mpeg4:` 将数据编码为MPEG4格式。'
- en: '`ffenc_png:` Encodes data in PNG format used in the *Saving video frames as
    images* section.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ffenc_png:` 将数据编码为PNG格式，用于“将视频帧保存为图像”部分。'
- en: Playing a video
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 播放视频
- en: Earlier, we saw how to play an audio. Like audio, there are different ways in
    which a video can be streamed. The simplest of these methods is to use the `playbin`
    plugin. Another method is to go by the basics, where we create a conventional
    pipeline and create and link the required pipeline elements. If we only want to
    play the 'video' track of a video file, then the latter technique is very similar
    to the one illustrated for audio playback. However, almost always, one would like
    to hear the audio track for the video being streamed. There is additional work
    involved to accomplish this. The following diagram is a representative GStreamer
    pipeline that shows how the data flows in case of a video playback.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们看到了如何播放音频。与音频一样，视频流式传输有不同的方法。这些方法中最简单的是使用`playbin`插件。另一种方法是遵循基本原理，即创建传统的管道并创建和连接所需的管道元素。如果我们只想播放视频文件的“视频”轨道，那么后一种技术与音频播放中展示的方法非常相似。然而，几乎总是，人们还希望听到正在流式传输的视频的音频轨道。为此需要额外的工作。以下图是代表GStreamer管道的图，展示了视频播放时数据是如何流动的。
- en: '![Playing a video](img/0165_07_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![播放视频](img/0165_07_01.jpg)'
- en: In this illustration, the `decodebin` uses an appropriate decoder to decode
    the media data from the source element. Depending on the type of data (audio or
    video), it is then further streamed to the audio or video processing elements
    through the `queue` elements. The two `queue` elements, `queue1` and `queue2`,
    act as media data buffer for audio and video data respectively. When the queue
    elements are added and linked in the pipeline, the thread creation within the
    pipeline is handled internally by the GStreamer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个说明中，`decodebin`使用适当的解码器从源元素解码媒体数据。根据数据类型（音频或视频），它随后通过`queue`元素进一步流式传输到音频或视频处理元素。两个`queue`元素，`queue1`和`queue2`，分别作为音频和视频数据的媒体数据缓冲区。当队列元素在管道中添加并连接时，GStreamer会内部处理管道中的线程创建。
- en: Time for action - video player!
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 视频播放器！
- en: Let's write a simple video player utility. Here we will not use the `playbin`
    plugin. The use of `playbin` will be illustrated in a later sub-section. We will
    develop this utility by constructing a GStreamer pipeline. The key here is to
    use the queue as a data buffer. The audio and video data needs to be directed
    so that this 'flows' through audio or video processing sections of the pipeline
    respectively.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个简单的视频播放器实用工具。在这里，我们不会使用`playbin`插件。`playbin`的使用将在后面的子节中说明。我们将通过构建GStreamer管道来开发这个实用工具。关键在于使用队列作为数据缓冲区。音频和视频数据需要被引导，以便分别通过管道的音频或视频处理部分进行“流动”。
- en: Download the file `PlayingVidio.py` from the Packt website. The file has the
    source code for this video player utility.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Packt网站下载文件`PlayingVidio.py`。该文件包含此视频播放器实用工具的源代码。
- en: The following code gives an overview of the Video player class and its methods.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码概述了视频播放器类及其方法。
- en: '[PRE0]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, the overall structure of the code and the main program execution
    code remains the same as in the audio processing examples. The thread module is
    used to create a new thread for playing the video. The method VideoPlayer.play
    is sent on this thread. The gobject.threads_init() is an initialization function
    for facilitating the use of Python threading within the gobject modules. The main
    event loop for executing this program is created using gobject and this loop is
    started by the call evt_loop.run().
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所见，代码的整体结构和主要程序执行代码与音频处理示例中的相同。线程模块用于创建一个新线程来播放视频。VideoPlayer.play方法被发送到这个线程。gobject.threads_init()是一个初始化函数，用于促进在gobject模块中使用Python线程。创建用于执行此程序的主要事件循环使用gobject，并通过调用evt_loop.run()启动此循环。
- en: Tip
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Instead of using `thread` module you can make use of `threading` module as
    well. The code to use it will be something like:'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了使用`thread`模块外，您还可以使用`threading`模块。使用它的代码将类似于：
- en: '`import threading`'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`import threading`'
- en: '`threading.Thread(target=player.play).start()`'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`threading.Thread(target=player.play).start()`'
- en: You will need to replace the line thread.start_new_thread(player.play, ()) in
    earlier code snippet with line 2 illustrated in the code snippet within this note.
    Try it yourself!
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要将早期代码片段中的`thread.start_new_thread(player.play, ())`行替换为这个笔记中代码片段中展示的第2行。自己试试看！
- en: Now let's discuss a few of the important methods, starting with `self.contructPipeline:`
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一些重要的方法，从`self.contructPipeline:`开始。
- en: '[PRE1]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In various audio processing applications, we have used several of the elements
    defined in this method. First, the pipeline object, `self.player`, is created.
    The `self.filesrc` element specifies the input video file. This element is connected
    to a `decodebin`.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在各种音频处理应用中，我们已经使用了在此方法中定义的几个元素。首先，创建管道对象`self.player`。`self.filesrc`元素指定了输入视频文件。此元素连接到`decodebin`。
- en: On line 15, `autoconvert` element is created. It is a GStreamer `bin` that automatically
    selects a converter based on the capabilities (caps). It translates the decoded
    data coming out of the `decodebin` in a format playable by the video device. Note
    that before reaching the video sink, this data travels through a `capsfilter`
    and `ffmpegcolorspace` converter. The `capsfilter` element is defined on line
    26\. It is a filter that restricts the allowed capabilities, that is, the type
    of media data that will pass through it. In this case, the `videoCap` object defined
    on line 25 instructs the filter to only allow `video-xraw-yuv` capabilities .
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第15行，创建了`autoconvert`元素。它是一个GStreamer `bin`，能够根据能力（caps）自动选择转换器。它将`decodebin`输出的解码数据转换成视频设备可播放的格式。请注意，在到达视频输出端之前，这些数据会通过一个`capsfilter`和`ffmpegcolorspace`转换器。`capsfilter`元素在第26行定义。它是一个限制允许能力的过滤器，即将通过它的媒体数据类型。在这种情况下，第25行定义的`videoCap`对象指示过滤器只允许`video-xraw-yuv`能力。
- en: The `ffmpegcolorspace` is a plugin that has the ability to convert video frames
    to a different color space format. At this time, it is necessary to explain what
    a color space is. A variety of colors can be created by use of basic colors. Such
    colors form, what we call, a **color space**. A common example is an rgb color
    space where a range of colors can be created using a combination of red, green,
    and blue colors. The color space conversion is a representation of a video frame
    or an image from one color space into the other. The conversion is done in such
    a way that the converted video frame or image is a closer representation of the
    original one.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ffmpegcolorspace`是一个可以将视频帧转换为不同颜色空间格式的插件。此时，有必要解释一下什么是颜色空间。通过使用基本颜色，可以创建各种颜色。这些颜色形成我们所说的**颜色空间**。一个常见的例子是rgb颜色空间，其中可以通过红色、绿色和蓝色颜色的组合创建一系列颜色。颜色空间转换是将视频帧或图像从一个颜色空间转换到另一个颜色空间的过程。转换是以一种方式进行的，即转换后的视频帧或图像是原始帧或图像的更接近的表示。'
- en: Tip
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The video can be streamed even without using the combination of `capsfilter`
    and the `ffmpegcolorspace`. However, the video may appear distorted. So it is
    recommended to use `capsfilter` and `ffmpegcolorspace` converter. Try linking
    the `autoconvert` element directly to the `autovideosink` to see if it makes any
    difference.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使不使用`capsfilter`和`ffmpegcolorspace`的组合，也可以进行视频流传输。然而，视频可能会出现扭曲。因此，建议使用`capsfilter`和`ffmpegcolorspace`转换器。尝试直接将`autoconvert`元素链接到`autovideosink`，看看是否有所改变。
- en: Notice that we have created two sinks, one for audio output and the other for
    the video. The two `queue` elements are created on lines 32 and 33\. As mentioned
    earlier, these act as media data buffers and are used to send the data to audio
    and video processing portions of the GStreamer pipeline. The code block 35-45
    adds all the required elements to the pipeline.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，我们已经创建了两个输出端，一个用于音频输出，另一个用于视频。两个`queue`元素是在第32行和第33行创建的。如前所述，这些元素作为媒体数据缓冲区，用于将数据发送到GStreamer管道的音频和视频处理部分。代码块35-45向管道添加了所有必需的元素。
- en: Next, the various elements in the pipeline are linked. As we already know, the
    `decodebin` is a plugin that determines the right type of decoder to use. This
    element uses dynamic pads. While developing audio processing utilities, we connected
    the `pad-added` signal from `decodebin` to a method `decodebin_pad_added`. We
    will do the same thing here; however, the contents of this method will be different.
    We will discuss that later.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将管道中的各个元素进行链接。正如我们已经知道的，`decodebin`是一个插件，用于确定使用正确的解码器类型。此元素使用动态垫。在开发音频处理工具时，我们将`decodebin`的`pad-added`信号连接到了`decodebin_pad_added`方法。我们在这里也将做同样的事情；然而，这个方法的内容将会有所不同。我们将在稍后讨论这一点。
- en: On lines 50-52, the video processing portion of the pipeline is linked. The
    `self.videoQueue` receives the video data from the `decodebin`. It is linked to
    an `autoconvert` element discussed earlier. The `capsfilter` allows only `video-xraw-yuv`
    data to stream further. The `capsfilter` is linked to a `ffmpegcolorspace` element,
    which converts the data into a different color space. Finally, the data is streamed
    to the `videosink`, which, in this case, is an `autovideosink` element. This enables
    the 'viewing' of the input video. The audio processing portion of the pipeline
    is very similar to the one used in earlier chapter.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第50-52行，管道的视频处理部分被链接。`self.videoQueue`从`decodebin`接收视频数据。它与之前讨论过的`autoconvert`元素相连接。`capsfilter`只允许`video-xraw-yuv`数据进一步流式传输。`capsfilter`连接到`ffmpegcolorspace`元素，该元素将数据转换为不同的颜色空间。最后，数据被流式传输到`videosink`，在这种情况下，是一个`autovideosink`元素。这使您可以“查看”输入视频。管道的音频处理部分与早期章节中使用的方法非常相似。
- en: Now we will review the `decodebin_pad_added` method.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将回顾`decodebin_pad_added`方法。
- en: '[PRE2]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This method captures the `pad-added` signal, emitted when the `decodebin` creates
    a dynamic pad. In an earlier chapter, we simply linked the `decodebin` pad with
    a compatible pad on the `autoaudioconvert` element. We could do this because the
    `caps` or the type media data being streamed was always the audio data. However,
    here the media data can either represent an audio or video data. Thus, when a
    dynamic pad is created on the `decodebin`, we must check what `caps` this `pad`
    has. The name of the `get_name` method of `caps` object returns the type of media
    data handled. For example, the name can be of the form `video/x-raw-rgb` when
    it is a video data or `audio/x-raw-int` for audio data. We just check the first
    five characters to see if it is video or audio media type. This is done by the
    code block 4-11 in the code snippet. The `decodebin pad` with video media type
    is linked with the compatible pad on `self.videoQueue` element. Similarly, the
    `pad` with audio `caps` is linked with the one on `self.audioQueue`.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法捕获当`decodebin`创建一个动态垫时发出的`pad-added`信号。在早期章节中，我们只是将`decodebin`垫与`autoaudioconvert`元素上的兼容垫相连接。我们可以这样做，因为正在流式传输的`caps`或媒体数据类型始终是音频数据。然而，在这里，媒体数据可以代表音频或视频数据。因此，当在`decodebin`上创建一个动态垫时，我们必须检查这个`pad`有什么`caps`。`caps`对象的`get_name`方法的名称返回处理媒体数据类型。例如，名称可以是`video/x-raw-rgb`的形式，当它是视频数据时，或者对于音频数据是`audio/x-raw-int`。我们只检查前五个字符以查看它是否是视频或音频媒体类型。这是通过代码片段中的代码块4-11完成的。具有视频媒体类型的`decodebin
    pad`与`self.videoQueue`元素上的兼容垫相连接。同样，具有音频`caps`的`pad`与`self.audioQueue`上的一个相连接。
- en: 'Review the rest of the code from the `PlayingVideo.py`. Make sure you specify
    an appropriate video file path for the variable `self.inFileLocation` and then
    run this program from the command prompt as:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`PlayingVideo.py`中查看其余的代码。确保为变量`self.inFileLocation`指定一个合适的视频文件路径，然后从命令提示符运行此程序，如下所示：
- en: '[PRE3]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This should open a GUI window where the video will be streamed. The audio output
    will be synchronized with the playing video.
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会打开一个GUI窗口，视频将在其中进行流式传输。音频输出将与播放的视频同步。
- en: What just happened?
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We created a command-line video player utility. We learned how to create a GStreamer
    pipeline that can play synchronized audio and video streams. It explained how
    the `queue` element can be used to process the audio and video data in a pipeline.
    In this example, the use of GStreamer plugins such as `capsfilter` and `ffmpegcolorspace`
    was illustrated. The knowledge gained in this section will be applied in the upcoming
    sections in this chapter.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个命令行视频播放器实用程序。我们学习了如何创建一个可以播放同步音频和视频流的GStreamer管道。它解释了如何使用`queue`元素在管道中处理音频和视频数据。在这个例子中，展示了如何使用GStreamer插件，如`capsfilter`和`ffmpegcolorspace`。本节中获得的知识将在本章后续部分的应用中体现。
- en: Have a go hero add playback controls
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试添加播放控制
- en: In [Chapter 6](ch06.html "Chapter 6. Audio Controls and Effects"), *Audio Controls
    and Effects* we learned different techniques to control the playback of an audio.
    Develop command-line utilities that will allow you to pause the video or directly
    jump to a specified position on the video track.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.html "第6章。音频控制和效果")中，我们学习了不同的技术来控制音频的播放。开发命令行实用程序，允许您暂停视频或直接跳转到视频轨道上的指定位置。
- en: Playing video using 'playbin'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`playbin`播放视频
- en: The goal of the previous section was to introduce you to the fundamental method
    of processing input video streams. We will use that method one way or another
    in the future discussions. If just video playback is all that you want, then the
    simplest way to accomplish this is by means of `playbin` plugin. The video can
    be played just by replacing the `VideoPlayer.constructPipeline` method in file
    `PlayingVideo.py` with the following code. Here, `self.player` is a `playbin`
    element. The `uri` property of `playbin` is set as the input video file path.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节的目标是向您介绍处理输入视频流的基本方法。我们将在未来的讨论中以某种方式使用该方法。如果您只想进行视频播放，那么最简单的方法是通过`playbin`插件来实现。只需将文件`PlayingVideo.py`中的`VideoPlayer.constructPipeline`方法替换为以下代码即可播放视频。在这里，`self.player`是一个`playbin`元素。`playbin`的`uri`属性被设置为输入视频文件路径。
- en: The goal of the previous section was to introduce you to the fundamental method
    of processing input video streams. We will use that method one way or another
    in the future discussions. If just video playback is all that you want, then the
    simplest way to accomplish this is by means of `playbin` plugin. The video can
    be played just by replacing the `VideoPlayer.constructPipeline` method in file
    `PlayingVideo.py` with the following code. Here, `self.player` is a `playbin`
    element. The `uri` property of `playbin` is set as the input video file path.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节的目标是向您介绍处理输入视频流的基本方法。我们将在未来的讨论中以某种方式使用该方法。如果您只想进行视频播放，那么最简单的方法是通过`playbin`插件来实现。只需将文件`PlayingVideo.py`中的`VideoPlayer.constructPipeline`方法替换为以下代码即可播放视频。在这里，`self.player`是一个`playbin`元素。`playbin`的`uri`属性被设置为输入视频文件路径。
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Video format conversion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频格式转换
- en: Saving the video in a different file format is one of the frequently performed
    tasks for example, the task of converting a recorded footage on to your camcorder
    to a format playable on a DVD player. So let's list out the elements we need in
    a pipeline to carry out the video format conversion.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 将视频保存为不同的文件格式是经常执行的任务之一，例如，将摄像机上录制的视频转换为DVD播放器可播放的格式。因此，让我们列出在管道中执行视频格式转换所需的元素。
- en: A `filesrc` element to stream the video file and a `decodebin` to decode the
    encoded input media data.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`filesrc`元素用于流式传输视频文件，一个`decodebin`用于解码编码的输入媒体数据。
- en: Next, the audio processing elements of the pipeline, such as `audioconvert`,
    an encoder to encode the raw audio data into an appropriate audio format to be
    written.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，管道中的音频处理元素，例如`audioconvert`，这是一个编码器，用于将原始音频数据编码成适当的音频格式以便写入。
- en: The video processing elements of the pipeline, such as a video encoder element
    to encode the video data.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道中的视频处理元素，例如一个视频编码器元素，用于编码视频数据。
- en: A multiplexer or a **muxer** that takes the encoded audio and video data streams
    and puts them into a single channel.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个复用器或**复用器**，它将编码的音频和视频数据流合并到一个单独的通道中。
- en: There needs to be an element that, depending on the media type, can send the
    media data to an appropriate processing unit. This is accomplished by `queue`
    elements that act as data buffers. Depending on whether it is an audio or video
    data, it is streamed to the audio or video processing elements. The queue is also
    needed to stream the encoded data from audio pipeline to the multiplexer.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个元素，根据媒体类型，可以将媒体数据发送到适当的处理单元。这是通过`queue`元素实现的，它们充当数据缓冲区。根据是音频还是视频数据，它将被流式传输到音频或视频处理元素。队列还需要将编码数据从音频管道流式传输到复用器。
- en: Finally, a `filesink` element to save the converted video file (containing both
    audio and video tracks).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，一个`filesink`元素用于保存转换后的视频文件（包含音频和视频轨道）。
- en: Time for action - video format converter
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 视频格式转换器
- en: 'We will create a video conversion utility that will convert an input video
    file into a format specified by the user. The file you need to download from the
    Packt website is `VideoConverter.py`. This file can be run from the command line
    as:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个视频转换实用程序，该实用程序将输入视频文件转换为用户指定的格式。您需要从Packt网站下载的文件是`VideoConverter.py`。此文件可以从命令行运行，如下所示：
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Where, the options are as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，选项如下：
- en: '`--input_path:` The full path of the video file we wish to convert. The video
    format of the input files. The format should be in a supported list of formats.
    The supported input formats are MP4, OGG, AVI, and MOV.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--input_path:` 我们希望转换的视频文件的完整路径。输入文件的视频格式。格式应在一个支持的格式列表中。支持的输入格式有MP4、OGG、AVI和MOV。'
- en: '`--output_path:` The full path of the output video file. If not specified,
    it will create a folder `OUTPUT_VIDEOS` within the input directory and save the
    file there with same name.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_path:` 输出视频文件的完整路径。如果没有指定，它将在输入目录中创建一个名为 `OUTPUT_VIDEOS` 的文件夹，并将文件以相同的名称保存在那里。'
- en: '`--output_format:` The audio format of the output file. The supported output
    formats are OGG and MP4.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--output_format:` 输出文件的音频格式。支持的输出格式有 OGG 和 MP4。'
- en: Tip
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: As we will be using a `decodebin` element for decoding the input media data;
    there is actually a wider range of input formats this utility can handle. Modify
    the code in `VideoPlayer.processArguments` or add more formats to dictionary `VideoPlayer.supportedInputFormats`.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们将使用 `decodebin` 元素进行输入媒体数据的解码；实际上，这个实用程序可以处理更广泛的输入格式。修改 `VideoPlayer.processArguments`
    中的代码或向字典 `VideoPlayer.supportedInputFormats` 中添加更多格式。
- en: If not done already, download the file `VideoConverter.py` from the Packt website.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未完成，请从 Packt 网站下载文件 `VideoConverter.py`。
- en: 'The overall structure of the code is:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的整体结构如下：
- en: '[PRE6]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: A new thread is created by calling `thread.start_new_thread`, to run the application.
    The method `VideoConverter.convert` is sent on this thread. It is similar to the
    `VideoPlayer.play` method discussed earlier. Let's review some key methods of
    the class `VideoConverter`.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过调用 `thread.start_new_thread` 创建一个新线程来运行应用程序。将 `VideoConverter.convert` 方法发送到这个线程。这与之前讨论的
    `VideoPlayer.play` 方法类似。让我们回顾一下 `VideoConverter` 类的一些关键方法。
- en: 'The `__init__` method contains the initialization code. It also calls methods
    to process command-line arguments and then build the pipeline. The code is illustrated
    as follows:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`__init__` 方法包含初始化代码。它还调用方法处理命令行参数，然后构建管道。代码如下所示：'
- en: '[PRE8]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To process the video file, we need audio and video encoders. This utility will
    support the conversion to only MP4 and OGG file formats. This can be easily extended
    to include more formats by adding appropriate encoders and muxer plugins. The
    values of the self.audioEncoders and self.videoEncoders dictionary objects specify
    the encoders to use for the streaming audio and video data respectively. Therefore,
    to store the video data in MP4 format, we use the ffenc_mp4 encoder. The encoders
    illustrated in the code snippet should be a part of the GStreamer installation
    on your computer. If not, visit the GStreamer website to find out how to install
    these plugins. The values of dictionary self.muxers represent the multiplexer
    to use in a specific output format.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要处理视频文件，我们需要音频和视频编码器。这个实用程序将只支持转换为 MP4 和 OGG 文件格式。通过添加适当的编码器和复用器插件，可以轻松扩展以包括更多格式。self.audioEncoders
    和 self.videoEncoders 字典对象的值分别指定用于流式传输音频和视频数据的编码器。因此，为了将视频数据存储为 MP4 格式，我们使用 ffenc_mp4
    编码器。代码片段中显示的编码器应该是您计算机上 GStreamer 安装的一部分。如果不是，请访问 GStreamer 网站，了解如何安装这些插件。self.muxers
    字典的值表示在特定输出格式中使用的复用器。
- en: The `constructPipeline` method does the main conversion job. It builds the required
    pipeline, which is then set to playing state in the `convert` method.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`constructPipeline` 方法执行主要的转换工作。它构建所需的管道，然后在 `convert` 方法中将管道设置为播放状态。'
- en: '[PRE9]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In an earlier section, we covered several of the elements used in the previous
    pipeline. The code on lines 43 to 48 establishes linkage for the audio and video
    processing elements. On line 44, the multiplexer, self.muxer is linked with the
    video encoder element. It puts the separate parts of the stream in this case,
    the video and audio data, into a single file. The data output from audio encoder,
    self.audio_encoder, is streamed to the muxer via a queue element, self.queue3\.
    The muxed data coming out of self.muxer is then streamed to the self.filesink.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的部分，我们介绍了之前管道中使用的几个元素。第 43 到 48 行的代码为音频和视频处理元素建立了连接。在第 44 行，复用器 self.muxer
    与视频编码器元素连接。它将流的不同部分（在这种情况下，视频和音频数据）放入一个单独的文件中。音频编码器 self.audio_encoder 输出的数据通过队列元素
    self.queue3 流向复用器。然后，来自 self.muxer 的复用数据流到 self.filesink。
- en: Let's quickly review the `VideoConverter.convert` method.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速回顾一下 `VideoConverter.convert` 方法。
- en: '[PRE10]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: On line 10, the GStreamer pipeline built earlier is set to playing. When the
    conversion is complete, it will generate the End Of Stream (EOS) message. The
    self.is_playing flag is modified in the method self.message_handler. The while
    loop on line 11 is executed until the EOS message is posted on the bus or some
    error occurs. Finally, on line 24, the main execution loop is terminated.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第10行，之前构建的GStreamer管道被设置为播放。当转换完成后，它将生成流的结束（EOS）消息。在`self.message_handler`方法中修改了`self.is_playing`标志。第11行的while循环执行，直到EOS消息在总线上发布或发生某些错误。最后，在第24行，主执行循环被终止。
- en: Tip
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: On line 3, we make a call to `time.clock()`. This actually gives the CPU time
    spent on the process.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第3行，我们调用了`time.clock()`。这实际上给出了该进程所消耗的CPU时间。
- en: The other methods such as `VideoConverter.decodebin_pad_added` are identical
    to the one developed in the *Playing a video* section. Review the remaining methods
    from the file `VideoConverter.py` and then run this utility by specifying appropriate
    command-line arguments. The following screenshot shows sample output messages
    when the program is run from the console window.![Time for action - video format
    converter](img/0165_07_02.jpg)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其他方法，如`VideoConverter.decodebin_pad_added`与*播放视频*部分中开发的方法相同。请回顾`VideoConverter.py`文件中的剩余方法，然后通过指定适当的命令行参数运行此实用工具。以下截图显示了从控制台窗口运行程序时的示例输出消息。![操作时间
    - 视频格式转换器](img/0165_07_02.jpg)
- en: This is a sample run of the video conversion utility from the console.
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是视频转换实用工具从控制台运行的示例运行。
- en: What just happened?
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We created another useful utility that can convert video files from one format
    to the other. We learned how to encode the audio and video data into a desired
    output format and then use a multiplexer to put these two data streams into a
    single file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个另一个有用的实用工具，可以将视频文件从一种格式转换为另一种格式。我们学习了如何将音频和视频数据编码成所需的输出格式，然后使用复用器将这些两个数据流放入一个单独的文件中。
- en: Have a go hero batch-convert the video files
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试批量转换视频文件
- en: The video converter developed in previous sections can convert a single video
    file at a time. Can you make it a batch-processing utility? Refer to the code
    for the audio conversion utility developed in the *Working with Audios* chapter.
    The overall structure will be very similar. However, there could be challenges
    in converting multiple video files because of the use of queue elements. For example,
    when it is done converting the first file, the data in the queue may not be flushed
    when we start conversion of the other file. One crude way to address this would
    be to reconstruct the whole pipeline and connect signals for each audio file.
    However, there will be a more efficient way to do this. Think about it!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中开发的视频转换器一次只能转换一个视频文件。你能将其制作成一个批量处理实用工具吗？请参考*处理音频*章节中开发的音频转换器代码。整体结构将非常相似。然而，由于使用了队列元素，转换多个视频文件可能会遇到挑战。例如，当第一个文件转换完成时，当我们开始转换其他文件时，队列中的数据可能不会被刷新。一种粗略的解决方法是在每个音频文件上重建整个管道并连接信号。然而，将会有一个更有效的方法来做这件事。想想看！
- en: Video manipulations and effects
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频操作和效果
- en: Suppose you have a video file that needs to be saved with an adjusted default
    brightness level. Alternatively, you may want to save another video with a different
    aspect ratio. In this section, we will learn some of the basic and most frequently
    performed operations on a video. We will develop code using Python and GStreamer
    for tasks such as resizing a video or adjusting its contrast level.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个需要以调整后的默认亮度级别保存的视频文件。或者，你可能想保存另一个具有不同宽高比的视频。在本节中，我们将学习一些视频的基本且最常执行的操作。我们将使用Python和GStreamer开发代码，以执行诸如调整视频大小或调整其对比度级别等任务。
- en: Resizing
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整大小
- en: The data that can flow through an element is described by the capabilities (caps)
    of a pad on that element. If a decodebin element is decoding video data, the capabilities
    of its dynamic pad will be described as, for instance, `video/x-raw-yuv`. Resizing
    a video with GStreamer multimedia framework can be accomplished by using a `capsfilter`
    element, that has `width` and `height` parameters specified. As discussed earlier,
    the `capsfilter` element limits the media data type that can be transferred between
    two elements. For example, a `cap` object described by the string, `video/x-raw-yuv,
    width=800, height=600` will set the width of the video to 800 pixels and the height
    to 600 pixels.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过一个元素上 pad 的能力（caps）来描述通过该元素的数据。如果一个 decodebin 元素正在解码视频数据，其动态 pad 的能力将被描述为，例如，`video/x-raw-yuv`。使用
    GStreamer 多媒体框架调整视频大小可以通过使用具有指定 `width` 和 `height` 参数的 `capsfilter` 元素来实现。如前所述，`capsfilter`
    元素限制了两个元素之间可以传输的媒体数据类型。例如，由字符串描述的 `cap` 对象，`video/x-raw-yuv, width=800, height=600`
    将将视频宽度设置为 800 像素，高度设置为 600 像素。
- en: Time for action - resize a video
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 调整视频大小
- en: We will now see how to resize a streaming video using the `width` and `height`
    parameters described by a GStreamer `cap` object.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到如何使用由 GStreamer `cap` 对象描述的 `width` 和 `height` 参数来调整流视频的大小。
- en: Download the file `VideoManipulations.py` from the Packt website. The overall
    class design is identical to the one studied in the *Playing a video* section.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Packt 网站下载文件 `VideoManipulations.py`。整体类设计与在 *播放视频* 部分研究的设计相同。
- en: The methods `self.constructAudioPipeline()` and `self.constructVideoPipeline()`,
    respectively, define and link elements related to audio and video portions of
    the main pipeline object `self.player`. As we have already discussed most of the
    audio/video processing elements in earlier sections, we will only review the `constructVideoPipeline`
    method here.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`self.constructAudioPipeline()` 和 `self.constructVideoPipeline()` 方法分别定义和链接与主管道对象
    `self.player` 的音频和视频部分相关的元素。由于我们已经在前面章节中讨论了大多数音频/视频处理元素，我们在这里只回顾 `constructVideoPipeline`
    方法。'
- en: '[PRE11]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The capsfilter element is defined on line 16\. It is a filter that restricts
    the type of media data that will pass through it. The videocap is a GStreamer
    cap object created on line 10\. This cap specifies the width and height parameters
    of the streaming video. It is set as a property of the capsfilter, self.capsFilter.
    It instructs the filter to only stream video-xraw-yuv data with width and height
    specified by the videocap object.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: capsfilter 元素在第 16 行定义。它是一个限制将通过它的媒体数据类型的过滤器。videocap 是在第 10 行创建的 GStreamer
    cap 对象。此 cap 指定了流视频的宽度和高度参数。它被设置为 capsfilter 的属性，self.capsFilter。它指示过滤器只流式传输由
    videocap 对象指定的宽度和高度的视频-xraw-yuv 数据。
- en: Tip
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In the source file, you will see an additional element `self.videobox` linked
    in the pipeline. It is omitted in the above code snippet. We will see what this
    element is used for in the next section.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在源文件中，你会看到在管道中链接了一个额外的元素 `self.videobox`。在上面的代码片段中省略了它。我们将在下一节中看到这个元素的作用。
- en: 'The rest of the code is straightforward. We already covered similar methods
    in earlier discussions. Develop the rest of the code by reviewing the file `VideoManipulations.py`.
    Make sure to specify an appropriate video file path for the variable `self.inFileLocation`
    .Then run this program from the command prompt as:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的其余部分很简单。我们已经在之前的讨论中介绍了类似的方法。通过回顾文件 `VideoManipulations.py` 来开发代码的其余部分。确保为变量
    `self.inFileLocation` 指定一个合适的视频文件路径。然后从命令提示符运行此程序，如下所示：
- en: '[PRE12]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This should open a GUI window where the video will be streamed. The default
    size of this window will be controlled by the parameters self.video_width and
    self.video_height specified in the code.
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会打开一个GUI窗口，视频将在其中流式传输。此窗口的默认大小将由代码中指定的 `self.video_width` 和 `self.video_height`
    参数控制。
- en: What just happened?
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: The command-line video player developed earlier was extended in the example
    we just developed. We used `capsfilter` plugin to specify the `width` and `height`
    parameters of the streaming video and thus resize the video.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前开发的命令行视频播放器在刚刚开发的示例中得到了扩展。我们使用了 `capsfilter` 插件来指定流视频的 `width` 和 `height`
    参数，从而调整视频大小。
- en: Cropping
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 裁剪
- en: Suppose you have a video that has a large 'gutter space' at the bottom or some
    unwanted portion on a side that you would like to trim off. The `videobox` GStreamer
    plugin facilitates cropping the video from left, right, top, or bottom.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个视频在底部有较大的“空白空间”或者你想要裁剪掉的一侧的不需要的部分。`videobox` GStreamer插件可以方便地从左侧、右侧、顶部或底部裁剪视频。
- en: Time for action - crop a video
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 是时候行动起来 - 裁剪视频
- en: Let's add another video manipulation feature to the command-line video player
    developed earlier.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们给之前开发的命令行视频播放器添加另一个视频处理功能。
- en: The file we need here is the one used in the earlier section, `VideoManipulations.py`.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要的文件是前面章节中使用的文件，即`VideoManipulations.py`。
- en: Once again, we will focus our attention on the `constructVideoPipeline` method
    of the class `VideoPlayer`. The following code snippet is from this method. The
    rest of the code in this method is identical to the one reviewed in the earlier
    section.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次强调，我们将关注`VideoPlayer`类中的`constructVideoPipeline`方法。以下代码片段来自此方法。此方法中的其余代码与前面章节中审查的代码相同。
- en: '[PRE13]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code is self-explanatory. The `videobox` element is created on line 1\.
    The properties of `videobox` that crop the streaming video are set on lines 2-5\.
    It receives the media data from the `autoconvert` element. The source pad of `videobox`
    is connected to the sink of either `capsfilter` or directly the `ffmpegcolorspace`
    element.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码是自解释的。`videobox`元素在第1行创建。用于裁剪流媒体视频的`videobox`属性在第2-5行设置。它从`autoconvert`元素接收媒体数据。`videobox`的源端连接到`capsfilter`的接收端或直接连接到`ffmpegcolorspace`元素。
- en: 'Develop the rest of the code by reviewing the file `VideoManipulations.py`.
    Make sure to specify an appropriate video file path for the variable `self.inFileLocation`.
    Then run this program from the command prompt as:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过审查文件`VideoManipulations.py`来开发剩余的代码。确保为变量`self.inFileLocation`指定一个合适的视频文件路径。然后从命令提示符运行此程序，如下所示：
- en: '[PRE14]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This should open a GUI window where the video will be streamed. The video will
    be cropped from left, right, bottom, and top sides by the parameters `self.crop_left,
    self.crop_right, self.crop_bottom`, and `self.crop_top` respectively.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该会打开一个GUI窗口，视频将通过该窗口进行流式传输。视频将从左侧、右侧、底部和顶部通过`self.crop_left`、`self.crop_right`、`self.crop_bottom`和`self.crop_top`参数分别进行裁剪。
- en: What just happened?
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We extended the video player application further to add a GStreamer element
    that can crop the video frames from sides. The `videobox` plugin was used to accomplish
    this task.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步扩展了视频播放器应用程序，添加了一个可以裁剪视频帧的GStreamer元素。我们使用了`videobox`插件来完成这个任务。
- en: Have a go hero add borders to a video
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试给视频添加边框
- en: In the previous section, we used `videobox` element to trim the video from sides.
    The same plugin can be used to add a border around the video. If you set negative
    values for `videobox` properties, such as, bottom, top, left and right, instead
    of cropping the video, it will add black border around the video. Set negative
    values of parameters such as `self.crop_left` to see this effect.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了`videobox`元素从视频两侧进行裁剪。同一个插件也可以用来给视频添加边框。如果你为`videobox`属性设置负值，例如底部、顶部、左侧和右侧，那么不是裁剪视频，而是在视频周围添加黑色边框。将`self.crop_left`等参数设置为负值来查看这个效果。
- en: The video cropping can be accomplished by using `videocrop` plugin. It is similar
    to the `videobox` plugin, but it doesn't support adding a border to the video
    frames. Modify the code and use this plugin to crop the video.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过使用`videocrop`插件来完成视频裁剪。它与`videobox`插件类似，但不支持给视频帧添加边框。修改代码并使用此插件来裁剪视频。
- en: Adjusting brightness and contrast
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整亮度和对比度
- en: We saw how to adjust the brightness and contrast level in [Chapter 3](ch03.html
    "Chapter 3. Enhancing Images"), *Enhancing Images*. If you have a homemade video
    recorded in poor lighting conditions, you would probably adjust its brightness
    level. The contrast-level highlights the difference between the color and brightness
    level of each video frame. The `videobalance` plugin can be used to adjust the
    brightness, contrast, hue, and saturation. The next code snippet creates this
    element and sets the brightness and contrast properties. The brightness property
    can accept values in the range `-1` to `1`, the default (original) brightness
    level is `0`. The contrast can have values in the range `0` to `2` with the default
    value as `1`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第3章](ch03.html "第3章。增强图像")*增强图像*中看到了如何调整亮度和对比度级别。如果您有一个在光线条件不佳的情况下录制的家庭视频，您可能会调整其亮度级别。对比度级别强调每个视频帧的颜色和亮度级别之间的差异。`videobalance`插件可用于调整亮度、对比度、色调和饱和度。以下代码片段创建此元素并设置亮度和对比度属性。亮度属性可以接受`-1`到`1`范围内的值，默认（原始）亮度级别为`0`。对比度可以具有`0`到`2`范围内的值，默认值为`1`。
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `videobalance` is then linked in the GStreamer pipeline as:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`videobalance`在GStreamer管道中链接如下：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Review the rest of the code from file `VideoEffects.py`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 查看文件`VideoEffects.py`中的其余代码。
- en: Creating a gray scale video
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建灰度视频
- en: 'The video can be rendered as gray scale by adjusting the saturation property
    of the `videobalance` plugin. The saturation can have a value in the range `0`
    to `2`. The default value is `1`. Setting this value to `0.0` converts the images
    to gray scale. The code is illustrated as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整`videobalance`插件的饱和度属性，可以将视频渲染为灰度。饱和度可以具有`0`到`2`范围内的值。默认值是`1`。将此值设置为`0.0`将图像转换为灰度。代码如下所示：
- en: '[PRE17]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You can refer to the file `VideoEffects.py`, which illustrates how to use the
    `videobalance` plugin to adjust saturation and other parameters discussed in earlier
    sections.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考文件`VideoEffects.py`，它展示了如何使用`videobalance`插件调整饱和度和其他在前面章节中讨论的参数。
- en: Adding text and time on a video stream
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在视频流中添加文本和时间
- en: Ability to add a text string or a subtitles track to a video is yet another
    desirable feature one needs when processing videos. The GStreamer plugin `textoverlay`
    enables overlaying informative text string, such as the name of the file, on top
    of a video stream. The other useful plugins such as `timeoverlay` and `clockoverlay`
    provide a way to put the video buffer timestamp and the CPU clock time on top
    of the streaming video.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理视频时，将文本字符串或字幕轨道添加到视频的能力是另一个需要的特性。GStreamer插件`textoverlay`允许在视频流上叠加信息性文本字符串，例如文件名。其他有用的插件，如`timeoverlay`和`clockoverlay`，提供了一种将视频缓冲区时间戳和CPU时钟时间放在流视频顶部的方法。
- en: Time for action - overlay text on a video track
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 在视频轨道上叠加文本
- en: Let's see how to add a text string on a video track. We will write a simple
    utility, which essentially has the same code structure as the one we developed
    in the *Playing a video* section. This tool will also add the buffer timestamp
    and the current CPU clock time on the top of the video. For this section, it is
    important that you have `textoverlay, timeoverlay`, and `clockoverlay` plugins
    available in your GStreamer installation. Otherwise, you need to install these
    plugins or use some other plugins, such as `cairotextoverlay`, if available.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在视频轨道上添加文本字符串。我们将编写一个简单的实用工具，其代码结构本质上与我们之前在*播放视频*部分开发的结构相同。此工具还将添加缓冲区时间戳和当前CPU时钟时间到视频顶部。对于本节，重要的是您在GStreamer安装中拥有`textoverlay`、`timeoverlay`和`clockoverlay`插件。否则，您需要安装这些插件或使用其他插件，如可用的`cairotextoverlay`。
- en: Download the file `VideoTextOverlay.py` from the Packt website.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Packt网站下载文件`VideoTextOverlay.py`。
- en: 'The `constructVideoPipeline` method of the class `VideoPlayer` is illustrated
    in the following code snippet:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类`VideoPlayer`的`constructVideoPipeline`方法在以下代码片段中展示：
- en: '[PRE18]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the elements for overlaying text, time, or clock can be simply
    added and linked in a GStreamer pipeline like other elements. Let's discuss various
    properties of these elements now. On lines 20-23, the textoverlay element is defined.
    The text property sets the text string that appears on the streaming video. To
    ensure that the text string is clearly visible in the video, we add a background
    contrast to this text. This is done on line 23 by setting the shaded-background
    property to True. The other properties of this plugin help fix the text position
    on the video. Run gst-inspect-0.10 on textoverlay plugin to see what these properties
    are.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如你所见，用于叠加文本、时间或时钟的元素可以像其他元素一样简单地添加并连接到 GStreamer 流程中。现在让我们讨论这些元素的各个属性。在第 20-23
    行，定义了 `textoverlay` 元素。文本属性设置了在流式视频上出现的文本字符串。为了确保文本字符串在视频中清晰可见，我们为此文本添加了背景对比。这是通过在第
    23 行将带阴影的背景属性设置为 True 来实现的。此插件的其他属性有助于在视频中固定文本位置。运行 `gst-inspect-0.10` 在 `textoverlay`
    插件上，以查看这些属性。
- en: Next, on lines 25-36, the time and clock overlay elements are defined. The properties
    are similar to the ones available in `textoverlay` plugin. The clock time will
    appear on the bottom-left corner of the streaming video. This is accomplished
    by setting the `valign` and `halign` properties. These three elements are then
    linked in the GStreamer pipeline. The internal order in which they are linked
    doesn't matter.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在 25-36 行，定义了时间和时钟叠加元素。它们的属性与 `textoverlay` 插件中可用的属性类似。时钟时间将出现在流式视频的左下角。这是通过设置
    `valign` 和 `halign` 属性来实现的。这三个元素随后在 GStreamer 流程中连接。它们连接的内部顺序并不重要。
- en: 'Develop the rest of the code by reviewing the file `VideoTextOverlay.py`. Make
    sure you specify an appropriate video file path for the variable `self.inFileLocation`.
    Then run this program from the command prompt as:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过查阅文件 `VideoTextOverlay.py` 开发剩余的代码。确保为变量 `self.inFileLocation` 指定适当的视频文件路径。然后从命令提示符运行此程序：
- en: '[PRE19]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This should open a GUI window where the video will be streamed. The video will
    show a text string "hello" along with the running time and the clock time. This
    is illustrated by the following snapshot of a video frame.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会打开一个 GUI 窗口，视频将在其中流式传输。视频将显示文本字符串 "hello"，以及运行时间和时钟时间。这可以通过以下视频帧的快照来展示。
- en: '![Time for action - overlay text on a video track](img/0165_07_03.jpg)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![行动时间 - 在视频轨道上叠加文本](img/0165_07_03.jpg)'
- en: The screenshot depicts a video frame showing text, time, and clock overlay.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 截图展示了包含文本、时间和时钟叠加的视频帧。
- en: What just happened?
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We learned how to use elements such as `textoverlay, timeoverlay`, and `clockoverlay`
    in a GStreamer pipeline to add text string, timestamp, and clock respectively,
    on top of a video buffer. The `textoverlay` element can be used further to add
    a subtitle track to the video file.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何在 GStreamer 流程中使用 `textoverlay`、`timeoverlay` 和 `clockoverlay` 等元素，分别在上面的视频缓冲区上添加文本字符串、时间戳和时钟。`textoverlay`
    元素还可以进一步用来给视频文件添加字幕轨道。
- en: Have a go hero add subtitles to a video track!
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试英雄添加视频轨道字幕！
- en: Extend the code we just developed to add a subtitles track to the video file.
    To add a subtitle track, you will need the `subparse` plugin. Note that this plugin
    is not available by default in the windows installation of GStreamer using the
    GStreamer-WinBuilds binary. Thus, Windows users may need to install this plugin
    separately. Review the `subparse` plugin reference to see how to accomplish this
    task. The following code snippet shows how to create the `subparse` element.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们刚刚开发的代码扩展以向视频文件添加字幕轨道。要添加字幕轨道，你需要 `subparse` 插件。请注意，此插件在 GStreamer-WinBuilds
    二进制文件安装的 GStreamer Windows 版本中默认不可用。因此，Windows 用户可能需要单独安装此插件。查阅 `subparse` 插件参考以了解如何完成此任务。以下代码片段展示了如何创建
    `subparse` 元素。
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Separating audio and video tracks
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分离音频和视频轨道
- en: There are times when you would like to separate an audio and a video track.
    Imagine that you have a collection of your favorite video songs. You are going
    on a long drive and the old CD player in your car can only play audio files in
    a specific file format. Let's write a utility that can separate out the audio
    from a video file!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能想要分离音频和视频轨道。想象一下，你有一系列你最喜欢的视频歌曲。你将进行长途驾驶，而你车上的老式 CD 播放器只能播放特定格式的音频文件。让我们编写一个可以将音频从视频文件中分离出来的实用程序！
- en: Time for action - audio and video tracks
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 音频和视频轨道
- en: We will develop code that takes a video file as an input and then creates two
    output files, one with only the audio track of the original file and the other
    with the video portion.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开发代码，该代码以视频文件作为输入，然后创建两个输出文件，一个仅包含原始文件的音频轨道，另一个包含视频部分。
- en: Download the file `SeparatingAudio.py` from the Packt website. The structure
    of the class `AudioSeparator` is similar to the one seen in the *Playing a Video*
    section. We will review two methods of this class, `constructPipeline` and `decodebin_pad_added`.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Packt网站下载文件`SeparatingAudio.py`。类`AudioSeparator`的结构与在*播放视频*部分看到的结构相似。我们将回顾这个类的两个方法，`constructPipeline`和`decodebin_pad_added`。
- en: Let's start with the code in the `constructPipeline` method.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从`constructPipeline`方法中的代码开始。
- en: '[PRE21]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We have already used all the necessary elements in various examples. The key
    here is to link them properly. The self.audiosink and self.videoSink elements
    are filesink elements that define audio and video output file locations respectively.
    Note that, in this example, we will save the output audio in MP3 format and video
    in MP4 format. Thus, the lame encoder is used for the audio file whereas we use
    encoder ffenc_mpeg4 and multiplexer ffmux_mp4 for the video output. Note that
    we have not used ffmpegcolorspace element. It just helps to get an appropriate
    color space format for the video sink (in this case, the output video file). In
    this case, it is not needed. You can always link it in the pipeline if the output
    file doesn't appropriately display the video frames. The media data decoded by
    self.decodebin needs to be streamed to the audio and video portions of the pipeline,
    using the queue elements as data buffers.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经在各种示例中使用了所有必要的元素。关键是正确地将它们连接起来。self.audiosink和self.videoSink元素是filesink元素，分别定义音频和视频输出文件的位置。请注意，在这个例子中，我们将输出音频保存为MP3格式，视频保存为MP4格式。因此，我们使用lame编码器进行音频文件，而使用编码器ffenc_mpeg4和multiplexer
    ffmux_mp4进行视频输出。请注意，我们没有使用ffmpegcolorspace元素。它只是帮助为视频sink（在这种情况下，输出视频文件）获取适当的颜色空间格式。在这种情况下，它是不需要的。如果输出文件没有适当地显示视频帧，您始终可以在管道中将其链接。由self.decodebin解码的媒体数据需要通过队列元素作为数据缓冲区流式传输到管道的音频和视频部分。
- en: The `decodebin` creates dynamic pads to decode the input audio and video data.
    The `decodebin_pad_added` method needs to check the capabilities (caps) on the
    dynamic pad of the `decodebin`.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`decodebin`创建动态pad以解码输入音频和视频数据。`decodebin_pad_added`方法需要检查`decodebin`动态pad上的功能（caps）。'
- en: '[PRE22]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This check is done by the code block 6-12\. If capabilities indicate it's an
    audio data, the `decodebin pad` is linked to the compatible pad on `self.audioQueue`.
    Similarly, a link between to `self.videoQueue` and `self.decodebin` is created
    when `caps` indicate it is the video data.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个检查是通过代码块6-12完成的。如果功能表明它是音频数据，则`decodebin pad`连接到`self.audioQueue`上的兼容pad。同样，当`caps`表明它是视频数据时，在`self.videoQueue`和`self.decodebin`之间创建一个链接。
- en: 'You can work through the remaining code in the file `SeparatingAudio.py`. Replace
    the paths represented by `self.inFileLocation, self.audioOutLocation`, and `self.videoOutLocation`
    with appropriate paths on your computer and then run this utility as:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以处理文件`SeparatingAudio.py`中剩余的代码。将`self.inFileLocation`、`self.audioOutLocation`和`self.videoOutLocation`表示的路径替换为您计算机上的适当路径，然后以以下方式运行此实用程序：
- en: '[PRE23]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This should create two output files a file in MP3 format that contains only
    the audio track from the input file and a file in MP4 format containing the video
    track.
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会创建两个输出文件，一个包含输入文件中仅有的音频轨道的MP3格式的文件，另一个包含视频轨道的MP4格式的文件。
- en: What just happened?
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We build a GStreamer pipeline that separates audio and video tracks from an
    input video file. Several of the GStreamer elements that we learned about in a
    number of examples earlier were used to develop this utility. We also learned
    how to use the capabilities (caps) on the dynamic pads of `decodebin` to make
    proper linkage between the `decodebin` and the `queue` elements.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个GStreamer管道，从输入视频文件中分离音频和视频轨道。我们之前在多个示例中学习到的几个GStreamer元素被用于开发此实用程序。我们还学习了如何使用`decodebin`动态pad上的功能（caps）在`decodebin`和`queue`元素之间建立适当的链接。
- en: Mixing audio and video tracks
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合音频和视频轨道
- en: Suppose you have recorded your friend's wedding on your camcorder. For some
    specific moments, you would like to mute all other sounds and replace those with
    background music. To accomplish this, first you need to save the video track without
    the audio as a separate file. We just learned that technique. Then you need to
    combine this video track with audio track containing the background music you
    wish to play. Let's now learn how to mix audio and video tracks into a single
    video file.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你用摄像机记录了你朋友的婚礼。对于一些特定的时刻，你希望静音所有其他声音，并用背景音乐替换它们。为了完成这个任务，首先你需要将视频轨道（不含音频）保存为单独的文件。我们刚刚学习了这项技术。然后你需要将这个视频轨道与包含你希望播放的背景音乐的音频轨道合并。现在让我们学习如何将音频和视频轨道混合成一个单独的视频文件。
- en: Time for action - audio/video track mixer
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 音频/视频轨道混合器
- en: We will develop a program that generates a video output file, by mixing an audio
    and a video track. Think about what change we will need to incorporate when compared
    to the audio/video track separation utility developed earlier. In that application,
    two `filesink` elements were required as two output files were created. Here,
    we need the opposite. We require two `filesrc` elements containing the audio and
    video data and a single `filesink` element that will contain both the audio and
    the video track.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开发一个程序，通过混合音频和视频轨道来生成视频输出文件。思考一下，与之前开发的音频/视频轨道分离实用程序相比，我们需要整合哪些变化。在那个应用程序中，需要两个`filesink`元素，因为创建了两个输出文件。在这里，我们需要相反的。我们需要两个包含音频和视频数据的`filesrc`元素，以及一个包含音频和视频轨道的单个`filesink`元素。
- en: Download the file `AudioVideoMixing.py` from the Packt website. We will review
    some of the important methods of class `AudioVideoMixer`.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Packt网站下载文件`AudioVideoMixing.py`。我们将回顾`AudioVideoMixer`类的一些重要方法。
- en: The `constructPipeline` method, as usual, builds the GStreamer pipeline with
    all necessary elements.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与往常一样，`constructPipeline`方法构建了包含所有必要元素的GStreamer管道。
- en: '[PRE24]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The audio and video file sources are defined by the elements `self.audiosrc`
    and `self.videosrc` respectively. These are connected to two separate `decodebins`
    (see lines 54 and 59). The `pad-added` signals of `self.audio_decodebin` and `self.video_decodebin`
    are connected in the `connectSignals` method.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音频和视频文件源分别由元素`self.audiosrc`和`self.videosrc`定义。它们连接到两个单独的`decodebins`（见第54行和第59行）。`self.audio_decodebin`和`self.video_decodebin`的`pad-added`信号在`connectSignals`方法中连接。
- en: The audio and video data then travels through a chain of audio and video processing
    elements respectively. The data is encoded by their respective encoders. The encoded
    data streams are combined so that the output video file contains both audio and
    video tracks. This job is done by the multiplexer, self.muxer. It is linked with
    the video encoder element. The audio data is streamed to the muxer through a queue
    element (line 57). The data is 'muxed' and fed to the filesink element, self.filesink.
    Note that the ffmpegcolorspace element and the capsfilter, self.capsfiter is not
    really required. In this case, the output video should have proper display format.
    You can try running this application by removing those two elements to see if
    it makes any difference.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 音频和视频数据随后分别通过音频和视频处理元素的链。数据由各自的编码器进行编码。编码后的数据流被合并，使得输出视频文件包含音频和视频轨道。这项工作由多路复用器self.muxer完成。它与视频编码器元素相连接。音频数据通过队列元素（第57行）流到多路复用器。数据被‘多路复用’并输入到filesink元素self.filesink。请注意，ffmpegcolorspace元素和capsfilter，self.capsfiter实际上并不是必需的。在这种情况下，输出视频应该具有正确的显示格式。你可以尝试移除这两个元素来运行此应用程序，看看是否会有任何区别。
- en: In the `decodebin_pad_added` method, we will check a few extra things before
    linking the dynamic pads.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`decodebin_pad_added`方法中，我们在链接动态垫片之前会检查一些额外的事项。
- en: '[PRE25]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: It could happen that each of the input files contains audio as well as video
    data. For example, both self.audiosrc and self.videosrc represent different video
    files with both audio and video data. The file self.audiosrc is linked to self.audio_decodebin.
    Thus, we should make sure that when the self.audio_decodebin generates a pad-added
    signal, the dynamic pad is linked only when its caps have audio data. On similar
    lines, the pad on self.video_decodebin is linked only when caps represent video
    data. This is ensured by the code block 6 13.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能会发生每个输入文件都包含音频和视频数据的情况。例如，self.audiosrc和self.videosrc代表不同的视频文件，这些文件都包含音频和视频数据。self.audiosrc文件连接到self.audio_decodebin。因此，我们应该确保当self.audio_decodebin生成垫片添加信号时，只有当其caps包含音频数据时才将其动态垫片连接。按照类似的方式，只有当caps代表视频数据时，self.video_decodebin上的垫片才被连接。这是通过代码块6
    13确保的。
- en: 'Develop the rest of the code by reviewing file `AudioVideoMixer.py`. Replace
    the paths represented by, `self.audioInLocation, self.videoInLocation`, and `self.outFileLocation`
    with appropriate paths on your computer and then run this utility as:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过审查文件`AudioVideoMixer.py`来开发其余的代码。将表示为`self.audioInLocation`、`self.videoInLocation`和`self.outFileLocation`的路径替换为您的计算机上的适当路径，然后运行此实用程序：
- en: '[PRE26]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This should create an output video file in MP4 format that contains the audio
    and video tracks from the specified input files!
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这应该会创建一个包含指定输入文件中的音频和视频轨道的MP4格式的输出视频文件！
- en: What just happened?
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We developed a tool that mixes input audio and video tracks and stores them
    into a single output file. To accomplish this task we used most of the audio/video
    processing elements that were used in video conversion utility. We learned how
    to link the dynamic pads on `decodebin` based on the streaming data represented
    by its 'caps'. The multiplexer plugin `ffmux_mp4` element was used to put the
    audio and video data together.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个工具，它可以将输入音频和视频轨道混合，并将它们存储到一个单独的输出文件中。为了完成这个任务，我们使用了在视频转换工具中使用的几乎所有音频/视频处理元素。我们学习了如何根据`decodebin`的`caps`表示的流数据链接其动态垫片。使用了多路复用插件`ffmux_mp4`元素来将音频和视频数据组合在一起。
- en: Saving video frames as images
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将视频帧保存为图像
- en: Imagine that you have a wildlife video and it has recorded a very special moment.
    You would like to save this image. Let's learn how this can be achieved using
    the GStreamer framework.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一个野生动物视频，它记录了一个非常特别的时刻。你想要保存这张图片。让我们学习如何使用GStreamer框架实现这一点。
- en: Time for action - saving video frames as images
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行动时间 - 将视频帧保存为图像
- en: 'This file can be run from the command line as:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件可以从命令行运行：
- en: '[PRE27]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here the `[options]` are:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这里`[options]`是：
- en: '`--input_file:` The full path to input video file from which one or more frames
    need to be captured and saved as images.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--input_file:` 需要从其中捕获一个或多个帧并保存为图像的输入视频文件的完整路径。'
- en: '`--start_time:` The position in seconds on the video track. This will be the
    starting position from which one or more video frames will be captured as still
    image(s). The first snapshot will always be at `start_time`.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--start_time:` 视频轨道上的位置（以秒为单位）。这将是捕获一个或多个视频帧作为静态图像的起始位置。第一张快照总是在`start_time`。'
- en: '`--duration:` The duration (in seconds) of the video track starting from the
    `start_time`. ''N'' number of frames will be captured starting from the `start_time`.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--duration:` 从`start_time`开始的视频轨道的持续时间（以秒为单位）。从`start_time`开始将捕获`N`个帧。'
- en: '`--num_of_captures:` Total number of frames that need to be captured from `start_time`
    (including it) up to, `end_time= start_time + duration` (but not including the
    still image at `end_time)`.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_of_captures:` 从`start_time`（包括它）到`end_time= start_time + duration`（但不包括`end_time`处的静态图像）需要捕获的总帧数。'
- en: If not already done, download the file `ImagesFromVideo.py` from the Packt website.
    Following is an outline of the code for saving video frames.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未完成，请从Packt网站下载文件`ImagesFromVideo.py`。以下是保存视频帧的代码概述。
- en: '[PRE28]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The program execution starts by calling the captureImage method. The gnlfilesource
    element discussed in audio processing chapters will be used here to seek a particular
    frame on the streaming video. The capture_single_image does the main job of saving
    a single frame as an image. We will discuss some of these methods next.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序执行从调用`captureImage`方法开始。在音频处理章节中讨论的gnlfilesource元素将在这里用于在流视频上查找特定帧。`capture_single_image`执行将单个帧保存为图像的主要工作。我们将在下面讨论这些方法中的一些。
- en: Let's start with the `constructPipeline` method which defines and links various
    elements needed to capture the video frames.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从`constructPipeline`方法开始，该方法定义并链接了捕获视频帧所需的各种元素。
- en: '[PRE29]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We already know how to create and connect the gnlfilesource element (called
    self.gnlfilesrc). In the examples we have seen so far, the encoder element used
    in a GStreamer pipeline encoded the streaming media data either in an audio or
    a video format. On line 11, we define a new encoder element that enables saving
    a particular frame in the streaming video as an image. In this example, we use
    the encoder ffenc_png to save the video frame as an image file with PNG file format.
    This plugin should be available by default in your GStreamer installation. If
    not, you will need to install it. There are similar plugins available to save
    the image in different file formats. For example, use jpegenc plugin to save it
    as a JPEG image and so on.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经知道如何创建和连接 `gnlfilesource` 元素（称为 `self.gnlfilesrc`）。在迄今为止的示例中，GStreamer 管道中使用的编码器元素将流媒体数据编码为音频或视频格式。在第
    11 行，我们定义了一个新的编码器元素，它允许将流视频中的特定帧保存为图像。在这个例子中，我们使用编码器 `ffenc_png` 将视频帧保存为 PNG 格式的图像文件。此插件应默认在您的
    GStreamer 安装中可用。如果不适用，您将需要安装它。有类似的插件可用于保存不同文件格式的图像。例如，使用 `jpegenc` 插件将其保存为 JPEG
    图像等。
- en: The self.gnlfilesrc uses dynamic pad, which is connected to an appropriate pad
    on ffmpegcolorspace discussed earlier. The self.colorspace element converts the
    color space and this video data is then encoded by the ffenc_png element. The
    self.filesink defines the location to save a particular video frame as an image.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`self.gnlfilesrc` 使用动态垫，该垫连接到之前讨论的 `ffmpegcolorspace` 的适当垫。`self.colorspace`
    元素转换颜色空间，然后此视频数据由 `ffenc_png` 元素编码。`self.filesink` 定义了保存特定视频帧为图像的位置。'
- en: The `captureImage` is the main controlling method. The overall structure is
    very similar to the audio conversion utility developer in [Chapter 5](ch05.html
    "Chapter 5. Working with Audios"), *Working with Audios*. This method runs the
    top-level controlling loop to capture the frames specified as an argument to the
    program.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`captureImage` 是主要的控制方法。整体结构非常类似于第 5 章（[Chapter 5](ch05.html "Chapter 5. Working
    with Audios")）中音频转换实用工具的开发者，*Working with Audios*。此方法运行程序参数指定的顶层控制循环以捕获帧。'
- en: '[PRE30]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The method capture_single_image does the main job of saving each of these frames.
    The self.media_start_time defines the position on the streaming video from which
    this utility should start saving the video frames as images. This is specified
    as a command-line argument to this utility. The media_end variable defines the
    position on the video track at which the program should 'stop' capturing the still
    images (the video frames). The self.media_start_time is when the first video frame
    will be saved as an image. This is the initial value assigned to the local variable
    start, which is then incremented in the loop.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`capture_single_image` 方法负责保存这些帧中的每一个。`self.media_start_time` 定义了从哪个位置开始，这个实用工具应该开始保存视频帧作为图像。这作为命令行参数指定给这个实用工具。`media_end`
    变量定义了视频轨道上程序应该“停止”捕获静态图像（视频帧）的位置。`self.media_start_time` 是第一个视频帧将被保存为图像的时间。这是分配给局部变量
    `start` 的初始值，然后在循环中递增。'
- en: 'The while loop (lines 8-10) calls the capture_single_image method for each
    of the video frames we wish to save as an image. The self.deltaTime variable defines
    the incremental time steps for capturing video frames. Its value is determined
    in the constructor as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当前行号 8-10 的 `while` 循环为我们要保存为图像的每个视频帧调用 `capture_single_image` 方法。`self.deltaTime`
    变量定义了捕获视频帧的增量时间步。其值在构造函数中如下确定：
- en: '[PRE31]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here, self.numberOfCaptures is specified as an argument. If this argument is
    not specified, it will save only a single frame as an image. It is used to increment
    the variable start.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，`self.numberOfCaptures` 被指定为一个参数。如果没有指定此参数，它将只保存一个帧作为图像。它用于递增变量 `start`。
- en: Now, let's see what `ImageCapture.capture_single_image` does. As the name suggests,
    its job is to save a single image corresponding to the video frame at `media_start_time`
    in the streaming video.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `ImageCapture.capture_single_image` 做了什么。正如其名所示，其任务是保存与流视频中 `media_start_time`
    对应的单个图像。
- en: '[PRE32]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The media_duration is set to a very small value (0.01 seconds), just enough
    to play the video frame at media_start_time. The media_start_time and media_duration
    used to set the properties of the gnlfilesource represented by self.gnlfilesrc.
    On line 14, the location of the output image file is specified. Note that the
    filename is appended with a timestamp that represents the time on the timeline
    of the streaming video, at which this snapshot was taken. After setting up the
    necessary parameter, the pipeline is 'started' on line 20 and will be played until
    the EOS message is posted on the bus, that is, when it finishes writing the output
    PNG file.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 媒体持续时间被设置为非常小的值（0.01秒），仅足够在media_start_time处播放视频帧。media_start_time和media_duration用于设置self.gnlfilesrc表示的gnlfilesource的属性。在第14行指定了输出图像文件的位置。请注意，文件名附加了一个时间戳，它代表了在流媒体视频时间线上这个快照被捕获的时间。在设置必要的参数后，在第20行“启动”管道，并将播放直到在总线上发布EOS消息，即完成输出PNG文件的写入。
- en: Review the remaining methods from the file ImagesFromVideo.py and then run this
    utility by specifying appropriate command-line arguments. The following screenshot
    shows sample output messages when the program is run from the console window.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回顾文件ImagesFromVideo.py中剩余的方法，然后通过指定适当的命令行参数运行此实用程序。以下截图显示了从控制台窗口运行程序时的示例输出消息。
- en: '![Time for action - saving video frames as images](img/0165_07_04.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![行动时间 - 将视频帧保存为图像](img/0165_07_04.jpg)'
- en: What just happened?
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 刚才发生了什么？
- en: We developed a very useful application that can save specified frames in a streaming
    video as image files. To accomplish this, we re-used several of the GStreamer
    elements/plugins studied earlier. For example, elements such as `gnlfilesource,
    ffmpegcolorspace`, and so on were used to construct the GStreamer pipeline. Additionally,
    we used an image encoder to save the video data in an image format.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个非常有用的应用程序，可以将流媒体视频中的指定帧保存为图像文件。为了实现这一点，我们重新使用了之前研究过的几个GStreamer元素/插件。例如，使用`gnlfilesource,
    ffmpegcolorspace`等元素来构建GStreamer管道。此外，我们还使用了一个图像编码器将视频数据保存为图像格式。
- en: Summary
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We learned fundamentals of GStreamer API in previous chapters on audio processing.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的音频处理章节中，我们学习了GStreamer API的基础知识。
- en: In this chapter we moved one step further to develop some useful video processing
    utilities using Python and GStreamer. To accomplish this task, we learned about
    several new GStreamer plugins required for processing videos.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们进一步开发了一些有用的视频处理实用程序，使用Python和GStreamer。为了完成这个任务，我们学习了几个新的GStreamer插件，这些插件是处理视频所必需的。
- en: 'Specifically, we covered:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们涵盖了：
- en: 'Pipeline that handles audio and video: We learned how to build a GStreamer
    pipeline that can handle both audio and video tracks from the input video file.
    This was used to ''play'' a video file and it was also the basic pipeline used
    in several video-processing tools developed in this chapter.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理音频和视频的管道：我们学习了如何构建一个GStreamer管道，它可以处理输入视频文件中的音频和视频轨道。这被用来“播放”视频文件，也是本章中开发的一些视频处理工具的基本管道。
- en: 'Separating audio/video: With the help of example, we learned how to save an
    audio/video track of a video file into two different files.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分离音频/视频：通过示例，我们学习了如何将视频文件的音频/视频轨道保存到两个不同的文件中。
- en: 'Mixing audio/video: We wrote a program that can mix an audio and video stream
    into a single video file.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频/视频混合：我们编写了一个程序，可以将音频和视频流混合到一个单独的视频文件中。
- en: 'Video effects: How to adjust the properties such as brightness, contrast, and
    saturation for a streaming video.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频效果：如何调整流媒体视频的亮度、对比度和饱和度等属性。
- en: 'Text overlay: We developed a utility that can add text, timestamp, and clock
    strings on the streaming video.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本叠加：我们开发了一个实用程序，可以在流媒体视频上添加文本、时间戳和时钟字符串。
- en: 'Still images from video: We learned how to save a video frame of a streaming
    video as an image.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频中的静态图像：我们学习了如何将流媒体视频的帧保存为图像。
- en: This concludes our discussion on video processing using Python and GStreamer.
    For the audio as well as video processing, we mostly developed various command-line
    tools. It gave us a good understanding of the use of the underlying components
    of a multimedia framework. There was no user interface component involved in our
    discussion. The default GUI appeared only while playing a video.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们关于使用Python和GStreamer进行视频处理的讨论。对于音频和视频处理，我们主要开发了各种命令行工具。这让我们对多媒体框架底层组件的使用有了很好的理解。在我们的讨论中没有涉及用户界面组件。默认的GUI只会在播放视频时出现。
- en: The focus of the next chapter will be on GUI-based audio and video applications.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章的重点将集中在基于图形用户界面的音频和视频应用上。
