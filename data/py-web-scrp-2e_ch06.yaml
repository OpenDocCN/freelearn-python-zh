- en: Interacting with Forms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与表单交互
- en: 'In earlier chapters, we downloaded static web pages that return the same content.
    In this chapter, we will interact with web pages which depend on user input and
    state to return relevant content. This chapter will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们下载了返回相同内容的静态网页。在本章中，我们将与依赖于用户输入和状态的网页进行交互，以返回相关内容。本章将涵盖以下主题：
- en: Sending a `POST` request to submit a form
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送 `POST` 请求提交表单
- en: Using cookies and sessions to log in to a website
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 cookies 和 sessions 登录网站
- en: Using Selenium for form submissions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Selenium 进行表单提交
- en: To interact with these forms, you'll need a user account to log in to the website.
    You can register an account manually at [http://example.webscraping.com/user/register](http://example.webscraping.com/user/register).
    Unfortunately, we can't yet automate the registration form until the next chapter,
    which deals with `CAPTCHA` images.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要与这些表单交互，你需要一个用户账户来登录网站。你可以在 [http://example.webscraping.com/user/register](http://example.webscraping.com/user/register)
    手动注册账户。不幸的是，我们目前还不能自动化注册表单，直到下一章，那时我们将讨论 `CAPTCHA` 图像。
- en: Form methods
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 表单方法
- en: HTML forms define two methods for submitting data to the server-`GET` and `POST`.
    With the `GET` method, data such as `?name1=value1&name2=value2` is appended to
    the URL, which is known as a "query string". The browser sets a limit on the URL
    length, so this is only useful for small amounts of data. Additionally, this method
    is generally intended to only retrieve data from the server and not make changes
    to it, but sometimes this intention is ignored. With `POST` requests, the data
    is sent in the request body, not the URL. Sensitive data should only be sent in
    a `POST` request to avoid exposing it in the URL. How the `POST` data is represented
    in the body depends on the encoding type.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: HTML 表单定义了两种将数据提交给服务器的方法 - `GET` 和 `POST`。使用 `GET` 方法时，数据如 `?name1=value1&name2=value2`
    将附加到 URL 上，这被称为“查询字符串”。浏览器对 URL 长度设置了一个限制，因此这仅适用于少量数据。此外，这种方法通常仅用于从服务器检索数据，而不是对其进行更改，但有时这种意图会被忽略。使用
    `POST` 请求时，数据在请求体中发送，而不是 URL。敏感数据应仅通过 `POST` 请求发送，以避免在 URL 中暴露。`POST` 数据在体中的表示方式取决于编码类型。
- en: Servers can also support other HTTP methods, such as `PUT` and `DELETE`, however,
    these are not supported in standard HTML forms.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器也可以支持其他 HTTP 方法，例如 `PUT` 和 `DELETE`，然而，这些方法在标准 HTML 表单中并不被支持。
- en: The Login form
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 登录表单
- en: 'The first form we''ll automate is the Login form, which is available at [http://example.webscraping.com/user/login](http://example.webscraping.com/user/login).
    To understand the form, we can use our browser development tools. With the full
    version of Firebug or Chrome Developer Tools, it is possible to simply submit
    the form and check what data was transmitted in the Network tab (similar to how
    we did in [Chapter 5](py-web-scrp-2e_ch05.html), *Dynamic Content*). However,
    we can also see information about the form if we use "Inspect Element" features:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将自动化的第一个表单是登录表单，它位于 [http://example.webscraping.com/user/login](http://example.webscraping.com/user/login)。为了理解表单，我们可以使用我们的浏览器开发工具。使用
    Firebug 或 Chrome 开发者工具的完整版本，我们可以简单地提交表单并检查在“网络”标签中传输了哪些数据（类似于我们在第 5 章 [Dynamic
    Content](py-web-scrp-2e_ch05.html) 中所做的那样）。然而，如果我们使用“检查元素”功能，我们还可以看到有关表单的信息：
- en: '![](img/post_image.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/post_image.png)'
- en: The important parts regarding how to send the form are the `action`, `enctype`,
    and `method` attributes of the `form` tag, and the two `input` fields (in the
    above image we have expanded the "password" field). The `action` attribute sets
    the HTTP location where the form data will be submitted, in this case, `#`, which
    represents the current URL. The `enctype` attribute (or encoding type) sets the
    encoding used for the submitted data, in this case, `application/x-www-form-urlencoded`.
    The `method` attribute is set to `post` to submit form data with a `POST` method in
    the message body to the server. For each `input` tags, the important attribute
    is `name`, which sets the name of the field when the `POST` data is submitted
    to the server.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何发送表单的重要部分是 `form` 标签的 `action`、`enctype` 和 `method` 属性，以及两个 `input` 字段（在上面的图像中我们扩展了“密码”字段）。`action`
    属性设置表单数据将被提交的 HTTP 位置，在这种情况下，`#` 代表当前 URL。`enctype` 属性（或编码类型）设置提交数据使用的编码，在这种情况下，`application/x-www-form-urlencoded`。`method`
    属性设置为 `post`，以便将表单数据以 `POST` 方法提交到服务器。对于每个 `input` 标签，重要的属性是 `name`，它设置当 `POST`
    数据提交到服务器时字段的名称。
- en: Form encoding
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 表单编码
- en: When a form uses the `POST` method, there are two useful choices for how the
    form data is encoded before being submitted to the server. The default is `application/x-www-form-urlencoded`,
    which specifies all non-alphanumeric characters must be converted to ASCII Hex
    values. However, this is inefficient for forms which contain a large amount of
    non-alphanumeric data, such as a binary file upload, so `multipart/form-data`
    encoding was defined. Here, the input is not encoded but sent as multiple parts
    using the MIME protocol, which is the same standard used for e-mail.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个表单使用 `POST` 方法时，在将表单数据提交到服务器之前，有两种有用的选择来编码表单数据。默认是 `application/x-www-form-urlencoded`，它指定所有非字母数字字符必须转换为ASCII十六进制值。然而，对于包含大量非字母数字数据的表单，例如二进制文件上传，这并不高效，因此定义了
    `multipart/form-data` 编码。在这里，输入不进行编码，而是使用MIME协议作为多个部分发送，这与电子邮件使用的标准相同。
- en: The official details of this standard can be viewed at [http://www.w3.org/TR/html5/forms.html](http://www.w3.org/TR/html5/forms.html)#selecting-a-form-submission-encoding.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[http://www.w3.org/TR/html5/forms.html](http://www.w3.org/TR/html5/forms.html)#selecting-a-form-submission-encoding)查看此标准的官方详情。
- en: 'When regular users open this web page in their browser, they will enter their
    e-mail and password, and click on the Login button to submit their details to
    the server. Then, if the login process on the server is successful, they will
    be redirected to the home page; otherwise, they will return to the Login page
    to try again. Here is an initial attempt to automate this process:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当普通用户在他们的浏览器中打开这个网页时，他们会输入他们的电子邮件和密码，然后点击登录按钮将他们的详细信息提交到服务器。然后，如果服务器上的登录过程成功，他们将被重定向到主页；否则，他们将被返回到登录页面再次尝试。以下是自动化此过程的初步尝试：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This example sets the e-mail and password fields, encodes them with `urlencode`,
    and submits them to the server. When the final print statement is executed, it
    will output the URL of the Login page, which means the login process has failed.
    You will notice we must also encode the already encoded data as bytes so `urllib`
    will accept it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例设置了电子邮件和密码字段，使用 `urlencode` 对其进行编码，并将它们提交到服务器。当执行最后的打印语句时，它将输出登录页面的URL，这意味着登录过程失败了。你会注意到我们必须也将已编码的数据作为字节进行编码，这样
    `urllib` 才能接受它。
- en: 'We can write the same process using `requests` in fewer lines:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `requests` 在更少的行中编写相同的流程：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `requests` library allows us to explicitly post data, and will do the encoding
    internally. Unfortunately, this code still fails to log in.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests` 库允许我们明确地提交数据，并且会内部进行编码。不幸的是，这段代码仍然无法登录。'
- en: 'The Login form is particularly strict and requires some additional fields to
    be submitted along with the e-mail and password. These additional fields can be
    found at the bottom of the previous screenshot, but are set to `hidden` and so
    they aren''t displayed in the browser. To access these hidden fields, here is
    a function using the `lxml` library covered in Chapter 2, *Scraping the Data*,
    to extract all the `input` tag details in a form:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 登录表单特别严格，需要提交一些额外的字段，这些字段与电子邮件和密码一起提交。这些额外的字段可以在上一张截图的底部找到，但它们被设置为 `hidden`，因此它们在浏览器中不会显示。要访问这些隐藏字段，这里有一个使用第2章中介绍的
    `lxml` 库的函数来提取表单中所有 `input` 标签的详细信息：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The function in the preceding code uses `lxml` CSS selectors to iterate over
    all `input` tags in a form and return their `name` and `value` attributes in a
    dictionary. Here is the result when the code is run on the Login page:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码中的函数使用 `lxml` CSS选择器遍历表单中的所有 `input` 标签，并返回它们的 `name` 和 `value` 属性的字典。以下是代码在登录页面上运行的结果：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `_formkey` attribute is the crucial piece; it contains a unique ID used
    by the server to prevent multiple form submissions. Each time the web page is
    loaded, a different ID is used, and the server can tell whether a form with a
    given ID has already been submitted. Here is an updated version of the login process which submits
    `_formkey` and other hidden values:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`_formkey` 属性是关键部分；它包含服务器用于防止多次表单提交的唯一ID。每次网页加载时，都会使用不同的ID，服务器可以判断具有给定ID的表单是否已经被提交。以下是提交
    `_formkey` 和其他隐藏值的登录过程的更新版本：'
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Unfortunately, this version doesn''t work either, because the login URL was
    again returned. We are missing another essential component--browser cookies. When
    a regular user loads the Login form, this `_formkey` value is stored in a cookie,
    which is compared to the `_formkey` value in the submitted Login form data. We
    can take a look at the cookies and their values via our `response` object:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这个版本也不起作用，因为登录 URL 再次返回。我们缺少另一个基本组件——浏览器 Cookie。当普通用户加载登录表单时，这个 `_formkey`
    值会被存储在一个 Cookie 中，并与提交的登录表单数据中的 `_formkey` 值进行比较。我们可以通过我们的 `response` 对象查看 Cookie
    和它们的值：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can also see via your Python interpreter that the `response.cookies` is
    a special object type, called a cookie jar. This object can also be passed to
    new requests. Let''s retry our submission with cookies:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过 Python 解释器看到 `response.cookies` 是一种特殊对象类型，称为 Cookie jar。此对象还可以传递给新的请求。让我们带
    Cookie 重新尝试我们的提交：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: What are cookies?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是 Cookie？
- en: 'Cookies are small amounts of data sent by a website in the HTTP `response`
    headers, which look like this: `Set-Cookie: session_id=example`;. The web browser
    will store them, and then include them in the headers of subsequent requests to
    that website. This allows a website to identify and track users.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'Cookie 是由网站在 HTTP `response` 头部发送的小量数据，其格式如下：`Set-Cookie: session_id=example`;。网络浏览器会将它们存储起来，并在随后的请求中包含在网站的头信息中。这允许网站识别和跟踪用户。'
- en: Success! The submitted form values have been accepted and the `response` URL
    is the home page. Note that we needed to use the cookies which properly align
    with our form data from our initial request (which we have stored in the `html`
    variable). This snippet and the other login examples in this chapter are available
    for download at [https://github.com/kjam/wswp/tree/master/code/chp6](https://github.com/kjam/wswp/tree/master/code/chp6).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 成功！提交的表单值已被接受，`response` URL 是主页。请注意，我们需要使用与我们的初始请求（我们已将其存储在 `html` 变量中）正确匹配的
    Cookie。这个片段和本章中的其他登录示例可在 [https://github.com/kjam/wswp/tree/master/code/chp6](https://github.com/kjam/wswp/tree/master/code/chp6)
    下载。
- en: Loading cookies from the web browser
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从网络浏览器加载 Cookie
- en: Working out how to submit the login details expected by a server can be quite
    complex, as demonstrated by the previous example. Fortunately, there's a workaround
    for difficult websites--we can log in to the website manually using a web browser,
    and have our Python script load and reuse the cookies to be automatically logged
    in.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 确定服务器期望提交的登录细节可能相当复杂，如前例所示。幸运的是，对于难以访问的网站有一个解决方案——我们可以使用网络浏览器手动登录网站，并让我们的 Python
    脚本加载和重用 Cookie 以自动登录。
- en: Some web browsers store their cookies in different formats, but Firefox and
    Chrome use an easy-to-access format we can parse with Python: a `sqlite` database.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网络浏览器以不同的格式存储他们的 Cookie，但 Firefox 和 Chrome 使用一种易于访问的格式，我们可以用 Python 解析：一个
    `sqlite` 数据库。
- en: '[SQLite](https://www.sqlite.org/) is a very popular open-source SQL database.
    It can be easily installed on many platforms and comes pre-installed on Mac OSX.
    To download and install it on your operating system, check [the Download page](https://www.sqlite.org/download.html)
    or simply search for your operating system instructions.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[SQLite](https://www.sqlite.org/) 是一个非常流行的开源 SQL 数据库。它可以在许多平台上轻松安装，并且预装在 Mac
    OSX 上。要下载并安装到您的操作系统上，请查看 [下载页面](https://www.sqlite.org/download.html) 或直接搜索您操作系统的安装说明。'
- en: 'To take a look at your cookies, you can (if installed) run the `sqlite3` command
    and then the path to your cookie file (shown below is an example for Chrome):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看您的 Cookie，您可以通过运行 `sqlite3` 命令并指定您的 Cookie 文件路径（下面是一个 Chrome 的示例）来查看：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You will need to first find the path to your browser's configuration files which
    can either be done by searching your filesystem or simply searching the web for
    your browser and operating system. To see table schema in SQLite, you can use
    `.schema` and select syntax functions similarly to other SQL databases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要首先找到浏览器配置文件的路径，这可以通过在文件系统中搜索或简单地在网上搜索您的浏览器和操作系统来完成。要在 SQLite 中查看表架构，您可以使用
    `.schema` 并选择语法，类似于其他 SQL 数据库。
- en: 'In addition to storing cookies in a `sqlite` database, some browsers (such
    as Firefox) store sessions directly in a JSON file, which can be easily parsed
    using Python. There are also numerous browser extensions, such as SessionBuddy
    which can export your sessions into JSON files. For the login, we only need to
    find the proper sessions, which are stored in this structure:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在`sqlite`数据库中存储cookies外，一些浏览器（如Firefox）将会话直接存储在JSON文件中，这可以使用Python轻松解析。还有许多浏览器扩展，如SessionBuddy，可以将你的会话导出为JSON文件。对于登录，我们只需要找到适当的会话，这些会话存储在这个结构中：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here is a function that can be used to parse Firefox sessions into a Python
    dictionary, which we can then feed to the `requests` library:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个函数，可以将Firefox会话解析成Python字典，然后我们可以将其输入到`requests`库中：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'One complexity is that the location of the Firefox sessions file will vary,
    depending on the operating system. On Linux, it should be located at this path:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个复杂性是Firefox会话文件的存储位置会根据操作系统而变化。在Linux中，它应该位于此路径：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In OS X, it should be located at:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在OS X中，它应该位于：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Also, for Windows Vista and above, it should be located at:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于Windows Vista及以上版本，它应该位于：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is a helper function to return the path to the session file:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个辅助函数，用于返回会话文件的路径：
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Note that the `glob` module used here will return all matching files for the
    given path. Now here is an updated snippet using the browser cookies to log in:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里使用的`glob`模块将返回给定路径的所有匹配文件。现在这里有一个使用浏览器cookies登录的更新片段：
- en: '[PRE14]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To check whether the session was loaded successfully, we cannot rely on the
    login redirect this time. Instead, we will scrape the resulting HTML to check
    whether the logged in user label exists. If the result here is `Login`, the sessions
    have failed to load correctly. If this is the case, make sure you are already
    logged in to the example website using your Firefox browser. We can inspect the `User`
    label for the site using our browser tools:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查会话是否成功加载，这次我们不能依赖于登录重定向。相反，我们将抓取生成的HTML以检查登录用户标签是否存在。如果这里的结果是`Login`，则表示会话未能正确加载。如果是这种情况，请确保您已经使用Firefox浏览器登录到示例网站。我们可以使用浏览器工具检查网站的`User`标签：
- en: '![](img/user_nav.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/user_nav.png)'
- en: 'The browser tools show this label is located within a `<ul>` tag of ID "navbar",
    which can easily be extracted with the `lxml` library used in [Chapter 2](py-web-scrp-2e_ch02.html),
    *Scraping the Data*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览器工具显示此标签位于ID为"navbar"的`<ul>`标签内，这可以使用[第2章](py-web-scrp-2e_ch02.html)中使用的`lxml`库轻松提取，*抓取数据*：
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The code in this section was quite complex and only supports loading sessions
    from the Firefox browser. There are numerous browser add-ons and extensions that
    support saving your sessions in JSON files, so you can explore these as an option
    if you need session data for login.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码相当复杂，仅支持从Firefox浏览器加载会话。有许多浏览器插件和扩展支持将你的会话保存到JSON文件中，因此如果你需要登录的会话数据，你可以将这些作为选项进行探索。
- en: In the next section, we will take a look at the `requests` library advanced
    usage for sessions [http://docs.python-requests.org/en/master/user/advanced/#session-objects](http://docs.python-requests.org/en/master/user/advanced/#session-objects),
    which allows you utilize browser sessions easily when scraping with Python.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨`requests`库的高级会话用法[http://docs.python-requests.org/en/master/user/advanced/#session-objects](http://docs.python-requests.org/en/master/user/advanced/#session-objects)，这允许你在使用Python抓取时轻松利用浏览器会话。
- en: Extending the login script to update content
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将登录脚本扩展以更新内容
- en: Now that we can login via a script, we can extend this script by adding code
    to update the website country data. The code used in this section is available
    at [https://github.com/kjam/wswp/blob/master/code/chp6/edit.py](https://github.com/kjam/wswp/blob/master/code/chp6/edit.py)
    and [https://github.com/kjam/wswp/blob/master/code/chp6/login.py](https://github.com/kjam/wswp/blob/master/code/chp6/login.py).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过脚本登录，我们可以通过添加代码来扩展此脚本，以更新网站国家数据。本节中使用的代码可在[https://github.com/kjam/wswp/blob/master/code/chp6/edit.py](https://github.com/kjam/wswp/blob/master/code/chp6/edit.py)和[https://github.com/kjam/wswp/blob/master/code/chp6/login.py](https://github.com/kjam/wswp/blob/master/code/chp6/login.py)找到。
- en: 'You may have already noticed an Edit link at the bottom of each country:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到了每个国家底部的编辑链接：
- en: '![](img/4364OS_06_03.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4364OS_06_03.png)'
- en: 'When logged in, clicking this link leads to another page where each property
    of a country can be edited:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，点击此链接将跳转到另一个页面，在该页面中可以编辑每个国家的属性：
- en: '![](img/4364OS_06_04.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4364OS_06_04.png)'
- en: 'We will make a script to increase the population of a country by one person
    every time it''s run. The first step is to rewrite our `login` function to utilize
    `Session` objects. This will make our code cleaner and allow us to remain logged
    into our current session. The new code is as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写一个脚本，每次运行时都会使一个国家的人口增加一个人。第一步是重写我们的`login`函数以利用`Session`对象。这将使我们的代码更简洁，并允许我们保持当前会话的登录状态。新的代码如下：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now our login form can work with or without sessions. By default, it doesn''t
    use sessions and expects the user to utilize the cookies to stay logged in. This
    can be problematic for some forms, however, so adding the session functionality
    is useful when extending our login function. Next, we need to extract the current
    values of the country by reusing the `parse_form()` function:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在登录表单可以与或不与会话一起工作。默认情况下，它不使用会话，并期望用户使用cookie保持登录状态。然而，对于某些表单来说，这可能是个问题，因此当扩展我们的登录功能时，添加会话功能是有用的。接下来，我们需要通过重用`parse_form()`函数来提取国家的当前值：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now we can increase the population by one and submit the updated version to
    the server:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以增加人口数量一个单位，并将更新后的版本提交到服务器：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When we return to the country page, we can verify that the population has increased
    to 62,348,449:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们返回到国家页面时，我们可以验证人口是否已增加到62,348,449：
- en: '![](img/population_increase.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![人口增加](img/population_increase.png)'
- en: Feel free to test and modify the other fields as well--the database is restored
    to the original country data each hour to keep the data sane.  There is code for
    modifying the currency field in [the edit script](https://github.com/kjam/wswp/blob/master/code/chp6/edit.py)
    to use as another example. You can also play around with modifying other countries.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 随意测试和修改其他字段也可以——数据库每小时都会恢复到原始的国家数据，以保持数据的合理性。在[编辑脚本](https://github.com/kjam/wswp/blob/master/code/chp6/edit.py)中有修改货币字段的代码，可以作为另一个示例。你还可以尝试修改其他国家的数据。
- en: Note that the example covered here is not strictly web scraping, but falls under
    the wider scope of online bots. The form techniques we used can also be applied
    to interacting with complex forms to access data you want to scrape. Make sure
    you use your new automated form powers for good and not for spam or malicious
    content bots!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里讨论的示例并不严格属于网络爬虫，而是属于更广泛的在线机器人范畴。我们使用的表单技术也可以应用于与复杂表单交互以访问你想要抓取的数据。确保你使用你新的自动化表单能力来做好事，而不是用于垃圾邮件或恶意内容机器人！
- en: Automating forms with Selenium
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Selenium自动化表单
- en: The examples built so far work, but each form requires a fair amount of work
    and testing. This effort can be minimized by using Selenium as we did in [Chapter
    5](py-web-scrp-2e_ch05.html), *Dynamic Content*. Because it is a browser-based
    solution, Selenium can mock many user interactions including clicks, scrolling
    and typing. If you are using it with a headless browser like PhantomJS, you will
    also be able to parallelize and scale your processes because it has less overhead
    than running a full browser.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止构建的示例是有效的，但每个表单都需要相当多的工作和测试。通过使用我们在第5章中使用的Selenium，我们可以最小化这种努力，*动态内容*。因为它是一个基于浏览器的解决方案，Selenium可以模拟许多用户交互，包括点击、滚动和输入。如果你使用像PhantomJS这样的无头浏览器，你还将能够并行化和扩展你的进程，因为它比运行完整浏览器有更少的开销。
- en: Using a complete browser can also be a good solution for "humanizing" your interactions,
    particularly if you are using a well-known browser or other browser-like headers
    which can set you apart from other more robot-like identifiers.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用完整的浏览器也可以是“人性化”你交互的一个好方法，尤其是如果你使用的是知名浏览器或其他类似浏览器的头部，这可以使你与其他更像机器人的标识符区分开来。
- en: Rewriting our login and editing scripts to use Selenium is fairly straightforward,
    but we must first investigate the page to pick out the CSS or XPath identifiers
    to use. Doing so with our browser tools, we notice the login form has easy-to-identify
    CSS IDs for the login form and the country edit form. Now we can rewrite the login
    and edit using Selenium.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的登录和编辑脚本重写为使用Selenium相对简单，但我们必须首先调查页面以挑选出要使用的CSS或XPath标识符。使用我们的浏览器工具进行操作时，我们注意到登录表单有易于识别的CSS
    ID用于登录表单和国家编辑表单。现在我们可以使用Selenium重写登录和编辑。
- en: 'First, let''s write a few methods for getting a driver and logging in:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们编写一些获取驱动器和登录的方法：
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here the `get_driver` function first attemps to get a PhantomJS driver, since
    it is faster and easier to install on servers. If that fails, we use Firefox.
    The `login` function uses a `driver` object passed as the argument, and uses the
    browser driver to login by first loading the page, then using the driver's `send_keys`
    method to type into the identified input elements. The `Keys.RETURN` sends the
    signal for a Return key, which on many forms will be mapped to submit the form.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`get_driver` 函数首先尝试获取一个 PhantomJS 驱动程序，因为它在服务器上更快且更容易安装。如果失败，我们使用 Firefox。`login`
    函数使用作为参数传递的 `driver` 对象，并使用浏览器驱动程序通过首先加载页面，然后使用驱动程序的 `send_keys` 方法在已识别的输入元素中输入来登录。`Keys.RETURN`
    发送 Return 键的信号，在许多表单中这将映射为提交表单。
- en: We are also utilizing the Selenium explicit waits (`WebDriverWait` and `EC`
    for ExpectedConditions), which allow us to tell the browser to wait until a particular
    element or condition is met. In this case, we know that the homepage when logged
    in shows an element with the CSS ID `"results"`. The `WebDriverWait` object will
    wait 10 seconds for the element to load before raising an Exception. We can easily
    toggle this wait, or use other expected conditions to match how the page we are
    currently loading behaves.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在使用 Selenium 显式等待（`WebDriverWait` 和 `EC` for ExpectedConditions），这允许我们告诉浏览器等待直到特定的元素或条件满足。在这种情况下，我们知道登录后的主页显示一个具有
    CSS ID `"results"` 的元素。`WebDriverWait` 对象将在元素加载前等待 10 秒，然后抛出异常。我们可以轻松地切换这个等待，或使用其他预期条件来匹配我们正在加载的页面的行为。
- en: To read more about Selenium explicit waits, I recommend looking at the Python
    bindings documentation: [http://selenium-python.readthedocs.io/waits.html](http://selenium-python.readthedocs.io/waits.html).
    Explicit waits are preferred to implicit waits as you are telling Selenium exactly
    what to wait for and can ensure the part of the page you want to interact with
    has been loaded.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 Selenium 显式等待的信息，我建议查看 Python 绑定文档：[http://selenium-python.readthedocs.io/waits.html](http://selenium-python.readthedocs.io/waits.html)。显式等待比隐式等待更受欢迎，因为您正在告诉
    Selenium 精确等待什么，并可以确保您想要与之交互的页面部分已经加载。
- en: 'Now that we can get a webdriver and login to the site, we want to interact
    with the form and change the population:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够获取 webdriver 并登录到网站，我们想要与表单交互并更改人口：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The only new Selenium feature used is the `clear` method to clear the input
    value for the form (rather than appending it to the end of the field). We also
    use the element's `get_attribute` method to retrieve particular attributes from
    a HTML elements on the page. Because we are dealing with HTML `input` elements,
    we need to grab the `value` attribute, rather than checking the text attribute.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们唯一使用的新 Selenium 功能是 `clear` 方法来清除表单的输入值（而不是将其附加到字段的末尾）。我们还使用元素的 `get_attribute`
    方法从页面上的 HTML 元素中检索特定属性。因为我们正在处理 HTML `input` 元素，我们需要获取 `value` 属性，而不是检查文本属性。
- en: 'Now we have all of our methods for using Selenium to add one to the population,
    so we can run this script like so:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了使用 Selenium 为人口添加一个的所有方法，因此我们可以这样运行这个脚本：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Since our `assert` statement passed, we know we have updated the population
    using this simple script.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的 `assert` 语句通过了，我们知道我们已经使用这个简单的脚本更新了人口。
- en: There are many more ways to use Selenium to interact with forms, and I encourage
    you to experiment further by reading the documentation. Selenium can be especially
    helpful for debugging problematic websites because of the ability to use `save_screenshot`
    to see what the browser has loaded.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以使用 Selenium 与表单进行交互，我鼓励您通过阅读文档进一步实验。由于可以使用 `save_screenshot` 来查看浏览器加载的内容，Selenium
    在调试有问题的网站时特别有帮助。
- en: '"Humanizing" methods for Web Scraping'
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '"使网络爬取人性化"的方法'
- en: There are sites which detect web scrapers via particular behaviors. In [Chapter
    5](py-web-scrp-2e_ch05.html), *Dynamic Content*, we covered how to avoid honeypots
    by avoiding clicking on hidden links. Here are a few other tips for appearing
    more like a human while scraping content online.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有些网站通过特定的行为检测网络爬虫。在 [第 5 章](py-web-scrp-2e_ch05.html) “动态内容”中，我们介绍了如何通过避免点击隐藏链接来避免蜜罐。这里有一些在在线抓取内容时看起来更像人类的其他技巧。
- en: '**Utilize Headers**: Most of the scraping libraries we have covered can alter
    the headers of your requests, allowing you to modify things like `User-Agent`, `Referrer`, `Host`,
    and `Connection`. Also, when utilizing browser-based scrapers like Selenium, your
    scraper will look like a normal browser with normal headers. You can always take
    a look at what headers your browser is using by opening your browser tools and
    viewing one of the recent requests in the Network tab. This might give you a good
    idea of what headers the site is expecting.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用头部信息**：我们介绍的大多数爬取库都可以更改请求的头部信息，允许您修改诸如`User-Agent`、`Referrer`、`Host`和`Connection`等设置。此外，当使用基于浏览器的爬虫如Selenium时，您的爬虫将看起来像带有正常头部的正常浏览器。您可以通过打开浏览器工具并查看网络标签中的最近请求之一来查看您的浏览器正在使用哪些头部信息。这可能会给您一个关于网站期望哪些头部信息的良好想法。'
- en: '**Add Delays:** Some scraper detection techniques use timing to determine if
    a form is filled out too quickly or links are clicked too soon after page load.
    To appear more "human-like", add reasonable delays when interacting with forms
    or use `sleep` to add delays between requests. This is also the polite way to
    scrape a site so as to not overload the server.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**添加延迟**：一些爬虫检测技术使用时间来确定表单是否填写得太快，或者链接在页面加载后点击得太早。为了看起来更像“人类”，在与表单交互时添加合理的延迟，或者使用`sleep`在请求之间添加延迟。这也是一种礼貌地爬取网站的方式，以免服务器过载。'
- en: '**Use Sessions and Cookies:** As we have covered in this chapter, using sessions
    and cookies will help your scraper navigate the site easier and allow you to appear
    more like a normal browser. By saving sessions and cookies locally, you can pick
    up sessions where you left off and resume scraping with saved data.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用会话和Cookies**：正如我们在本章中提到的，使用会话和Cookies可以帮助您的爬虫更容易地导航网站，并使您看起来更像一个正常浏览器。通过本地保存会话和Cookies，您可以从中断的地方恢复会话，并使用保存的数据继续爬取。'
- en: Summary
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Interacting with forms is a necessary skill when scraping web pages. This chapter
    covered two approaches: first, analyzing the form to generate the expected `POST`
    request manually and utilizing browser sessions and cookies to stay logged in.
    Then, we were able to replicate those interactions using Selenium. We also covered
    some tips to follow when "humanizing" your scrapers.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与表单交互是爬取网页时的一项必要技能。本章介绍了两种方法：首先，分析表单以手动生成预期的`POST`请求，并利用浏览器会话和Cookies保持登录状态。然后，我们能够使用Selenium复制这些交互。我们还介绍了一些在“人性化”您的爬虫时应该遵循的技巧。
- en: In the following chapter, we will expand our form skillset and learn how to
    submit forms that require passing `CAPTCHA` image solving.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将扩展我们的表单技能集，学习如何提交需要通过`CAPTCHA`图像识别的表单。
