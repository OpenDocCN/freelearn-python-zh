- en: The Serverless Paradigm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器范式
- en: Most probably, if you are reading this book, you have already heard about the
    serverless paradigm and the terms serverless engineering and serverless architecture.
    Nowadays, the way developers deploy applications has changed drastically, especially
    in the domain of data engineering and web development, thanks to **event-based
    architectural designs**, also called **serverless architectures**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，如果你正在阅读这本书，你已经听说过无服务器范式和无服务器工程以及无服务器架构这些术语。如今，开发人员部署应用程序的方式发生了巨大变化，特别是在数据工程和Web开发领域，这要归功于**基于事件的架构设计**，也称为**无服务器架构**。
- en: It is not uncommon to have idle resources and servers in production idle after
    the server workload has finished, or waiting for the next workload to come. This
    introduces a bit of redundancy in the infrastructure. What if there was no need
    for idle resources lying around when there is no workload? What if resources can
    be created when necessary and be destroyed once the work is done?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，服务器负载完成后可能会有空闲资源和服务器空闲，或者在等待下一个工作负载到来。这在基础设施中引入了一些冗余。如果没有工作负载时不需要空闲资源会怎样？如果资源可以在需要时创建，并在工作完成后被销毁呢？
- en: At the end of this chapter, you will understand how serverless architectures
    and functions as a service work, and how you can build them into your existing
    software infrastructure. You will also learn what microservices are, and decide
    whether microservices or serverless operations are well-suited for your architecture
    or not. You will also learn how to build serverless applications with Python on
    major cloud service providers, such as **Amazon Web Services** (**AWS**) and **Microsoft's
    Azure**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解无服务器架构和函数即服务的工作原理，以及如何将它们构建到您现有的软件基础设施中。您还将了解什么是微服务，并决定微服务或无服务器操作是否适合您的架构。您还将学习如何在主要的云服务提供商（如**亚马逊网络服务**（**AWS**）和**微软的Azure**）上使用Python构建无服务器应用程序。
- en: 'This chapter will cover the following points:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Understanding serverless architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解无服务器架构
- en: Understanding microservices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解微服务
- en: Serverless architectures don't have to be real-time only
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器架构不一定只能是实时的。
- en: Pros and cons of serverless architectures
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器架构的优缺点
- en: Understanding serverless architectures
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解无服务器架构
- en: 'The concept of serverless architectures or serverless engineering revolves
    entirely around understanding the concept of functions as a service. The most
    technical and accurate definition of serverless computing on the internet is as
    follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器架构或无服务器工程的概念完全围绕理解函数即服务的概念。互联网上对无服务器计算的最技术和准确的定义如下：
- en: '"Serverless computing, also known as **function as a service** (**FAAS**),
    is a cloud computing and code execution model in which the cloud provider fully
    manages starting and stopping of a function''s container **platform as a service**
    (**PaaS**)."'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '"无服务器计算，也称为**函数即服务**（**FAAS**），是一种云计算和代码执行模型，其中云提供商完全管理函数容器的启动和停止**平台即服务**（**PaaS**）。"'
- en: 'Now, let''s go into the details of each part of that definition to understand
    the paradigm of serverless computing better. We shall start with the term function
    as a service. It means that every serverless model has a function that is executed
    on the cloud. These functions are nothing but blocks of code, that are executed
    depending on the trigger that is associated with the function. This is a complete
    list of triggers in the AWS Lambda environment:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解该定义的每个部分，以更好地理解无服务器计算的范式。我们将从函数即服务这个术语开始。这意味着每个无服务器模型都有一个在云上执行的函数。这些函数只是一些代码块，根据与函数关联的触发器执行。这是AWS
    Lambda环境中触发器的完整列表：
- en: '![](img/7b29be3e-815c-410f-ae54-59adf322e984.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7b29be3e-815c-410f-ae54-59adf322e984.png)'
- en: 'Now let''s understand what manages the starting and stopping of a function.
    Whenever a function is triggered via one of these available triggers, the cloud
    provider launches a container in which the function executes. Also, after the
    function is successfully executed the function has returned something, or if the
    function has run out of time, the container gets thatched away or destroyed. The
    thatching happens so that the container can be reused in the event of high demand
    and whenever there is very little time between two triggers. Now, we come to the
    next part of the sentence, the function''s container. This means that the functions
    are launched and executed in containers. This is the standard definition of a
    container from Docker, a company that made the concept of containers very popular:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们了解是谁管理函数的启动和停止。每当函数通过其中一个可用的触发器触发时，云提供商会启动一个容器，函数在其中执行。此外，在函数成功执行后，函数已经返回了一些东西，或者函数已经用完了时间，容器就会被销毁。这种销毁是为了在需求高峰时重复使用容器，以及在两个触发器之间的时间很短的情况下。现在，我们来到句子的下一部分，函数的容器。这意味着函数是在容器中启动和执行的。这是Docker的标准容器定义，Docker是一个使容器概念非常流行的公司：
- en: '"A container image is a lightweight, stand-alone, executable package of a piece
    of software that includes everything needed to run it: code, runtime, system tools,
    system libraries, settings."'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '"容器镜像是一个轻量级的、独立的、可执行的软件包，包括运行它所需的一切：代码、运行时、系统工具、系统库、设置。"'
- en: This helps in packaging the code, the runtime environment, and so on of the
    function into a single deployment package for seamless execution. The **deployment
    package** contains the main code file for the function, all the non-standard libraries
    which are required for the function to execute. The creation process of a deployment
    package looks very similar to that of a virtual environment in Python.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于将代码、运行环境等功能打包成一个单一的部署包，以实现无缝执行。**部署包**包含了函数的主要代码文件，以及执行函数所需的所有非标准库。部署包的创建过程看起来非常类似于Python中的虚拟环境。
- en: So, we can clearly make out that there are no servers running round the clock
    in the case of serverless infrastructures. There is a clear benefit for this,
    which includes not having a dedicated Ops team member for monitoring the server
    boxes. So the extra member, if any, can focus on better things, such as software
    research, and so on. Not having servers running through the entire day saves a
    lot of money and resources for the company and/or personally. This benefit can
    be very clearly seen among machine learning and data engineering teams who make
    use of GPU instances for their regular workload. So having on-demand serverless
    GPU instances running, saves a lot of money without the developers or the Ops
    team needing to maintain them around the clock.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以清楚地看出，在无服务器基础架构中没有服务器全天候运行。这有明显的好处，包括不需要专门的运维团队成员来监控服务器。因此，如果有任何额外的成员，可以专注于更好的事情，比如软件研究等。整天不运行服务器可以为公司和/或个人节省大量资金和资源。这一好处在机器学习和数据工程团队中非常明显，他们经常使用GPU实例进行工作。因此，运行按需的无服务器GPU实例可以节省大量资金，而开发人员或运维团队无需全天候维护它们。
- en: Understanding microservices
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解微服务
- en: 'Similar to the concept of serverless, the design strategy, which is the microservice-oriented
    strategy, has also been very popular recently. This architecture design existed
    a long time before the idea of serverless came into existence though. Just as
    we tried to understand the serverless architectures from the technical definition
    on the internet, we shall try to do the same for microservices. The technical
    definition for microservices is:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与无服务器概念类似，面向微服务的设计策略最近也变得非常流行。尽管这种架构设计在无服务器概念出现之前就存在了很长时间。就像我们试图从互联网上的技术定义理解无服务器架构一样，我们也应该尝试对微服务做同样的事情。微服务的技术定义是：
- en: '"Microservices, also known as the **microservice architecture**, is an architectural
    style that structures an application as a collection of loosely coupled services,
    which implement business capabilities."'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “微服务，也称为**微服务架构**，是一种将应用程序构建为一组松散耦合的服务的架构风格，这些服务实现业务功能。”
- en: Planning and designing the architecture in the form of microservices has its
    fair share of positives and negatives, just like serverless architectures. It's
    important to know about both, in order to appreciate and understand when and when
    not to leverage microservices in your existing architecture. Let's look at this
    and understand the positives of having microservice architectures, before moving
    over to the negatives.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以微服务的形式规划和设计架构既有积极的一面，也有消极的一面，就像无服务器架构一样。了解这两者非常重要，以便在现有架构中何时以及何时不应该利用微服务。让我们先看看拥有微服务架构的积极之处，然后再看看消极之处。
- en: Microservices help software teams stay agile, and improve incrementally. In
    simpler terms, as the services are decoupled from each other, it is very easy
    to upgrade and improve a service without causing the other to go down. For example,
    in social network software, if the chat and the feed are both microservices, then
    the feed doesn't have to go down when the software team are trying to upgrade
    or do minor fixes on the chat service. However, in large monolithic systems, it
    is difficult to break things up so easily in the way one can do with microservices.
    So, any fix or upgrade on even a small component of the architecture comes with
    downtime with the fix taking more time than intended.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务有助于软件团队保持敏捷，并逐步改进。简单来说，由于服务之间解耦，很容易升级和改进服务而不会导致其他服务中断。例如，在社交网络软件中，如果聊天和动态都是微服务，那么在软件团队尝试升级或对聊天服务进行小修复时，动态不必中断。然而，在大型单片系统中，很难像微服务那样轻松地分解事物。因此，即使是架构的一个小组件的修复或升级也会带来停机时间，修复所需的时间比预期的更长。
- en: The sheer size of the code base of monolithic architectures itself acts as a
    hindrance progress in the case of any small failures. Microservices, on the other
    hand, greatly help in boosting developer productivity by keeping code bases lean,
    so that they can fix and improve the service with very little or no overhead and
    downtime. Microservices can be much better leveraged via containers, which provide
    effective and complete virtual operating system environments, processes with isolation,
    and dedicated access to underlying hardware resources.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 单片架构的代码库规模本身就是在任何小故障情况下阻碍进展的障碍。另一方面，微服务通过保持代码库精简大大提高了开发人员的生产力，因此他们可以在几乎没有额外开销和停机时间的情况下修复和改进服务。通过容器，微服务可以更好地利用，容器提供有效和完整的虚拟操作系统环境，隔离的进程以及对底层硬件资源的专用访问。
- en: However, microservices come with their own bunch of disadvantages and downsides,
    the major one being having to deal with distributed systems. Now that each service
    is surviving on its own, the architect needs to figure out how each of them interacts
    with the others in order to make a fully functional product. So, proper co-ordination
    between the services and the decisions regarding how services move data between
    them is a very difficult choice that needs to be taken by the architect. Major
    distributed problems such as the *consensus*, the *CAP theorem*, and *maintaining
    the stability of consensus*, and the *connection*, are some issues that the engineer
    needs to handle while architecting for microservices. Ensuring and maintaining
    security is also a major problem in distributed systems and microservices. You
    needs to decide on separate security patterns and layers for each microservice,
    along with the security decisions necessary for the data interaction to happen
    between the services.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，微服务也有其自身的一系列缺点和不利因素，其中最主要的是必须处理分布式系统。现在每个服务都是独立存在的，架构师需要弄清楚它们之间的相互作用，以使产品完全功能。因此，服务之间的适当协调以及关于服务之间如何移动数据的决策是架构师需要做出的非常困难的选择。在为微服务架构设计时，架构师需要处理一些主要的分布式问题，如*共识*、*CAP定理*和*维护共识的稳定性*以及*连接*等问题。确保和维护安全性也是分布式系统和微服务的一个主要问题。您需要为每个微服务决定单独的安全模式和层，以及为服务之间的数据交互所需的安全决策。
- en: Serverless architectures don't have to be real-time only
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器架构不一定只能是实时的
- en: Serverless architectures generally are leveraged as real-time systems as they
    work as a *function as service* which is triggered by a set of available triggers.
    However, this is a very common misconception, as serverless systems can be leveraged
    equally well both as real-time and batch architectures. Knowing how to leverage
    the concept of serverless systems as batch architectures will open up many engineering
    possibilities, as all engineering teams don't necessarily need or have real-time
    systems to operate.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器架构通常被用作实时系统，因为它们作为*函数即服务*，由一组可用的触发器触发。然而，这是一个非常常见的误解，因为无服务器系统既可以作为实时系统，也可以作为批处理架构同样有效。了解如何将无服务器系统的概念作为批处理架构来利用，将为工程团队打开许多工程可能性，因为并非所有工程团队都需要或拥有实时系统来运行。
- en: 'Serverless systems can be batched by leveraging the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用以下方法，无服务器系统可以作为批处理：
- en: The cron facility in triggers
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触发器中的cron功能
- en: The concept of queues
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列的概念
- en: 'Firstly, let''s understand the concept of the **cron facility** in triggers.
    Serverless systems on the cloud have the ability to set up monitoring, which enables
    the trigger to get triggered every few minutes or hours and can be set as a normal
    cron job. This helps in leveraging the concept of serverless as a regular cron
    batch job. In the AWS environment, Lambda can be triggered as a cron via AWS CloudWatch,
    by setting the frequency of the cron by manually entering the time interval as
    the input and also by entering the interval in the cron format:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解触发器中的**cron功能**的概念。云上的无服务器系统具有设置监控的能力，这使得触发器可以每隔几分钟或几小时触发一次，并且可以设置为普通的cron作业。这有助于将无服务器的概念作为常规的cron批处理作业。在AWS环境中，可以通过AWS
    CloudWatch设置Lambda作为cron触发器，通过手动输入时间间隔来设置cron的频率，并且还可以按照cron格式输入间隔：
- en: '![](img/c7243445-2703-477c-b218-d9d702bce746.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7243445-2703-477c-b218-d9d702bce746.png)'
- en: 'One can also leverage the concept of queues when building serverless batch
    architectures. Let''s understand this by setting an example data pipeline. Let''s
    say the system which we intend to build does the following tasks:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建无服务器批处理架构时，也可以利用队列的概念。让我们通过设置一个示例数据管道来理解这一点。假设我们打算构建的系统执行以下任务：
- en: A user or a service sends some data into a database or a much simpler data store,
    such as AWS's S3.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户或服务将一些数据发送到数据库或更简单的数据存储中，例如AWS的S3。
- en: Once there are more than 100 files in my data store, we'll want to do some task.
    Let's say, doing some analytics on them, for example, such as counting the pages.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我的数据存储中有超过100个文件，我们就需要执行一些任务。比如说，对它们进行一些分析，例如计算页面数量。
- en: 'This can be achieved via queues, and this is one of the simpler serverless
    systems we can consider as an example. So, this can be achieved as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过队列实现，这是我们可以考虑的一个更简单的无服务器系统示例。因此，可以按以下方式实现：
- en: The user or the service uploads or sends the data to the data store which we
    have selected.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户或服务将数据上传或发送到我们选择的数据存储中。
- en: A queue is configured for the purpose of this task.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此任务配置了一个队列。
- en: An event can be configured to S3 buckets or data stores so that as soon as data
    enters into the store, a message is sent to the queue which we have configured
    earlier.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以配置事件到S3存储桶或数据存储，以便一旦数据进入存储，就会向我们之前配置的队列发送消息。
- en: Monitoring systems can be set to monitor the queue for the number of messages
    in it. It is advisable to use the monitoring system of the cloud provider you
    are using so that the system stays completely serverless.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以设置监控系统来监视队列中的消息数量。建议使用您正在使用的云提供商的监控系统，以便系统保持完全无服务器。
- en: Alarms can be set to the monitoring systems, configuring a threshold for these
    alarms. For example, the alarm needs to be triggered whenever the number of messages
    in our queue reaches or exceeds 100.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以设置警报到监控系统，为这些警报配置阈值。例如，每当我们的队列中的消息数量达到或超过100时，就需要触发警报。
- en: This alarm can act as a trigger to the Lambda function which does the analytics
    by first receiving messages from the queue and then querying the data store using
    the filename received from the message.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此警报可以作为触发器，触发Lambda函数，该函数首先从队列接收消息，然后使用从消息中接收的文件名查询数据存储。
- en: Once the analytics are completed on the files, the processed files can be pushed
    to another data store for storage.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文件的分析完成后，处理后的文件可以推送到另一个数据存储进行存储。
- en: After the entire task is completed, the container or the server where the Lambda
    function has run will be terminated, thus making this pipeline completely serverless.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在整个任务完成后，运行 Lambda 函数的容器或服务器将被终止，从而使这个流水线完全无服务器。
- en: Pros and cons of serverless
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器的利弊
- en: As we now understand what serverless architectures and pipelines look like,
    how they may be leveraged into existing architectures, and also how microservices
    help keep architectures leaner and boost developer productivity, we shall look
    at the pros and cons of serverless systems in detail, so that software developers
    and architects can make decisions regarding when to leverage the serverless paradigm
    into their existing systems and when not to.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了无服务器架构和流水线的样子，以及它们如何可以整合到现有架构中，以及微服务如何帮助保持架构的精简并提高开发人员的生产力，我们将详细讨论无服务器系统的利弊，以便软件开发人员和架构师可以决定何时将无服务器范例整合到其现有系统中，何时不这样做。
- en: 'The positives of serverless systems are:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器系统的优点包括：
- en: '**Lower infrastructure costs**: By deploying serverless systems, the infrastructure
    costs can be greatly optimized, as there would not be a need for servers to be
    running around the clock every day. As the servers start whenever the function
    is triggered, and stop whenever the function gets executed successfully, the billing
    would only be done for that brief time period when the function was running.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更低的基础设施成本**：通过部署无服务器系统，基础设施成本可以得到极大的优化，因为不需要每天全天候运行服务器。由于服务器仅在触发函数时启动，并在函数成功执行时停止，因此计费仅针对函数运行的短暂时间段。'
- en: '**Less maintenance needed**: By virtue of the preceding reason, there is also
    no need for continuous monitoring and maintenance of servers. As the functions
    and triggers are automated, there is almost zero maintenance required for serverless
    systems.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要更少的维护**：由于前述原因，也不需要对服务器进行持续监控和维护。由于函数和触发器是自动化的，因此无服务器系统几乎不需要维护。'
- en: '**Higher developer productivity**: As the developers don''t need to worry about
    downtime and server maintenance, they can focus and work on better software challenges,
    such as scaling and designing functionalities.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更高的开发人员生产力**：由于开发人员不需要担心停机时间和服务器维护，他们可以专注于解决更好的软件挑战，如扩展和设计功能。'
- en: The remaining part of the book will show you how serverless systems are changing
    the way software is done. So, as this chapter is intended to help architects decide
    whether serverless systems are a good choice for their architecture or not, we
    shall now look at the disadvantages of serverless systems.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的其余部分将向您展示无服务器系统如何改变软件的方式。因此，由于本章旨在帮助架构师决定无服务器系统是否适合其架构，我们现在将看一下无服务器系统的缺点。
- en: 'The disadvantages of serverless systems are:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器系统的缺点包括：
- en: '**Time limit of the function**: The function which is whether executed, be
    it AWS''s Lambda or GCP''s cloud functions, has an upper time limit of 5 minutes.
    This makes execution of heavy computations impossible. However, this can be solved
    by executing a provisioning tool''s playbook in nohup mode. This will be covered
    in detail, later in the chapter. However, making the playbook ready and setting
    up the container and anything else should be completed within the 5 minute time
    limit. The container gets automatically killed when the 5 minute limit is exceeded.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**函数的时间限制**：无论是 AWS 的 Lambda 还是 GCP 的云函数，执行函数都有一个 5 分钟的时间限制。这使得执行繁重的计算变得不可能。然而，这可以通过以
    nohup 模式执行配置工具的 playbook 来解决。这将在本章后面详细介绍。然而，准备好 playbook 并设置容器和其他任何事情应该在 5 分钟的时间限制内完成。当超过
    5 分钟限制时，容器会自动被终止。'
- en: '**No control over the container environment**: The developer has no control
    over the environment of the container that is being created for executing the
    function. The operating system, the filesystem, and so on, are all decided by
    the cloud provider. For example, AWS''s Lambda functions are executed inside containers
    that run the Amazon Linux operating system.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无法控制容器环境**：开发人员无法控制为执行函数而创建的容器的环境。操作系统、文件系统等都由云提供商决定。例如，AWS 的 Lambda 函数在运行
    Amazon Linux 操作系统的容器内执行。'
- en: '**Monitoring containers**: Apart from the basic monitoring capabilities that
    are provided by the cloud provider via their in-house monitoring tools, there
    is no mechanism to do detailed monitoring of the container that is executing the
    serverless function. This becomes even more difficult when scaling up serverless
    systems to accommodate distributed systems.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控容器**：除了云提供商通过其内部监控工具提供的基本监控功能外，没有机制可以对执行无服务器函数的容器进行详细监控。当将无服务器系统扩展到容纳分布式系统时，这变得更加困难。'
- en: '**No control on security**: There is no control on how the security of the
    data flow is ensured, as there is very little control over the container''s environment.
    The container can be run in the VPC and subnets of the developer''s choice, though,
    which helps work around this disadvantage.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性无法控制**：无法控制数据流的安全性如何得到保障，因为对容器环境的控制非常有限。不过，容器可以在开发人员选择的 VPC 和子网中运行，这有助于解决这个缺点。'
- en: However, serverless systems can be scaled up to distributed systems for large-
    scale computations where the developer need not worry about the time limit. As
    already mentioned, this will be discussed in detail in the upcoming chapters.
    However, for insight into an intuition on how one can choose serverless systems
    over monolithic systems for large-scale computations, let us understand some important
    pointers that need to be kept in mind when taking that architectural decision.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，无服务器系统可以扩展到大规模计算的分布式系统，开发人员无需担心时间限制。如前所述，这将在接下来的章节中详细讨论。然而，为了了解如何在进行架构决策时选择无服务器系统而不是单片系统进行大规模计算，让我们了解一些重要的指针。
- en: 'The pointers to be kept in mind when scaling serverless systems to distributed
    systems are:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将无服务器系统扩展到分布式系统时需要牢记的要点包括：
- en: To scale up serverless systems into serverless distributed systems, one must
    understand how the concept of nohup works. It is a **POSIX** command that allows
    programs and processes to run in the background.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要将无服务器系统扩展到无服务器分布式系统，必须了解nohup的概念是如何工作的。这是一个允许程序和进程在后台运行的**POSIX**命令。
- en: Nohup processes should be properly logged, including both the output and the
    error logs. This is the only source of information for your processes.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nohup进程应该被正确记录，包括输出和错误日志。这是您的进程的唯一信息来源。
- en: A provisioning tool, such as **Ansible** or **Chef** or a similar one, needs
    to be leveraged to create a master-workers architecture which has been spawned
    via the playbook running in nohup mode in the container where the serverless function
    is being executed.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要利用诸如**Ansible**或**Chef**之类的配置工具来创建一个主从架构，该架构是通过在无服务器函数执行的容器中以nohup模式运行的playbook生成的。
- en: It is a good practice to ensure that all tasks that are being executed by the
    provisioning tool via the master server are properly monitored and logged, as
    there is no way one can retrieve the logs once the entire setup finishes executing.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保通过主服务器执行的所有任务都得到适当的监控和记录是一个良好的做法，因为一旦整个设置完成执行，就没有办法检索日志。
- en: Proper security needs to be ensured by using a temporary credential facility
    available from the cloud providers.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须通过使用云提供商提供的临时凭证设施来确保适当的安全性。
- en: Proper closure should be ensured for the system. The workers and the master
    should self-terminate immediately after the pipeline of tasks finishes executing.
    This is very important and this is what makes the system serverless.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须确保系统的适当关闭。工作进程和主进程应该在任务流程执行完成后立即自我终止。这非常重要，也是使系统无服务器的关键。
- en: Generally, temporary credentials come with an expiry time, which is 3,600 seconds
    for most environments. So, if the developer is using temporary credentials to
    execute a task which is supposed to take more than the expiry time, then there
    is a danger of the credentials getting expired.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，临时凭证会有一个过期时间，对于大多数环境来说是3,600秒。因此，如果开发人员使用临时凭证来执行一个预计需要超过过期时间的任务，那么凭证可能会过期。
- en: 'Debugging distributed serverless systems is an extremely difficult task for
    the following reasons:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试分布式无服务器系统是一个极其困难的任务，原因如下：
- en: Monitoring and debugging a nohup process is extremely difficult. Whenever you
    want to debug one, you have to either refer to the log file created by the process
    or kill the nohup process by using the process ID, and then manually run the scripts
    for debugging.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和调试一个nohup进程是非常困难的。每当你想要调试一个进程时，你要么参考进程创建的日志文件，要么使用进程ID杀死nohup进程，然后手动运行脚本进行调试。
- en: As the complete list of tasks executes sequentially in the provisioning tool,
    there is a danger that the instances may get terminated because the developer
    has forgotten to kill the nohup process before starting the debugging process.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于在配置工具中完整的任务列表是顺序执行的，存在一个危险，即开发人员在开始调试过程之前忘记杀死nohup进程，从而导致实例可能被终止。
- en: As this is a distributed system, it goes without saying that the architecture
    should be able to self-heal in the case of any failure or a disaster. An example
    scenario can be when one of the workers goes down while performing some operation
    on a bunch of files. The entire bunch of files is now lost, and there is no means
    of recovery.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这是一个分布式系统，可以毫无疑问地说，架构应该能够在发生任何故障或灾难时自我修复。一个例子是当一个工作进程在执行一些操作时崩溃了。整个一堆文件现在丢失了，没有任何恢复的手段。
- en: Another advanced disaster scenario can be when two worker servers go down while
    performing some operations on a bunch of files. In this case, the developer does
    not know which files have been executed successfully and which haven't.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个高级灾难场景可能是当两个工作服务器在执行一些操作时崩溃了。在这种情况下，开发人员不知道哪些文件已成功执行，哪些没有。
- en: It is a good practice to ensure that all the worker instances receive an equal
    amount of the load to execute so that the load across the distributed system stays
    even and time and resources are well optimized.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保所有工作实例都能够平均分配负载以执行，以便分布式系统中的负载保持均匀，时间和资源得到充分优化，这是一个良好的做法。
- en: Summary
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned what serverless architecture is. Most importantly,
    the chapter helps architects decide if serverless is the way forward for their
    team and their engineering, and how to transition/migrate from their existing
    infrastructure to a serverless paradigm. We also looked at the paradigm of microservices
    and how they help make lightweight and highly agile architectures. This chapter
    also went into great detail about when a team should start thinking about microservices
    and when can they migrate or break their existing monolith(s) into microservices.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了什么是无服务器架构。最重要的是，本章帮助架构师决定无服务器是否适合他们的团队和工程，并且如何从现有基础架构过渡/迁移到无服务器范式。我们还研究了微服务的范式以及它们如何帮助构建轻量级和高度敏捷的架构。本章还详细介绍了团队何时应该开始考虑微服务，以及何时可以迁移或将其现有的单体架构拆分成微服务。
- en: We then learned the art of building batch architectures in the serverless domain.
    One of the most common myths is that serverless systems are only for real-time
    computation purposes. However, we have learned how to leverage these systems for
    batch computations too, thus facilitating a whole lot of applications with the
    serverless paradigm. We looked at the pros and cons of going serverless so that
    better engineering decisions can be taken accordingly.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们学习了在无服务器领域构建批处理架构的艺术。最常见的一个误解是无服务器系统只适用于实时计算目的。然而，我们已经学会了如何利用这些系统进行批量计算，从而为无服务器范式提供了大量的应用。我们研究了无服务器的利弊，以便能够做出更好的工程决策。
- en: In the next chapter, we will cover a very detailed understanding of how AWS
    Lambda works, which is the core component of serverless engineering in the AWS
    cloud environment. We will understand how triggers work and how AWS Lambda functions
    work. You will learn about the concept of leveraging containers for executing
    serverless functions and the associated computational workload. Following that,
    we will also learn about configuring and testing Lambda functions, along with
    understanding the best practices while doing so. We will also cover versioning
    Lambda functions, in the same way versioning is done in code, and then create
    deployment packages for AWS Lambda, so that the developer can accommodate third-party
    libraries comfortably, along with the standard library ones.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将详细了解AWS Lambda的工作原理，这是AWS云环境中无服务器工程的核心组件。我们将了解触发器的工作原理以及AWS Lambda函数的工作方式。您将学习利用容器执行无服务器函数和相关的计算工作负载的概念。之后，我们还将学习配置和测试Lambda函数，以及在此过程中了解最佳实践。我们还将介绍Lambda函数的版本控制，就像代码的版本控制一样，并为AWS
    Lambda创建部署包，以便开发人员可以舒适地适应第三方库，以及标准库。
