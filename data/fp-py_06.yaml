- en: Chapter 6. Recursions and Reductions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。递归和归约
- en: 'In previous chapters, we''ve looked at several related kinds of processing
    designs; some of them are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们已经看过几种相关的处理设计；其中一些如下：
- en: Mapping and filtering that create collections from collections
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从集合中创建集合的映射和过滤
- en: Reductions that create a scalar value from a collection
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从集合中创建标量值的归约
- en: The distinction is exemplified by functions such as `map()` and `filter()` that
    accomplish the first kind of collection processing. There are several specialized
    reduction functions, which include `min()`, `max()`, `len(),` and `sum()`. There's
    a general-purpose reduction function, also, `functools.reduce()`.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别体现在诸如`map()`和`filter()`之类的函数中，这些函数完成了第一种集合处理。还有几个专门的归约函数，包括`min()`、`max()`、`len()`和`sum()`。还有一个通用的归约函数，`functools.reduce()`。
- en: We'll also consider a `collections.Counter()` function as a kind of reduction
    operator. It doesn't produce a single scalar value per se, but it does create
    a new organization of the data that eliminates some of the original structure.
    At its heart, it's a kind of count-group-by operation that has more in common
    with a counting reduction than with a mapping.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将考虑`collections.Counter()`函数作为一种归约运算符。它本身并不产生单个标量值，但它确实创建了数据的新组织形式，消除了一些原始结构。从本质上讲，它是一种计数分组操作，与计数归约更类似于映射。
- en: In this chapter, we'll look at reduction functions in more detail. From a purely
    functional perspective, a reduction is defined recursively. For this reason, we'll
    look at recursion first before we look at reduction algorithms.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更详细地研究归约函数。从纯粹的功能角度来看，归约是递归地定义的。因此，我们将首先研究递归，然后再研究归约算法。
- en: Generally, a functional programming language compiler will optimize a recursive
    function to transform a call in the tail of the function to a loop. This will
    dramatically improve performance. From a Python perspective, pure recursion is
    limited, so we must do the tail-call optimization manually. The tail-call optimization
    technique available in Python is to use an explicit `for` loop.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，函数式编程语言编译器会优化递归函数，将函数尾部的调用转换为循环。这将大大提高性能。从Python的角度来看，纯递归是有限的，因此我们必须手动进行尾调用优化。Python中可用的尾调用优化技术是使用显式的`for`循环。
- en: We'll look at a number of reduction algorithms including `sum()`, `count()`,
    `max()`, and `min()`. We'll also look at the `collections.Counter()` function
    and related `groupby()` reductions. We'll also look at how parsing (and lexical
    scanning) are proper reductions since they transform sequences of tokens (or sequences
    of characters) into higher-order collections with more complex properties.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究许多归约算法，包括`sum()`、`count()`、`max()`和`min()`。我们还将研究`collections.Counter()`函数和相关的`groupby()`归约。我们还将研究解析（和词法扫描）是适当的归约，因为它们将标记序列（或字符序列）转换为具有更复杂属性的高阶集合。
- en: Simple numerical recursions
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的数值递归
- en: We can consider all numeric operations to be defined by recursions. For more
    depth, read about the **Peano axioms** that define the essential features of numbers.
    [http://en.wikipedia.org/wiki/Peano_axioms](http://en.wikipedia.org/wiki/Peano_axioms)
    is one place to start.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以认为所有数值运算都是通过递归定义的。要了解更多，请阅读定义数字的基本特征的**皮亚诺公理**。[http://en.wikipedia.org/wiki/Peano_axioms](http://en.wikipedia.org/wiki/Peano_axioms)是一个开始的地方。
- en: From these axioms, we can see that addition is defined recursively using more
    primitive notions of the next number, or successor of a number, *n*, ![Simple
    numerical recursions](graphics/B03652_06_01.jpg).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些公理中，我们可以看到加法是使用更原始的下一个数字或数字的后继*n*的概念递归地定义的，![Simple numerical recursions](graphics/B03652_06_01.jpg)。
- en: To simplify the presentation, we'll assume that we can define a predecessor
    function,![Simple numerical recursions](graphics/B03652_06_02.jpg), such that
    ![Simple numerical recursions](graphics/B03652_06_03.jpg), as long as ![Simple
    numerical recursions](graphics/B03652_06_04.jpg)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化演示，我们假设我们可以定义一个前驱函数，![Simple numerical recursions](graphics/B03652_06_02.jpg)，使得![Simple
    numerical recursions](graphics/B03652_06_03.jpg)，只要![Simple numerical recursions](graphics/B03652_06_04.jpg)。
- en: 'Addition between two natural numbers could be defined recursively as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 两个自然数之间的加法可以递归地定义如下：
- en: '![Simple numerical recursions](graphics/B03652_06_05.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![Simple numerical recursions](graphics/B03652_06_05.jpg)'
- en: If we use more common ![Simple numerical recursions](graphics/B03652_06_06.jpg)
    and ![Simple numerical recursions](graphics/B03652_06_07.jpg) instead of ![Simple
    numerical recursions](graphics/B03652_06_01.jpg) and ![Simple numerical recursions](graphics/B03652_06_02.jpg),
    we can see that ![Simple numerical recursions](graphics/B03652_06_08.jpg).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用更常见的![Simple numerical recursions](graphics/B03652_06_06.jpg)和![Simple
    numerical recursions](graphics/B03652_06_07.jpg)而不是![Simple numerical recursions](graphics/B03652_06_01.jpg)和![Simple
    numerical recursions](graphics/B03652_06_02.jpg)，我们可以看到![Simple numerical recursions](graphics/B03652_06_08.jpg)。
- en: 'This translates neatly in Python, as shown in the following command snippet:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这在Python中可以很好地转换，如下面的命令片段所示：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We've simply rearranged common mathematical notation into Python. The `if` clauses
    are placed to the left instead of the right.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是将常见的数学符号重新排列成Python。`if`子句放在左边而不是右边。
- en: Generally, we don't provide our own functions in Python to do simple addition.
    We rely on Python's underlying implementation to properly handle arithmetic of
    various kinds. Our point here is that fundamental scalar arithmetic can be defined
    recursively.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不会在Python中提供自己的函数来进行简单的加法。我们依赖于Python的底层实现来正确处理各种类型的算术。我们的观点是，基本的标量算术可以递归地定义。
- en: 'All of these recursive definitions include at least two cases: the nonrecursive
    cases where the value of the function is defined directly and recursive cases
    where the value of the function is computed from a recursive evaluation of the
    function with different values.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些递归定义都包括至少两种情况：非递归情况，其中函数的值直接定义，以及递归情况，其中函数的值是从对具有不同值的函数的递归评估中计算出来的。
- en: In order to be sure the recursion will terminate, it's important to see how
    the recursive case computes values that approach the defined nonrecursive case.
    There are often constraints on the argument values that we've omitted from the
    functions here. The `add()` function in the preceding command snippet, for example,
    can include `assert a>= and b>=0` to establish the constraints on the input values.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保递归会终止，重要的是要看递归情况如何计算接近定义的非递归情况的值。我们在这里的函数中通常省略了参数值的约束。例如，前面命令片段中的`add()`函数可以包括`assert
    a>= and b>=0`来建立输入值的约束。
- en: Without these constraints. `a-1` can't be guaranteed to approach the nonrecursive
    case of `a == 0`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有这些约束的情况下，`a-1`不能保证接近`a == 0`的非递归情况。
- en: In most cases, this is obvious. In a few rare cases, it might be difficult to
    prove. One example is the Syracuse function. This is one of the pathological cases
    where termination is unclear.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这是显而易见的。在少数情例中，可能难以证明。一个例子是Syracuse函数。这是终止不明确的病态情况之一。
- en: Implementing tail-call optimization
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现尾递归优化
- en: In the case of some functions, the recursive definition is the one often stated
    because it is succinct and expressive. One of the most common examples is the
    `factorial()` function.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些函数的情况下，递归定义是经常被提及的，因为它简洁而富有表现力。最常见的例子之一是`factorial()`函数。
- en: 'We can see how this is rewritten as a simple recursive function in Python from
    the following formula:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这可以被重写为Python中的一个简单递归函数，从以下公式：
- en: '![Implementing tail-call optimization](graphics/B03652_06_09.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: 实现尾递归优化
- en: 'The preceding formula can be executed in Python by using the following commands:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式可以通过以下命令在Python中执行：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This has the advantage of simplicity. The recursion limits in Python artificially
    constrain us; we can't do anything larger than about fact(997). The value of 1000!
    has 2,568 digits and generally exceeds our floating-point capacity; on some systems
    this is about ![Implementing tail-call optimization](graphics/B03652_06_10.jpg)
    Pragmatically, it's common to switch to a `log gamma` function, which works well
    with large floating-point values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的好处是简单。在Python中，递归限制人为地限制了我们；我们不能计算大约fact(997)以上的任何值。1000!的值有2568位数，通常超出了我们的浮点容量；在某些系统上，这大约是![实现尾递归优化](graphics/B03652_06_10.jpg)。从实用的角度来看，通常会切换到`log
    gamma`函数，它在处理大浮点值时效果很好。
- en: This function demonstrates a typical tail recursion. The last expression in
    the function is a call to the function with a new argument value. An optimizing
    compiler can replace the function call stack management with a loop that executes
    very quickly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数演示了典型的尾递归。函数中的最后一个表达式是对具有新参数值的函数的调用。优化编译器可以用一个很快执行的循环替换函数调用堆栈管理。
- en: Since Python doesn't have an optimizing compiler, we're obliged to look at scalar
    recursions with an eye toward optimizing them. In this case, the function involves
    an incremental change from *n* to *n-1*. This means that we're generating a sequence
    of numbers and then doing a reduction to compute their product.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python没有优化编译器，我们必须着眼于标量递归并对其进行优化。在这种情况下，函数涉及从*n*到*n-1*的增量变化。这意味着我们正在生成一系列数字，然后进行缩减以计算它们的乘积。
- en: 'Stepping outside purely functional processing, we can define an imperative
    `facti()` calculation as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 走出纯粹的函数处理，我们可以定义一个命令式的`facti()`计算如下：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This version of the factorial function will compute values beyond 1000! (2000!,
    for example, has 5733 digits). It isn't purely functional. We've optimized the
    tail recursion into a stateful loop depending on the `i` variable to maintain
    the state of the computation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶乘函数的版本将计算超过1000!的值（例如，2000!有5733位数）。它并不是纯粹的函数。我们已经将尾递归优化为一个有状态的循环，取决于`i`变量来维护计算的状态。
- en: In general, we're obliged to do this in Python because Python can't automatically
    do the tail-call optimization. There are situations, however, where this kind
    of optimization isn't actually helpful. We'll look at a few situations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们在Python中被迫这样做，因为Python无法自动进行尾递归优化。然而，有些情况下，这种优化实际上并不会有所帮助。我们将看几种情况。
- en: Leaving recursion in place
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保留递归
- en: 'In some cases, the recursive definition is actually optimal. Some recursions
    involve a divide and conquer strategy that minimizes the work from ![Leaving recursion
    in place](graphics/B03652_06_11.jpg) to ![Leaving recursion in place](graphics/B03652_06_12.jpg).
    One example of this is the exponentiation by the squaring algorithm. We can state
    it formally like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，递归定义实际上是最优的。一些递归涉及分而治之的策略，可以将工作量最小化从![保留递归](graphics/B03652_06_11.jpg)到![保留递归](graphics/B03652_06_12.jpg)。其中一个例子是平方算法的指数运算。我们可以正式地将其陈述如下：
- en: '![Leaving recursion in place](graphics/B03652_06_13.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: 保留递归
- en: 'We''ve broken the process into three cases, easily written in Python as a recursion.
    Look at the following command snippet:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个过程分成三种情况，可以很容易地在Python中写成递归。看一下以下命令片段：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This function has three cases. The base case, the `fastexp(a, 0)` method is
    defined as having a value of 1\. The other two cases take two different approaches.
    For odd numbers, the `fastexp()` method is defined recursively. The exponent,
    *n*, is reduced by 1\. A simple tail-recursion optimization would work for this
    case.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数有三种情况。基本情况，`fastexp(a, 0)`方法被定义为值为1。另外两种情况采取了两种不同的方法。对于奇数，`fastexp()`方法被递归定义。指数*n*减少了1。简单的尾递归优化对这种情况有效。
- en: For even numbers, however, the `fastexp()` recursion uses `n/2`, chopping the
    problem into half of its original size. Since the problem size is reduced by a
    factor of 2, this case results in a significant speed-up of the processing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于偶数，`fastexp()`递归使用`n/2`，将问题分成原始大小的一半。由于问题规模减小了一半，这种情况会显著加快处理速度。
- en: We can't trivially reframe this kind of function into a tail-call optimization
    loop. Since it's already optimal, we don't really need to optimize this further.
    The recursion limit in Python would impose the constraint of ![Leaving recursion
    in place](graphics/B03652_06_14.jpg), a generous upper bound.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能简单地将这种函数重新构建为尾递归优化循环。由于它已经是最优的，我们实际上不需要进一步优化。Python中的递归限制将强加约束![Leaving
    recursion in place](graphics/B03652_06_14.jpg)，这是一个宽松的上限。
- en: Handling difficult tail-call optimization
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理困难的尾递归优化
- en: 'We can look at the definition of **Fibonacci** numbers recursively. Following
    is one widely used definition for the *nth* Fibonacci number:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以递归地查看**斐波那契**数的定义。以下是一个广泛使用的第*n*个斐波那契数的定义：
- en: '![Handling difficult tail-call optimization](graphics/B03652_06_15.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![Handling difficult tail-call optimization](graphics/B03652_06_15.jpg)'
- en: 'A given Fibonacci number, ![Handling difficult tail-call optimization](graphics/B03652_06_16.jpg),
    is defined as the sum of the previous two numbers, ![Handling difficult tail-call
    optimization](graphics/B03652_06_17.jpg). This is an example of multiple recursion:
    it can''t be trivially optimized as a simple tail-recursion. However, if we don''t
    optimize it to a tail-recursion, we''ll find it to be too slow to be useful.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 给定的斐波那契数，![Handling difficult tail-call optimization](graphics/B03652_06_16.jpg)，被定义为前两个数的和，![Handling
    difficult tail-call optimization](graphics/B03652_06_17.jpg)。这是一个多重递归的例子：它不能简单地优化为简单的尾递归。然而，如果我们不将其优化为尾递归，我们会发现它太慢而无法使用。
- en: 'The following is a naïve implementation:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个天真的实现：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This suffers from the multiple recursion problem. When computing the `fib(n)`
    method, we must compute `fib(n-1)` and `fib(n-2)` methods. The computation of
    `fib(n-1)` method involves a duplicate calculation of `fib(n-2)` method. The two
    recursive uses of the Fibonacci function will duplicate the amount of computation
    being done.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这遭受了多重递归问题。在计算`fib(n)`方法时，我们必须计算`fib(n-1)`和`fib(n-2)`方法。计算`fib(n-1)`方法涉及重复计算`fib(n-2)`方法。斐波那契函数的两个递归使用将使得计算量翻倍。
- en: Because of the left-to-right Python evaluation rules, we can evaluate values
    up to about `fib(1000)`. However, we have to be patient. Very patient.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python的从左到右的评估规则，我们可以计算到大约`fib(1000)`的值。然而，我们必须要有耐心。非常有耐心。
- en: 'Following is an alternative which restates the entire algorithm to use stateful
    variables instead of a simple recursion:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个替代方案，它重新陈述了整个算法，使用有状态变量而不是简单的递归：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Our stateful version of this function counts up from 0, unlike the recursion,
    which counts down from the initial value of *n*. It saves the values of ![Handling
    difficult tail-call optimization](graphics/B03652_06_18.jpg) and ![Handling difficult
    tail-call optimization](graphics/B03652_06_19.jpg) that will be used to compute
    ![Handling difficult tail-call optimization](graphics/B03652_06_16.jpg). This
    version is considerably faster than the recursive version.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的有状态版本的这个函数从0开始计数，不像递归，递归是从初始值*n*开始计数。它保存了用于计算![Handling difficult tail-call
    optimization](graphics/B03652_06_16.jpg)和![Handling difficult tail-call optimization](graphics/B03652_06_19.jpg)的值。这个版本比递归版本快得多。
- en: What's important here is that we couldn't trivially optimize the recursion with
    an obvious rewrite. In order to replace the recursion with an imperative version,
    we had to look closely at the algorithm to determine how many stateful intermediate
    variables were required.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，我们无法轻松地通过明显的重写来优化递归。为了用命令式版本替换递归，我们必须仔细研究算法，确定需要多少个有状态的中间变量。
- en: Processing collections via recursion
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过递归处理集合
- en: 'When working with a collection, we can also define the processing recursively.
    We can, for example, define the `map()` function recursively. The formalism looks
    as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理集合时，我们也可以递归地定义处理。例如，我们可以递归地定义`map()`函数。形式主义如下所示：
- en: '![Processing collections via recursion](graphics/B03652_06_20.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![Processing collections via recursion](graphics/B03652_06_20.jpg)'
- en: We've defined the mapping of a function to an empty collection as an empty sequence.
    We've also specified that applying a function to a collection can be defined recursively
    with a three step expression. First, apply the function to all of the collection
    except the last element, creating a sequence object. Then apply the function to
    the last element. Finally, append the last calculation to the previously built
    sequence.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将函数映射到空集合定义为一个空序列。我们还指定了将函数应用于集合可以通过三个步骤的表达式进行递归定义。首先，将函数应用于除最后一个元素之外的所有集合，创建一个序列对象。然后将函数应用于最后一个元素。最后，将最后的计算附加到先前构建的序列中。
- en: 'Following is a purely recursive function version of the older `map()` function:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是较旧的`map()`函数的纯递归函数版本：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The value of the `mapr(f,[])` method is defined to be an empty `list` object.
    The value of the `mapr()` function with a non-empty list will apply the function
    to the last element in the `list` and append this to the list built recursively
    from the `mapr()` function applied to the head of the list.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`mapr(f,[])`方法的值被定义为一个空的`list`对象。`mapr()`函数对非空列表的值将应用函数到列表的最后一个元素，并将其附加到从`mapr()`函数递归应用到列表头部构建的列表中。'
- en: We have to emphasize that this `mapr()` function actually creates a `list` object,
    similar to the older `map()` function in Python. The Python 3 `map()` function
    is an iterable, and isn't as good an example of tail-call optimization.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须强调这个`mapr()`函数实际上创建了一个`list`对象，类似于Python中较旧的`map()`函数。Python 3中的`map()`函数是可迭代的，并不是尾递归优化的很好的例子。
- en: While this is an elegant formalism, it still lacks the tail-call optimization
    required. The tail-call optimization allows us to exceed the recursion depth of
    1000 and also performs much more quickly than this naïve recursion.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个优雅的形式主义，但它仍然缺乏所需的尾递归优化。尾递归优化允许我们超过1000的递归深度，并且比这种天真的递归执行得更快。
- en: Tail-call optimization for collections
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合的尾递归优化
- en: 'We have two general ways to handle collections: we can use a higher-order function
    which returns a generator expression or we can create a function which uses a
    `for` loop to process each item in a collection. The two essential patterns are
    very similar.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两种处理集合的一般方法：我们可以使用一个返回生成器表达式的高阶函数，或者我们可以创建一个使用`for`循环来处理集合中的每个项目的函数。这两种基本模式非常相似。
- en: 'Following is a higher-order function that behaves like the built-in `map()`
    function:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个行为类似于内置`map()`函数的高阶函数：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We've returned a generator expression which produces the required mapping. This
    uses an explicit `for` loop as a kind of tail-call optimization.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们返回了一个生成器表达式，它产生了所需的映射。这使用了一个显式的`for`循环作为一种尾调用优化。
- en: 'Following is a generator function with the same value:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个具有相同值的生成器函数：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This uses a complete `for` statement for the required optimization.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用了一个完整的`for`语句进行所需的优化。
- en: 'In both cases, the result is iterable. We must do something following this
    to materialize a sequence object:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，结果是可迭代的。我们必须在此之后做一些事情来实现一个序列对象：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For performance and scalability, this kind of tail-call optimization is essentially
    required in Python programs. It makes the code less than purely functional. However,
    the benefit far outweighs the lack of purity. In order to reap the benefits of
    succinct and expression functional design, it is helpful to treat these less-than-pure
    functions as if they were proper recursions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了性能和可伸缩性，在Python程序中基本上需要这种尾调用优化。它使代码不纯粹功能。然而，好处远远超过了纯度的缺失。为了获得简洁和表达式功能设计的好处，有助于将这些不纯粹的函数视为适当的递归。
- en: What this means, pragmatically, is that we must avoid cluttering up a collection
    processing function with additional stateful processing. The central tenets of
    functional programming are still valid even if some elements of our programs are
    less than purely functional.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从实用的角度来看，这意味着我们必须避免用额外的有状态处理来使集合处理函数混乱。即使我们程序的一些元素不纯粹，函数式编程的核心原则仍然有效。
- en: Reductions and folding – from many to one
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少和折叠 - 从多个到一个
- en: 'We can consider the `sum()` function to have the following kind of definition:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以认为`sum()`函数具有以下类型的定义：
- en: We could say that the sum of a collection is 0 for an empty collection. For
    a non-empty collection the sum is the first element plus the sum of the remaining
    elements.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说一个集合的总和对于一个空集合是0。对于一个非空集合，总和是第一个元素加上剩余元素的总和。
- en: '![Reductions and folding – from many to one](graphics/B03652_06_21.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![从多个到一个的减少和折叠](graphics/B03652_06_21.jpg)'
- en: 'Similarly, we can compute the product of a collection of numbers recursively
    using two cases:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以使用两种情况递归地计算一组数字的乘积：
- en: '![Reductions and folding – from many to one](graphics/B03652_06_22.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![从多个到一个的减少和折叠](graphics/B03652_06_22.jpg)'
- en: The base case defines the product of an empty sequence as 1\. The recursive
    case defines the product as the first item times the product of the remaining
    items.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 基本情况将空序列的乘积定义为1。递归情况将乘积定义为第一个项目乘以剩余项目的乘积。
- en: We've effectively folded in `×` or `+` operators between each item of the sequence.
    Further, we've grouped the items so that processing will be done right-to-left.
    This could be called a fold-right way of reducing a collection to a single value.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在序列的每个项目之间有效地折叠了`×`或`+`运算符。此外，我们对项目进行了分组，以便处理将从右到左进行。这可以称为将集合减少为单个值的右折叠方式。
- en: 'In Python, the product function can be defined recursively as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，可以递归地定义乘积函数如下：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is technically correct. It's a trivial rewrite from mathematical notation
    to Python. However, it is less than optimal because it tends to create a large
    number of intermediate `list` objects. It's also limited to only working with
    explicit collections; it can't work easily with `iterable` objects.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，这是正确的。这是从数学符号转换为Python的一个微不足道的重写。然而，它不够优化，因为它倾向于创建大量中间的`list`对象。它也仅限于与显式集合一起使用；它不能轻松地与`iterable`对象一起使用。
- en: 'We can revise this slightly to work with an iterable, which avoids creating
    any intermediate `collection` objects. Following is a properly recursive product
    function which works with an iterable source of data:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍微修改这个函数，使其适用于可迭代对象，从而避免创建任何中间的`collection`对象。以下是一个可以与可迭代数据源一起使用的适当递归乘积函数：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can''t interrogate an iterable with the `len()` function to see how many
    elements it has. All we can do is attempt to extract the head of the `iterable`
    sequence. If there are no items in the sequence, then any attempt to get the head
    will raise the `StopIteration` exception. If there is an item, then we can multiply
    this item by the product of the remaining items in the sequence. For a demo, we
    must explicitly create an iterable from a materialized `sequence` object, using
    the `iter()` function. In other contexts, we might have an iterable result that
    we can use. Following is an example:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能使用`len()`函数来查询可迭代对象有多少个元素。我们所能做的就是尝试提取`iterable`序列的头部。如果序列中没有项目，那么任何获取头部的尝试都将引发`StopIteration`异常。如果有一个项目，那么我们可以将该项目乘以序列中剩余项目的乘积。对于演示，我们必须明确地使用`iter()`函数从一个具体化的`sequence`对象中创建一个可迭代对象。在其他情境中，我们可能会有一个可迭代的结果可以使用。以下是一个例子：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This recursive definition does not rely on explicit state or other imperative
    features of Python. While it''s more purely functional, it is still limited to
    working with collections of under 1000 items. Pragmatically, we can use the following
    kind of imperative structure for reduction functions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个递归定义不依赖于Python的显式状态或其他命令式特性。虽然它更加纯粹功能，但它仍然局限于处理少于1000个项目的集合。从实用的角度来看，我们可以使用以下类型的命令式结构来进行减少函数：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This lacks the recursion limits. It includes the required tail-call optimization.
    Further, this will work equally well with either a `sequence` object or an iterable.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这缺乏递归限制。它包括所需的尾调用优化。此外，这将同样适用于`sequence`对象或可迭代对象。
- en: 'In other functional languages, this is called a `foldl` operation: the operators
    are folded into the iterable collection of values from left-to-right. This is
    unlike the recursive formulations which are generally called `foldr` operations
    because the evaluations are done from right-to-left in the collection.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他函数式语言中，这被称为`foldl`操作：运算符从左到右折叠到可迭代的值集合中。这与通常称为`foldr`操作的递归公式不同，因为在集合中的评估是从右到左进行的。
- en: For languages with optimizing compilers and lazy evaluation, the fold-left and
    fold-right distinction determines how intermediate results are created. This may
    have profound performance implications, but the distinction might not be obvious.
    A fold-left, for example, could immediately consume and process the first elements
    in a sequence. A fold-right, however, might consume the head of the sequence,
    but not do any processing until the entire sequence was consumed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有优化编译器和惰性评估的语言，fold-left和fold-right的区别决定了中间结果的创建方式。这可能具有深远的性能影响，但这种区别可能并不明显。例如，fold-left可能会立即消耗和处理序列中的第一个元素。然而，fold-right可能会消耗序列的头部，但在整个序列被消耗之前不进行任何处理。
- en: Group-by reductions – from many to fewer
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分组缩减-从多到少
- en: A very common operation is a reduction that groups values by some key or indicator.
    In **SQL**, this is often called the `SELECT GROUP BY` operation. The raw data
    is grouped by some columns value and reductions (sometimes aggregate functions)
    are applied to other columns. The SQL aggregate functions include `SUM`, `COUNT`,
    `MAX`, and `MIN`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常常见的操作是通过某个键或指示器对值进行分组的缩减。在**SQL**中，这通常称为`SELECT GROUP BY`操作。原始数据按某些列的值分组，然后对其他列应用缩减（有时是聚合函数）。SQL聚合函数包括`SUM`、`COUNT`、`MAX`和`MIN`。
- en: The statistical summary called the mode is a count that's grouped by some independent
    variable. Python offers us several ways to group data before computing a reduction
    of the grouped values. We'll start by looking at two ways to get simple counts
    of grouped data. Then we'll look at ways to compute different summaries of grouped
    data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 统计摘要称为模式，是按独立变量分组的计数。Python为我们提供了几种在计算分组值的缩减之前对数据进行分组的方法。我们将首先看两种获取分组数据的简单计数的方法。然后我们将看看计算分组数据的不同摘要的方法。
- en: 'We''ll use the trip data that we computed in [Chapter 4](ch04.html "Chapter 4. Working
    with Collections"), *Working with Collections*. This data started as a sequence
    of latitude-longitude waypoints. We restructured it to create legs represented
    by three tuples of start, end, and distance for the `leg`. The data looks as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们在[第4章](ch04.html "第4章。与集合一起工作")*与集合一起工作*中计算的行程数据。这些数据最初是一系列纬度-经度航点。我们重新构造它以创建由`leg`的起点、终点和距离表示的航段。数据如下所示：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'A common operation that can be approached either as a stateful map or as a
    materialized, sorted object is computing the mode of a set of data values. When
    we look at our trip data, the variables are all continuous. To compute a mode,
    we''ll need to quantize the distances covered. This is also called **binning**:
    we''ll group the data into different bins. Binning is common in data visualization
    applications, also. In this case, we''ll use 5 nautical miles as the size of each
    bin.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的操作，可以作为有状态的映射或作为一个实现、排序的对象来处理，就是计算一组数据值的模式。当我们查看我们的行程数据时，变量都是连续的。要计算模式，我们需要量化所覆盖的距离。这也被称为**分箱**：我们将数据分组到不同的箱中。分箱在数据可视化应用中很常见。在这种情况下，我们将使用5海里作为每个箱的大小。
- en: 'The quantized distances can be produced with a generator expression:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用生成器表达式生成量化距离：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will divide each distance by 5 – discarding any fractions – and then multiply
    by 5 to compute a number that represents the distance rounded down to the nearest
    5 nautical miles.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把每个距离除以5-丢弃任何小数-然后乘以5来计算代表四舍五入到最近5海里的距离的数字。
- en: Building a mapping with Counter
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Counter构建映射
- en: A mapping like the `collections.Counter` method is a great optimization for
    doing reductions that create counts (or totals) grouped by some value in the collection.
    A more typical functional programming solution to grouping data is to sort the
    original collection, and then use a recursive loop to identify when each group
    begins. This involves materializing the raw data, performing a ![Building a mapping
    with Counter](graphics/B03652_06_27.jpg) sort, and then doing a reduction to get
    the sums or counts for each key.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 像`collections.Counter`方法这样的映射是进行创建计数（或总数）的优化的好方法，这些计数（或总数）是按集合中的某个值分组的。对于分组数据的更典型的函数式编程解决方案是对原始集合进行排序，然后使用递归循环来识别每个组的开始。这涉及将原始数据实现化，执行![使用Counter构建映射](graphics/B03652_06_27.jpg)排序，然后进行缩减以获得每个键的总和或计数。
- en: 'We''ll use the following generator to create an simple sequence of distances
    transformed into bins:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下生成器创建一个简单的距离序列，转换为箱：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We divided each distance by 5 using truncated integer division, and then multiplied
    by 5 to create a value that's rounded down to the nearest 5 miles.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用截断的整数除法将每个距离除以5，然后乘以5，以创建一个四舍五入到最近5英里的值。
- en: 'The following expression creates a `mapping` from distance to frequency:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表达式创建了一个从距离到频率的`映射`：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This is a stateful object, that was created by – technically – imperative object-oriented
    programming. Since it looks like a function, however, it seems a good fit for
    a design based on functional programming ideas.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有状态的对象，由技术上的命令式面向对象编程创建。然而，由于它看起来像一个函数，它似乎很适合基于函数式编程思想的设计。
- en: 'If we print `Counter(quantized).most_common()` function, we''ll see the following
    results:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印`Counter(quantized).most_common()`函数，我们将看到以下结果：
- en: '[PRE18]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The most common distance was about 30 nautical miles. The shortest recorded
    `leg` was four instances of 0\. The longest leg was 125 nautical miles.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的距离约为30海里。记录的最短`leg`是4个0的实例。最长的航段是125海里。
- en: 'Note that your output may vary slightly from this. The results of the `most_common()`
    function are in order by frequency; equal-frequency bins may be in any order.
    These 5 lengths may not always be in the order shown:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你的输出可能与此略有不同。`most_common()`函数的结果按频率排序；相同频率的箱可能以任何顺序出现。这5个长度可能不总是按照所示的顺序排列：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Building a mapping by sorting
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过排序构建映射
- en: 'If we want to implement this without using the `Counter` class, we can use
    a more functional approach of sorting and grouping. Following is a common algorithm:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要在不使用`Counter`类的情况下实现这一点，我们可以使用更多基于函数的排序和分组方法。以下是一个常见的算法：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The internal `group()` function steps through the sorted sequence of data items.
    If a given item has already been seen – it matches the value in `previous` – then
    the counter can be incremented. If a given item does not match the previous value
    and the previous value is `not-None`, then we''ve had a change in value; we can
    emit the previous value and the count, and begin a new accumulation of counts
    for the new value. The third condition only applies once: if the previous value
    has never been set, then this is the first value, and we should save it.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 内部的`group()`函数遍历排序后的数据项序列。如果给定项已经被看到 - 它与`previous`中的值匹配 - 那么计数器可以递增。如果给定项与前一个值不匹配，并且前一个值不是`None`，那么我们就有了值的变化；我们可以输出前一个值和计数，并开始对新值进行新的累积计数。第三个条件只适用一次：如果前一个值从未被设置过，那么这是第一个值，我们应该保存它。
- en: The final line of the function creates a dictionary from the grouped items.
    This dictionary will be similar to a Counter dictionary. The primary difference
    is that a `Counter()` function will have a `most_common()` method function which
    a default dictionary lacks.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的最后一行从分组的项中创建一个字典。这个字典将类似于一个Counter字典。主要的区别在于`Counter()`函数有一个`most_common()`方法函数，而默认字典则没有。
- en: The `elif previous is None` method case is an irksome overhead. Getting rid
    of this `elif` clause (and seeing a slight performance improvement) isn't terribly
    difficult.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`elif previous is None`方法是一个让人讨厌的开销。摆脱这个`elif`子句（并看到轻微的性能改进）并不是非常困难。'
- en: 'To remove the extra `elif` clause, we need to use a slightly more elaborate
    initialization in the internal `group()` function:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了去掉额外的`elif`子句，我们需要在内部的`group()`函数中使用稍微更复杂的初始化：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This picks the first item out of the set of data to initialize the `previous`
    variable. The remaining items are then processed through the loop. This design
    shows a loose parallel with recursive designs where we initialize the recursion
    with the first item, and each recursive call provides either a next item or `None`
    to indicate that no items are left to process.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这会从数据集中挑选出第一个项目来初始化`previous`变量。然后剩下的项目通过循环进行处理。这种设计与递归设计有一定的相似之处，其中我们使用第一个项目初始化递归，每次递归调用都提供下一个项目或`None`来指示没有剩余项目需要处理。
- en: We can also do this with `itertools.groupby()`. We'll look at this function
    closely in [Chapter 8](ch08.html "Chapter 8. The Itertools Module"), *The Itertools
    Module*.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用`itertools.groupby()`来实现这一点。我们将在[第8章](ch08.html "第8章. Itertools模块")*Itertools模块*中仔细研究这个函数。
- en: Grouping or partitioning data by key values
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按键值对数据进行分组或分区
- en: There are no limits to the kinds of reductions we might want to apply to grouped
    data. We might have data with a number of independent and dependent variables.
    We can consider partitioning the data by an independent variable and computing
    summaries like maximum, minimum, average, and standard deviation of the values
    in each partition.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想要对分组数据应用的归约类型没有限制。我们可能有一些独立和因变量的数据。我们可以考虑通过一个独立变量对数据进行分区，并计算每个分区中值的最大值、最小值、平均值和标准差等摘要。
- en: The essential trick to doing more sophisticated reductions is to collect all
    of the data values into each group. The `Counter()` function merely collects counts
    of identical items. We want to create sequences of the original items based on
    a key value.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 进行更复杂的归约的关键是将所有数据值收集到每个组中。`Counter()`函数仅仅收集相同项的计数。我们想要基于关键值创建原始项的序列。
- en: Looked at in a more general way, each 5-mile bin will contain the entire collection
    of legs of that distance, not merely a count of the legs. We can consider the
    partitioning as a recursion or as a stateful application of `defaultdict(list)`
    object. We'll look at the recursive definition of a `groupby()` function, since
    it's easy to design.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从更一般的角度来看，每个5英里的箱都将包含该距离的所有腿，而不仅仅是腿的计数。我们可以将分区视为递归，或者作为`defaultdict(list)`对象的有状态应用。我们将研究`groupby()`函数的递归定义，因为它很容易设计。
- en: Clearly, the `groupby(C, key)` method for an empty collection, `C`, is the empty
    dictionary, `dict()`. Or, more usefully, the empty `defaultdict(list)` object.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，对于空集合`C`，`groupby(C, key)`方法返回的是空字典`dict()`。或者更有用的是空的`defaultdict(list)`对象。
- en: 'For a non-empty collection, we need to work with item `C[0]`, the head, and
    recursively process sequence `C[1:]`, the tail. We can use `head, *tail = C` command
    to do this parsing of the collection, as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非空集合，我们需要处理项`C[0]`，即头，然后递归处理序列`C[1:]`，即尾。我们可以使用`head, *tail = C`命令来解析集合，如下所示：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We need to do the `dict[key(head)].append(head)` method to include the head
    element in the resulting dictionary. And then we need to do the `groupby(tail,key)`
    method to process the remaining elements.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要执行`dict[key(head)].append(head)`方法来将头元素包含在结果字典中。然后我们需要执行`groupby(tail,key)`方法来处理剩余的元素。
- en: 'We can create a function as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个如下的函数：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The interior function handles our essential recursive definition. An empty collection
    returns the provided dictionary. A non-empty collection is parsed into a head
    and tail. The head is used to update the dictionary. The tail is then used, recursively,
    to update the dictionary with all remaining elements.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 内部函数处理我们的基本递归定义。一个空集合返回提供的字典。非空集合被解析为头和尾。头用于更新字典。然后使用尾递归地更新字典中的所有剩余元素。
- en: 'We can''t easily use Python''s default values to collapse this into a single
    function. We cannot use the following command snippet:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法轻松地使用Python的默认值将其合并为一个函数。我们不能使用以下命令片段：
- en: '[PRE24]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If we try this, all uses of the `group_by()` function share one common `defaultdict(list)`
    object. Python builds default values just once. Mutable objects as default values
    rarely do what we want. Rather than try to include more sophisticated decision-making
    to handle an immutable default value (like `None`), we prefer to use a nested
    function definition. The `wrapper()` function properly initializes the arguments
    to the interior function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试这样做，`group_by()`函数的所有用法都共享一个`defaultdict(list)`对象。Python只构建默认值一次。可变对象作为默认值很少能实现我们想要的效果。与其尝试包含更复杂的决策来处理不可变的默认值（如`None`），我们更喜欢使用嵌套函数定义。`wrapper()`函数正确地初始化了内部函数的参数。
- en: 'We can group the data by distance as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按距离对数据进行分组，如下所示：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We've defined simple, reusable `lambda` which puts our distances into 5 nm bins.
    We then grouped the data using the provided `lambda`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个简单的可重用的`lambda`，将我们的距离放入5纳米的箱中。然后使用提供的`lambda`对数据进行分组。
- en: 'We can examine the binned data as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式检查分箱数据：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Following is what the output looks like:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出的样子：
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This can also be written as an iteration as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以写成迭代，如下所示：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: When doing the tail-call optimization, the essential line of the code in the
    imperative version will match the recursive definition. We've highlighted that
    line to emphasize that the rewrite is intended to have the same outcome. The rest
    of the structure represents the tail-call optimization we've adopted as a common
    way to work around the Python limitations.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行尾递归优化时，命令式版本中的关键代码行将与递归定义相匹配。我们已经突出显示了该行以强调重写的目的是具有相同的结果。其余结构代表了我们采用的尾递归优化，这是一种常见的解决Python限制的方法。
- en: Writing more general group-by reductions
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写更一般的分组约简
- en: Once we have partitioned the raw data, we can compute various kinds of reductions
    on the data elements in each partition. We might, for example, want the northern-most
    point for the start of each leg in the distance bins.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对原始数据进行了分区，我们就可以对每个分区中的数据元素进行各种类型的约简。例如，我们可能希望每个距离箱的起始点是每个腿的最北端。
- en: 'We''ll introduce some helper functions to decompose the tuple as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍一些辅助函数来分解元组，如下所示：
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Each of these helper functions expects a `tuple` object to be provided using
    the `*` operator to map each element of the tuple to a separate parameter of the
    `lambda`. Once the tuple is expanded into the `s`, `e`, and `p` parameters, it's
    reasonably obvious to return the proper parameter by name. It's much more clear
    than trying to interpret the `tuple_arg[2]` method.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这些辅助函数中的每一个都期望提供一个`tuple`对象，使用`*`运算符将元组的每个元素映射到`lambda`的单独参数。一旦元组扩展为`s`、`e`和`p`参数，通过名称返回正确的参数就变得相当明显。这比尝试解释`tuple_arg[2]`方法要清晰得多。
- en: 'Following is how we use these helper functions:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何使用这些辅助函数：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Our initial point object is a nested three tuple with `(0)` - a starting position,
    `(1)` - the ending position, and `(2)` - the distance. We extracted various fields
    using our helper functions.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初始点对象是一个嵌套的三元组，包括`(0)` - 起始位置，`(1)` - 结束位置和`(2)` - 距离。我们使用我们的辅助函数提取了各种字段。
- en: 'Given these helpers, we can locate the northern-most starting position for
    the legs in each bin:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些辅助函数，我们可以找到每个箱中腿的最北端起始位置：
- en: '[PRE31]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The data that we grouped by distance included each leg of the given distance.
    We supplied all of the legs in each bin to the `max()` function. The `key` function
    we provided to the `max()` function extracted just the latitude of the starting
    point of the leg.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按距离分组的数据包括给定距离的每条腿。我们将每个箱中的所有腿提供给`max()`函数。我们提供给`max()`函数的`key`函数仅提取了腿的起始点的纬度。
- en: 'This gives us a short list of the northern-most legs of each distance as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们一个关于每个距离的最北端腿的简短列表，如下所示：
- en: '[PRE32]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Writing higher-order reductions
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写高阶约简
- en: We'll look at an example of a higher-order reduction algorithm here. This will
    introduce a rather complex topic. The simplest kind of reduction develops a single
    value from a collection of values. Python has a number of built-in reductions,
    including `any()`, `all()`, `max()`, `min()`, `sum()`, and `len()`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里看一个高阶约简算法的示例。这将介绍一个相当复杂的主题。最简单的约简类型是从一组值中生成一个值。Python有许多内置的约简，包括`any()`、`all()`、`max()`、`min()`、`sum()`和`len()`。
- en: 'As we noted in [Chapter 4](ch04.html "Chapter 4. Working with Collections"),
    *Working with Collections*, we can do a great deal of statistical calculation
    if we start with a few simple reductions such as the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第4章](ch04.html "第4章。处理集合")中所指出的，*处理集合*，如果我们从一些简单的约简开始，我们可以进行大量的统计计算，例如以下内容：
- en: '[PRE33]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This allows us to define mean, standard deviation, normalized values, correction,
    and even least-squares linear regression using a few simple functions.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够使用几个简单的函数来定义均值、标准差、归一化值、校正，甚至最小二乘线性回归。
- en: 'The last of our simple reductions, `s2()`, shows how we can apply existing
    reductions to create higher-order functions. We might change our approach to be
    more like the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一个简单约简`s2()`显示了我们如何应用现有的约简来创建高阶函数。我们可能会改变我们的方法，使其更像以下内容：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We've added a function that we'll use to transform the data. We'll compute the
    sum of the transformed values.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了一个函数，用于转换数据。我们将计算转换值的总和。
- en: 'Now we can apply this function in three different ways to compute the three
    essential sums as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以以三种不同的方式应用此函数来计算三个基本总和，如下所示：
- en: '[PRE35]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We've plugged in a small `lambda` to compute ![Writing higher-order reductions](graphics/B03652_06_23.jpg),
    which is the count, ![Writing higher-order reductions](graphics/B03652_06_24.jpg),
    the sum, and ![Writing higher-order reductions](graphics/B03652_06_25.jpg), the
    sum of the squares, which we can use to compute standard deviation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们插入了一个小的`lambda`来计算![Writing higher-order reductions](graphics/B03652_06_23.jpg)，即计数，![Writing
    higher-order reductions](graphics/B03652_06_24.jpg)，即总和，以及![Writing higher-order
    reductions](graphics/B03652_06_25.jpg)，即平方和，我们可以用它来计算标准偏差。
- en: 'A common extension to this includes a filter to reject raw data which is unknown
    or unsuitable in some way. We might use the following command to reject bad data:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常包括一个过滤器，用于拒绝某种方式未知或不合适的原始数据。我们可以使用以下命令来拒绝错误的数据：
- en: '[PRE36]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Execution of the following command snippet allows us to do things like reject
    `None` values in a simple way:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下命令片段允许我们以简单的方式拒绝`None`值：
- en: '[PRE37]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This shows how we can provide two distinct `lambda` to our `sum_filter_f()`
    function. The `filter` argument is a `lambda` that rejects `None` values, we've
    called it `valid` to emphasize its meaning. The `function` argument is a `lambda`
    that implements a `count` or a `sum` method. We can easily add a `lambda` to compute
    a sum of squares.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了我们如何向`sum_filter_f()`函数提供两个不同的`lambda`。`filter`参数是一个拒绝`None`值的`lambda`，我们称之为`valid`以强调其含义。`function`参数是一个实现`count`或`sum`方法的`lambda`。我们可以轻松地添加一个`lambda`来计算平方和。
- en: It's important to note that this function is similar to other examples in that
    it actually returns a function rather than a value. This is one of the defining
    characteristics of higher-order functions, and is pleasantly simple to implement
    in Python.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，这个函数与其他示例类似，因为它实际上返回一个函数而不是一个值。这是高阶函数的定义特征之一，在Python中实现起来非常简单。
- en: Writing file parsers
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写文件解析器
- en: 'We can often consider a file parser to be a kind of reduction. Many languages
    have two levels of definition: the lower-level tokens in the language and the
    higher-level structures built from those tokens. When looking at an XML file,
    the tags, tag names, and attribute names form this lower-level syntax; the structures
    which are described by XML form a higher-level syntax.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常可以将文件解析器视为一种缩减。许多语言有两个级别的定义：语言中的低级标记和从这些标记构建的高级结构。当查看XML文件时，标签、标签名称和属性名称形成了这种低级语法；由XML描述的结构形成了高级语法。
- en: 'The lower-level lexical scanning is a kind of reduction that takes individual
    characters and groups them into tokens. This fits well with Python''s generator
    function design pattern. We can often write functions that look as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 低级词法扫描是一种将单个字符组合成标记的缩减。这与Python的生成器函数设计模式非常匹配。我们经常可以编写如下的函数：
- en: '[PRE38]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: For our purposes, we'll rely on lower-level file parsers to handle this for
    us. We'll use the CSV, JSON, and XML packages to manage these details. We'll write
    higher-level parsers based on these packages.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们将依赖于低级文件解析器来处理这些问题。我们将使用CSV、JSON和XML包来管理这些细节。我们将基于这些包编写高级解析器。
- en: We'll still rely on a two-level design pattern. A lower-level parser will produce
    a useful canonical representation of the raw data. It will be an iterator over
    tuples of text. This is compatible with many kinds of data files. The higher-level
    parser will produce objects useful for our specific application. These might be
    tuples of numbers, or namedtuples, or perhaps some other class of immutable Python
    objects.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然依赖于两级设计模式。一个低级解析器将产生原始数据的有用的规范表示。它将是一个文本元组的迭代器。这与许多种类的数据文件兼容。高级解析器将产生对我们特定应用程序有用的对象。这些可能是数字元组，或者是命名元组，或者可能是一些其他类的不可变Python对象。
- en: 'We provided one example of a lower-level parser in [Chapter 4](ch04.html "Chapter 4. Working
    with Collections"), *Working with Collections*. The input was a KML file; KML
    is an XML representation of geographic information. The essential features of
    the parser look similar to the following command snippet:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4章](ch04.html "第4章。处理集合")*处理集合*中提供了一个低级解析器的示例。输入是一个KML文件；KML是地理信息的XML表示。解析器的基本特征看起来类似于以下命令片段：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The bulk of the `row_iter_kml()` function is the XML parsing that allows us
    to use the `doc.findall()` function to iterate through the `<ns0:coordinates>`
    tags in the document. We've used a function named `comma_split()` to parse the
    text of this tag into a three tuple of values.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`row_iter_kml()`函数的主要部分是XML解析，它允许我们使用`doc.findall()`函数来迭代文档中的`<ns0:coordinates>`标签。我们使用了一个名为`comma_split()`的函数来解析这个标签的文本为一个三元组的值。'
- en: This is focused on working with the normalized XML structure. The document mostly
    fits the database designer's definitions of **First Normal Form**, that is, each
    attribute is atomic and only a single value. Each row in the XML data had the
    same columns with data of a consistent type. The data values weren't properly
    atomic; we had to split the points on a "," to separate longitude, latitude, and
    altitude into atomic string values.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这专注于使用规范化的XML结构。文档大部分符合数据库设计师对**第一范式**的定义，也就是说，每个属性都是原子的，只有一个值。XML数据中的每一行都具有相同的列，数据类型一致。数据值并不是完全原子的；我们需要将经度、纬度和海拔分割成原子字符串值。
- en: A large volume of data – xml tags, attributes, and other punctuation – was reduced
    to a somewhat smaller volume including just floating-point latitude and longitude
    values. For this reason, we can think of parsers as a kind of reduction.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 大量数据——xml标签、属性和其他标点——被缩减为一个相对较小的体积，其中只包括浮点纬度和经度值。因此，我们可以将解析器视为一种缩减。
- en: 'We''ll need a higher-level set of conversions to map the tuples of text into
    floating-point numbers. Also, we''d like to discard altitude, and reorder longitude
    and latitude. This will produce the application-specific tuple we need. We can
    use functions as follows for this conversion:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个更高级别的转换来将文本的元组映射为浮点数。此外，我们希望丢弃海拔，并重新排列经度和纬度。这将产生我们需要的特定于应用程序的元组。我们可以使用以下函数进行此转换：
- en: '[PRE40]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The essential tool is the `float_lat_lon()` function. This is a higher-order
    function which returns a generator expression. The generator uses `map()` function
    to apply the `float()` function conversion to the results of `pick_lat_lon()`
    class. We've used the `*row` parameter to assign each member of the row `tuple`
    to a different parameter of the `pick_lat_lon()` function. This function then
    returns a tuple of the selected items in the required order.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 关键工具是`float_lat_lon()`函数。这是一个返回生成器表达式的高阶函数。生成器使用`map()`函数将`float()`函数转换应用到`pick_lat_lon()`类的结果上。我们使用`*row`参数将行元组的每个成员分配给`pick_lat_lon()`函数的不同参数。然后该函数以所需顺序返回所选项目的元组。
- en: 'We can use this parser as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式使用此解析器：
- en: '[PRE41]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This will build a tuple-of-tuple representation of each waypoint along the path
    in the original KML file. It uses a low-level parser to extract rows of text data
    from the original representation. It uses a high-level parser to transform the
    text items into more useful tuples of floating-point values. In this case, we
    have not implemented any validation.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为原始KML文件中路径上的每个航路点构建一个元组表示。它使用低级解析器从原始表示中提取文本数据行。它使用高级解析器将文本项转换为更有用的浮点值元组。在这种情况下，我们没有实现任何验证。
- en: Parsing CSV files
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解析CSV文件
- en: 'In [Chapter 3](ch03.html "Chapter 3. Functions, Iterators, and Generators"),
    *Functions, Iterators and Generators*, we saw another example where we parsed
    a CSV file that was not in a normalized form: we had to discard header rows to
    make it useful. To do this, we used a simple function that extracted the header
    and returned an iterator over the remaining rows.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html“第3章。函数，迭代器和生成器”)，“函数，迭代器和生成器”中，我们看到了另一个例子，我们解析了一个不是规范化形式的CSV文件：我们不得不丢弃标题行才能使其有用。为了做到这一点，我们使用了一个简单的函数，提取了标题并返回了剩余行的迭代器。
- en: 'The data looks as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下：
- en: '[PRE42]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The columns are separated by tab characters. Plus there are three rows of headers
    that we can discard.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 列由制表符分隔。另外还有三行标题，我们可以丢弃。
- en: 'Here''s another version of that CSV-based parser. We''ve broken it into three
    functions. The first, `row_iter()` function, returns the iterator over the rows
    in a tab-delimited file. The function looks as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于CSV的解析器的另一个版本。我们将其分为三个函数。第一个`row_iter()`函数返回制表符分隔文件中行的迭代器。函数如下所示：
- en: '[PRE43]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This is a simple wrapper around the CSV parsing process. When we look back at
    the previous parsers for XML and plain text, this was the kind of thing that was
    missing from those parsers. Producing an iterable over row tuples can be a common
    feature of parsers for normalized data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这是围绕CSV解析过程的简单包装。当我们回顾以前用于XML和纯文本的解析器时，这是那些解析器缺少的东西。生成可迭代的行元组可以是规范化数据解析器的常见特征。
- en: Once we have a row of tuples, we can pass rows that contain usable data and
    reject rows that contain other metadata, like titles and column names. We'll introduce
    a helper function that we can use to do some of the parsing, plus a `filter()`
    function to validate a row of data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了一行元组，我们可以传递包含可用数据的行，并拒绝包含其他元数据的行，例如标题和列名。我们将介绍一个辅助函数，我们可以使用它来执行一些解析，以及一个`filter()`函数来验证数据行。
- en: 'Following is the conversion:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是转换：
- en: '[PRE44]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This function handles the conversion of a single `string` to `float` values,
    converting bad data to `None` value. We can embed this function in a mapping so
    that we convert all columns of a row to a `float` or `None` value. The `lambda`
    looks as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数处理将单个`string`转换为`float`值，将错误数据转换为`None`值。我们可以将此函数嵌入到映射中，以便将行的所有列转换为`float`或`None`值。`lambda`如下所示：
- en: '[PRE45]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Following is a row-level validator based on the use of the `all()` function
    to assure that all values are `float` (or none of the values are `None`):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于使用`all()`函数的行级验证器，以确保所有值都是`float`（或没有值是`None`）：
- en: '[PRE46]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Following is a higher-order function which combines the row-level conversion
    and filtering:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个高阶函数，它结合了行级转换和过滤：
- en: '[PRE47]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This function gives us a slightly more complete pattern for parsing an input
    file. The foundation is a lower-level function that iterates over tuples of text.
    We can then wrap this in functions to convert and validate the converted data.
    For the cases where files are either in first normal form (all rows are the same)
    or a simple validator can reject the other rows, this design works out nicely.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数为我们提供了一个稍微更完整的解析输入文件的模式。基础是一个低级函数，它迭代文本元组。然后我们可以将其包装在函数中以转换和验证转换后的数据。对于文件要么处于第一正规形式（所有行都相同），要么简单验证器可以拒绝其他行的情况，这种设计非常有效。
- en: All parsing problems aren't quite this simple, however. Some files have important
    data in header or trailer rows that must be preserved, even though it doesn't
    match the format of the rest of the file. These non-normalized files will require
    a more sophisticated parser design.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有解析问题都如此简单。一些文件的重要数据位于必须保留的标题或尾随行中，即使它与文件的其余部分的格式不匹配。这些非规范化文件将需要更复杂的解析器设计。
- en: Parsing plain text files with headers
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解析带有标题的纯文本文件
- en: 'In [Chapter 3](ch03.html "Chapter 3. Functions, Iterators, and Generators"),
    *Functions, Iterators, and Generators*, the `Crayola.GPL` file was presented without
    showing the parser. This file looks as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html“第3章。函数，迭代器和生成器”)，“函数，迭代器和生成器”中，`Crayola.GPL`文件是在没有显示解析器的情况下呈现的。该文件如下所示：
- en: '[PRE48]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We can parse a text file using regular expressions. We need to use a filter
    to read (and parse) header rows. We also want to return an iterable sequence of
    data rows. This rather complex two-part parsing is based entirely on the two-part
    – head and tail – file structure.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用正则表达式解析文本文件。我们需要使用过滤器来读取（和解析）标题行。我们还希望返回一个可迭代的数据行序列。这种相当复杂的两部分解析完全基于两部分
    - 头部和尾部 - 文件结构。
- en: 'Following is a low-level parser that handles both head and tail:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是处理头部和尾部的低级解析器：
- en: '[PRE49]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We've defined a regular expression that parses all four lines of the header,
    and assigned this to the `header_pat` variable. There are two internal functions
    for parsing different parts of the file. The `read_head()` function parses the
    header lines. It does this by reading four lines and merging them into a single
    long `string`. This is then parsed with the regular expression. The results include
    the two data items from the header plus an iterator ready to process additional
    lines.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了一个正则表达式，用于解析标题的所有四行，并将其分配给`header_pat`变量。有两个内部函数用于解析文件的不同部分。`read_head()`函数解析标题行。它通过读取四行并将它们合并成一个长字符串来实现这一点。然后使用正则表达式对其进行解析。结果包括标题中的两个数据项以及一个准备处理额外行的迭代器。
- en: The `read_tail()` function accepts the output from the `read_head()` function
    and parses the iterator over the remaining lines. The parsed information from
    the header rows forms a two tuple that is given to the `read_tail()` function
    along with the iterator over the remaining lines. The remaining lines are merely
    split on spaces, since that fits the description of the GPL file format.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_tail()`函数接受`read_head()`函数的输出，并解析剩余行的迭代器。标题行的解析信息形成一个两元组，与剩余行的迭代器一起传递给`read_tail()`函数。剩余行仅仅是按空格分割，因为这符合GPL文件格式的描述。'
- en: Note
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'For more information, visit the following link:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请访问以下链接：
- en: '[https://code.google.com/p/grafx2/issues/detail?id=518](https://code.google.com/p/grafx2/issues/detail?id=518).'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://code.google.com/p/grafx2/issues/detail?id=518](https://code.google.com/p/grafx2/issues/detail?id=518)。'
- en: Once we've transformed each line of the file into a canonical tuple-of-strings
    format, we can apply the higher level of parsing to this data. This involves conversion
    and (if necessary) validation.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将文件的每一行转换为规范的字符串元组格式，我们就可以对这些数据应用更高级别的解析。这涉及转换和（如果必要）验证。
- en: 'Following is a higher-level parser command snippet:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个更高级别的解析器命令片段：
- en: '[PRE50]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This function will work with the output of the lower-level `row_iter_gpl()`
    parser: it requires the headers and the iterator. This function will use the multiple
    assignment to separate the `color` numbers and the remaining words into four variables,
    `r`, `g`, `b,` and `name`. The use of the `*name` parameter assures that all remaining
    values will be assigned to names as a `tuple`. The `" ".join(name)` method then
    concatenates the words into a single space-separated string.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将使用低级`row_iter_gpl()`解析器的输出：它需要标题和迭代器。这个函数将使用多重赋值将`color`数字和剩余单词分成四个变量，`r`、`g`、`b`和`name`。使用`*name`参数确保所有剩余值都将被分配给名字作为一个`tuple`。然后`"
    ".join(name)`方法将单词连接成一个以空格分隔的字符串。
- en: 'Following is how we can use this two-tier parser:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何使用这个两层解析器：
- en: '[PRE51]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We've applied the higher-level parser to the results of the lower-level parser.
    This will return the headers and a tuple built from the sequence of `Color` objects.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将高级解析器应用于低级解析器的结果。这将返回标题和从`Color`对象序列构建的元组。
- en: Summary
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've looked at two significant functional programming topics.
    We've looked at recursions in some detail. Many functional programming language
    compilers will optimize a recursive function to transform a call in the tail of
    the function to a loop. In Python, we must do the tail-call optimization manually
    by using an explicit `for` loop instead of a purely function recursion.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们已经详细讨论了两个重要的函数式编程主题。我们详细讨论了递归。许多函数式编程语言编译器将优化递归函数，将函数尾部的调用转换为循环。在Python中，我们必须通过使用显式的`for`循环而不是纯函数递归来手动进行尾调用优化。
- en: We've also looked at reduction algorithms including `sum()`, `count()`, `max(),`
    and `min()` functions. We looked at the `collections.Counter()` function and related
    `groupby()` reductions.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了包括`sum()`、`count()`、`max()`和`min()`函数在内的归约算法。我们研究了`collections.Counter()`函数和相关的`groupby()`归约。
- en: We've also looked at how parsing (and lexical scanning) are similar to reductions
    since they transform sequences of tokens (or sequences of characters) into higher-order
    collections with more complex properties. We've examined a design pattern that
    decomposes parsing into a lower level that tries to produce tuples of raw strings
    and a higher level that creates more useful application objects.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了解析（和词法扫描）如何类似于归约，因为它们将标记序列（或字符序列）转换为具有更复杂属性的高阶集合。我们研究了一种将解析分解为尝试生成原始字符串元组的较低级别和创建更有用的应用对象的较高级别的设计模式。
- en: In the next chapter, we'll look at some techniques appropriate to working with
    namedtuples and other immutable data structures. We'll look at techniques that
    make stateful objects unnecessary. While stateful objects aren't purely functional,
    the idea of a class hierarchy can be used to package related method function definitions.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究一些适用于使用命名元组和其他不可变数据结构的技术。我们将研究一些使有状态对象不必要的技术。虽然有状态的对象并不是纯粹的函数式，但类层次结构的概念可以用来打包相关的方法函数定义。
