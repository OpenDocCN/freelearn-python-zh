- en: Python and the Web – Using urllib and Requests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python和Web - 使用urllib和Requests
- en: From the previous chapter, we now have an idea about what web scraping is, what
    the core development technologies that exist are, and where or how we can plan
    to find the information we are looking for.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章，我们现在对Web抓取是什么，存在哪些核心开发技术以及我们可以计划在哪里或如何找到我们正在寻找的信息有了一个概念。
- en: Web scraping requires tools and techniques to be implemented and deployed using
    scripts or programs. The Python programming language consists of a huge set of
    libraries that are fit for interacting with the web and for scraping purposes. In
    this chapter, we will communicate with web resources using Python; we'll also explore
    and search for the contents to be extracted from the web.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Web抓取需要使用脚本或程序实施和部署的工具和技术。Python编程语言包括一大批适用于与Web交互和抓取目的的库。在本章中，我们将使用Python与Web资源进行通信；我们还将探索并搜索要从Web中提取的内容。
- en: This chapter will also provide a detailed overview of using Python libraries
    such as `requests` and `urllib`.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还将详细介绍使用Python库，如`requests`和`urllib`。
- en: 'In particular, we will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将学习以下主题：
- en: Setting Python and its required libraries, `requests` and `urllib`, to load
    URLs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Python及其所需的库`requests`和`urllib`来加载URL
- en: A detailed overview of `requests` and `urllib`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`和`urllib`的详细概述'
- en: Implementing HTTP methods (`GET`/`POST`)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现HTTP方法（`GET`/`POST`）
- en: We assume that you have some prior basic experience of using the Python programming
    language. If not, then please refer to Python tutorials from W3schools ([https://www.w3schools.com/python/default.asp](https://www.w3schools.com/python/default.asp)),
    Python course ([https://python-course.eu/](https://python-course.eu/)), or search
    Google for *learn Python programming*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您具有一些使用Python编程语言的基本经验。如果没有，请参考W3schools的Python教程（[https://www.w3schools.com/python/default.asp](https://www.w3schools.com/python/default.asp)）、Python课程（[https://python-course.eu/](https://python-course.eu/)）或在Google上搜索*学习Python编程*。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We will be using Python 3.7.0, which has been installed on the Windows operating
    system. There are plenty of choices for code editors; choose one that is convenient
    to use and deal with the libraries that are used in this chapter's code examples.
    We will be using PyCharm (Community Edition [https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=windows&code=PCC](https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=windows&code=PCC)) from
    JetBrains and Python IDLE ([https://www.python.org/downloads/](https://www.python.org/downloads/)) side
    by side.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用已安装在Windows操作系统上的Python 3.7.0。有很多选择的代码编辑器；选择一个方便使用并处理本章代码示例中使用的库的编辑器。我们将同时使用来自JetBrains的PyCharm（社区版[https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=windows&code=PCC](https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=windows&code=PCC)）和Python
    IDLE（[https://www.python.org/downloads/](https://www.python.org/downloads/)）。
- en: 'To follow along with this chapter, you will need to install the following applications:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟着本章进行，您需要安装以下应用程序：
- en: Python 3.7.* or the latest version that's appropriate for your OS: [https://www.python.org/downloads/](https://www.python.org/downloads/)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.*或适合您操作系统的最新版本：[https://www.python.org/downloads/](https://www.python.org/downloads/)
- en: The `pip` Python package management: [https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` Python软件包管理：[https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)'
- en: Either Google Chrome or Mozilla Firefox
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要么使用谷歌Chrome，要么使用Mozilla Firefox
- en: JetBrains PyCharm or Visual Studio Code
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JetBrains PyCharm或Visual Studio Code
- en: 'The Python libraries that are required for this chapter are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所需的Python库如下：
- en: '`requests`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`'
- en: '`urllib`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urllib`'
- en: The code files for this chapter are available online on GitHub: [https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter02](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter02).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可在GitHub上找到：[https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter02](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter02)。
- en: Accessing the web with Python
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python访问网络
- en: Python is a programming language that's used to code various types of applications,
    from simple scripts to AI algorithms and web frameworks. We will be writing scripts
    in Python to access the URLs that we are interested in from a data extraction
    or scraping perspective.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种用于编写各种类型应用程序的编程语言，从简单脚本到人工智能算法和Web框架。我们将使用Python编写脚本来从数据提取或抓取的角度访问我们感兴趣的URL。
- en: A number of Python libraries exist for HTTP communication and web-related purposes
    (including `http`, `cookielib`, `urllib`, `requests`, `html`, `socket`, `json`,
    `xmlrpc`, `httplib2`, and `urllib3`). We will explore and use a few of them that
    have been praised by the programmers' community for HTTP access or client-server
    communication. The `urllib` and `requests` Python modules are the ones we are
    interested in using. These libraries possess various functions that can be used
    to communicate with the web using Python and deal with HTTP requests and responses.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多用于HTTP通信和与Web相关目的的Python库（包括`http`、`cookielib`、`urllib`、`requests`、`html`、`socket`、`json`、`xmlrpc`、`httplib2`和`urllib3`）。我们将探索并使用一些被程序员社区赞扬的用于HTTP访问或客户端-服务器通信的库。我们感兴趣使用的是`urllib`和`requests`
    Python模块。这些库具有各种函数，可用于使用Python与Web通信并处理HTTP请求和响应。
- en: In order to start a few coding tasks and explore the Python-based modules straightaway,
    let's verify that we have installed all the Python resources we want before moving
    on.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了立即开始一些编码任务并探索基于Python的模块，让我们在继续之前验证我们已经安装了所有想要的Python资源。
- en: Setting things up
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置事物
- en: It is assumed that Python has been preinstalled. If not, please visit [https://www.python.org/downloads/](https://www.python.org/downloads/) and [https://www.python.org/download/other/](https://www.python.org/download/other/)
    for the latest Python version for your operating system. Regarding the general
    setup and installation procedure, please visit [https://realpython.com/installing-python/](https://realpython.com/installing-python/) to
    find out how to install Python on your chosen platform. We will be using the Windows
    operating system here.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设Python已预先安装。如果没有，请访问[https://www.python.org/downloads/](https://www.python.org/downloads/)和[https://www.python.org/download/other/](https://www.python.org/download/other/)获取您操作系统的最新Python版本。关于一般设置和安装程序，请访问[https://realpython.com/installing-python/](https://realpython.com/installing-python/)了解如何在您选择的平台上安装Python。我们将在这里使用Windows操作系统。
- en: To verify that we have all the required tools available, let's check that Python
    and `pip` are installed and are up to date.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们是否拥有所有所需的工具，请检查Python和`pip`是否已安装并且是否是最新版本。
- en: '`pip` package management system is used to install and manage software packages
    written in Python. More on installing Python packages and `pip` can be found at [https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip`包管理系统用于安装和管理用Python编写的软件包。有关安装Python软件包和`pip`的更多信息，请访问[https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)。'
- en: 'We will be using Python 3.7 on the Windows operating system. Press Windows
    + *R* to open the Run box and type `cmd` to get the command-line interface:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在Windows操作系统上使用Python 3.7。按下Windows + *R*打开运行框，输入`cmd`以获取命令行界面：
- en: '![](assets/c9e94300-8d7a-4f84-875d-c926ec32cce7.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c9e94300-8d7a-4f84-875d-c926ec32cce7.png)'
- en: Opening the command-line interface on the Windows operating system
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows操作系统上打开命令行界面
- en: 'Now, move to your root directory and type the following command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，转到您的根目录并键入以下命令：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding command will provide us with the Python version that we currently
    have on our system. Let''s get some information on the `pip` version that we are
    using. The following command will display the current `pip` version, as well as
    its location:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将为我们提供当前系统上的Python版本。让我们获取一些关于我们正在使用的`pip`版本的信息。以下命令将显示当前的`pip`版本以及其位置：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We are happy to proceed after seeing the preceding responses. If you encounter
    an error stating Application not found or `not recognized as an internal or external
    command`, then we need to reinstall Python or check for the proper drive that
    was used during installation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到前面的响应后，我们很高兴继续进行。如果遇到“找不到应用程序”或“不被识别为内部或外部命令”的错误，则需要重新安装Python或检查安装过程中使用的正确驱动器。
- en: It's always advisable to check for the system and library version and keep them
    updated unless a specific version is required.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 始终建议检查系统和库的版本，并保持它们更新，除非需要特定版本。
- en: 'To update `pip` to its latest release, use the following command:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要将`pip`更新到最新版本，请使用以下命令：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can verify the libraries we wish to use, that is, `requests` and `urllib`,
    either from the command line or by importing the Python IDE and getting details
    on the package using the `help()` method:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以验证我们希望使用的库，即`requests`和`urllib`，可以从命令行或通过导入Python IDE并使用`help()`方法获取有关包的详细信息：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As shown in the preceding code, we are trying to install `requests`, but the
    command returns `Requirement already satisfied`. The `pip` command checks for
    an existing installation on the system before installing a fresh library.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，我们尝试安装`requests`，但命令返回“要求已满足”。`pip`命令在安装新库之前会检查系统上是否已存在安装。
- en: In the following code block, we will be using the Python IDE to import `urllib`.
    We'll view its details using Python's built-in `help()` method*.*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们将使用Python IDE来导入`urllib`。我们将使用Python的内置`help()`方法查看其详细信息。
- en: 'The `>>>` symbol in code represents use of the Python IDE; it accepts the code
    or instructions and displays the output on the next line:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的`>>>`符号表示使用Python IDE；它接受代码或指令，并在下一行显示输出：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following is the output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Similar to the previous code, lets import `requests` using the Python IDE:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的代码类似，让我们在Python IDE中导入`requests`：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If we import `urllib `or `requests` and these libraries don''t exist, the result
    will throw an error:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们导入`urllib`或`requests`，并且这些库不存在，结果将会抛出错误：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For missing modules or in the previous case, install the module first; use
    `pip` as follows to install or upgrade. You can install it from your command line,
    as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于缺少的模块或在先前的情况下，首先安装模块；使用以下`pip`安装或升级。您可以按照以下方式从命令行安装它：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can also upgrade the module version using the `--upgrade` argument:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用`--upgrade`参数升级模块版本：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Loading URLs
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载URL
- en: Now that we've confirmed the required libraries and system requirements, we
    will proceed with loading the URLs. While looking for contents from a URL, it
    is also necessary to confirm and verify the exact URL that has been chosen for
    the required content. Contents can be found on single web pages or scattered across
    multiple pages, and it might not always be the HTML sources we are looking for.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已确认所需的库和系统要求，我们将继续加载URL。在查找URL的内容时，还需要确认和验证已选择的所需内容的确切URL。内容可以在单个网页上找到，也可以分布在多个页面上，并且可能并非始终是我们要寻找的HTML源。
- en: We will load some URLs and explore the content using a couple of tasks.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载一些URL并使用一些任务来探索内容。
- en: Before loading URLs using Python script, it's also advisable to verify the URLs
    are working properly and contain the detail we are looking for, using web browsers.
    Developer tools can also be used for similar scenarios, as discussed in [Chapter
    1](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml), *Web Scraping Fundamentals*, in
    the *Developer tools* section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Python脚本加载URL之前，还建议使用Web浏览器验证URL是否正常工作并包含我们正在寻找的详细信息。开发人员工具也可以用于类似的场景，如[第1章](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml)中所讨论的*Web
    Scraping Fundamentals*的*Developer tools*部分。
- en: '**Task 1**: To view data related to the listings of the most popular websites
    from Wikipedia. We will identify data from the Site, Domain, and Type columns
    in the page source.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**任务1**：查看来自维基百科的最受欢迎网站列表相关的数据。我们将从页面源中识别*Site*、*Domain*和*Type*列中的数据。'
- en: We will follow the steps at the following link to achieve our task (a data extraction-related
    activity will be done in [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XPath and CSS Selectors*): [https://en.wikipedia.org/wiki/List_of_most_popular_websites](https://en.wikipedia.org/wiki/List_of_most_popular_websites).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下链接中的步骤来完成我们的任务（[第3章](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml)将进行与数据提取相关的活动，*Using
    LXML, XPath and CSS Selectors*）：[https://en.wikipedia.org/wiki/List_of_most_popular_websites](https://en.wikipedia.org/wiki/List_of_most_popular_websites)。
- en: Search Wikipedia for the information we are looking for. The preceding link
    can be easily viewed in a web browser. The content is in tabular format (as shown
    in the following screenshot), and so the data can be collected by repeatedly using
    the select, copy, and paste actions, or by collecting all the text inside the
    table.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索维基百科以获取我们正在寻找的信息。前面的链接可以在Web浏览器中轻松查看。内容以表格格式呈现（如下面的屏幕截图所示），因此可以通过重复使用选择、复制和粘贴操作，或者收集表格内的所有文本来收集数据。
- en: 'However, such actions will not result in the content that we are interested
    in being in a desirable format, or it will require extra editing and formatting
    tasks being performed on the text to achieve the desired result. We are also not
    interested in the page source that''s obtained from the browser:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这样的操作不会导致我们感兴趣的内容以理想的格式显示，或者将需要在文本上执行额外的编辑和格式化任务才能实现所需的结果。我们也对从浏览器获取的页面源不感兴趣：
- en: '![](assets/ff896cba-9530-485c-bdd9-130ac843833d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ff896cba-9530-485c-bdd9-130ac843833d.png)'
- en: Page from Wikipedia, that is, https://en.wikipedia.org/wiki/List_of_most_popular_websites
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 来自维基百科的页面，即https://en.wikipedia.org/wiki/List_of_most_popular_websites
- en: 'After finalizing the link that contains the content we require, let''s load
    the link using Python. We are making a request to the link and willing to see
    the response returned by both libraries, that is, `urllib` and `requests`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定包含我们需要的内容的链接后，让我们使用Python加载链接。我们正在请求链接，并希望看到由`urllib`和`requests`返回的响应：
- en: 'Let''s use `urllib`:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用`urllib`：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `urlopen()` function from `urllib.request` has been passed with the selected
    URL or request that has been made to the URL and `response` is received, that
    is, `HTTPResponse`. `response` that's received for the request made can be read
    using the `read()` method.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.request`中的`urlopen()`函数已经传递了所选的URL或对URL进行的请求，并收到了`response`，即`HTTPResponse`。可以使用`read()`方法读取对请求的`response`。'
- en: '2\. Now, let''s use `requests`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 现在，让我们使用`requests`：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we are using the `requests` module to load the page source, just like
    we did using `urllib`. `requests` with the `get()` method, which accepts a URL
    as a parameter. The `response` type for both examples has also been checked.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`requests`模块来加载页面源，就像我们使用`urllib`一样。`requests`使用`get()`方法，该方法接受URL作为参数。对于这两个示例，也已经检查了`response`类型。
- en: The output that's displayed in the preceding code blocks has been shortened.
    You can find the code files for this at [https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中显示的输出已经被缩短。您可以在[https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python)找到此代码文件。
- en: In the preceding examples, the page content—or the `response` object—contains
    the details we were looking for, that is, the Site, Domain, and Type columns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，页面内容或`response`对象包含了我们正在寻找的详细信息，即*Site*、*Domain*和*Type*列。
- en: We can choose any one library to deal with the HTTP request and response. Detailed
    information on these two Python libraries with examples is provided in the next
    section, *URL handling and operations with urllib and requests*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择任何一个库来处理HTTP请求和响应。关于这两个Python库的详细信息和示例将在下一节*URL handling and operations
    with urllib and requests*中提供。
- en: 'Let''s have a look at the following screenshot:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下下面的屏幕截图：
- en: '![](assets/6ea4c570-0bf3-4c2b-b970-a0978b106125.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6ea4c570-0bf3-4c2b-b970-a0978b106125.png)'
- en: Wikipedia.com page content, viewed using Python libraries
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python库查看维基百科页面内容
- en: Further activities like processing and parsing can be applied to content like
    this in order to extract the required data. More details about further processing
    tools/techniques and parsing can be found in [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XP**ath, and CSS Selectors,* [Chapter 4](30c30342-63a5-4452-9f61-a05a2e69e256.xhtml),
    *Scraping Using pyquery – a Python Library*, and [Chapter 5](5869ee86-6c67-4e6f-8151-61093795d94f.xhtml),
    *Web Scraping Using Scrapy an**d Beautiful Soup*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步的活动，如处理和解析，可以应用于这样的内容，以提取所需的数据。有关进一步处理工具/技术和解析的更多详细信息可以在[第3章](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml)、*Using
    LXML, XPath, and CSS Selectors*，[第4章](30c30342-63a5-4452-9f61-a05a2e69e256.xhtml)、*Scraping
    Using pyquery – a Python Library*和[第5章](5869ee86-6c67-4e6f-8151-61093795d94f.xhtml)、*Web
    Scraping Using Scrapy and Beautiful Soup*中找到。
- en: '**Task 2**: Load and save the page content from [https://www.samsclub.com/robots.txt](https://www.samsclub.com/robots.txt)
    and [https://www.samsclub.com/sitemap.xml](https://www.samsclub.com/sitemap.xml)
    using `urllib` and `requests`.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**任务2**：使用`urllib`和`requests`加载并保存来自[https://www.samsclub.com/robots.txt](https://www.samsclub.com/robots.txt)和[https://www.samsclub.com/sitemap.xml](https://www.samsclub.com/sitemap.xml)的页面内容。'
- en: 'Generally, websites provide files in their root path (for more information
    on these files, please refer to [Chapter 1](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml),
    *Web Scraping Fundamentals*, the *Data finding techniques for the web* section):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，网站在其根路径中提供文件（有关这些文件的更多信息，请参阅[第1章](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml)，*网络抓取基础知识*，*网络数据查找技术*部分）：
- en: '`robots.txt`: This contains information for the crawler, web agents, and so
    on'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`robots.txt`：其中包含爬虫、网络代理等的信息'
- en: '`sitemap.xml`: This contains links to recently modified files, published files,
    and so on'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sitemap.xml`：其中包含最近修改的文件、发布的文件等的链接'
- en: 'From *Task 1*, we were able to load the URL and retrieve its content. Saving
    the content to local files using libraries methods and using file handling concepts
    will be implemented in this task. Saving content to local files and working on
    content with tasks like parsing and traversing can be really quick and even reduce
    network resources:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从*任务1*中，我们能够加载URL并检索其内容。将内容保存到本地文件并使用文件处理概念将在此任务中实现。将内容保存到本地文件并处理内容，如解析和遍历等任务，可以非常快速，甚至可以减少网络资源：
- en: 'Load and save the content from [https://www.samsclub.com/robots.txt](https://www.samsclub.com/robots.txt)
    using `urllib`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`urllib`加载并保存来自[https://www.samsclub.com/robots.txt](https://www.samsclub.com/robots.txt)的内容：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `urlretrieve()` function, that is, `urlretrieve(url, filename=None, reporthook=None,
    data=None)`, from `urllib.request` returns a tuple with the filename and HTTP
    headers. You can find this file in the `C:\\Users..Temp` directory if no path
    is given; otherwise, the file will be generated in the current working directory
    with the name provided to the `urlretrieve()` method as the second argument. This
    was `testrobots.txt` in the preceding code:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlretrieve()`函数，即`urlretrieve(url, filename=None, reporthook=None, data=None)`，从`urllib.request`返回一个包含文件名和HTTP头的元组。如果没有给出路径，可以在`C:\\Users..Temp`目录中找到此文件；否则，文件将在当前工作目录中生成，文件名由`urlretrieve()`方法的第二个参数提供。在前面的代码中，这是`testrobots.txt`：'
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the preceding code, we are reading the URL and writing the content found
    using a file handling concept.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们正在读取URL并使用文件处理概念编写找到的内容。
- en: 'Load and save the content from [https://www.samsclub.com/sitemap.xml](https://www.samsclub.com/sitemap.xml) using
    `requests`:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`requests`加载并保存来自[https://www.samsclub.com/sitemap.xml](https://www.samsclub.com/sitemap.xml)的内容：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In both cases, we were able to find the content from the respective URL and
    save it to individual files and locations. The contents from the preceding code
    was found as bytes literals, for example, `b'<!DOCTYPE …` or `b'<?xml`. Page content
    can also be retrieved in a text format, such as `requests.get(link).text`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们都能够从相应的URL中找到内容并将其保存到各自的文件和位置。前面的代码中的内容被发现为字节文字，例如`b'<!DOCTYPE …`或`b'<?xml`。页面内容也可以以文本格式检索，例如`requests.get(link).text`。
- en: 'We can use the `decode()` method to convert bytes into a string and the `encode()` method
    to convert a string into bytes, as shown in the following code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`decode()`方法将字节转换为字符串，使用`encode()`方法将字符串转换为字节，如下面的代码所示：
- en: '[PRE15]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Identifying a proper character set or `charset` is important when dealing with
    various domains and type of documents. To identify a proper `charset` encoding
    type, we can seek help from the page source for the `<meta>` tag by using `content-type`
    or `charset`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理各种域和文档类型时，识别适当的字符集或`charset`是很重要的。要识别适当的`charset`编码类型，我们可以通过使用`content-type`或`charset`从页面源中寻求`<meta>`标签的帮助。
- en: 'The `<meta>` tag with the `charset` attribute, that is, `<meta charset="utf-8"/>`, is
    identified from the page source, as shown in the following screenshot (or `<meta
    http-equiv="content-type" content="text/html; charset=utf-8">`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从页面源中识别带有`charset`属性的`<meta>`标签，如下面的屏幕截图所示（或`<meta http-equiv="content-type"
    content="text/html; charset=utf-8">`：
- en: '![](assets/a224b37e-d00d-44a2-a460-7fcb132b97eb.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a224b37e-d00d-44a2-a460-7fcb132b97eb.png)'
- en: Identifying charset from the document response or page source
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从文档响应或页面源中识别字符集
- en: 'Also, the content for `<meta http-equiv="content-type" content="text/html;
    charset=utf-8">` can be obtained from the response header, as highlighted in the
    following screenshot:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`<meta http-equiv="content-type" content="text/html; charset=utf-8">`的内容可以从响应头中获取，如下面的屏幕截图所示：
- en: '![](assets/5b46e1f3-ee12-4967-8388-4b10b4f82ad1.png)Identifying charset through
    the browser DevTools, Network panel, Headers tab, and response headers'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/5b46e1f3-ee12-4967-8388-4b10b4f82ad1.png)通过浏览器DevTools、Network面板、Headers选项卡和响应头识别字符集'
- en: 'Using Python code, we can find `charset` in the HTTP header:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python代码，我们可以在HTTP头中找到`charset`：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`charset` that was identified will be used to encode and decode with `requests.get(link).content.decode(''utf-8'')`.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 识别的`charset`将用于使用`requests.get(link).content.decode('utf-8')`进行编码和解码。
- en: Python 3.0 uses the concepts of *text* and (binary) *data* instead of Unicode
    strings and 8-bit strings. All text is Unicode; however, *encoded* Unicode is
    represented as binary data. The type that's used to hold text is `str` ([https://docs.python.org/3/library/stdtypes.html#str](https://docs.python.org/3/library/stdtypes.html#str)),
    and the type that's used to hold data is bytes ([https://docs.python.org/3/library/stdtypes.html#bytes](https://docs.python.org/3/library/stdtypes.html#bytes)). For
    more information on Python 3.0, please visit [https://docs.python.org/3/whatsnew/3.0.html](https://docs.python.org/3/whatsnew/3.0.html).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.0使用*文本*和(二进制)*数据*的概念，而不是Unicode字符串和8位字符串。所有文本都是Unicode；然而，*编码*的Unicode被表示为二进制数据。用于保存文本的类型是`str`([https://docs.python.org/3/library/stdtypes.html#str](https://docs.python.org/3/library/stdtypes.html#str))，用于保存数据的类型是bytes([https://docs.python.org/3/library/stdtypes.html#bytes](https://docs.python.org/3/library/stdtypes.html#bytes))。有关Python
    3.0的更多信息，请访问[https://docs.python.org/3/whatsnew/3.0.html](https://docs.python.org/3/whatsnew/3.0.html)。
- en: In this section, we set up and verified our technical requirements, and also
    explored URL loading and content viewing. In the next section, we will explore
    Python libraries to find some useful functions and their attributes.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们设置并验证了我们的技术要求，并探索了URL加载和内容查看。在下一节中，我们将探索Python库，找到一些有用的函数及其属性。
- en: URL handling and operations with urllib and requests
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用urllib和requests进行URL处理和操作
- en: For our primary motive of extracting data from a web page, it's necessary to
    work with URLs. In the examples we've seen so far, we have noticed some pretty
    simple URLs being used with Python to communicate with their source or contents.
    The web scraping process often requires the use of different URLs from various
    domains that do not exist in the same format or pattern.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于从网页中提取数据的主要动机，需要使用URL。在我们迄今为止看到的示例中，我们注意到Python与其源或内容通信时使用了一些非常简单的URL。网络爬虫过程通常需要使用来自不同域的不同格式或模式的URL。
- en: Developers might also face many cases where there will be a requirement for
    URL manipulation (altering, cleaning) to access the resource quickly and conveniently.
    URL handling and operations are used to set up, alter query parameters, or clean
    up unnecessary parameters. It also passes the required request headers with the
    appropriate values and identification of the proper HTTP method for making requests.
    There will be many cases where you will find URL-related operations that are identified
    using browser DevTools or the Network panel.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员可能还会面临许多情况，需要对URL进行操作（更改、清理）以便快速方便地访问资源。URL处理和操作用于设置、更改查询参数或清理不必要的参数。它还传递了所需的请求标头和适当值，并确定了适当的HTTP方法来进行请求。您将发现许多与URL相关的操作，这些操作可以使用浏览器DevTools或网络面板进行识别。
- en: The `urllib `and `requests` Python libraries, which we will be using throughout
    this book, deal with URL and network-based client-server communication. These
    libraries provide various easy to use functions and attributes, and we will be
    exploring a few important ones.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib`和`requests` Python库将贯穿本书使用，处理URL和基于网络的客户端-服务器通信。这些库提供了各种易于使用的函数和属性，我们将探索一些重要的函数和属性。'
- en: urllib
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: urllib
- en: The `urllib` library is a standard Python package that collects several modules
    to work with HTTP-related communication models. Modules inside `urllib `are specially
    designed and contain functions and classes that deal with various types of client-server
    communication.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib`库是一个标准的Python包，它收集了几个模块，用于处理与HTTP相关的通信模型。`urllib`内部的模块经过特别设计，包含处理各种类型的客户端-服务器通信的函数和类。'
- en: Similarly named packages also exist, like `urllib2`, an extensible library,
    and `urllib3`, a powerful HTTP client that addresses missing features from Python
    standard libraries.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 类似命名的包也存在，如`urllib2`，一个可扩展的库，以及`urllib3`，一个功能强大的HTTP客户端，解决了Python标准库中缺少的功能。
- en: 'Two of the most important `urllib` modules that deal with URL requests and
    responses are as follows. We will be using these modules in this and upcoming
    chapters:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 处理URL请求和响应的两个最重要的`urllib`模块如下。我们将在本章和接下来的章节中使用这些模块：
- en: '`urllib.request`: Used for opening and reading URLs and requesting or accessing
    network resources (cookies, authentication, and so on)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urllib.request`：用于打开和读取URL以及请求或访问网络资源（cookie、身份验证等）'
- en: '`urllib.response`: This module is used to provide a response to the requests
    that are generated'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urllib.response`：该模块用于提供对生成的请求的响应'
- en: There are a number of functions and public attributes that exist to handle request
    information and process response data that's relevant to HTTP requests, such as
    `urlopen()`, `urlretrieve()`, `getcode()`, `getheaders()`, `getheader()`, `geturl()`, `read()`,
    `readline()`, and many more.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多函数和公共属性来处理与HTTP请求相关的请求信息和处理响应数据，例如`urlopen()`、`urlretrieve()`、`getcode()`、`getheaders()`、`getheader()`、`geturl()`、`read()`、`readline()`等等。
- en: 'We can use Python''s built-in `dir()` function to display a module''s content,
    such as its classes, functions, and attributes, as shown in the following code:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Python内置的`dir()`函数来显示模块的内容，例如其类、函数和属性，如下面的代码所示：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `urlopen()` function accepts a URL or an `urllib.request.Request` object,
    such as `requestObj`, and returns a response through the `urllib.response` `read()`
    function, as shown in the following code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlopen()`函数接受URL或`urllib.request.Request`对象（如`requestObj`），并通过`urllib.response`的`read()`函数返回响应，如下面的代码所示：'
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The object types that are returned are different in the case of `linkRequest` and
    `requestObj` from the `urlopen()` function and class request, respectively. The `linkResponse` and `requestObjResponse` objects
    were also created, which holds the `urllib.response` information of the `read()` function.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`linkRequest`和`requestObj`从`urlopen()`函数和类请求返回的对象类型是不同的。还创建了`linkResponse`和`requestObjResponse`对象，其中包含`urllib.response`的`read()`函数的信息。'
- en: 'Generally, `urlopen()` is used to read a response from the URL, while `urllib.request.Request`
    is used to send extra arguments like `data` or `headers`, and even to specify
    the HTTP method and retrieve a response. It can be used as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`urlopen()`用于从URL读取响应，而`urllib.request.Request`用于发送额外的参数，如`data`或`headers`，甚至指定HTTP方法并检索响应。可以如下使用：
- en: '`urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False,
    method=None)`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False,
    method=None)`'
- en: '`urllib.response` and its functions, such as `read()` and `readline()`, are
    used with the `urllib.request` objects.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.response`及其函数，如`read()`和`readline()`，与`urllib.request`对象一起使用。'
- en: 'If the request that was made was successful and received a response from the
    proper URL, we can check the HTTP status code, the HTTP method that was used,
    as well as the returned URL to view a description:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所做的请求成功并从正确的URL收到响应，我们可以检查HTTP状态码，使用的HTTP方法，以及返回的URL来查看描述：
- en: '`getcode()` returns a HTTP status code. The same result can also be achieved
    using the `code` and `status` public attributes, as shown in the following code:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getcode()` 返回 HTTP 状态码。如下面的代码所示，也可以使用 `code` 和 `status` 公共属性获得相同的结果：'
- en: '[PRE19]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`geturl()` returns current the URL. It is sometimes handy to verify whether
    any redirection occurred. The `url` attribute can be used for a similar purpose:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`geturl()` 返回当前的 URL。有时很方便验证是否发生了任何重定向。`url` 属性可用于类似的目的：'
- en: '[PRE20]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**`_method`** returns a HTTP method; `GET` is the default response:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_method` 返回一个 HTTP 方法；`GET` 是默认响应：'
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`getheaders()` returns a list with tuples that contains HTTP headers. As we
    can see from the following code, we can determine values regarding cookie, content
    type, date, and so on from the output:'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getheaders()` 返回一个包含 HTTP 头的元组列表。如下面的代码所示，我们可以从输出中确定有关 cookie、内容类型、日期等的值：'
- en: '[PRE22]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Individual request-based headers can also be retrieved when `getheader()` is
    passed with desired header element, as shown in the following code. Here, we can
    see we can obtain the value for the Content-Type header. The same result can also
    be achieved using the `info()` function:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用 `getheader()` 传递所需的头元素时，也可以检索单个基于请求的头，如下面的代码所示。在这里，我们可以看到我们可以获取 `Content-Type`
    头的值。相同的结果也可以使用 `info()` 函数实现：
- en: '[PRE23]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We have used code blocks and found the output that's relevant to our request
    and response. Web browsers also allow us to trace request/response-related information
    using browser DevTools (browser-based developer tools).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了代码块，并找到了与我们的请求和响应相关的输出。Web 浏览器还允许我们使用浏览器 DevTools（基于浏览器的开发人员工具）跟踪请求/响应相关的信息。
- en: 'The following screenshot displays the Network panel and the Doc tab, which
    includes the Headers option. This contains various sections, such as General,
    Response Headers, and Request Headers. Basic request and response-related information
    can be found inside the Headers option:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了网络面板和文档选项卡，其中包括头选项。其中包含各种部分，如常规、响应头和请求头。头选项中可以找到基本的请求和响应相关信息：
- en: '![](assets/b497f7dc-d4f4-4734-93d2-a91aa064ef87.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b497f7dc-d4f4-4734-93d2-a91aa064ef87.png)'
- en: Network panel and Document tab with General and Request header information
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 网络面板和文档选项卡显示了常规和请求头信息
- en: 'Note `urllib.error` deals with the exceptions raised by `urllib.request`. Exceptions
    like `URLError` and `HTTPError` can be raised for a request.The following code
    demonstrates the use of `urllib.error`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.error` 处理 `urllib.request` 引发的异常。例如，`URLError` 和 `HTTPError` 可能会为请求引发异常。以下代码演示了
    `urllib.error` 的使用：'
- en: Exception handling deals with error handling and management in programming.
    Code that uses exception handling is also considered an effective technique and
    is often prescribed to adapt.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 异常处理处理编程中的错误处理和管理。使用异常处理的代码也被认为是一种有效的技术，并经常被推荐用于适应。
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`urllib.parse` is used to encode/decode request(data) or links, add/update
    headers, and analyze, parse, and manipulate URLs. Parsed URL strings or objects
    are processed with `urllib.request`.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.parse` 用于编码/解码请求（数据）或链接，添加/更新头，并分析、解析和操作 URL。解析的 URL 字符串或对象使用 `urllib.request`
    处理。'
- en: 'Furthermore, `urlencode()`, `urlparse()`, `urljoin()`, `urlsplit()`, `quote_plus()`
    are a few important functions that are available in `urllib.parse`, as shown in
    the following code:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`urlencode()`、`urlparse()`、`urljoin()`、`urlsplit()`、`quote_plus()` 是 `urllib.parse`
    中可用的一些重要函数，如下面的代码所示：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We get the following output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `urlsplit()` function from `urllib.parse` splits the URL that''s passed
    into the `namedtuple` object. Each name in tuple identifies parts of the URL.
    These parts can be separated and retrieved in other variables and used as needed.
    The following code implements `urlsplit()` for `amazonUrl`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.parse` 中的 `urlsplit()` 函数将传递的 URL 拆分为 `namedtuple` 对象。元组中的每个名称标识 URL
    的部分。这些部分可以分开并在其他变量中检索和根据需要使用。以下代码实现了 `urlsplit()` 用于 `amazonUrl`：'
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Using the `urlparse()` function from `urllib.parse` results in the `ParseResult` object.
    It differs in terms of the parameters (`params` and `path`) that are retrieved
    in he URL compared to `urlsplit()`. The following code prints the object from
    `urlparse()`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `urllib.parse` 中的 `urlparse()` 函数会得到 `ParseResult` 对象。与 `urlsplit()` 相比，它在检索
    URL 中的参数（`params` 和 `path`）方面有所不同。以下代码打印了从 `urlparse()` 中获取的对象：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s confirm the differences between `urlparse()` and `urlsplit()`. The `localUrl` that''s
    created is parsed with both `urlsplit()` and `urlparse()`. `params` is only available
    with `urlparse()`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认 `urlparse()` 和 `urlsplit()` 之间的区别。创建的 `localUrl` 使用 `urlsplit()` 和 `urlparse()`
    进行解析。`params` 仅在 `urlparse()` 中可用：
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Basically, `urllib.request.Request` accepts data and headers-related information,
    and `headers` can be assigned to an object using `add_header()`*;* for example,
    `object.add_header('host','hostname')` or `object.add_header('referer','refererUrl')`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，`urllib.request.Request` 接受数据和与头相关的信息，`headers` 可以使用 `add_header()` 赋值给一个对象；例如，`object.add_header('host','hostname')`
    或 `object.add_header('referer','refererUrl')`。
- en: In order to request `data`, `Query Information`, or `URL arguments` need to
    be used as key-value pair of information that are appended to the desired URL.
    Such a URL is usually processed with the HTTP GET method. Query information that's
    passed to the request object should be encoded using `urlencode()`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了请求 `data`，需要使用 `Query Information` 或 `URL arguments` 作为附加到所需 URL 的键值对信息。这样的
    URL 通常使用 HTTP GET 方法处理。传递给请求对象的查询信息应使用 `urlencode()` 进行编码。
- en: '`urlencode()` ensures that arguments comply with the W3C standard and are accepted
    by the server. `parse_qs()` parses percent-encoded query strings to the Python
    dictionary. The following code demonstrates an example of using `urlencode()`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlencode()` 确保参数符合 W3C 标准并被服务器接受。`parse_qs()` 将百分比编码的查询字符串解析为 Python 字典。以下代码演示了使用
    `urlencode()` 的示例：'
- en: '[PRE30]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You may also need to encode the special characters in a URL before processing
    the request to the server:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理请求发送到服务器之前，您可能还需要对 URL 中的特殊字符进行编码：
- en: 'Note that `urllib.parse` contains the `quote()`, `quote_plus()`, and `unquote()`
    functions, which permit error-free server requests:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`urllib.parse`包含`quote()`、`quote_plus()`和`unquote()`函数，这些函数允许无误的服务器请求：
- en: '`quote()` is generally applied to the URL path (listed with `urlsplit()` or `urlparse()`)
    or queried with reserved and special characters (defined by RFC 3986) before it''s
    passed to `urlencode()` to ensure that the server''s acceptable. Default encoding
    is done with `UTF-8`.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quote()`通常应用于URL路径（与`urlsplit()`或`urlparse()`一起列出）或在传递给`urlencode()`之前使用保留和特殊字符（由RFC
    3986定义）进行查询，以确保服务器的可接受性。默认编码使用`UTF-8`进行。'
- en: '`quote_plus()` also encodes special characters, spaces, and the URL separator,
    `/`.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quote_plus()`还对特殊字符、空格和URL分隔符进行编码。'
- en: '`unquote()` and `unquote_plus()` are used to revert the encoding that''s applied
    by using `quote()` and `quote_plus()`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unquote()`和`unquote_plus()`用于恢复使用`quote()`和`quote_plus()`应用的编码。'
- en: 'These functions are demonstrated in the following code:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数在以下代码中进行了演示：
- en: '[PRE31]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `urljoin()` function from `urllib.parse` helps obtain the URL from the
    provided arguments, as demonstrated in the following code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.parse`中的`urljoin()`函数有助于从提供的参数中获取URL，如下面的代码所示：'
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`urllib.robotparser`, as its name suggests, helps parse `robots.txt` and identifies
    agent-based rules. Please refer to [Chapter 1](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml),
    *Web Scraping Fundamentals*, the *Data finding techniques for the web *section,
    for more detailed information on `robots.txt`.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.robotparser`，顾名思义，帮助解析`robots.txt`并识别基于代理的规则。有关`robots.txt`的更详细信息，请参阅[第1章](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml)，*网络爬虫基础*，*网络数据查找技术*部分。'
- en: 'As we can see in the following code, `par`, which is an object of `RobotFileParser`,
    can be used to set a URL via the `set_url()` function. It can also read contents
    with the `read()` function. Functions such as `can_fetch()` can return a Boolean answer
    for the evaluated condition:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如下面的代码所示，`par`是`RobotFileParser`的对象，可以通过`set_url()`函数设置URL。它还可以使用`read()`函数读取内容。诸如`can_fetch()`的函数可以返回对评估条件的布尔答案：
- en: '[PRE33]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As we can see, `https://www.samsclub.com/friend` returns `False` when passed
    with the `can_fetch()` function, thus satisfying the `Disallow: /friend` directives
    found in `robots.txt`. Similarly, `https://www.samsclub.com/category` returns
    `True` as there are no listed directives that restrict the category URL.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '正如我们所看到的，当使用`can_fetch()`函数传递`https://www.samsclub.com/friend`时，返回`False`，从而满足了`robots.txt`中找到的`Disallow:
    /friend`指令。同样，`https://www.samsclub.com/category`返回`True`，因为没有列出限制类别URL的指令。'
- en: However, there are some limitations to using `urllib.request`. Connection-based
    delays can occur while using functions like `urlopen()` and `urlretrieve()`. These
    functions return raw data and need to be converted into the required type for
    the parser before they can be used in the scraping process.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用`urllib.request`存在一些限制。在使用`urlopen()`和`urlretrieve()`等函数时可能会出现基于连接的延迟。这些函数返回原始数据，需要在它们可以在爬取过程中使用之前转换为解析器所需的类型。
- en: Deploying threads, or threading, is considered an effective technique when dealing
    with HTTP requests and responses.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 部署线程或线程在处理HTTP请求和响应时被认为是一种有效的技术。
- en: requests
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请求
- en: '`requests` HTTP Python library released in 2011 and is one of the most renowned
    HTTP libraries for developers in recent times.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests` HTTP Python库于2011年发布，是近年来开发人员中最著名的HTTP库之一。'
- en: '*Requests is an elegant and simple HTTP library for Python, built for human
    beings*. (source: [https://2.python-requests.org/en/master/](https://2.python-requests.org/en/master/)).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*Requests是一个优雅而简单的Python HTTP库，专为人类而建*。（来源：[https://2.python-requests.org/en/master/](https://2.python-requests.org/en/master/)）。'
- en: More information on `requests` can be found at [http://docs.python-requests.org/en/master/](http://docs.python-requests.org/en/master/).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`requests`的更多信息，请访问[http://docs.python-requests.org/en/master/](http://docs.python-requests.org/en/master/)。
- en: 'Compared to other HTTP libraries in Python, `requests` is rated highly in terms
    of its functioning capability with HTTP. A few of its capabilities are as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 与Python中的其他HTTP库相比，`requests`在处理HTTP方面的功能能力得到了高度评价。它的一些功能如下：
- en: Short, simple, and readable functions and attributes
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简短、简单和可读的函数和属性
- en: Access to various HTTP methods (GET, POST, and PUT, to name a few)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问各种HTTP方法（GET、POST等）
- en: Gets rid of manual actions, like encoding form values
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摆脱手动操作，如编码表单值
- en: Processes query strings
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理查询字符串
- en: Custom headers
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义标头
- en: Session and cookie processing
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话和cookie处理
- en: Deals with JSON requests and content
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理JSON请求和内容
- en: Proxy settings
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理设置
- en: Deploys encoding and compliance
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署编码和合规性
- en: API-based link headers
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于API的链接标头
- en: Raw socket response
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始套接字响应
- en: Timeouts and more...
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超时等等...
- en: 'We will be using the `requests` library and accessing some of its properties.
    The `get()` function from `requests` is used to send a GET HTTP request to the
    URL provided. The object that''s returned is of the `requests.model.Response`
    type, as shown in the following code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`requests`库并访问一些其属性。`requests`中的`get()`函数用于向提供的URL发送GET HTTP请求。返回的对象是`requests.model.Response`类型，如下面的代码所示：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `requests` library also supports HTTP requests such as `PUT`, `POST`, `DELETE`,
    `HEAD`, and `OPTIONS` using the `put()`, `post()`, `delete()`, `head()`, and `options()` methods,
    respectively.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests`库还支持HTTP请求，如`PUT`、`POST`、`DELETE`、`HEAD`和`OPTIONS`，分别使用`put()`、`post()`、`delete()`、`head()`和`options()`方法。'
- en: 'The following are some `requests` attributes, along with a short explanation
    of each:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些`requests`属性，以及对每个属性的简要解释：
- en: '`url` outputs the current URL'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url`输出当前URL'
- en: The HTTP status code is found using `status_code`
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`status_code`找到HTTP状态代码
- en: '`history` is used to track redirection:'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`history`用于跟踪重定向：'
- en: '[PRE35]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can also obtain some details that are found when we use developer tools,
    such as HTTP Header, Encoding, and so on:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以获取一些在使用开发人员工具时发现的细节，例如HTTP标头、编码等等：
- en: '`headers` returns response-related HTTP headers'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`headers`返回与响应相关的HTTP标头'
- en: '`requests.header` returns request-related HTTP headers'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests.header`返回与请求相关的HTTP标头'
- en: '`encoding` displays the `charset` that''s obtained from the content:'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoding`显示从内容中获取的`charset`：'
- en: '[PRE36]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Page or response content can be retrieved using the `content` in bytes, whereas
    `text` returns a `str` string:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`content`以字节形式检索页面或响应内容，而`text`返回一个`str`字符串：
- en: '[PRE37]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Furthermore, `requests` also returns a `raw` socket response from the server
    by using the `stream` argument in a `get()` request. We can read a raw response
    using the `raw.read()` function:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`requests`还通过在`get()`请求中使用`stream`参数返回服务器的`raw`套接字响应。我们可以使用`raw.read()`函数读取原始响应：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: A raw response that's received using the `raw` attribute is raw bytes of characters
    that haven't been transformed or automatically decoded.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`raw`属性接收的原始响应是未经转换或自动解码的原始字符字节。
- en: '`requests` handles JSON data very effectively with its built-in decoder. As
    we can see, URLs with JSON content can be parsed with `requests` and used as required:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests`使用其内置解码器非常有效地处理JSON数据。正如我们所看到的，具有JSON内容的URL可以使用`requests`进行解析并根据需要使用：'
- en: '[PRE39]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note that, `requests` uses `urllib3` for session and for raw socket response. At
    the time of writing, `requests` version 2.21.0 was available.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`requests`使用`urllib3`进行会话和原始套接字响应。在撰写本文时，`requests`版本2.21.0可用。
- en: Crawling the script might use any of the mentioned or available HTTP libraries
    to make web-based communications. Most of the time, functions and attributes from
    multiple libraries will make this task easy. In the next section, we will be using
    the `requests` library to implement the HTTP (`GET`/`POST`) methods.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 爬取脚本可能使用任何提到的或可用的HTTP库来进行基于Web的通信。大多数情况下，来自多个库的函数和属性将使这个任务变得容易。在下一节中，我们将使用`requests`库来实现HTTP（`GET`/`POST`）方法。
- en: Implementing HTTP methods
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现HTTP方法
- en: 'Generally, web-based interaction or communication between the web page and
    the user or reader is achieved as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，网页与用户或读者之间的基于Web的交互或通信是这样实现的：
- en: The user or reader can access the web page to read or navigate through information
    that's presented to them
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户或读者可以访问网页阅读或浏览呈现给他们的信息
- en: The user or reader can also submit certain information to the web page using
    the HTML form, such as by searching, logging in, user registration, password recovery,
    and so on
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户或读者还可以通过HTML表单提交某些信息到网页，比如搜索、登录、用户注册、密码恢复等
- en: In this section, we will be using the `requests` Python library to implement
    common HTTP methods (`GET` and `POST`) that execute the HTTP-based communication
    scenario we listed previously.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用`requests` Python库来实现常见的HTTP方法（`GET`和`POST`），执行我们之前列出的基于HTTP的通信场景。
- en: GET
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GET
- en: A command way to request information is to use safe methods since the resource
    state is not altered. The `GET` parameters, also known as query strings, are visible
    in the URL. They are appended to the URL using `?` and are available as `key=value`
    pairs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 请求信息的一种命令方式是使用安全方法，因为资源状态不会被改变。`GET`参数，也称为查询字符串，在URL中是可见的。它们使用`?`附加到URL，并以`key=value`对的形式可用。
- en: 'Generally, a processed URLs without any specified HTTP methods are normally
    GET requests. A request that''s made using GET can be cached and bookmarked. There
    are also length restrictions while making a `GET` request. Some examples URLs
    are as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，未指定任何HTTP方法的处理URL是正常的GET请求。使用GET发出的请求可以被缓存和书签标记。在进行`GET`请求时也有长度限制。以下是一些示例URL：
- en: '[http://www.test-domain.com](http://www.test-domain.com)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.test-domain.com](http://www.test-domain.com)'
- en: '[http://www.test-domain.com/indexes/](http://www.test-domain.com/indexes/)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.test-domain.com/indexes/](http://www.test-domain.com/indexes/)'
- en: '[http://www.test-domain.com/data file?id=1345322&display=yes](http://www.test-domain.com/data%20file?id=1345322&display=yes)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.test-domain.com/data file?id=1345322&display=yes](http://www.test-domain.com/data%20file?id=1345322&display=yes)'
- en: 'In the preceding sections, requests were made to normal URLs such as `robots.txt` and `sitemap.xml`,
    both of which use the HTTP `GET` method. The `get()` function from `requests` accepts
    URLs, parameters, and headers:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分，对正常的URL（如`robots.txt`和`sitemap.xml`）进行了请求，这两个URL都使用了HTTP `GET`方法。`requests`的`get()`函数接受URL、参数和标头：
- en: '[PRE40]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This is the output of the preceding code:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面代码的输出：
- en: '[PRE41]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: POST
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: POST
- en: These are known as secure requests that are made to a source. The requested
    resource state can be altered. Data that's posted or sent to the requested URL
    is not visible in the URL; instead, it's transferred to the request body. A request
    that's made using `POST` isn't cached or bookmarked and has no restrictions in
    terms of length.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这些被称为安全请求，这些请求是向源发出的。请求的资源状态可以被改变。发送到请求的URL的数据在URL中是不可见的；相反，它被传输到请求体中。使用`POST`发出的请求不会被缓存或书签标记，并且在长度方面没有限制。
- en: 'In the following example, a simple HTTP request and response service<q> (</q>source:
    [http://httpbin.org/](http://httpbin.org/)) has been used to make a `POST` request.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，使用了一个简单的HTTP请求和响应服务<q> (</q>来源：[http://httpbin.org/](http://httpbin.org/)) 来发出`POST`请求。
- en: '`pageUrl` accepts data to be posted, as defined in `params` to `postUrl`. Custom
    headers are assigned as `headers`. The `post()` function from the `requests` library
    accepts URLs, data, and headers, and returns a response in JSON format:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`pageUrl`接受要发布的数据，如`params`中定义的内容到`postUrl`。自定义标头被分配为`headers`。`requests`库的`post()`函数接受URL、数据和标头，并以JSON格式返回响应：'
- en: '[PRE42]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The previous code will result in the following output:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将产生以下输出：
- en: '[PRE43]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'For the `POST` request we attempted, we can find detailed information regarding
    Request Headers, Response Headers, HTTP Status, and `POST` data (params) using
    the DevTools Network panel, as shown in the following screenshot:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们尝试的`POST`请求，我们可以使用DevTools Network面板找到有关请求标头、响应标头、HTTP状态和`POST`数据（参数）的详细信息，如下图所示：
- en: '![](assets/ade91570-74a7-4bc6-99e7-708ac1ddb71e.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ade91570-74a7-4bc6-99e7-708ac1ddb71e.png)'
- en: POST data submitted and found as form data in the DevTools Network panelIt's
    always beneficial to learn and detect the request and response sequences that
    are made with URLs through the browser and the available DevTools.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在DevTools网络面板中提交的POST数据并作为表单数据找到总是有益的学习和检测通过浏览器和可用的DevTools进行的URL的请求和响应序列。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about using Python libraries to make a request to
    a web resource and collect the response that was returned. This chapter's main
    objective was to demonstrate core features that are available through the `urllib`
    and `requests` Python libraries, plus exploring page contents that are found in
    various formats.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用Python库向网络资源发出请求并收集返回的响应。本章的主要目标是演示通过`urllib`和`requests` Python库提供的核心功能，以及探索以各种格式找到的页面内容。
- en: In the next chapter, we will learn and use a few techniques to identify and
    extract data from web contents.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习并使用一些技术来识别和提取网页内容中的数据。
- en: Further reading
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: urllib:** [https://docs.python.org/3/library/urllib.html](https://docs.python.org/3/library/urllib.html) **
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: urllib：[https://docs.python.org/3/library/urllib.html](https://docs.python.org/3/library/urllib.html)
- en: Requests: [https://2.python-requests.org/en/master/](https://2.python-requests.org/en/master/)
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求：[https://2.python-requests.org/en/master/](https://2.python-requests.org/en/master/)
- en: urllib3 [https://urllib3.readthedocs.io/en/latest/index.html](https://urllib3.readthedocs.io/en/latest/index.html)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: urllib3 [https://urllib3.readthedocs.io/en/latest/index.html](https://urllib3.readthedocs.io/en/latest/index.html)
- en: HTTP methods (GET/POST): [https://www.w3schools.com/tags/ref_httpmethods.asp](https://www.w3schools.com/tags/ref_httpmethods.asp)
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP方法（GET/POST）：[https://www.w3schools.com/tags/ref_httpmethods.asp](https://www.w3schools.com/tags/ref_httpmethods.asp)
- en: Installing Python packages: [https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Python包：[https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)
- en: What are DevTools? [https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools)
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是DevTools？[https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools)
- en: HTTP request and response service: [http://httpbin.org/](http://httpbin.org/)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP请求和响应服务：[http://httpbin.org/](http://httpbin.org/)
