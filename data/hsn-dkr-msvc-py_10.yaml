- en: Configuring and Securing the Production System
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置和保护生产系统
- en: Production (from production environment) is a common name to describe the main
    system—the one that does the work for the real customers. This is the main environment
    available in the company. It can also be called **l****ive**. This system needs
    to be openly available on the internet to be useful, which also makes security
    and reliability a big priority. In this chapter, we'll see how to deploy a Kubernetes
    cluster for production.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生产（来自生产环境）是描述主要系统的常用名称-为真实客户提供服务的系统。这是公司中可用的主要环境。它也可以被称为**live**。该系统需要在互联网上公开可用，这也使得安全性和可靠性成为重要的优先事项。在本章中，我们将看到如何为生产部署Kubernetes集群。
- en: We'll see how to set one up using a third-party offering **Amazon Web Services**
    (**AWS**), and will cover why it's a bad idea to create your own. We will deploy
    our system in this new deployment, and will check how to set up a load balancer
    to move traffic from the old monolith to the new system in an ordered fashion.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如何使用第三方提供商Amazon Web Services（AWS）来设置一个，以及为什么自己创建是一个坏主意。我们将在这个新部署中部署我们的系统，并将查看如何设置负载均衡器以有序地将流量从旧的单体系统转移到新系统。
- en: We will also see how to scale automatically both the pods inside the Kubernetes
    cluster and the nodes to adapt the resources to the needs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将看到如何自动扩展Kubernetes集群内的Pod和节点，以使资源适应需求。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using Kubernetes in the wild
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在野外使用Kubernetes
- en: Setting up the Docker registry
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Docker注册表
- en: Creating the cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建集群
- en: Using HTTPS and TLS to secure external access
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用HTTPS和TLS保护外部访问
- en: Being ready for migration to microservices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为迁移到微服务做好准备
- en: Autoscaling the cluster
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展集群
- en: Deploying a new Docker image smoothly
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺利部署新的Docker镜像
- en: We will also cover some good practices to ensure that our deployments get deployed
    as smoothly and reliably as possible. By the end of the chapter, you'll have the
    system deployed in a publicly available Kubernetes cluster.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将介绍一些良好的实践方法，以确保我们的部署尽可能顺利和可靠地部署。到本章结束时，您将在一个公开可用的Kubernetes集群中部署系统。
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We will use AWS as our cloud vendor for the examples. We need to install some
    utilities to interact from the command line. Check how to install the AWS CLI
    utility in this documentation ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)).
    This utility allows performing AWS tasks from the command line.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中的示例中使用AWS作为我们的云供应商。我们需要安装一些实用程序以从命令行进行交互。查看如何在此文档中安装AWS CLI实用程序（[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)）。此实用程序允许从命令行执行AWS任务。
- en: To operate the Kubernetes cluster, we will use `eksctl`. Check this documentation
    ([https://eksctl.io/introduction/installation/](https://eksctl.io/introduction/installation/))
    for installation instructions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了操作Kubernetes集群，我们将使用`eksctl`。查看此文档（[https://eksctl.io/introduction/installation/](https://eksctl.io/introduction/installation/)）以获取安装说明。
- en: You'll need also to install `aws-iam-authenticator`. You can check the installation
    instructions here ([https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html](https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要安装`aws-iam-authenticator`。您可以在此处查看安装说明（[https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html](https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html)）。
- en: 'The code for this chapter can be found on GitHub at this link: [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在GitHub的此链接找到：[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07)。
- en: 'Be sure you have `ab` (Apache Bench) installed on your computer. It is bundled
    with Apache, and it''s installed by default in macOS and some Linux distributions.
    You can check this article: [https://www.petefreitag.com/item/689.cfm](https://www.petefreitag.com/item/689.cfm).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的计算机上安装了`ab`（Apache Bench）。它与Apache捆绑在一起，并且在macOS和一些Linux发行版中默认安装。您可以查看这篇文章：[https://www.petefreitag.com/item/689.cfm](https://www.petefreitag.com/item/689.cfm)。
- en: Using Kubernetes in the wild
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在野外使用Kubernetes
- en: When deploying a cluster to be used as production, the best possible advice
    is to use a commercial service. All the main cloud providers (AWS EKS, **Google
    Kubernetes Engine** (**GKE**), and **Azure Kubernetes Service** (**AKS**)) allow
    you to create a managed Kubernetes cluster, meaning that the only required parameter
    is to choose the number and type of physical nodes and then access it through
    `kubectl`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署用于生产的集群时，最好的建议是使用商业服务。所有主要的云提供商（AWS EKS，Google Kubernetes Engine（GKE）和Azure
    Kubernetes Service（AKS））都允许您创建托管的Kubernetes集群，这意味着唯一需要的参数是选择物理节点的数量和类型，然后通过`kubectl`访问它。
- en: We will use AWS for the examples in this book, but take a look at the documentation
    of other providers in case they work better for your use case.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的示例中，我们将使用AWS，但请查看其他提供商的文档，以确定它们是否更适合您的用例。
- en: Kubernetes is an abstraction layer, so this way of operation is very convenient.
    The pricing is similar to paying for raw instances to act as node servers and
    removes the need to install and manage the Kubernetes Control Plane so the instances
    act as Kubernetes nodes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个抽象层，因此这种操作方式非常方便。定价类似于支付原始实例以充当节点服务器，并且无需安装和管理Kubernetes控制平面，因此实例充当Kubernetes节点。
- en: 'It''s worth saying it again: unless you have a very good reason, *do not deploy
    your own Kubernetes cluster*; instead, use a cloud provider offering. It will
    be easier and will save you from a lot of maintenance costs. Configuring a Kubernetes
    node in a way that''s performant and implements good practices to avoid security
    problems is not trivial.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 值得再次强调：除非您有非常充分的理由，*不要部署自己的Kubernetes集群*；而是使用云提供商的服务。这样做会更容易，并且可以节省大量的维护成本。配置Kubernetes节点以实现高性能并实施良好的实践以避免安全问题并不是一件简单的事情。
- en: Creating your own Kubernetes cluster may be unavoidable if you have your own
    internal data center, but in any other case it makes much more sense to directly
    use one managed by a known cloud provider. Probably your current provider already
    has an offering for managed Kubernetes!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您拥有自己的内部数据中心，则可能无法避免创建自己的Kubernetes集群，但在其他任何情况下，直接使用已知云提供商管理的集群更有意义。可能您当前的提供商已经为托管的Kubernetes提供了服务！
- en: Creating an IAM user
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建IAM用户
- en: AWS works using different users to grant them several roles. They carry different
    permissions that enable the users to perform actions. This system is called **Identity
    and Access Management** (**IAM**) in AWS nomenclature.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: AWS使用不同的用户来授予它们多个角色。它们具有不同的权限，使用户能够执行操作。在AWS的命名约定中，这个系统称为**身份和访问管理**（**IAM**）。
- en: Creating a proper IAM user could be quite complicated, depending on your settings
    and how AWS is used in your organization. Check the documentation ([https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html))
    and find the people responsible for dealing with AWS in your organization and
    check with them to see what the required steps are.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的设置以及AWS在您的组织中的使用方式，创建适当的IAM用户可能会相当复杂。查阅文档（[https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html)），并找到负责处理AWS的人员，并与他们核实所需的步骤。
- en: 'Let''s take a look at the steps to create an IAM user:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看创建IAM用户的步骤：
- en: 'We need to create an AWS user if it is not created with proper permissions.
    Be sure that it will be able to access the API by activating the Programmatic
    access as seen in the following screenshot:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未创建具有适当权限的AWS用户，则需要创建。确保它能够通过激活程序化访问来访问API，如下面的屏幕截图所示：
- en: '![](img/cedad3a8-ea90-4541-9f22-c5605c90b77e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cedad3a8-ea90-4541-9f22-c5605c90b77e.png)'
- en: This will show its Access Key, Secret Key, and Password. Be sure to store them
    securely.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示其访问密钥、秘密密钥和密码。请务必将它们安全地存储起来。
- en: 'To access through the command line, you need to use the AWS CLI. With the AWS
    CLI and the access information, configure your command line to use `aws`:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要通过命令行访问，您需要使用AWS CLI。使用AWS CLI和访问信息，配置您的命令行以使用`aws`：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should be able to get the identity to check that the configuration is successful
    using the following command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够通过以下命令获取身份以检查配置是否成功：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can now access the command-line AWS actions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以访问命令行AWS操作。
- en: Keep in mind that the IAM user can create more keys if necessary, revoke the
    existing ones, and so on. This normally is handled by an admin user in charge
    of AWS security. You can read more in the Amazon documentation ([https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_API](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_API)).
    Key rotation is a good idea to ensure that old keys are deprecated. You can do
    it through the `aws` client interface.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，IAM用户可以根据需要创建更多密钥，撤销现有密钥等。这通常由负责AWS安全的管理员用户处理。您可以在亚马逊文档中阅读更多信息（[https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_API](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey_API)）。密钥轮换是一个不错的主意，以确保旧密钥被废弃。您可以通过`aws`客户端界面执行此操作。
- en: We will use the web console for some operations, but others require the usage
    of `aws`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Web控制台进行一些操作，但其他操作需要使用`aws`。
- en: Setting up the Docker registry
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Docker注册表
- en: We need to be able to reach the Docker registry where the images to be deployed
    are stored. The easiest way of ensuring that the Docker registry is reachable
    is to use the Docker registry in the same service.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要能够访问存储要部署的图像的Docker注册表。确保Docker注册表可访问的最简单方法是使用相同服务中的Docker注册表。
- en: You can still use the Docker Hub registry, but using a registry in the same
    cloud provider is typically easier as it's better integrated. It will also help
    in terms of authentication.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您仍然可以使用Docker Hub注册表，但是在同一云提供商中使用注册表通常更容易，因为它集成得更好。这也有助于身份验证方面。
- en: 'We need to configure an **Elastic Container Registry** (**ECR**), using the
    following steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用以下步骤配置**弹性容器注册表**（**ECR**）：
- en: 'Log into the AWS console and search for Kubernetes or ECR:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录AWS控制台并搜索Kubernetes或ECR：
- en: '![](img/29d9a38c-01d7-4df5-b22d-f0df643270b2.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29d9a38c-01d7-4df5-b22d-f0df643270b2.png)'
- en: 'Create a new registry called `frontend`. It will create a full URL, which you
    will need to copy:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建名为`frontend`的新注册表。它将创建一个完整的URL，您需要复制：
- en: '![](img/17c47ce3-fa05-48a7-aa03-48efcdc28818.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17c47ce3-fa05-48a7-aa03-48efcdc28818.png)'
- en: 'We need to make our local `docker` log in the registry. Note that `aws ecr
    get-login` will return a `docker` command that will log you in, so copy it and
    paste:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要使本地`docker`登录注册表。请注意，`aws ecr get-login`将返回一个`docker`命令，该命令将使您登录，因此请复制并粘贴：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we can tag the image that we want to push with the full registry name,
    and push it:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用完整的注册表名称标记要推送的图像，并将其推送：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The image is pushed! You can check it by opening the AWS console in the browser:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 镜像已推送！您可以通过在浏览器中打开AWS控制台来检查：
- en: '![](img/bed774ba-ff0f-45bc-aefa-38ed3337de56.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bed774ba-ff0f-45bc-aefa-38ed3337de56.png)'
- en: We need to repeat the process to also push the Users Backend and Thoughts Backend.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要重复这个过程，以推送用户后端和思想后端。
- en: We use the setting of two containers for the deployment of the Users Backend
    and Thoughts Backend, which includes one for the service and another for a volatile
    database. This is done for demonstration purposes, but won't be the configuration
    for a production system, as the data will need to be persistent.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两个容器的设置来部署用户后端和想法后端，其中包括一个用于服务，另一个用于易失性数据库。这是为了演示目的而做的，但不会是生产系统的配置，因为数据需要是持久的。
- en: At the end of the chapter, there's a question about how to deal with this situation.
    Be sure to check it!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，有一个关于如何处理这种情况的问题。一定要检查一下！
- en: 'All the different registries will be added. You can check them in the browser
    AWS console:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所有不同的注册表都将被添加。您可以在浏览器的AWS控制台中查看它们：
- en: '![](img/cb2a0221-97f4-427d-beab-1bcc17c237e1.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cb2a0221-97f4-427d-beab-1bcc17c237e1.png)'
- en: Our pipelines will need to be adapted to push to this repositories.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流水线需要适应推送到这些存储库。
- en: A good practice in deployment is to make a specific step called **promotion**,
    where the images ready to use in production are copied to an specific registry,
    lowering the chance that a bad image gets deployed by mistake in production.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署中的一个良好的做法是进行一个称为**推广**的特定步骤，其中准备用于生产的镜像被复制到一个特定的注册表，降低了错误地在生产中部署坏镜像的机会。
- en: This process may be done several times to promote the images in different environments.
    For example, deploy a version in an staging environment. Run some tests, and if
    they are correct, promote the version, copying it into the production registry
    and labelling it as good to deploy on the production environment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可能需要多次进行，以在不同的环境中推广镜像。例如，在一个暂存环境中部署一个版本。运行一些测试，如果它们正确，推广版本，将其复制到生产注册表并标记为在生产环境中部署的好版本。
- en: This process can be done with different registries in different providers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以在不同的提供商中使用不同的注册表进行。
- en: We need to use the name of the full URL in our deployments.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在我们的部署中使用完整URL的名称。
- en: Creating the cluster
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建集群
- en: 'To make our code available in the cloud and publicly accessible, we need to
    set up a working production cluster, which requires two steps:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的代码在云中可用并且可以公开访问，我们需要设置一个工作的生产集群，这需要两个步骤：
- en: Create the EKS cluster in AWS cloud (this enables you to run the `kubectl` commands
    that operate in this cloud cluster).
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS云中创建EKS集群（这使您能够运行在此云集群中操作的`kubectl`命令）。
- en: Deploy your services, using a set of `.yaml` files, as we've seen in previous
    chapters. The files require minimal changes to adapt them to the cloud.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署您的服务，使用一组`.yaml`文件，就像我们在之前的章节中看到的那样。这些文件需要进行最小的更改以适应云环境。
- en: Let's check the first step.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来检查第一步。
- en: Creating the Kubernetes cluster
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Kubernetes集群
- en: The best way to create a cluster is to use the `eksctl` utility. This automates
    most of the work for us, and allows us to scale it later if we have to.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建集群的最佳方式是使用`eksctl`实用程序。这将为我们自动化大部分工作，并且允许我们以后进行扩展。
- en: Be aware that EKS is available only in some regions, not all. Check the AWS
    regional table ([https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)) to
    see the available zones. We will use the Oregon (`us-west-2`) region.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，EKS只在一些地区可用，而不是所有地区。检查AWS区域表（[https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)）以查看可用的区域。我们将使用俄勒冈（`us-west-2`）地区。
- en: 'To create the Kubernetes cluster, let''s take the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建Kubernetes集群，让我们采取以下步骤：
- en: 'First, check that `eksctl` is properly installed:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，检查`eksctl`是否正确安装：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a new cluster. It will take around 10 minutes:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的集群。这将需要大约10分钟：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This creates the cluster. Checking the AWS web interface will show the newly
    configured elements.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建集群。检查AWS web界面将显示新配置的元素。
- en: The  `--arg-access` option needs to be added for a cluster capable of autoscaling.
    This will be described in more detail in the *Autoscaling the cluster* section.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 需要添加`--arg-access`选项以创建一个能够自动扩展的集群。这将在*自动扩展集群*部分中进行更详细的描述。
- en: The `eksctl create` command also adds a new context with the information about
    the remote Kubernetes cluster and activates it, so `kubectl` will now point to
    this new cluster.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`eksctl create`命令还会添加一个包含有关远程Kubernetes集群信息的新上下文，并激活它，因此`kubectl`现在将指向这个新集群。'
- en: Note that `kubectl` has the concept of contexts as different clusters it can
    connect. You can see all the available contexts running `kubectl config get-contexts`
    and `kubectl config use-context <context-name>` to change them. Check the Kubernetes
    documentation ([https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/))
    on how to create new contexts manually.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`kubectl`有上下文的概念，作为它可以连接的不同集群。您可以通过运行`kubectl config get-contexts`和`kubectl
    config use-context <context-name>`来查看所有可用的上下文，以更改它们。请查看Kubernetes文档（[https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)）以了解如何手动创建新的上下文。
- en: 'This command sets `kubectl` with the proper context to run commands. By default,
    it generates a cluster with two nodes:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个命令设置了`kubectl`以正确的上下文来运行命令。默认情况下，它生成一个具有两个节点的集群：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can scale the number of nodes. To reduce the usage of resources and save
    money. We need to retrieve the name of the nodegroup, which controls the number
    of nodes, and then downscale it:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以扩展节点的数量。为了减少资源使用和节省金钱。我们需要检索节点组的名称，它控制节点的数量，然后缩减它：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can contact the cluster through `kubectl` and carry the operations normally:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过`kubectl`联系集群并正常进行操作：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The cluster is set up, and we can run commands on it from our command line.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 集群已经设置好了，我们可以从命令行上对其进行操作。
- en: Creating an EKS cluster can be tweaked in a lot of ways, but AWS can be temperamental
    in terms of access, users, and permissions. For example, the cluster likes to
    have a CloudFormation rule to handle the cluster, and all the elements should
    be created with the same IAM user. Check with anyone that works with the infrastructure
    definition in your organization to check what's the proper configuration. Don't
    be afraid of running tests, a cluster can be quickly removed through the `eksctl`
    configuration or the AWS console.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 创建EKS集群可以以许多方式进行调整，但是AWS在访问、用户和权限方面可能会变化无常。例如，集群喜欢有一个CloudFormation规则来处理集群，并且所有元素应该由相同的IAM用户创建。与您组织中负责基础架构定义的任何人核对，以确定正确的配置是什么。不要害怕进行测试，集群可以通过`eksctl`配置或AWS控制台快速删除。
- en: Furthermore, `eksctl` creates the cluster with the nodes in different availability
    zones (AWS isolated locations within the same geographical region) wherever possible,
    which minimizes the risk of getting the whole cluster down because of problems
    in AWS data centers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`eksctl`会在不同的可用区（AWS同一地理区域内的隔离位置）中创建集群节点，以尽量减少因AWS数据中心出现问题而导致整个集群宕机的风险。
- en: Configuring the cloud Kubernetes cluster
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置云Kubernetes集群
- en: The next stage is to run our services on the EKS cluster, so it's available
    in the cloud. We will use the `.yaml` files as a base, but we need to make a few
    changes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 下一阶段是在EKS集群上运行我们的服务，以便在云中可用。我们将使用`.yaml`文件作为基础，但需要进行一些更改。
- en: Take a look at the files in the GitHub `Chapter07` ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07))
    subdirectory.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 查看GitHub `Chapter07`（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07)）子目录中的文件。
- en: We will see the differences from the Kubernetes configuration files in the previous
    chapter, and then we will deploy them in the *Deploying the system* section.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到与上一章中的Kubernetes配置文件的不同，然后在*部署系统*部分部署它们。
- en: Configuring the AWS image registry
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置AWS镜像注册表
- en: The first difference is that we need to change the image to the full registry,
    so the cluster uses the images available in the ECS registry.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个区别是我们需要将镜像更改为完整的注册表，以便集群使用ECS注册表中可用的镜像。
- en: Remember, you need to specify the registry inside AWS so the AWS cluster can
    properly access it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，您需要在AWS内部指定注册表，以便AWS集群可以正确访问它。
- en: 'For example, in the `frontend/deployment.yaml` file, we need to define them
    in this way:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在`frontend/deployment.yaml`文件中，我们需要以这种方式定义它们：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The image should pull from the AWS registry. The pull policy should be changed
    to force pulling from the cluster.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像应该从AWS注册表中拉取。拉取策略应更改为强制从集群中拉取。
- en: 'You can deploy in the remote server by applying the file, after creating the `example` namespace:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建`example`命名空间后，您可以通过应用文件在远程服务器上部署：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After a bit, the deployment creates the pods:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 过一会儿，部署会创建pod：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we need to change the rest of the elements. All the deployments need to
    be adapted to include the proper registry.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要更改其余的元素。所有部署都需要适应包括正确注册表。
- en: Check the code on GitHub to check all the `deployment.yaml` files.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上检查所有`deployment.yaml`文件的代码。
- en: Configuring the usage of an externally accessible load balancer
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置使用外部可访问负载均衡器
- en: The second difference is to make the frontend service available externally,
    so internet traffic can access the cluster.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个区别是使前端服务可以在外部访问，以便互联网流量可以访问集群。
- en: 'This is easily done by changing the service from `NodePort` to `LoadBalancer`.
    Check the  `frontend/service.yaml` file:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这很容易通过将服务从`NodePort`更改为`LoadBalancer`来完成。检查`frontend/service.yaml`文件：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This creates a new **Elastic Load Balancer** (**ELB**) that can be externally
    accessed. Now, let's start deploying.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个可以外部访问的新**弹性负载均衡器**（**ELB**）。现在，让我们开始部署。
- en: Deploying the system
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署系统
- en: 'The whole system can be deployed, from the `Chapter07` subdirectory, with the
    following code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 整个系统可以从`Chapter07`子目录中部署，使用以下代码：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This commands go iteratively through the subdirectories and applies any `.yaml`
    file.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令会迭代地通过子目录并应用任何`.yaml`文件。
- en: 'After a few minutes, you should see everything up and running:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，您应该看到一切都正常运行：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To obtain the public access point, you need to check the services:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取公共访问点，您需要检查服务：
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that the frontend service has an external ELB DNS available.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前端服务有一个外部ELB DNS可用。
- en: 'If you put that DNS in a browser, you can access the service as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在浏览器中输入该DNS，可以访问服务如下：
- en: '![](img/b27d1c74-f06d-4be2-b017-73f59bb4fa8d.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b27d1c74-f06d-4be2-b017-73f59bb4fa8d.png)'
- en: Congratulations, you have your own cloud Kubernetes service. The DNS name the
    service is accessible under is not great, so we will see how to add a registered
    DNS name and expose it under an HTTPS endpoint.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您拥有自己的云Kubernetes服务。服务可访问的DNS名称不太好，因此我们将看到如何添加注册的DNS名称并在HTTPS端点下公开它。
- en: Using HTTPS and TLS to secure external access
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HTTPS和TLS保护外部访问
- en: To provide a good service to your customers, your external endpoint should be
    served through HTTPS. This means that the communication between you and your customers
    is private, and it can't be sniffed throughout the network route.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向客户提供良好的服务，您的外部端点应通过HTTPS提供。这意味着您和客户之间的通信是私密的，不能在网络路由中被窃听。
- en: The way HTTPS works is that the server and client encrypt the communication.
    To be sure that the server is who they say they are, there needs to be an SSL
    certificate issued by an authority that grants that the DNS is verified.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: HTTPS的工作原理是服务器和客户端加密通信。为了确保服务器是他们所说的那样，需要有一个由授予DNS已验证的权威颁发的SSL证书。
- en: Remember, the point of HTTPS is *not* that the server is inherently trustworthy,
    but that the communication is private between the client and the server. The server
    can still be malicious. That's why verifying that a particular DNS does not contain
    misspellings is important.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，HTTPS的目的不是服务器本身是可信的，而是客户端和服务器之间的通信是私密的。服务器仍然可能是恶意的。这就是验证特定DNS不包含拼写错误的重要性。
- en: 'You can get more information on how HTTPS works in this fantastic comic: [https://howhttps.works/](https://howhttps.works/).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这本奇妙的漫画中获取有关HTTPS如何运作的更多信息：[https://howhttps.works/](https://howhttps.works/)。
- en: 'Obtaining a certificate for your external endpoint requires two stages:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 获取外部端点的证书需要两个阶段：
- en: You own a particular DNS name, normally by buying it from a name registrar.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您拥有特定的DNS名称，通常是通过从域名注册商购买获得的。
- en: You obtain a unique certificate for the DNS name by a recognized **Certificate
    Authority** (**CA**). The CA has to validate that you control the DNS name.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您通过认可的**证书颁发机构**（**CA**）获得DNS名称的唯一证书。 CA必须验证您控制DNS名称。
- en: To help in promoting the usage of HTTPS, the non-profit *Let's Encrypt* ([https://letsencrypt.org](https://letsencrypt.org))
    supplies free certificates valid for 60 days. This will be more work than obtaining
    one through your cloud provider, but could be an option if money is tight.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进HTTPS的使用，非营利性组织*Let's Encrypt*（[https://letsencrypt.org](https://letsencrypt.org)）提供有效期为60天的免费证书。这将比通过云服务提供商获得证书更费力，但如果资金紧张，这可能是一个选择。
- en: These days, this process is very easy to do with cloud providers as they can
    act as both, simplifying the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些天，这个过程非常容易通过云服务提供商来完成，因为它们可以同时充当两者，简化流程。
- en: The important element that needs to communicate through HTTPS is the edge of
    our network. The internal network where our own microservices are communicating
    doesn't require to be HTTPS, and HTTP will suffice. It needs to be a private network
    out of public interference, though.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 需要通过HTTPS进行通信的重要元素是我们网络的边缘。我们自己的微服务在内部网络中进行通信时不需要使用HTTPS，HTTP就足够了。但它需要是一个不受公共干扰的私有网络。
- en: Following our example, AWS allows us to create and associate a certificate with
    an ELB, serving traffic in HTTP.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 按照我们的例子，AWS允许我们创建并将证书与ELB关联，以HTTP提供流量。
- en: Having AWS to serve HTTPS traffic ensures that we are using the latest and safest
    security protocols, such as **Transport Layer Security** (**TLS**) v1.3 (the latest
    at the time of writing), but also that it keeps backward compatibility with older
    protocols, such as SSL.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让AWS提供HTTPS流量可以确保我们使用最新和最安全的安全协议，例如**传输层安全性**（**TLS**）v1.3（撰写时的最新版本），但也保持与旧协议的向后兼容性，例如SSL。
- en: In other words, it is the best option to use the most secure environment by
    default.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，默认情况下使用最安全的环境是最佳选择。
- en: The first step of setting HTTPS is either to buy a DNS domain name directly
    from AWS or to transfer  the control to AWS. This can be done through their service
    Route 53\. You can check the documentation at [https://aws.amazon.com/route53/](https://aws.amazon.com/route53/).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 设置HTTPS的第一步是直接从AWS购买DNS域名，或将控制权转移到AWS。这可以通过他们的Route 53服务完成。您可以在[https://aws.amazon.com/route53/](https://aws.amazon.com/route53/)上查看文档。
- en: It is not strictly required to transfer your DNS to Amazon, as long as you can
    point it toward the externally facing ELB, but it helps with the integration and
    obtaining of certificates. You'll need to prove that you own the DNS record when
    creating a certificate, and using AWS makes it simple as they create a certificate
    to a DNS record they control. Check the documentation at [https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html](https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，不需要将您的DNS转移到亚马逊，只要您可以将其指向外部ELB，但这有助于集成和获取证书。在创建证书时，您需要证明自己拥有DNS记录，使用AWS可以简化此过程，因为他们会为他们控制的DNS记录创建证书。请查看[https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html](https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html)上的文档。
- en: 'To enable HTTPS support on your ELB, let''s check the following steps:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要在ELB上启用HTTPS支持，请查看以下步骤：
- en: 'Go to Listeners in the AWS console:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到AWS控制台中的监听器：
- en: '![](img/fa6eb258-65a0-4953-a49c-4f0ac559524f.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa6eb258-65a0-4953-a49c-4f0ac559524f.png)'
- en: 'Click on Edit and add a new rule for HTTPS support:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“编辑”并添加HTTPS支持的新规则：
- en: '![](img/9bceff02-8ad6-4194-8315-75ea59238415.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bceff02-8ad6-4194-8315-75ea59238415.png)'
- en: 'As you can see, it will require an SSL certificate. Click on Change to go to
    management:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所见，它将需要SSL证书。单击“更改”以进行管理：
- en: '![](img/c0378dc3-fd4b-4c3a-ab55-11a07af6a74d.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0378dc3-fd4b-4c3a-ab55-11a07af6a74d.png)'
- en: From here, you can either add an existing certificate or buy one from Amazon.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这里，您可以添加现有证书或从亚马逊购买证书。
- en: Be sure to check the documentation about the load balancer in Amazon. There
    are several kinds of ELBs that can be used, and some have different features than
    others depending on your use case. For example, some of the new ELBs are able
    to redirect toward HTTPS even if your customer requests the data in HTTP. See
    the documentation at [https://aws.amazon.com/elasticloadbalancing/](https://aws.amazon.com/elasticloadbalancing/).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 务必查看亚马逊负载均衡器的文档。有几种类型的ELB可供使用，根据您的用例，一些ELB具有与其他ELB不同的功能。例如，一些新的ELB能够在客户端请求HTTP数据时重定向到HTTPS。请查看[https://aws.amazon.com/elasticloadbalancing/](https://aws.amazon.com/elasticloadbalancing/)上的文档。
- en: Congratulations, now your external endpoint supports HTTPS, ensuring that your
    communications with your customers are private.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，现在您的外部端点支持HTTPS，确保您与客户的通信是私密的。
- en: Being ready for migration to microservices
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备好迁移到微服务
- en: To operate smoothly while making the migration, you need to deploy a load balancer
    that allows you to quickly swap between backends and keeps the service up.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在进行迁移时顺利运行，您需要部署一个负载均衡器，它可以让您快速在后端之间切换并保持服务运行。
- en: As we discussed in [Chapter 1](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml),
    *Making the Move – Design, Plan, and Execute*, HAProxy is an excellent choice
    because it is very versatile and has a good UI that allows you to make operations
    quickly just by clicking on a web page. It also has an excellent stats page that
    allows you to monitor the status of the service.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](ddb0a00a-6c5b-4ffe-b403-0f5f9f7a7df2.xhtml)中讨论的那样，*进行移动-设计、计划和执行*，HAProxy是一个很好的选择，因为它非常灵活，并且有一个很好的UI，可以让您通过单击网页上的按钮快速进行操作。它还有一个出色的统计页面，可以让您监视服务的状态。
- en: AWS has an alternative to HAProxy called **Application Load Balancer** (**ALB**).
    This works as a feature-rich update on the ELB, which allows you to route different
    HTTP paths into different backend services.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: AWS有一个名为**应用负载均衡器**（**ALB**）的HAProxy替代方案。这是ELB的功能丰富更新，允许您将不同的HTTP路径路由到不同的后端服务。
- en: HAProxy has a richer set of features and a better dashboard to interact with
    it. It can also be changed through a configuration file, which helps in controlling
    changes, as we will see in [Chapter 8](9a5c53a2-9131-4233-9e4f-992af51d8321.xhtml),
    *Using GitOps Principles*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: HAProxy具有更丰富的功能集和更好的仪表板与之交互。它也可以通过配置文件进行更改，这有助于控制更改，正如我们将在[第8章](9a5c53a2-9131-4233-9e4f-992af51d8321.xhtml)中看到的那样，*使用GitOps原则*。
- en: It is, obviously, only available if all the services are available in AWS, but
    it can be a good solution in that case, as it will be simpler and more aligned with
    the rest of the technical stack. Take a look at the documentation at [https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/](https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，只有在所有服务都在AWS上可用时才能使用，但在这种情况下，它可能是一个很好的解决方案，因为它将更简单并且更符合技术堆栈的其余部分。查看文档：[https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/](https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/)。
- en: To deploy a load balancer in front of your service, I recommend not deploying
    it on Kubernetes, but running it in the same way as your traditional services.
    This kind of load balancer will be a critical part of the system, and removing
    uncertainty is important for a successful run. It's also a relatively simple service.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要在服务前部署负载均衡器，我建议不要在Kubernetes上部署它，而是以与传统服务相同的方式运行它。这种类型的负载均衡器将是系统的关键部分，消除不确定性对于成功运行是很重要的。它也是一个相对简单的服务。
- en: Keep in mind that a load balancer needs to be properly replicated, or it becomes
    a single point of failure. Amazon and other cloud providers allow you to set up
    an ELB or other kinds of load balancer toward your own deployment of load balancers,
    enabling the traffic to be balanced among them.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，负载均衡器需要正确复制，否则它将成为单点故障。亚马逊和其他云提供商允许您设置ELB或其他类型的负载均衡器，以便将流量平衡在它们之间。
- en: As an example, we've created an example configuration and the `docker-compose`
    file to quickly run it, but the configuration can be set up in whatever way your
    team is most comfortable with.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，我们创建了一个示例配置和`docker-compose`文件来快速运行它，但配置可以按照团队最舒适的方式进行设置。
- en: Running the example
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行示例
- en: The code is available on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07/haproxy](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07/haproxy)).
    We inherit from the HAProxy Docker image in Docker Hub ([https://hub.docker.com/_/haproxy/](https://hub.docker.com/_/haproxy/)),
    adding our own config file.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可在GitHub上找到（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07/haproxy](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter07/haproxy)）。我们从Docker
    Hub中的HAProxy Docker镜像继承（[https://hub.docker.com/_/haproxy/](https://hub.docker.com/_/haproxy/)），添加我们自己的配置文件。
- en: 'Let''s take a look at the main elements in the config file, `haproxy.cfg`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看配置文件`haproxy.cfg`中的主要元素：
- en: '[PRE16]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We define a frontend that accepts any requests into port `80` and sends the
    requests toward the backend. The backend balances the requests to two servers,
    `example` and `aws`. Basically, `example` points to `www.example.com` (a placeholder
    for your old service) and `aws` to the previously created load balancer.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个前端，接受任何端口`80`的请求，并将请求发送到后端。后端将请求平衡到两个服务器，`example`和`aws`。基本上，`example`指向`www.example.com`（您的旧服务的占位符），`aws`指向先前创建的负载均衡器。
- en: We enable the stats server in port `8001` and allow admin access.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在端口`8001`上启用统计服务器，并允许管理员访问。
- en: 'The `docker-compose` config starts the server and forwards the localhost ports
    towards the container ports `8000` (load balancer) and `8001` (stats). Start it
    with the following command:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-compose`配置启动服务器，并将本地端口转发到容器端口`8000`（负载均衡器）和`8001`（统计）。使用以下命令启动它：'
- en: '[PRE17]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now we can access `localhost:8000`, which will alternate between the `thoughts`
    service and a 404 error.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以访问`localhost:8000`，它将在`thoughts`服务和404错误之间交替。
- en: When calling `example.com` this way, we are forwarding the host request. This
    means we send a request requesting `Host:localhost` to `example.com`, which returns
    a 404 error. Be sure to check on your service that the same host information is
    accepted by all the backends.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式调用`example.com`时，我们正在转发主机请求。这意味着我们发送一个请求，请求`Host:localhost`到`example.com`，它返回一个404错误。请确保检查您的服务，所有后端都接受相同的主机信息。
- en: 'Open the stats page to check the setup:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 打开统计页面查看设置：
- en: '![](img/50260323-0ec3-4f15-a91e-3e66ece92b0e.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50260323-0ec3-4f15-a91e-3e66ece92b0e.png)'
- en: Check the entries for `aws` and `example` in the backend nodes. There is also
    a lot of interesting information, such as the number of requests, the last connection,
    data, and so on.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 检查后端节点中的`aws`和`example`条目。还有很多有趣的信息，比如请求数量、最后连接、数据等等。
- en: 'You can perform actions when checking the `example` backend, and then set state
    to MAINT in the drop-down menu. Once applied, the `example` backend is in maintenance
    mode and removed from the load balancer. The stats page is as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在检查`example`后端时执行操作，然后在下拉菜单中将状态设置为MAINT。应用后，`example`后端将处于维护模式，并从负载均衡器中移除。统计页面如下：
- en: '![](img/c4ee4c3e-ae10-4597-b4ff-f3ec513ce6ee.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c4ee4c3e-ae10-4597-b4ff-f3ec513ce6ee.png)'
- en: Accessing the load balancer in `localhost:8000` now will only return the **thoughts**
    frontend. You can re-enable the backend setting it to the READY state.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在`localhost:8000`中访问负载均衡器只会返回**thoughts**前端。您可以重新启用后端，将其设置为READY状态。
- en: There's a state called DRAIN that will stop new sessions going to the selected
    server, but existing sessions will keep going. This may be interesting in some
    configurations, but if the backend is truly stateless, moving directly to the MAINT
    state should be enough.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种称为DRAIN的状态，它将停止新会话进入所选服务器，但现有会话将继续。这在某些配置中可能很有趣，但如果后端真正是无状态的，直接转移到MAINT状态就足够了。
- en: 'HAProxy can also be configured to use checks to ensure that the backend is
    available. We added in the example a commented one, which sends an HTTP command
    to check a return:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: HAProxy也可以配置使用检查来确保后端可用。在示例中，我们添加了一个被注释的检查，它发送一个HTTP命令来检查返回。
- en: '[PRE18]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The check will be the same to both backends, so it needs to be returned successfully.
    By default, it will be run every couple of seconds.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 检查将对两个后端相同，因此需要成功返回。默认情况下，它将每隔几秒运行一次。
- en: You can check the full HAProxy documentation at [http://www.haproxy.org/](http://www.haproxy.org/).
    There are a lot of details that can be configured. Follow up with your team to
    be sure that the configuration of areas like timeouts, forwarding headers, and
    so on are correct.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[http://www.haproxy.org/](http://www.haproxy.org/)上查看完整的HAProxy文档。有很多可以配置的细节。与您的团队跟进，确保像超时、转发标头等区域的配置是正确的。
- en: The concept of the health check is also used in Kubernetes to ensure that pods
    and containers are ready to accept requests and are stable. We'll see how to ensure
    that a new image is deployed correctly in the next section.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 健康检查的概念也用于Kubernetes，以确保Pod和容器准备好接受请求并保持稳定。我们将在下一节中看到如何确保正确部署新镜像。
- en: Deploying a new Docker image smoothly
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平稳部署新的Docker镜像
- en: When deploying a service in a production environment, it is critically important
    to ensure that it is going to work smoothly to avoid interrupting the service.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中部署服务时，确保其能够平稳运行以避免中断服务至关重要。
- en: Kubernetes and HAProxy are able to detect when a service is running correctly,
    and take action when it's not, but we need to give an endpoint that acts as a
    health check and configure it to be pinged at regular intervals, for early detection
    of problems.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes和HAProxy能够检测服务是否正常运行，并在出现问题时采取行动，但我们需要提供一个充当健康检查的端点，并配置它以定期被ping，以便及早发现问题。
- en: For simplicity, we will use the root URL as a health check, but we can design
    specific endpoints to be tested. A good health checkup checks that the service
    is working as expected, but is light and quick. Avoid the temptation of over testing
    or performing an external verification that could make the endpoint take a long
    time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为简单起见，我们将使用根URL作为健康检查，但我们可以设计特定的端点进行测试。一个良好的健康检查应该检查服务是否按预期工作，但是轻便快速。避免过度测试或执行外部验证，这可能会使端点花费很长时间。
- en: An API endpoint that returns an empty response is a great example, as it checks
    that the whole piping system works, but it's very fast to answer.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 返回空响应的API端点是一个很好的例子，因为它检查整个管道系统是否正常工作，但回答非常快。
- en: In Kubernetes, there are two tests to ensure that a pod is working correctly,
    the readiness probe and the liveness probe.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，有两个测试来确保Pod正常工作，即就绪探针和活动探针。
- en: The liveness probe
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 活动探针
- en: The liveness probe checks that a container is working properly. It is a process
    started in the container that returns correctly. If it returns an error (or more,
    depending on the config), Kubernetes will kill the container and restart it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 活动探针检查容器是否正常工作。它是在容器中启动的返回正确的进程。如果返回错误（或更多，取决于配置），Kubernetes将终止容器并重新启动。
- en: 'The liveness probe will be executed inside the container, so it needs to be
    valid. For a web service, adding a `curl` command is a good idea:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 活动探针将在容器内执行，因此需要有效。对于Web服务，添加`curl`命令是一个好主意：
- en: '[PRE19]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: While there are options such as checking if a TCP port is open or sending an
    HTTP request, running a command is the most versatile option. It can also be checked
    for debugging purposes. See the documentation for more options.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有一些选项，比如检查TCP端口是否打开或发送HTTP请求，但运行命令是最通用的选项。它也可以用于调试目的。请参阅文档以获取更多选项。
- en: Be careful of being very aggressive on liveness probes. Each check puts some
    load on the container, so depending on load multiple probes can end up killing
    more containers than they should.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 要小心对活动探针过于激进。每次检查都会给容器增加一些负载，因此根据负载情况，多个探针可能会导致杀死更多的容器。
- en: If your services are restarted often by the liveness probe, either the probe
    is too aggressive or the load is high for the number of containers, or a combination
    of both.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的服务经常被活动探针重新启动，要么探针太过激进，要么容器数量负载过高，或者两者兼而有之。
- en: The probe is configured to wait for five seconds, and then run once every 30
    seconds. By default, after three failed checks, it will restart the container.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 该探针配置为等待五秒，然后每30秒运行一次。默认情况下，连续三次失败的检查后，将重新启动容器。
- en: The readiness probe
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 就绪探针
- en: The readiness probe checks if the container is ready to accept more requests.
    It's a less aggressive version. If the tests return an error or timeout, the container
    won't be restarted, but it will be just labeled as unavailable.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针检查容器是否准备好接受更多请求。这是一个不那么激进的版本。如果测试返回错误或超时，容器不会重新启动，而只会被标记为不可用。
- en: The readiness probe is normally used to avoid accepting requests too early,
    but it will run after startup. A smart readiness probe can label when a container
    is at full capacity and can't accept more requests, but normally a probe configured
    in a similar way to the liveness prove will be enough.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针通常用于避免过早接受请求，但它会在启动后运行。一个智能的就绪探针可以标记容器何时达到最大容量，无法接受更多请求，但通常配置类似于活跃探针的探针就足够了。
- en: 'The readiness probe is defined in the deployment configuration, in the same
    fashion as the liveness probe. Let''s take a look:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针在部署配置中定义，方式与活跃探针相同。让我们来看一下：
- en: '[PRE20]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The readiness probe should be more aggressive than the liveness probe, as the
    result is safer. That's why `periodSeconds` is shorter. You may require both or
    not, depending on your particular use case, but readiness probes are required
    to enable rolling updates, as we'll see next.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针应该比活跃探针更积极，因为结果更安全。这就是为什么`periodSeconds`更短。根据您的特定用例，您可能需要两者或者不需要，但就绪探针是启用滚动更新所必需的，接下来我们将看到。
- en: The `frontend/deployment.yaml` deployment in the example code includes both
    probes. Check the Kubernetes documentation ([https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/))
    for more details and options.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 示例代码中的`frontend/deployment.yaml`部署包括了两个探针。查看Kubernetes文档（[https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)）以获取更多详细信息和选项。
- en: Be aware that the two probes are used for different objectives. The readiness
    probe delays the input of requests until the pod is ready, while the liveness
    probe helps with stuck containers.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这两个探针用于不同的目标。就绪探针延迟请求的输入，直到Pod准备就绪，而活跃探针有助于处理卡住的容器。
- en: A delay in the liveness probe getting back will restart the pod, so an increase
    in load could produce a cascade effect of restarting pods. Adjust accordingly,
    and remember that both probes don't need to repeat the same command.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟的活跃探针返回将重新启动Pod，因此负载的增加可能会产生重新启动Pod的级联效应。相应地进行调整，并记住两个探针不需要重复相同的命令。
- en: Both readiness and liveness probes help Kubernetes to control how pods are created,
    which affects the update of a deployment.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针和活跃探针都帮助Kubernetes控制Pod的创建方式，这影响了部署的更新。
- en: Rolling updates
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滚动更新
- en: By default, each time that we update an image for deployment, the Kubernetes
    deployment will recreate the containers.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每次我们更新部署的镜像时，Kubernetes部署将重新创建容器。
- en: Notifying Kubernetes that a new version is available is not enough to push a
    new image to the registry, even if the tag is the same. You'll need to change
    the tag described in the `image` field in the deployment `.yaml` file.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通知Kubernetes新版本可用并不足以将新镜像推送到注册表，即使标签相同。您需要更改部署`.yaml`文件中`image`字段中描述的标签。
- en: We need to control how the images are being changed. To not interrupt the service,
    we need to perform a rolling update. This kind of update adds new containers,
    waits until they are ready, adds them to the pool, and removes the old containers.
    This deployment is a bit slower than removing all containers and restarting them,
    but it allows the service to be uninterrupted.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要控制图像的变化方式。为了不中断服务，我们需要执行滚动更新。这种更新方式会添加新的容器，等待它们就绪，将它们添加到池中，并移除旧的容器。这种部署比移除所有容器并重新启动它们要慢一些，但它允许服务不中断。
- en: 'How this process is performed can be configured by tweaking the `strategy` section
    in the deployment:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如何执行这个过程可以通过调整部署中的`strategy`部分来配置：
- en: '[PRE21]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s understand this code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解这段代码：
- en: '`strategy` and  `type` can be either `RollingUpdate` (the default) or `Recreate`,
    which stops existing pods and creates new ones.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strategy`和`type`可以是`RollingUpdate`（默认）或`Recreate`，后者会停止现有的Pod并创建新的Pod。'
- en: '`maxUnavailable` defines the maximum number of unavailable pods during a change.
    This defines how quick o new containers will be added and old ones removed. It
    can be described as a percentage, like our example, or a fixed number.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxUnavailable`定义了更改期间不可用的最大Pod数量。这定义了新容器将被添加和旧容器将被移除的速度。它可以被描述为一个百分比，就像我们的例子，或者是一个固定的数字。'
- en: '`maxSurge` defines the number of extra pods that can be created over the limit
    of desired pods. This can be a specific number or a percentage of the total.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxSurge`定义了可以在期望Pod的限制之上创建的额外Pod的数量。这可以是一个特定的数字或者是总数的百分比。'
- en: As we set `replicas` to `4`, in both cases the result is one pod. This means
    that during a change, up to one pod may be unavailable and that we will create
    the new pods one by one.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们将`replicas`设置为`4`时，在两种情况下的结果都是一个Pod。这意味着在更改期间，最多可以有一个Pod不可用，并且我们将逐个创建新的Pod。
- en: Higher numbers will perform the update faster but will consume more resources
    (`maxSurge`) or reduce more aggressively the available resources during the update
    (`maxUnavailable`).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的数字将使更新速度更快，但会消耗更多资源（`maxSurge`）或在更新期间更积极地减少可用资源（`maxUnavailable`）。
- en: For a small number of replicas, be conservative and grow the numbers when you
    are more comfortable with the process and have more resources.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于少量的副本，要保守并在您对流程更加熟悉并且有更多资源时增加数量。
- en: Initially, scaling the pods manually will be easiest and best option. If the
    traffic is highly variable, with high peaks and low valleys, it may be worth autoscaling
    the cluster.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，手动扩展Pod将是最简单和最好的选择。如果流量变化很大，有高峰和低谷，那么自动扩展集群可能是值得的。
- en: Autoscaling the cluster
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动扩展集群
- en: We've seen before how to change the number of pods for a service, and how to
    add and remove nodes. This can be automated to describe some rules, allowing the
    cluster to change its resources elastically.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经看到了如何为服务更改Pod的数量，以及如何添加和移除节点。这可以自动化地描述一些规则，允许集群弹性地改变其资源。
- en: Keep in mind that autoscaling requires tweaking to adjust to your specific use
    case. This is a technique to use if the resource utilization changes greatly over
    time; for example, if there's a daily pattern where some hours present way more
    activity than others, or if there's a viral element that means the service multiplies
    the requests by 10 unexpectedly.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，自动缩放需要调整以适应您的特定用例。如果资源利用率随时间发生很大变化，例如，如果某些小时的活动比其他小时多得多，或者如果有一种病毒元素意味着服务意外地将请求增加了10倍，那么这是一种使用技术。
- en: If your usage of servers is small and the utilization stays relatively constant,
    there's probably no need to add autoscaling.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对服务器的使用量很小，并且利用率相对恒定，可能没有必要添加自动缩放。
- en: 'The cluster can be scaled automatically up or down on two different fronts:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 集群可以在两个不同的方面自动扩展或缩小：
- en: The number of pods can be set to increase or decrease automatically in a Kubernetes
    configuration.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes配置中，pod的数量可以自动增加或减少。
- en: The number of nodes can be set to increase or decrease automatically in AWS.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点的数量可以在AWS中自动增加或减少。
- en: Both the number of pods and the number of nodes need to be in line with each
    other to allow natural growth.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: pod的数量和节点的数量都需要保持一致，以允许自然增长。
- en: If the number of pods increases without adding more hardware (nodes), the Kubernetes
    cluster won't have much more capacity, only the same resources allocated in a
    different distribution.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果pod的数量增加而没有添加更多的硬件（节点），Kubernetes集群将没有更多的容量，只是在不同分布中分配了相同的资源。
- en: If the number of nodes increases without more pods created, at some point the
    extra nodes won't have pods to allocate, producing underutilization of resources.
    On the other hand, any new node added will have a cost associated, so we want
    to be properly using it.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点数量增加而没有创建更多的pod，那么在某个时候，额外的节点将没有pod可分配，导致资源利用不足。另一方面，任何新添加的节点都会有相关成本，因此我们希望能够正确地使用它。
- en: To be able to automatically scale a pod, be sure that it is scalable. To ensure
    the pod is scalable check that it is an stateless web service and obtain all the
    information from an external source.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够自动缩放pod，请确保它是可扩展的。要确保pod是可扩展的，请检查它是否是无状态的Web服务，并从外部源获取所有信息。
- en: Note that, in our code example, the frontend pod is scalable, while the Thoughts
    and Users Backend is not, as they include their own database container the application
    connects to.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们的代码示例中，前端pod是可扩展的，而Thoughts和Users Backend不可扩展，因为它们包括自己的数据库容器，应用程序连接到该容器。
- en: Creating a new pod creates a new empty database, which is not the expected behavior.
    This has been done on purpose to simplify the example code. The intended production
    deployment is, as described before, to connect to an external database instead.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的pod会创建一个新的空数据库，这不是预期的行为。这是有意为之的，以简化示例代码。预期的生产部署是，如前所述，连接到外部数据库。
- en: Both Kubernetes configuration and EKS have features that allow changing the
    number of pods and nodes based on rules.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes配置和EKS都具有根据规则更改pod和节点数量的功能。
- en: Creating a Kubernetes Horizontal Pod Autoscaler
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Kubernetes水平Pod自动缩放器
- en: In Kubernetes nomenclature, the service to scale pods up and down is called
    a **Horizontal Pod Autoscaler** (**H****PA**).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes术语中，用于增加和减少pod的服务称为**水平Pod自动缩放器**（**HPA**）。
- en: This is because it requires a way of checking the measurement to scale. To enable
    these metrics, we need to deploy the Kubernetes metric server.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为它需要一种检查测量以进行缩放的方法。要启用这些指标，我们需要部署Kubernetes度量服务器。
- en: Deploying the Kubernetes metrics server
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署Kubernetes度量服务器
- en: The Kubernetes metrics server captures internal low-level metrics such as CPU
    usage, memory, and so on. The HPA will capture these metrics and use them to scale
    the resources.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes度量服务器捕获内部低级别的指标，如CPU使用率，内存等。HPA将捕获这些指标并使用它们来调整资源。
- en: The Kubernetes metrics server is not the only available server for feeding metrics
    to the HPA, and other metrics systems can be defined. The list of the currently
    available adaptors is available in the Kubernetes metrics project ([https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api](https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api)).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes度量服务器不是向HPA提供指标的唯一可用服务器，还可以定义其他度量系统。当前可用适配器的列表可在Kubernetes度量项目中找到（[https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api](https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api)）。
- en: This allows for custom metrics to be defined as a target. Start first with default
    ones, though, and only move to custom ones if there are real limitations for your
    specific deployment.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许定义自定义指标作为目标。首先从默认指标开始，只有在特定部署存在真正限制时才转移到自定义指标。
- en: To deploy the Kubernetes metrics server, download the latest version from the
    official project page ([https://github.com/kubernetes-incubator/metrics-server/releases](https://github.com/kubernetes-incubator/metrics-server/releases)).
    At the time of writing, it was `0.3.3`.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署Kubernetes度量服务器，请从官方项目页面下载最新版本（[https://github.com/kubernetes-incubator/metrics-server/releases](https://github.com/kubernetes-incubator/metrics-server/releases)）。写作时，版本为`0.3.3`。
- en: 'Download the `tar.gz` file, which at the time of writing was `metrics-server-0.3.3.tar.gz`.
    Uncompress it and apply the version to the cluster:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 下载`tar.gz`文件，写作时为`metrics-server-0.3.3.tar.gz`。解压缩并将版本应用到集群：
- en: '[PRE22]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You will see the new pod in the `kube-system` namespace:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在`kube-system`命名空间中看到新的pod：
- en: '[PRE23]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can use the `kubectl top` command to get basic information about the nodes
    and pods:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`kubectl top`命令获取有关节点和pod的基本信息：
- en: '[PRE24]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: To properly control what the limit of usage is, we need to configure in the
    deployment what is allocated and limit resources for it.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确控制使用量的限制，我们需要在部署中配置分配和限制资源。
- en: Configuring the resources in deployments
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在部署中配置资源
- en: In the configuration for a container, we can specify what the requested resources
    are and the maximum resources for them.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器的配置中，我们可以指定所请求的资源以及它们的最大资源。
- en: They both inform Kubernetes about the expected memory and CPU usage for a container.
    When creating a new container, Kubernetes will automatically deploy it on a node
    that has enough resources to cover it.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都向Kubernetes提供有关容器的预期内存和CPU使用情况的信息。在创建新容器时，Kubernetes将自动将其部署到具有足够资源覆盖的节点上。
- en: 'In the `frontend/deployment.yaml` file, we include the following `resources`
    instances:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在`frontend/deployment.yaml`文件中，我们包括以下`resources`实例：
- en: '[PRE25]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The initially requested memory is 64 MB, and 0.06 of a CPU core.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 最初请求的内存为64 MB，0.06个CPU核心。
- en: The resources for memory can also use Mi to the power of 2, which is equivalent
    to a megabyte (*1000²* bytes), which is called a mebibyte (*2^(20)* bytes). The
    difference is small in any case. You can use also G or T for bigger amounts.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 内存资源也可以使用Mi的平方，相当于兆字节（*1000²*字节），称为mebibyte（*2^(20)*字节）。在任何情况下，差异都很小。您也可以使用G或T来表示更大的数量。
- en: The CPU resources are measured fractionally where 1 being a core in whatever
    system the node is running (for example, AWS vCPU). Note that 1000m, meaning 1000
    milli CPUs is equivalent to a whole core.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: CPU资源是以分数形式衡量的，其中1表示节点运行的任何系统中的一个核心（例如，AWS vCPU）。请注意，1000m，表示1000毫核心，相当于一个完整的核心。
- en: The limits are 128 MB and 0.07 of a CPU core. The container won't be able to
    use more memory or CPU than the limit.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 限制为128 MB和0.07个CPU核心。容器将无法使用超过限制的内存或CPU。
- en: Aim at round simple numbers to understand the limits and requested resources.
    Don't expect to have them perfect the first time; the applications will change
    their consumption.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是获得简单的整数以了解限制和所请求的资源。不要期望第一次就完美无缺；应用程序将改变它们的消耗。
- en: Measuring the metrics in an aggregated way, as we will talk about in [Chapter
    11](06d0c451-77f1-4e4a-8d38-3abf112f79fa.xhtml), *Handling Change, Dependencies,
    and Secrets in the System*, will help you to see the evolution of the system and
    tweak it accordingly.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 以聚合方式测量指标，正如我们将在[第11章](06d0c451-77f1-4e4a-8d38-3abf112f79fa.xhtml)中讨论的那样，*处理系统中的变化、依赖关系和机密*，将帮助您看到系统的演变并相应地进行调整。
- en: The limit creates the benchmark for the autoscaler, as it will be measured in
    a percentage of the resource.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 限制为自动缩放器创建了基准，因为它将以资源的百分比来衡量。
- en: Creating an HPA
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建HPA
- en: 'To create a new HPA, we can use the `kubectl autoscale` command:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新的HPA，我们可以使用`kubectl autoscale`命令：
- en: '[PRE26]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This creates a new HPA that targets the `frontend` deployment in the `example` namespace,
    and sets the number of pods to be between `2` and `8`. The parameter to scale
    is the CPU, which we set to 10% of the available CPU, averaged across all the
    pods. If it's higher, it will create new pods, and if it's lower, it will reduce
    them.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的HPA，它以`example`命名空间中的`frontend`部署为目标，并设置要在`2`和`8`之间的Pod数量。要缩放的参数是CPU，我们将其设置为可用CPU的10%，并在所有Pod中平均。如果超过了，它将创建新的Pod，如果低于，它将减少它们。
- en: The 10% limit is used to be able to trigger the autoscaler and to demonstrate
    it.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 10%的限制用于触发自动缩放器并进行演示。
- en: 'The autoscaler works as a special kind of Kubernetes object, and it can be
    queried as such:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 自动缩放器作为一种特殊类型的Kubernetes对象工作，可以查询它：
- en: '[PRE27]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note how the target says it is currently at around 2%, near the limit. This
    was designed with the small available CPU that will have a relatively high baseline.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，目标显示当前约为2%，接近限制。这是为了小型可用CPU而设计的，将具有相对较高的基线。
- en: After some minutes, the number of replicas will go down until the minimum is
    reached, `2`.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，副本的数量将减少，直到达到最小值`2`。
- en: The downscaling may take a few minutes. This generally is the expected behavior,
    upscaling being more aggressive than downscaling.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 缩容可能需要几分钟。这通常是预期的行为，扩容比缩容更积极。
- en: 'To create some load, let''s use the application Apache Bench (`ab`) in combination
    with a specially created endpoint in the frontend that uses a lot of CPU:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一些负载，让我们使用应用程序Apache Bench（`ab`），并与前端中专门创建的端点结合使用大量CPU：
- en: '[PRE28]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that `ab` is a convenient test application that produces HTTP requests
    concurrently. If you prefer, you can hit the URL from a browser multiple times
    in quick succession.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`ab`是一个方便的测试应用程序，可以同时生成HTTP请求。如果愿意，您也可以在浏览器中多次快速点击URL。
- en: Remember to add the load balancer DNS, as retrieved in the *Creating the cluster*
    section.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住添加负载均衡器DNS，如在*创建集群*部分中检索到的。
- en: 'This will generate an extra CPU load in the cluster and will make the deployment
    scale up:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在集群中生成额外的CPU负载，并使部署扩展：
- en: '[PRE29]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: After the requests are completed, and after some minutes, the number of pods will
    slowly scale down until hitting the two pods again.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 请求完成后，几分钟后，Pod的数量将缓慢缩减，直到再次达到两个Pod。
- en: But we need a way of scaling the nodes as well, or we won't be able to grow
    the total number of resources in the system.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们需要一种方式来扩展节点，否则我们将无法增加系统中的资源总数。
- en: Scaling the number of nodes in the cluster
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展集群中节点的数量
- en: The number of AWS instances that work as nodes in the EKS cluster can also be
    increased. This adds extra resources to the cluster and makes it possible to start
    more pods.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: EKS集群中作为节点工作的AWS实例的数量也可以增加。这为集群增加了额外的资源，并使其能够启动更多的Pod。
- en: The underlying AWS service that allows that is an Auto Scaling group. This is
    a group of EC2 instances that share the same image and have a defined size, both
    for the minimum and maximum instances.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 支持这一功能的底层AWS服务是自动扩展组。这是一组共享相同镜像并具有定义大小的EC2实例，包括最小和最大实例。
- en: 'At the core of any EKS cluster, there''s an Auto Scaling group that controls
    the nodes of the cluster. Note that `eksctl` creates and exposes the Auto Scaling
    group as a nodegroup:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何EKS集群的核心，都有一个控制集群节点的自动扩展组。请注意，`eksctl`将自动扩展组创建并公开为节点组：
- en: '[PRE30]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With `eksctl`, we can scale the cluster up or down manually as we described
    when creating the cluster:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`eksctl`，我们可以手动扩展或缩小集群，就像我们创建集群时描述的那样。
- en: '[PRE31]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This nodegroup is also visible in the AWS console, under EC2 | Auto Scaling
    Groups:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点组也可以在AWS控制台中看到，在EC2 | 自动缩放组下：
- en: '![](img/1a35c1f7-06fa-4243-b336-1db202e9b03b.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a35c1f7-06fa-4243-b336-1db202e9b03b.png)'
- en: In the web interface, we have some interesting information that we can use to
    collect information about the Auto Scaling group. The Activity History tab allows
    you to see any scaling up or down event, and the Monitoring tab allows you to
    check metrics.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web界面中，我们可以收集有关自动缩放组的一些有趣信息。活动历史选项卡允许您查看任何扩展或缩小事件，监控选项卡允许您检查指标。
- en: Most of the handling has been created automatically with `eksctl`, such as the
    Instance Type and the AMI-ID (the initial software on the instance, containing
    the operating system). They should be mainly controlled by `eksctl`.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分处理都是由`eksctl`自动创建的，比如实例类型和AMI-ID（实例上的初始软件，包含操作系统）。它们应该主要由`eksctl`控制。
- en: If you need to change the Instance Type, `eksctl` requires you to create a new
    nodegroup, move all the pods, and then delete the old. You can learn more about
    the process in the `eksctl` documentation ([https://eksctl.io/usage/managing-nodegroups/](https://eksctl.io/usage/managing-nodegroups/)).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要更改实例类型，`eksctl`要求您创建一个新的节点组，移动所有的pod，然后删除旧的。您可以在`eksctl`文档中了解更多关于这个过程的信息。
- en: But from the web interface, it is easy to edit the scale parameters and to add
    policies for autoscaling.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 但是从Web界面，很容易编辑缩放参数并为自动缩放添加策略。
- en: Changing the parameters through the web interface may confuse the data retrieved
    in `eksctl`, as it's independently set up.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Web界面更改参数可能会使`eksctl`中检索的数据混乱，因为它是独立设置的。
- en: It is possible to install a Kubernetes autoscaler for AWS, but it requires a `secrets`
    configuration file to include a proper AMI in the autoscaler pod, with AWS permissions
    to add instances.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 可以为AWS安装Kubernetes自动缩放器，但需要一个`secrets`配置文件，其中包括在自动缩放器pod中添加适当的AMI的AWS权限。
- en: Describing the autoscale policy in AWS terms in code can also be quite confusing.
    The web interface makes it a bit easier. The pro is that you can describe everything
    in config files that can be under source control.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中以AWS术语描述自动缩放策略也可能会令人困惑。Web界面使这变得更容易一些。好处是你可以在配置文件中描述一切，这些文件可以在源代码控制下。
- en: We will go with the web interface configuration, here, but you can follow the
    instructions at [https://eksctl.io/usage/autoscaling/](https://eksctl.io/usage/autoscaling/).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用Web界面配置，但您可以按照[https://eksctl.io/usage/autoscaling/](https://eksctl.io/usage/autoscaling/)上的说明进行操作。
- en: 'For scaling policies, there are two main components that can be created:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 对于缩放策略，有两个主要的组件可以创建：
- en: '**Scheduled actions**: They are scale up and down events that happen at defined
    times. The action can change the number of nodes through a combination of the
    desired number and the minimum and maximum number, for example, increasing the
    cluster during the weekend. The actions can be repeated periodically, such as
    each day or each hour. The action can also have an ending time, which will revert
    the values to the ones previously defined. This can be used to give a boost for
    a few hours if we expect extra load in the system, or to reduce costs during night
    hours.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定时操作**：这些是在定义的时间发生的扩展和缩小事件。该操作可以通过所需数量和最小和最大数量的组合来改变节点的数量，例如，在周末增加集群。操作可以定期重复，例如每天或每小时。操作还可以有一个结束时间，这将使值恢复到先前定义的值。这可以在系统中预期额外负载时提供几个小时的提升，或者在夜间减少成本。'
- en: '**Scaling policies**: These are policies that look for demand at a particular
    time and scale up or down the instances, between the described numbers. There
    are three types of policies: target tracking, step scaling, and simple scaling.
    Target tracking is the simplest, as it monitors the target (typically CPU usage)
    and scales up and down to keep close to the number. The other two policies require
    you to generate alerts using the AWS CloudWatch metrics system, which is more
    powerful but also requires using CloudWatch and a more complex configuration.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩放策略**：这些策略是在特定时间查找需求并在所描述的数字之间扩展或缩小实例的策略。有三种类型的策略：目标跟踪、阶梯缩放和简单缩放。目标跟踪是最简单的，因为它监视目标（通常是CPU使用率）并根据需要扩展和缩小以保持接近该数字。另外两种策略需要您使用AWS
    CloudWatch指标系统生成警报，这更强大，但也需要使用CloudWatch和更复杂的配置。'
- en: The number of nodes can change not only going up but also down, which implies
    deleting nodes.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的数量不仅可以增加，还可以减少，这意味着删除节点。
- en: Deleting nodes
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除节点
- en: When deleting a node, the pods running need to move to another node. This is
    handled automatically by Kubernetes, and EKS will do the operation in a safe way.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 删除节点时，正在运行的pod需要移动到另一个节点。Kubernetes会自动处理这个操作，EKS会以安全的方式执行该操作。
- en: This can also happen if a node is down for any reason, such as an unexpected
    hardware problem. As we've seen before, the cluster is created in multiple availability
    zones to minimize risks, but some nodes may have problems if there's a problem
    in an Amazon availability zone.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点由于任何原因关闭，例如意外的硬件问题，也会发生这种情况。正如我们之前所看到的，集群是在多个可用区创建的，以最小化风险，但如果Amazon的一个可用区出现问题，一些节点可能会出现问题。
- en: Kubernetes was designed for this kind of problem, so it's good at moving pods
    from one node to another in unforeseen circumstances.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是为这种问题而设计的，因此在意外情况下很擅长将pod从一个节点移动到另一个节点。
- en: Moving a pod from one node to another is done by destroying the pod and restarting
    it in the new node. As pods are controlled by deployments, they will keep the
    proper number of pods, as described by the replicas or autoscale values.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个pod从一个节点移动到另一个节点是通过销毁该pod并在新节点上重新启动来完成的。由于pod受部署控制，它们将保持副本或自动缩放值所描述的适当数量的pod。
- en: Remember that pods are inherently volatile and should be designed so they can
    be destroyed and recreated.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Pod本质上是不稳定的，应设计成可以被销毁和重新创建。
- en: Upscaling can also result in existing pods moving to other nodes to better utilize
    resources, though this is less common. An increase in the number of nodes is normally
    done at the same time as growing the number of pods.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展还可以导致现有的Pod移动到其他节点以更好地利用资源，尽管这种情况较少。增加节点数量通常是在增加Pod数量的同时进行的。
- en: Controlling the number of nodes requires thinking about the strategy to follow
    to achieve the best result, depending on the requirements.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 控制节点的数量需要考虑要遵循的策略，以实现最佳结果，具体取决于要求。
- en: Designing a winning autoscaling strategy
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计一个成功的自动缩放策略
- en: As we've seen, both kinds of autoscaling, pods and nodes, need to be related
    to each other. Keeping the number of nodes down reduces costs but limits the available
    resources that could be used for growing the number of pods.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，Pod和节点两种自动缩放需要相互关联。保持节点数量减少可以降低成本，但会限制可用于增加Pod数量的资源。
- en: Always keep in mind that autoscaling is a big numbers game. Unless you have
    enough load variation to justify it, tweaking it will produce cost savings that
    are not comparable to the cost of developing and maintaining the process. Run
    a cost analysis of expected gains and maintenance costs.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，自动缩放是一个大量数字的游戏。除非您有足够的负载变化来证明其必要性，否则调整它将产生成本节省，这与开发和维护过程的成本不可比。对预期收益和维护成本进行成本分析。
- en: Prioritize simplicity when dealing with changing the size of a cluster. Scaling
    down during nights and weekends could save a lot of money, and it's much easier
    to handle than generating a complex CPU algorithm to detect highs and lows.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理集群大小变化时，优先考虑简单性。在夜间和周末缩减规模可以节省大量资金，而且比生成复杂的CPU算法来检测高低要容易得多。
- en: Keep in mind that autoscaling is not the only way of reducing costs with cloud
    providers, and can be used combined with other strategies.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，自动缩放并不是与云服务提供商降低成本的唯一方法，可以与其他策略结合使用。
- en: 'For example, in AWS, reserving EC2 instances for a year or more allows you
    to greatly reduce the bill. They can be used for the cluster baseline and combined
    with more expensive on-demand instances for autoscaling, which yields an extra
    reduction in costs: [https://aws.amazon.com/ec2/pricing/reserved-instances/](https://aws.amazon.com/ec2/pricing/reserved-instances/).'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在AWS中，预订EC2实例一年或更长时间可以大大减少账单。它们可以用于集群基线，并与更昂贵的按需实例结合使用进行自动缩放，从而额外降低成本：[https://aws.amazon.com/ec2/pricing/reserved-instances/](https://aws.amazon.com/ec2/pricing/reserved-instances/)。
- en: As a general rule, you should aim to have an extra bit of hardware available
    to allow scaling pods, as this is faster. This is allowed in cases where different
    pods are scaled at different rates. It is possible, depending on the application,
    that when the usage of one service goes up, another goes down, which will keep
    the utilization in similar numbers.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，您应该有额外的硬件可用于扩展Pod，因为这样更快。这在不同的Pod以不同的速度扩展的情况下是允许的。根据应用程序的不同，当一个服务的使用量增加时，另一个服务的使用量可能会减少，这将保持利用率在相似的数字。
- en: This is not the use case that comes to mind, but for example, scheduled tasks
    during the night may make use of available resources that at daytime are being
    used by external requests.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是您首先想到的用例，但例如，在夜间安排的任务可能会利用白天被外部请求使用的可用资源。
- en: They can work in different services, balancing automatically as the load changes
    from one service to the other.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 它们可以在不同的服务中工作，随着负载从一个服务转移到另一个服务而自动平衡。
- en: Once the headroom is reduced, start scaling nodes. Always leave a security margin
    to avoid getting stuck in a situation where the nodes are not scaling fast enough
    and no more pods can be started because of a lack of resources.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦头部空间减少，就开始扩展节点。始终留出安全余地，以避免陷入节点扩展不够快，由于资源不足而无法启动更多的Pod的情况。
- en: The pod autoscaler can try to create new pods, and if there are no resources
    available, they won't be started. In the same fashion, if a node is removed, any
    Pod that is not deleted may not start because of a lack of resources.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Pod自动缩放器可以尝试创建新的Pod，如果没有可用资源，它们将不会启动。同样，如果删除了一个节点，任何未删除的Pod可能由于资源不足而无法启动。
- en: Remember that we describe to Kubernetes the requirements for a new pod in the
    `resources` section of the deployment. Be sure that the numbers there are indicative
    of the required ones for the pod.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们在部署的`resources`部分向Kubernetes描述了新Pod的要求。确保那里的数字表明了Pod所需的数字。
- en: To ensure that the pods are adequately distributed across different nodes, you
    can use the Kubernetes affinity and anti-affinity rules. These rules allow defining
    whether pods of a certain kind should run in the same node or not.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保Pod在不同节点上充分分布，您可以使用Kubernetes的亲和性和反亲和性规则。这些规则允许定义某种类型的Pod是否应在同一节点上运行。
- en: This is useful, for example, to make sure that all kinds of pods are evenly
    distributed across zones, or for ensuring that two services are always deployed
    in the same node to reduce latency.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这对于确保各种Pod均匀分布在区域中，或者确保两个服务始终部署在同一节点以减少延迟非常有用。
- en: You can learn more about affinity and how to configure in this blog post: [https://supergiant.io/blog/learn-how-to-assign-pods-to-nodes-in-kubernetes-using-nodeselector-and-affinity-features/](https://supergiant.io/blog/learn-how-to-assign-pods-to-nodes-in-kubernetes-using-nodeselector-and-affinity-features/), and
    in the Kubernetes official configuration ([https://kubernetes.io/docs/concepts/configuration/assign-pod-node/](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)).
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这篇博客文章中了解有关亲和性和如何进行配置的更多信息：[https://supergiant.io/blog/learn-how-to-assign-pods-to-nodes-in-kubernetes-using-nodeselector-and-affinity-features/](https://supergiant.io/blog/learn-how-to-assign-pods-to-nodes-in-kubernetes-using-nodeselector-and-affinity-features/)，以及在Kubernetes官方配置中（[https://kubernetes.io/docs/concepts/configuration/assign-pod-node/](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/)）。
- en: In general, Kubernetes and `eksctl` defaults work fine for most applications.
    Use this advice only for advanced configuration.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，Kubernetes和`eksctl`默认情况下对大多数应用程序都能很好地工作。仅在高级配置时使用此建议。
- en: Summary
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've seen how to apply a Kubernetes cluster into a production
    environment and create a Kubernetes cluster in a cloud provider, in this case,
    AWS. We've seen how to set up our Docker registries, create a cluster using EKS,
    and adapt our existing YAML files so they are ready for the environment.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何将Kubernetes集群应用到生产环境中，并在云提供商（在本例中是AWS）中创建Kubernetes集群。我们看到了如何设置我们的Docker注册表，使用EKS创建集群，并调整现有的YAML文件，使其适用于该环境。
- en: Remember that, though we used AWS as an example, all of the elements we discussed
    are available in other cloud providers. Check their documentation to see if they
    work better for you.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，尽管我们以AWS为例，但我们讨论的所有元素都可以在其他云提供商中使用。查看它们的文档，看看它们是否更适合您。
- en: We also saw how to deploy an ELB so the cluster is available to the public interface,
    and how to enable HTTPS support on it.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何部署ELB，以便集群对公共接口可用，并如何在其上启用HTTPS支持。
- en: We discussed the different elements of deployments to make the cluster more
    resilient and to deploy new versions smoothly, not interrupting the service—both
    by using HAProxy to be able to quickly enable or disable services and by making
    sure that changing the container image is done in an orderly fashion.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了部署的不同元素，以使集群更具弹性，并顺利部署新版本，不中断服务——既可以通过使用HAProxy快速启用或禁用服务，也可以确保以有序方式更改容器映像。
- en: We also covered how autoscaling can help rationalize the use of resources and
    allow you to cover peaks in load in the system, both by creating more pods and
    by adding more AWS instances to add resources to the cluster when needed and remove
    them to avoid needless costs.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还介绍了自动缩放如何帮助合理利用资源，并允许您覆盖系统中的负载峰值，既可以通过创建更多的pod，也可以通过在需要时向集群添加更多的AWS实例来增加资源，并在不需要时将其删除以避免不必要的成本。
- en: In the next chapter, we will see how to control the state of the Kubernetes
    cluster using GitOps principles to be sure that any changes on it are properly
    reviewed and captured.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何使用GitOps原则控制Kubernetes集群的状态，以确保对其进行的任何更改都经过适当审查和捕获。
- en: Questions
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the main disadvantages of managing your own Kubernetes cluster?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理自己的Kubernetes集群的主要缺点是什么？
- en: Can you name some commercial cloud providers that have a managed Kubernetes
    solution?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您能否列举一些具有托管Kubernetes解决方案的商业云提供商的名称？
- en: Is there any action you need to do to be able to push to an AWS Docker registry?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有没有什么操作需要您执行才能推送到AWS Docker注册表？
- en: What tool do we use to set up an EKS cluster?
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用什么工具来设置EKS集群？
- en: What are the main changes we did in this chapter to adapt the YAML files from
    previous chapters?
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们对先前章节的YAML文件进行了哪些主要更改？
- en: Are there any Kubernetes elements that are not required in the cluster from
    this chapter?
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，有哪些Kubernetes元素在集群中是不需要的？
- en: Why do we need to control the DNS associated with an SSL certificate?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们需要控制与SSL证书相关的DNS？
- en: What is the difference between the liveness and readiness probes?
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 活跃探针和就绪探针之间有什么区别？
- en: Why are rolling updates important in production environments?
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在生产环境中滚动更新很重要？
- en: What is the difference between autoscaling pods and nodes?
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动缩放pod和节点有什么区别？
- en: In this chapter, we deployed our own database containers. In production this
    will change, as it's required to connect to an already existing external database.
    How would you change the configuration to do so?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们部署了自己的数据库容器。在生产中，这将发生变化，因为需要连接到已经存在的外部数据库。您将如何更改配置以实现这一点？
- en: Further reading
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about how to use AWS, networking capabilities, which are vast,
    you can check out the book *AWS Networking Cookbook* ([https://www.packtpub.com/eu/virtualization-and-cloud/aws-networking-cookbook](https://www.packtpub.com/eu/virtualization-and-cloud/aws-networking-cookbook)).
    To learn how to ensure that you set up a secure system in AWS, read *AWS: Security
    Best Practices on AWS* ([https://www.packtpub.com/eu/virtualization-and-cloud/aws-security-best-practices-aws](https://www.packtpub.com/eu/virtualization-and-cloud/aws-security-best-practices-aws)).'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '要了解更多关于如何使用AWS的网络能力的信息，您可以查看书籍*AWS Networking Cookbook* ([https://www.packtpub.com/eu/virtualization-and-cloud/aws-networking-cookbook](https://www.packtpub.com/eu/virtualization-and-cloud/aws-networking-cookbook))。要了解如何确保在AWS中设置安全系统，请阅读*AWS:
    Security Best Practices on AWS* ([https://www.packtpub.com/eu/virtualization-and-cloud/aws-security-best-practices-aws](https://www.packtpub.com/eu/virtualization-and-cloud/aws-security-best-practices-aws))。'
