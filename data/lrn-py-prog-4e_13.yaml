- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Data Science in Brief
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简明数据分析
- en: ”If we have data, let’s look at data. If all we have are opinions, let’s go
    with mine.”
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “如果我们有数据，就让我们看看数据。如果我们只有意见，那就听我的。”
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Jim Barksdale, former Netscape CEO
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ——吉姆·巴克斯代尔，前网景CEO
- en: '**Data science** is a broad term that can have different meanings depending
    on the context, understanding, and tools, amongst other factors. To do proper
    data science, you need to, at the very least, know mathematics and statistics.
    Then, you may want to dig into other subjects, such as pattern recognition and
    machine learning, and, of course, there is a plethora of languages and tools you
    can use.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据分析**是一个广泛的概念，其含义可能因上下文、理解、工具等因素而异。要做好数据分析，至少需要了解数学和统计学。然后，你可能还想深入研究其他主题，如模式识别和机器学习，当然，还有大量的语言和工具可供使用。'
- en: We will not be able to talk about everything here. Therefore, to render this
    chapter meaningful, we are going to work on a project together instead.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里无法讨论所有内容。因此，为了使这一章节有意义，我们将一起完成一个项目。
- en: Around 2012/2013, Fabrizio was working for a top-tier social media company in
    London. He stayed there for two years and was privileged to work with several
    very brilliant people. The company was the first in the world to have access to
    the Twitter Ads API, and they were partners with Facebook as well. That means
    a lot of data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在2012/2013年，Fabrizio在伦敦的一家顶级社交媒体公司工作。他在那里工作了两年，有幸与几位非常聪明的人共事。这家公司是世界上第一个能够访问Twitter
    Ads API的公司，他们也是Facebook的合作伙伴。这意味着有大量的数据。
- en: Their analysts were dealing with a vast number of campaigns, and they were struggling
    with the amount of work they had to do, so the development team Fabrizio was a
    part of tried to help by introducing them to Python and to the tools Python gives
    us to deal with data. It was an interesting journey that led him to mentor several
    people in the company, eventually taking him to Manila, where he gave a two-week
    intensive training course in Python and data science to the analysts over there.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的分析师正在处理大量的活动，他们正在努力应对他们必须完成的工作量，因此Fabrizio所在的开发团队试图通过向他们介绍Python和Python提供的数据处理工具来帮助他们。这是一段有趣的旅程，使他成为公司中几位人的导师，最终带他去马尼拉，在那里他为那里的分析师提供了一周两期的Python和数据分析强化培训课程。
- en: The project we are going to do in this chapter is a lightweight version of the
    final example Fabrizio presented to his students in Manila. We have rewritten
    it to a size that will fit this chapter and made a few adjustments here and there
    for teaching purposes, but all the main concepts are there, so it should be fun
    and instructional for you.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将要做的项目是Fabrizio在马尼拉向他的学生展示的最终示例的一个轻量级版本。我们将其改写为适合本章的大小，并对教学目的进行了一些调整，但所有主要概念都在其中，所以这应该会很有趣，也很有教育意义。
- en: 'Specifically, we are going to explore the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将探索以下内容：
- en: The Jupyter Notebook and JupyterLab
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook和JupyterLab
- en: 'pandas and NumPy: the main libraries for data science in Python'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas和NumPy：Python数据分析的主要库
- en: A few concepts around pandas’s `DataFrame` class
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于pandas的`DataFrame`类的一些概念
- en: Creating and manipulating a dataset
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和处理数据集
- en: Let us start by talking about Roman gods.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从罗马神祇说起。
- en: IPython and Jupyter Notebook
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IPython和Jupyter Notebook
- en: In 2001, Fernando Perez was a graduate student in physics at CU Boulder and
    was trying to improve the Python shell so that he could have the niceties he was
    used to when working with tools such as Mathematica and Maple. The result of these
    efforts took the name **IPython** .
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 2001年，Fernando Perez是科罗拉多大学博尔德分校的物理研究生，他试图改进Python壳，以便他能够在使用Mathematica和Maple等工具时享受到他习惯的便利。这些努力的成果被命名为**IPython**。
- en: That small script began as an enhanced version of the Python shell and, through
    the efforts of other coders and eventually with funding from several different
    companies, it became the successful project it is today. Some 10 years after its
    birth, a Notebook environment was created, powered by technologies such as WebSockets,
    the Tornado web server, jQuery, CodeMirror, and MathJax. The ZeroMQ library was
    also used to handle the messages between the Notebook interface and the Python
    core that lies behind it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那个小脚本最初是Python壳的一个增强版本，通过其他程序员的努力，以及几家不同公司的资助，它最终成为了今天这个成功的项目。在其诞生后的大约10年后，一个笔记本环境被创建，它由WebSocket、Tornado网络服务器、jQuery、CodeMirror和MathJax等技术驱动。ZeroMQ库也被用来处理笔记本界面和其背后的Python核心之间的消息。
- en: The IPython Notebook became so popular and widely used that, over time, numerous
    features were added to it. It can handle widgets, parallel computing, various
    media formats, and much more. Moreover, at some point, it became possible to code
    in languages other than Python from within the Notebook.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: IPython Notebook 因其流行和广泛使用，随着时间的推移，它被添加了众多功能。它可以处理小部件、并行计算、各种媒体格式等等。此外，在某个时刻，从
    Notebook 内部使用除 Python 之外的语言进行编码也成为可能。
- en: 'Eventually, the project was split into two: IPython has been stripped down
    to focus more on the kernel and the shell, while the Notebook has become a new
    project called **Jupyter** . Jupyter allows interactive scientific computations
    to be done in more than 40 languages. More recently, the Jupyter project has created
    **JupyterLab** , a web-based **IDE** incorporating Jupyter notebooks, interactive
    consoles, a code editor, and more.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，项目被拆分为两个部分：IPython 被简化以更多地关注内核和外壳，而 Notebook 成为了一个新的项目，称为 **Jupyter**。Jupyter
    允许在超过 40 种语言中进行交互式科学计算。最近，Jupyter 项目创建了 **JupyterLab**，这是一个基于网页的 **IDE**，它集成了
    Jupyter 笔记本、交互式控制台、代码编辑器等等。
- en: This chapter’s project will all be coded and run in a Jupyter Notebook, so let
    us briefly explain what a Notebook is. A Notebook environment is a web page that
    exposes a simple menu and cells in which you can run Python code. Even though
    the cells are separate entities that you can run individually, they all share
    the same Python kernel. This means that all the names that you define in one cell
    (the variables, functions, and so on) will be available in any other cell.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的项目都将使用 Jupyter Notebook 编写和运行，因此让我们简要解释一下什么是 Notebook。Notebook 环境是一个网页，它暴露了一个简单的菜单和单元格，你可以在这里运行
    Python 代码。尽管单元格是独立的实体，你可以单独运行它们，但它们都共享同一个 Python 内核。这意味着你在其中一个单元格（变量、函数等）中定义的所有名称都将可在任何其他单元格中使用。
- en: Simply put, a Python kernel is a process in which Python is running. The Notebook
    web page is an interface exposed to the user for driving this kernel. The web
    page communicates with it using a fast messaging system.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Python 内核是 Python 运行的一个进程。Notebook 网页是提供给用户驱动这个内核的界面。网页通过快速消息系统与之通信。
- en: Apart from all the graphical advantages, the beauty of having such an environment
    lies in the ability to run a Python script in chunks, and this can be a tremendous
    advantage. Take a script that connects to a database to fetch data and then manipulates
    that data. If you do it in the conventional way, with a Python script, you have
    to fetch the data every time you want to experiment with it. Within a Notebook
    environment, you can fetch the data in one cell and then manipulate and experiment
    with it in other cells, so fetching it every time is not necessary.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有图形优势之外，拥有这样一个环境的美妙之处在于能够分块运行 Python 脚本，这可以是一个巨大的优势。假设有一个脚本连接到数据库以获取数据，然后操作这些数据。如果你用传统的
    Python 脚本方式来做，每次你想实验它时都必须重新获取数据。在 Notebook 环境中，你可以在一个单元格中获取数据，然后在其他单元格中操作和实验它，因此不需要每次都获取数据。
- en: The Notebook environment is also helpful for data science because it allows
    for the step-by-step inspection of results. You do one chunk of work and then
    verify it. You then do another chunk and verify again, and so on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Notebook 环境对于数据科学也很有帮助，因为它允许逐步检查结果。你完成一块工作后，然后验证它。然后你做另一块工作并再次验证，依此类推。
- en: It is also invaluable for prototyping because the results are there, right in
    front of your eyes, immediately available.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 它对于原型设计也非常有价值，因为结果就在你眼前，立即可用。
- en: If you would like to know more about these tools, please check out [ipython.org](http://ipython.org)
    and [jupyter.org](http://jupyter.org) .
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于这些工具的信息，请访问 [ipython.org](http://ipython.org) 和 [jupyter.org](http://jupyter.org)
    。
- en: 'We have created a simple example Notebook with a `fibonacci()` function that
    gives you a list of all the Fibonacci numbers smaller than a given `N` . It looks
    like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个简单的 Notebook 示例，其中包含一个 `fibonacci()` 函数，它可以给出小于给定 `N` 的所有斐波那契数的列表。它看起来是这样的：
- en: '![img](img/B30992_13_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_01.png)'
- en: 'Figure 13.1: A Jupyter Notebook'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1：一个 Jupyter Notebook
- en: Every cell has a label in square brackets, like **[1]** . If there is nothing
    between the brackets, it means that the cell has never been executed. If there
    is a number, it means that the cell has been executed, and the number represents
    the order in which the cell was executed. An asterisk, like ***** , means that
    the cell is currently being executed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个单元都有一个方括号中的标签，如 **[1]**。如果方括号中没有内容，则表示该单元从未被执行。如果有数字，则表示该单元已被执行，数字代表单元执行的顺序。一个星号，如
    *****，表示该单元目前正在执行。
- en: 'You can see in the screenshot that in the first cell we have defined the `fibonacci()`
    function and executed it. This has the effect of placing the `fibonacci` name
    in the global scope associated with the Notebook, and therefore the `fibonacci()`
    function is now available to the other cells as well. In fact, in the second cell,
    we can run `list(fibonacci(100))` and see the results output below cell **[2]**
    (the output for each cell is labeled with the same number as the cell itself).
    In the third cell, we have shown you one of the several “magic” functions you
    can find in a Notebook: `%timeit` runs the code several times and provides you
    with a benchmark for it (this is implemented using the `timeit` module, which
    we briefly introduced in *Chapter 11, Debugging and Profiling* ).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '您可以在截图看到，在第一个单元中我们定义了 `fibonacci()` 函数并执行了它。这会将 `fibonacci` 名称放置在笔记本关联的全局作用域中，因此
    `fibonacci()` 函数现在也对其他单元可用。实际上，在第二个单元中，我们可以运行 `list(fibonacci(100))` 并在下面的单元 **[2]**（每个单元的输出都标记与单元相同的数字）中看到结果输出。在第三个单元中，我们向您展示了笔记本中可以找到的几个“魔法”函数之一：`%timeit`
    函数多次运行代码并提供基准（这是使用我们在 *第11章，调试和性能分析* 中简要介绍的 `timeit` 模块实现的）。 '
- en: 'You can execute a cell as many times as you want and change the order in which
    you run them. Cells are very versatile: you can also have Raw cells, which contain
    plain text, or Markdown cells, which are useful for adding formatted textual explanations
    or headings.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按需多次执行一个单元，并改变它们的执行顺序。单元非常灵活：您还可以有原始单元，其中包含纯文本，或者Markdown单元，这对于添加格式化的文本说明或标题非常有用。
- en: '**Markdown** is a lightweight markup language with plain text formatting syntax
    designed so that it can be converted to HTML and many other formats.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**Markdown** 是一种轻量级标记语言，具有纯文本格式化语法，旨在能够将其转换为HTML和其他多种格式。'
- en: Another useful feature is that whatever you place in the last line of a cell
    will automatically be printed for you. This means you are not forced to explicitly
    write `print(…)` every time you want to inspect a value.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的功能是，无论您在单元的最后一行放置什么内容，它都会自动为您打印出来。这意味着您不必每次想要检查一个值时都明确写出 `print(…)`。
- en: Using Anaconda
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Anaconda
- en: As usual, you can install the libraries required for this chapter using the
    `requirements.txt` file in the source code for the chapter. Sometimes, however,
    installing data science libraries can be quite painful. If you are struggling
    to install the libraries for this chapter in your virtual environment, you could
    install Anaconda instead. Anaconda is a free and open-source distribution of the
    Python and R programming languages for data science and machine learning-related
    applications, which aims to simplify package management and deployment. You can
    download it from the [anaconda.org](http://anaconda.org) website. Once you have
    installed it, you can use the Anaconda interface to create a virtual environment
    and install the packages listed in the `requirements.in` file, which you can also
    find in the source code for the chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，您可以使用该章节源代码中的 `requirements.txt` 文件安装本章节所需的库。有时，安装数据科学库可能会相当痛苦。如果您在虚拟环境中安装本章节的库有困难，您可以安装Anaconda。Anaconda是Python和R编程语言的一个免费开源数据科学和机器学习相关应用的发行版，旨在简化包管理和部署。您可以从
    [anaconda.org](http://anaconda.org) 网站下载它。安装后，您可以使用Anaconda界面创建虚拟环境并安装 `requirements.in`
    文件中列出的包，该文件也可以在章节源代码中找到。
- en: Starting a Notebook
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用笔记本
- en: 'Once you have all the required libraries installed, you can start a Notebook
    with the following command:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了所有必需的库，您可以使用以下命令开始一个笔记本：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you install the requirements via Anaconda, you can also launch the Notebook
    from the Anaconda interface. In either case, you will have an open page in your
    web browser at this address (the port might be different): [http://localhost:8888/](http://localhost:8888/)
    .'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你通过Anaconda安装需求，你也可以从Anaconda界面启动笔记本。在任何情况下，你都会在网页浏览器的此地址（端口号可能不同）打开一个页面：[http://localhost:8888/](http://localhost:8888/)
    。
- en: 'You can also launch JupyterLab from Anaconda, or with the following command:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以从Anaconda启动JupyterLab，或者使用以下命令：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It will also open as a new page in your web browser.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 它也会在你的网页浏览器中作为一个新页面打开。
- en: Explore both interfaces. Create a new Notebook or open the `example.ipynb` Notebook
    we showed you above. See which interface you prefer and get comfortable with it
    before proceeding with the rest of the chapter. We have included a saved JupyterLab
    workspace containing the Notebooks used in the rest of this chapter in the source
    code for the chapter (the file is called `ch13.jupyterlab-workspace` ). You can
    use that to follow along in JupyterLab or stick to the classic Notebook interface
    if you prefer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 探索这两个界面。创建一个新的笔记本或打开我们上面展示的`example.ipynb`笔记本。看看你更喜欢哪个界面，并在继续本章的其余部分之前熟悉它。我们在本章的源代码中包含了包含本章其余部分使用的笔记本的保存JupyterLab工作空间（文件名为`ch13.jupyterlab-workspace`）。你可以使用它来在JupyterLab中跟随，或者如果你更喜欢，可以坚持使用经典笔记本界面。
- en: Alternatively, if you use a modern IDE to follow the chapter’s example, it’s
    likely you will be able to install a plugin to work with a notebook directly from
    inside the IDE.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你使用现代IDE来跟随本章的示例，你很可能会安装一个插件，直接在IDE中工作与笔记本。
- en: To help you follow along, we will tag each code example in this chapter with
    the Notebook cell number it belongs to.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你跟上进度，我们将在这个章节中为每个代码示例标记它所属的笔记本单元格编号。
- en: If you familiarize yourself with the keyboard shortcuts (look in the classic
    Notebook **Help** menu or the **Settings Editor** in JupyterLab), you will be
    able to move between cells and handle their content without having to reach for
    the mouse. This will make you much faster when you work in a Notebook.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉键盘快捷键（在经典笔记本的**帮助**菜单或JupyterLab的**设置编辑器**中查找），你将能够在单元格之间移动并处理它们的内容，而无需伸手去拿鼠标。这将使你在笔记本中工作更快。
- en: 'Let us now move on and talk about the most interesting part of this chapter:
    data.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续前进，谈谈本章最有趣的部分：数据。
- en: Dealing with data
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据
- en: 'Typically, when you deal with data, this is the path you go through: you fetch
    it; you clean and manipulate it; and then you analyze it and present results as
    values, spreadsheets, graphs, and so on. We want you to be able to perform all
    three steps of the process without having any external dependency on a data provider,
    so we are going to do the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你处理数据时，你会经过以下路径：你获取它；你清理和操作它；然后你分析它，并以值、电子表格、图表等形式展示结果。我们希望你能独立完成这个过程的所有三个步骤，而不需要依赖任何外部数据提供者，因此我们将执行以下操作：
- en: Create the data, simulating that it comes in a format that is not perfect or
    ready to be worked on.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据，模拟它以不完美或未准备好工作的格式到来。
- en: Clean it and feed it to the main tool we will use in the project, which is a
    `DataFrame` from the `pandas` library.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理它，并将其提供给我们在项目中将使用的主要工具，即来自`pandas`库的`DataFrame`。
- en: Manipulate the data in a `DataFrame` .
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`DataFrame`中操作数据。
- en: Save a `DataFrame` to a file in different formats.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`DataFrame`保存到不同格式的文件中。
- en: Analyze the data and get some results out of it.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析数据并从中获取一些结果。
- en: Setting up the Notebook
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置笔记本
- en: 'First, let us produce the data. We start from the `ch13-dataprep` Notebook.
    Cell `#1` takes care of the imports:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们生成数据。我们从`ch13-dataprep`笔记本开始。单元格`#1`负责导入：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The only modules we have not already encountered are `random` and `faker` .
    `random` is a standard library module for generating pseudo-random numbers. `faker`
    is a third-party module for generating fake data. It is particularly useful in
    tests, when you prepare your fixtures, to get all sorts of things such as names,
    email addresses, phone numbers, and credit card details.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有遇到的最主要的模块是`random`和`faker`。`random`是一个用于生成伪随机数的标准库模块。`faker`是一个用于生成假数据的第三方模块。它在测试中特别有用，当你准备你的固定数据时，可以获取各种东西，如姓名、电子邮件地址、电话号码和信用卡详情。
- en: Preparing the data
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'We want to achieve the following data structure: we are going to have a list
    of user objects. Each user object will be linked to several campaign objects.
    In Python, everything is an object, so we are using this term in a generic way.
    The user object may be a string, a dictionary, or something else.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望达到以下数据结构：我们将有一个用户对象的列表。每个用户对象将链接到几个活动对象。在Python中，一切都是对象，所以我们以通用方式使用这个术语。用户对象可能是一个字符串、一个字典或其他东西。
- en: 'A **campaign** in the social media world is a promotional campaign that a media
    agency runs on social media networks on behalf of a client. Remember that we are
    going to prepare this data so that it is not in perfect shape. Firstly, we instantiate
    the `Faker` that we will use to create the data:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在社交媒体世界中，**活动**是指媒体代理代表客户在社交媒体网络上运行的促销活动。请记住，我们将准备这些数据，以便它们不是完美的形状。首先，我们实例化我们将用于创建数据的`Faker`：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will internally keep track of values that have been generated and only
    yield unique values. We use a list comprehension to generate 1,000 unique usernames.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在内部跟踪已生成的值，并且只产生唯一的值。我们使用列表推导式生成1,000个唯一的用户名。
- en: Next, we create a list of `users` . We will generate 1,000 `user` dictionaries
    with details such as `username` , `name` , `gender` , and `email` . Each `user`
    dictionary is then dumped to JSON and added to the list. This data structure is
    not optimal, of course, but we are simulating a scenario where users come to us
    like that.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个`users`列表。我们将生成1,000个包含诸如`username`、`name`、`gender`和`email`等详细信息的`user`字典。然后，每个`user`字典被转换为JSON格式并添加到列表中。这种数据结构当然不是最优的，但我们正在模拟用户以这种方式来到我们这里的场景。
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `get_users()` generator function takes the number of users to create as
    a parameter. We use `fake.unique.user_name()` in a generator expression to generate
    unique usernames. The `fake.unique` property keeps track of values that have been
    generated and yields only unique values. Next, we call `random.choices()` to generate
    a list of `no_of_users` random elements from the list `["M", "F", "O"]` (to represent
    male, female, or other genders). The weights 0.43, 0.47, and 0.1 will ensure that
    roughly 43% of our users will be male, 47% female, and 10% will not identify as
    either male or female. We use `zip()` to iterate over the usernames and genders.
    For each user, we call `get_random_name()` , which uses a `match` statement to
    generate a gender-appropriate name, and then generate a fake email address, age,
    and address. We dump the user data in a JSON string and `yield` it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_users()`生成函数接受要创建的用户数量作为参数。我们使用生成表达式中的`fake.unique.user_name()`来生成唯一的用户名。`fake.unique`属性跟踪已生成的值，并且只产生唯一的值。接下来，我们调用`random.choices()`来从列表`["M",
    "F", "O"]`（代表男性、女性或其他性别）中生成一个包含`no_of_users`个随机元素的列表。权重0.43、0.47和0.1将确保我们大约43%的用户是男性，47%是女性，10%不认同为男性或女性。我们使用`zip()`遍历用户名和性别。对于每个用户，我们调用`get_random_name()`，它使用`match`语句生成适合性别的名字，然后生成一个假的电子邮件地址、年龄和地址。我们将用户数据转换为JSON字符串并`yield`它。'
- en: 'Also note the last line in the cell. Each cell automatically prints what is
    on the last line; therefore, the output of #3 is a list with the first three users:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意单元格中的最后一行。每个单元格都会自动打印最后一行上的内容；因此，#3的输出是一个包含前三个用户的列表：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We hope you are following along with your own Notebook. If you are, please note
    that all data is generated using random functions and values; therefore, you will
    see different results. They will change every time you execute the Notebook. Also
    note that we have had to trim most of the output in this chapter to fit onto the
    page, so you will see a lot more output in your Notebook than we have reproduced
    here.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望您正在跟随自己的笔记本进行学习。如果您正在这样做，请注意，所有数据都是使用随机函数和值生成的；因此，您将看到不同的结果。每次您执行笔记本时，它们都会发生变化。另外请注意，我们不得不裁剪本章的大部分输出以适应页面，所以您在笔记本中看到的输出将比我们在这里复制的要多得多。
- en: Analysts use spreadsheets all the time, and they create all sorts of coding
    techniques to compress as much information as possible into the campaign names.
    The format we have chosen is a simple example of that technique—there is a code
    that tells us the campaign type, then the start and end dates, then the target
    `age` and `gender` ( `"M"` for male, `"F"` for female, or `"A"` for any), and
    finally the currency.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 分析师们经常使用电子表格，他们创建各种编码技术，尽可能将尽可能多的信息压缩到活动名称中。我们选择这种格式是那种技术的简单示例——有一个代码告诉我们活动类型，然后是开始和结束日期，然后是目标`年龄`和`性别`（`"M"`代表男性，`"F"`代表女性，或`"A"`代表任何），最后是货币。
- en: 'All values are separated by an underscore. The code to generate these campaign
    names can be found in cell `#4` :'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所有值都用下划线分隔。生成这些营销活动名称的代码可以在单元格 `#4` 中找到：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the `get_type()` function, we use `random.choice()` to get one value randomly
    out of a collection. `get_start_end_dates()` is a bit more interesting. We compute
    two random integers: the `duration` of the campaign in days (between one day and
    two years) and an `offset` (a number of days between –365 and 365). We subtract
    `offset` (as a `timedelta` ) from today’s date to get the start date and add the
    `duration` to get the end date. Finally, we return string representations of both
    dates.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `get_type()` 函数中，我们使用 `random.choice()` 从一个集合中随机获取一个值。`get_start_end_dates()`
    函数稍微有趣一些。我们计算两个随机整数：活动的 `duration`（天数，介于一天和两年之间）和一个 `offset`（介于-365和365天之间的天数）。我们从今天的日期减去
    `offset`（作为一个 `timedelta` ）以得到开始日期，并加上 `duration` 以得到结束日期。最后，我们返回两个日期的字符串表示。
- en: The `get_age_range()` function generates a random target age range, where both
    endpoints are multiples of five. We use the `random.randrange()` function, which
    returns a random number from a range defined by `start` , `stop` , and `step`
    parameters (these parameters have the same meaning as for the `range` object that
    we first encountered in *Chapter 3, Conditionals and Iteration* ). We generate
    random numbers `age` (a multiple of 5 between 20 and 46) and `diff` (a multiple
    of 5 between 5 and 26). We add `diff` to `age` to get the upper limit of our age
    range and return a string representation of the age range.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_age_range()` 函数生成一个随机的目标年龄范围，其中两个端点都是五的倍数。我们使用 `random.randrange()` 函数，该函数返回一个由
    `start`、`stop` 和 `step` 参数定义的范围内的随机数（这些参数的含义与我们在 *第3章，条件语句和迭代* 中首次遇到的 `range`
    对象相同）。我们生成随机数 `age`（20到46岁之间的5的倍数）和 `diff`（5到26岁之间的5的倍数）。我们将 `diff` 加到 `age` 上以得到年龄范围的上限，并返回年龄范围的字符串表示。'
- en: The rest of the functions are just some applications of `random.choice()` and
    the last one, `get_campaign_name()` , assembles all the pieces and returns the
    final campaign name.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的函数只是对 `random.choice()` 的一些应用，最后一个函数 `get_campaign_name()` 将所有片段组合起来并返回最终的营销活动名称。
- en: 'In `#5` , we write a function that creates a complete campaign object:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `#5` 中，我们编写了一个函数来创建一个完整的营销活动对象：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We used a few functions from the `random` module. `random.randint()` gives you
    an integer between two extremes. It follows a uniform probability distribution,
    which means that any number in the interval has the same probability of coming
    up. To avoid having all our data look similar, we chose to use `triangular()`
    and `gauss()` , for `clicks` and `impressions` . They use different probability
    distributions so that we will have something more interesting to see in the end.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一些来自 `random` 模块的功能。`random.randint()` 给你两个极端之间的整数。它遵循均匀概率分布，这意味着区间内的任何数字出现的概率相同。为了避免我们的所有数据看起来都相似，我们选择使用
    `triangular()` 和 `gauss()`，用于 `clicks` 和 `impressions`。它们使用不同的概率分布，这样我们最终会看到更有趣的东西。
- en: 'Just to make sure we are on the same page with the terminology: `clicks` represents
    the number of clicks on a campaign advertisement, `budget` is the total amount
    of money allocated for the campaign, `spent` is how much of that money has already
    been spent, and `impressions` is the number of times the campaign has been displayed,
    regardless of the number of clicks that were performed on the campaign. Normally,
    the number of `impressions` is greater than the number of `clicks` because an
    advertisement is often viewed without being clicked on.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 只为了确保我们对术语的理解一致：`clicks` 代表对营销活动广告的点击次数，`budget` 是分配给活动的总金额，`spent` 是已经花费的金额，而
    `impressions` 是活动被展示的次数，无论在活动中执行了多少点击。通常，`impressions` 的数量大于 `clicks` 的数量，因为广告通常被查看而没有被点击。
- en: 'Now that we have the data, we can put it all together:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数据，我们可以将其全部组合起来：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, each item in `data` is a dictionary with a `user` and a list
    of campaigns that are associated with that `user` .
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`data` 中的每个条目都是一个包含 `user` 和与该 `user` 关联的营销活动列表的字典。
- en: Cleaning the data
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'Next, we can start cleaning the data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以开始清理数据：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We simulate fetching the data from a source and then inspect it. The Notebook
    is the perfect tool for inspecting your steps.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模拟从源中获取数据，然后检查它。笔记本是检查您步骤的完美工具。
- en: 'You can vary the granularity to suit your needs. The first item in `rough_data`
    looks like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据需要调整粒度。`rough_data` 中的第一个条目看起来像这样：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we can start working on the data. The first thing we need to do to be able
    to work with this `data` is to denormalize it. **Denormalization** is a process
    of restructuring data into a single table. This involves merging data from multiple
    tables or flattening out nested data structures. It usually introduces some duplication
    of data; however, it simplifies data analysis by eliminating the need to deal
    with nested structures or to look related data up across multiple tables. In our
    case, this means transforming `data` into a list whose items are campaign dictionaries,
    augmented with their relative `user` dictionary. Users will be duplicated in each
    campaign they are associated with:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以开始处理数据。为了能够使用这些 `data`，我们首先需要做的事情是将它去规范化。**去规范化**是一个将数据重新结构化到单个表中的过程。这涉及到合并来自多个表的数据或展开嵌套的数据结构。它通常会引入一些数据重复；然而，通过消除处理嵌套结构或跨多个表查找相关数据的需求，它简化了数据分析。在我们的案例中，这意味着将
    `data` 转换为一个列表，其项是带有它们相对 `user` 字典的战役字典。用户将在他们关联的每个战役中重复：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The first item in `data` now looks like this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`data` 中的第一个项目现在看起来像这样：'
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we would like to help you and offer a deterministic second part of the
    chapter, so we are going to save the data we generated here so that we (and you,
    too) will be able to load it from the next Notebook, and we should then have the
    same results:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要帮助你并提供本章的确定性第二部分，因此我们将保存这里生成的数据，以便我们（以及你）能够从下一个笔记本中加载它，然后我们应该得到相同的结果：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You should find the `data.json` file in the source code for the book. Now, we
    are done with `ch13-dataprep` , so we can close it and open the `ch13` notebook.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在书的源代码中找到 `data.json` 文件。现在，我们已经完成了 `ch13-dataprep`，所以我们可以关闭它并打开 `ch13` 笔记本。
- en: Creating the DataFrame
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 DataFrame
- en: 'Now that we have prepared our data, we can start analyzing it. First, we have
    another round of imports:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了数据，我们可以开始分析它。首先，我们进行另一轮导入：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We have already seen the `json` module in *Chapter 8, Files and Data Persistence*
    . We also briefly introduced `arrow` in *Chapter 2, Built-In Data Types* . It
    is a very useful third-party library that makes working with dates and times a
    lot easier. `pandas` is the core upon which the whole project is based. **pandas**
    stands for **Python Data Analysis Library** . Among many other things, it provides
    the `DataFrame` , a matrix-like data structure with advanced processing capabilities.
    It is customary to `import pandas as pd` and also import `DataFrame` separately
    **.**
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 *第 8 章，文件和数据持久化* 中看到了 `json` 模块。我们也在 *第 2 章，内置数据类型* 中简要介绍了 `arrow`。这是一个非常实用的第三方库，它使得处理日期和时间变得容易得多。`pandas`
    是整个项目的基础。**pandas** 代表 **Python 数据分析库**。在许多其他功能中，它提供了 `DataFrame`，这是一个具有高级处理能力的类似矩阵的数据结构。通常我们会
    `import pandas as pd` 并单独导入 `DataFrame` **。**
- en: 'After the imports, we load our data into a `DataFrame` using the `pandas.read_json()`
    function:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 导入之后，我们使用 `pandas.read_json()` 函数将我们的数据加载到一个 `DataFrame` 中：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We inspect the first five rows using the `head()` method of `DataFrame` . You
    should see something like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `DataFrame` 的 `head()` 方法检查前五行。你应该看到类似这样的内容：
- en: '![img](img/B30992_13_02.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_02.png)'
- en: 'Figure 13.2: The first few rows of the DataFrame'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2：DataFrame 的前几行
- en: Jupyter automatically renders the output of the `df.head()` call as HTML. To
    get a plain text representation, you can wrap `df.head()` in a `print` call.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 会自动将 `df.head()` 调用的输出渲染为 HTML。要获取纯文本表示，你可以在 `df.head()` 中包裹一个 `print`
    调用。
- en: The `DataFrame` structure allows you to perform various operations on its contents.
    You can filter by rows or columns, aggregate data, and so on. You can operate
    on entire rows or columns without suffering the time penalty you would have to
    pay if you were working on data with pure Python. This is possible because, under
    the hood, `pandas` harnesses the power of the **NumPy** library, which itself
    draws its incredible speed from the low-level implementation of its core.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame` 结构允许你对它的内容执行各种操作。你可以按行或列进行筛选，聚合数据，等等。你可以对整个行或列进行操作，而无需支付如果你使用纯
    Python 处理数据时必须支付的时间惩罚。这是可能的，因为底层 `pandas` 利用 **NumPy** 库的力量，而 **NumPy** 本身从其核心的低级实现中获得了惊人的速度。'
- en: NumPy stands for Numeric Python. It is one of the most widely used libraries
    in the data science environment.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 代表 Numeric Python。它是数据科学环境中最广泛使用的库之一。
- en: Using `DataFrame` allows us to couple the power of NumPy with spreadsheet-like
    capabilities so that we can work on our data in a way that is similar to what
    an analyst would normally do, only we do it with code.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `DataFrame` 允许我们将 NumPy 的强大功能与类似电子表格的能力结合起来，这样我们就可以以类似于分析师通常所做的方式处理我们的数据，只是我们用代码来做。
- en: 'Let us see two ways to quickly get an overview of the data:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看两种快速获取数据概览的方法：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `count()` method returns a count of all the non-empty cells in each column.
    This is useful to help you understand how sparse your data is. In our case, we
    have no missing values, so the output is:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`count()` 方法返回每列中所有非空单元格的计数。这有助于您了解您的数据有多稀疏。在我们的例子中，我们没有缺失值，所以输出是：'
- en: '| `cmp_name` | 5065 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `cmp_name` | 5065 |'
- en: '| `cmp_bgt` | 5065 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `cmp_bgt` | 5065 |'
- en: '| `cmp_spent` | 5065 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `cmp_spent` | 5065 |'
- en: '| `cmp_clicks` | 5065 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `cmp_clicks` | 5065 |'
- en: '| `cmp_impr` | 5065 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `cmp_impr` | 5065 |'
- en: '| `user` | 5065 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `user` | 5065 |'
- en: '| `dtype: int64` |  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `dtype: int64` |  |'
- en: We have 5,065 rows. Given that we have 1,000 users and the number of campaigns
    per user is a random number between 2 and 8, that is in line with what we would
    expect.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 5,065 行。考虑到我们有 1,000 个用户，每个用户的活动数量是一个介于 2 和 8 之间的随机数，这与我们的预期相符。
- en: 'The `dtype: int64` line at the end of the output indicates that the values
    returned by `df.count()` are NumPy `int64` objects. Here, `dtype` stands for “data
    type” and `int64` means 64-bit integers. NumPy is largely implemented in C and,
    instead of using Python’s built-in numeric types, it uses its own types, which
    are closely related to C language data types. This allows it to perform numerical
    operations much more quickly than pure Python.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '输出末尾的 `dtype: int64` 行表示 `df.count()` 返回的值是 NumPy 的 `int64` 对象。在这里，`dtype`
    代表“数据类型”，而 `int64` 表示 64 位整数。NumPy 主要用 C 语言实现，它不使用 Python 的内置数字类型，而是使用自己的类型，这些类型与
    C 语言的数据类型密切相关。这使得它能够比纯 Python 更快地执行数值运算。'
- en: 'The `describe` method is useful to quickly obtain a statistical summary of
    our data:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe` 方法有助于快速获取数据的统计摘要：'
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As shown in the output below, it gives us several measures, such as `count`
    , `mean` , `std` (standard deviation), `min` , and `max` , and shows how data
    is distributed in the various quartiles. Thanks to this method, we already have
    an idea of how our data is structured:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如下面的输出所示，它提供了几个度量，如 `count`、`mean`、`std`（标准差）、`min` 和 `max`，并显示了数据在各个四分位数中的分布情况。多亏了这种方法，我们已经有了一个关于数据结构的大致了解：
- en: '|  | **cmp_bgt** | **cmp_spent** | **cmp_clicks** | **cmp_impr** |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | **cmp_bgt** | **cmp_spent** | **cmp_clicks** | **cmp_impr** |'
- en: '| **count** | 5065.000000 | 5065.000000 | 5065.000000 | 5065.000000 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **count** | 5065.000000 | 5065.000000 | 5065.000000 | 5065.000000 |'
- en: '| **mean** | 502965.054097 | 253389.854689 | 40265.781639 | 499999.474630 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| **mean** | 502965.054097 | 253389.854689 | 40265.781639 | 499999.474630 |'
- en: '| **std** | 290468.998656 | 222774.897138 | 21840.783154 | 2.023801 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **std** | 290468.998656 | 222774.897138 | 21840.783154 | 2.023801 |'
- en: '| **min** | 1764.000000 | 107.000000 | 899.000000 | 499992.000000 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| **min** | 1764.000000 | 107.000000 | 899.000000 | 499992.000000 |'
- en: '| **25%** | 251171.000000 | 67071.000000 | 22575.000000 | 499998.000000 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| **25%** | 251171.000000 | 67071.000000 | 22575.000000 | 499998.000000 |'
- en: '| **50%** | 500694.000000 | 187743.000000 | 36746.000000 | 499999.000000 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| **50%** | 500694.000000 | 187743.000000 | 36746.000000 | 499999.000000 |'
- en: '| **75%** | 756850.000000 | 391790.000000 | 55817.000000 | 500001.000000 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| **75%** | 756850.000000 | 391790.000000 | 55817.000000 | 500001.000000 |'
- en: '| **max** | 999565.000000 | 984705.000000 | 98379.000000 | 500007.000000 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **max** | 999565.000000 | 984705.000000 | 98379.000000 | 500007.000000 |'
- en: 'We can use the `sort_values()` and `head()` methods to see the campaigns with
    the highest budgets:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `sort_values()` 和 `head()` 方法查看预算最高的活动：
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This gives the following output (we have omitted some columns to fit the output
    on the page):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出以下输出（我们省略了一些列以适应页面输出）：
- en: '|  | **cmp_name** | **cmp_bgt** | **cmp_clicks** | **cmp_impr** |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | **cmp_name** | **cmp_bgt** | **cmp_clicks** | **cmp_impr** |'
- en: '| **3186** | `GRZ_20230914_20230929_40-60_A_EUR` | 999565 | 63869 | 499998
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **3186** | `GRZ_20230914_20230929_40-60_A_EUR` | 999565 | 63869 | 499998
    |'
- en: '| **3168** | `KTR_20250315_20260507_25-40_M_USD` | 999487 | 21097 | 500000
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **3168** | `KTR_20250315_20260507_25-40_M_USD` | 999487 | 21097 | 500000
    |'
- en: '| **3624** | `GRZ_20250227_20250617_30-45_F_USD` | 999482 | 3435 | 499998 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **3624** | `GRZ_20250227_20250617_30-45_F_USD` | 999482 | 3435 | 499998 |'
- en: 'Calling `tail()` instead of `head()` shows us the campaigns with the lowest
    budgets:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `tail()` 而不是 `head()` 可以显示预算最低的活动：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, we will take on some more complex tasks.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将承担一些更复杂的任务。
- en: Unpacking the campaign name
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解包活动名称
- en: Firstly, we want to get rid of the campaign name column ( `cmp_name` ). We need
    to explode it into parts and put each part in its own dedicated column. We will
    use the `apply()` method of the `Series` object to do this.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们想要去除活动名称列（`cmp_name`）。我们需要将其分解成部分，并将每个部分放入其专用的列中。我们将使用`Series`对象的`apply()`方法来完成此操作。
- en: The `pandas.core.series.Series` class is a powerful wrapper around an array
    (think of it as a list with augmented capabilities). We can extract a `Series`
    object from `DataFrame` by accessing it in the same way we do with a key in a
    dictionary. We will then use the `apply()` method of the `Series` object to call
    a function on each item in the `Series` and obtain a new `Series` with the results.
    Finally, we compose the result into a new `DataFrame` , and then join that `DataFrame`
    with `df` .
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas.core.series.Series`类是一个围绕数组的强大包装器（将其视为具有增强功能的列表）。我们可以通过以字典中键的方式访问它来从`DataFrame`中提取`Series`对象。然后我们将使用`Series`对象的`apply()`方法对`Series`中的每个项目调用一个函数，并获取一个包含结果的新的`Series`。最后，我们将结果组合成一个新的`DataFrame`，然后将其与`df`连接。'
- en: We start by defining a function to split a campaign name into a tuple containing
    the type, start and end dates, target age, target gender, and currency. Note that
    we use `arrow.get()` to convert the start and end date strings to `date` objects.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个函数，将活动名称拆分为包含类型、开始和结束日期、目标年龄、目标性别和货币的元组。请注意，我们使用`arrow.get()`将开始和结束日期字符串转换为`date`对象。
- en: '[PRE20]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Next, we extract the `Series` with the campaign names from `df` and apply the
    `unpack_campaign_name()` function to each name.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从`df`中提取带有活动名称的`Series`，并将`unpack_campaign_name()`函数应用于每个名称。
- en: '[PRE21]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now we can construct a new `DataFrame` from the `campaign_data` :'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从`campaign_data`构建一个新的`DataFrame`：
- en: '[PRE22]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'A quick peek at the first three rows reveals:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看前几行显示：
- en: '|  | **Type** | **Start** | **End** | **Target Age** | **Target Gender** |
    **Currency** |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  | **类型** | **开始** | **结束** | **目标年龄** | **目标性别** | **货币** |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | `KTR` | `2025-04-04` | `2025-09-16` | `35-50` | `A` | `EUR` |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 0 | `KTR` | `2025-04-04` | `2025-09-16` | `35-50` | `A` | `EUR` |'
- en: '| 1 | `AKX` | `2024-01-30` | `2024-10-17` | `20-25` | `M` | `GBP` |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `AKX` | `2024-01-30` | `2024-10-17` | `20-25` | `M` | `GBP` |'
- en: '| 2 | `BYU` | `2023-08-28` | `2025-01-15` | `25-45` | `M` | `GBP` |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 2 | `BYU` | `2023-08-28` | `2025-01-15` | `25-45` | `M` | `GBP` |'
- en: 'That looks better. Now, we can more easily work with the data represented by
    the column names. One important thing to remember: even if the dates are printed
    as strings, they are just the representation of the real `date` objects that are
    stored in `DataFrame` .'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来更好。现在，我们可以更容易地处理由列名称表示的数据。要记住的一个重要事项：即使日期以字符串的形式打印出来，它们也只是存储在`DataFrame`中的真实`date`对象的表示。
- en: Finally, we can join the original `DataFrame` ( `df` ) and `campaign_df` into
    a single `DataFrame` . When joining two `DataFrame` instances, it is imperative
    that they have the same `index` , otherwise `pandas` will not be able to match
    up the rows. We took care of this by explicitly using the index from `df` when
    creating `campaign_df.`
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将原始`DataFrame`（`df`）和`campaign_df`连接成一个单一的`DataFrame`。在连接两个`DataFrame`实例时，它们必须具有相同的`index`，否则`pandas`无法匹配行。我们通过在创建`campaign_df`时显式使用`df`的索引来处理这个问题。
- en: '[PRE23]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let us inspect the data to verify that everything matches correctly:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查数据以验证一切是否正确匹配：
- en: '[PRE24]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The first few columns of the output are as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的前几列如下：
- en: '|  | **cmp_name** | **Type** | **Start** | **End** |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | **cmp_name** | **类型** | **开始** | **结束** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | `KTR_20250404_20250916_35-50_A_EUR` | `KTR` | `2025-04-04` | `2025-09-16`
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 0 | `KTR_20250404_20250916_35-50_A_EUR` | `KTR` | `2025-04-04` | `2025-09-16`
    |'
- en: '| 1 | `AKX_20240130_20241017_20-25_M_GBP` | `AKX` | `2024-01-30` | `2024-10-17`
    |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `AKX_20240130_20241017_20-25_M_GBP` | `AKX` | `2024-01-30` | `2024-10-17`
    |'
- en: '| 2 | `BYU_20230828_20250115_25-45_M_GBP` | `BYU` | `2023-08-28` | `2025-01-15`
    |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 2 | `BYU_20230828_20250115_25-45_M_GBP` | `BYU` | `2023-08-28` | `2025-01-15`
    |'
- en: As you can see, `join()` was successful; the campaign name and the separated
    columns represent the same data.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`join()`操作成功；活动名称和分离的列代表相同的数据。
- en: Note how we access the `DataFrame` using the square brackets syntax, passing
    a list of column names. This will produce a new `DataFrame` , with those columns
    (in the same order), on which we then call the `head()` method.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何使用方括号语法访问`DataFrame`，传递一个列名列表。这将产生一个新的`DataFrame`，其中包含这些列（按相同顺序），然后我们调用`head()`方法。
- en: Unpacking the user data
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解包用户数据
- en: 'We now do the same thing for each piece of `user` JSON data. We call `apply()`
    on the `user` series, running the `unpack_user_json()` function, which takes a
    JSON `user` object and transforms it into a list of its fields. We create a new
    `DataFrame` , `user_df` , with this data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对每一份 `user` JSON 数据做同样的事情。我们在 `user` 系列上调用 `apply()`，运行 `unpack_user_json()`
    函数，该函数接收一个 JSON `user` 对象并将其转换为字段列表。我们使用这些数据创建一个新的 `DataFrame`，名为 `user_df`：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we join `user_df` back with `df` (like we did with `campaign_df` ), and
    inspect the result:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将 `user_df` 与 `df`（就像我们之前对 `campaign_df` 做的那样）连接起来，并检查结果：
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The output shows us that everything went well.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示一切正常。
- en: Renaming columns
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重命名列
- en: 'If you evaluate `df.columns` in a cell, you will see that we still have ugly
    names for our columns. Let us change that:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个单元格中评估 `df.columns`，你会看到我们列的名称仍然很丑陋。让我们来改变一下：
- en: '[PRE27]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `rename()` method can be used to change the column (or row) labels. We have
    given it a dictionary mapping old column names to our preferred names. Any column
    that is not mentioned in the dictionary will remain unchanged.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`rename()` 方法可以用来更改列（或行）标签。我们给它提供了一个映射旧列名到我们首选名称的字典。任何未在字典中提到的列将保持不变。'
- en: Computing some metrics
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算一些指标
- en: 'Our next step will be to add some additional columns. For each campaign, we
    have the number of clicks and impressions, and we have the amounts spent. This
    allows us to introduce three measurement ratios: `CTR` , `CPC` , and `CPI` . They
    stand for *Click Through Rate* , *Cost Per Click* , and *Cost Per Impression*
    , respectively.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一步将添加一些额外的列。对于每个活动，我们都有点击数和展示数，以及花费的金额。这使我们能够引入三个测量比率：`CTR`、`CPC` 和 `CPI`。它们分别代表
    *点击通过率*、*每点击成本* 和 *每展示成本*。
- en: 'The last two are straightforward, but `CTR` is not. Suffice it to say that
    it is the ratio between clicks and impressions. It gives you a measure of how
    many clicks were performed on a campaign advertisement per impression—the higher
    this number, the more successful the advertisement is in attracting users to click
    on it. Let us write a function that calculates all three ratios and adds them
    to the `DataFrame` :'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个很简单，但 `CTR` 不一样。简单来说，它是点击和展示的比率。它衡量了每展示一次活动广告时点击的次数——这个数字越高，广告在吸引用户点击方面就越成功。让我们编写一个函数来计算所有三个比率并将它们添加到
    `DataFrame` 中：
- en: '[PRE28]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice that we are adding those three columns with one line of code each, but
    the `DataFrame` applies the operation automatically (the division, in this case)
    to each pair of cells from the appropriate columns. So, even though it looks like
    we are only doing three divisions, there are actually *5,140 * 3* divisions because
    they are performed for each row. `pandas` does a lot of work for us while hiding
    much of the complexity of it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们通过一行代码添加了这三个列，但 `DataFrame` 会自动（在这种情况下是除法）对适当列中的每一对单元格执行操作。所以，尽管看起来我们只做了三次除法，但实际上有
    *5,140 * 3* 次除法，因为它们是针对每一行执行的。`pandas` 在为我们做大量工作的同时，隐藏了其中的许多复杂性。
- en: The `calculate_metrics()` function takes a `DataFrame` ( `df` ) and works directly
    on it. This mode of operation is called **in-place** . This is similar to how
    the `list.sort()` method sorts a list. You could also say that this function is
    not pure, which means it has side effects, as it modifies the mutable object it
    is passed as an argument.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`calculate_metrics()` 函数接收一个 `DataFrame`（`df`）并在其上直接操作。这种操作模式被称为**原地**。这类似于
    `list.sort()` 方法对列表进行排序的方式。你也可以说这个函数不是纯函数，这意味着它有副作用，因为它修改了作为参数传递的可变对象。'
- en: 'We can take a look at the results by filtering on the relevant columns and
    calling `head()` :'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过筛选相关列并调用 `head()` 来查看结果：
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This shows us that the calculations were performed correctly on each row:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明计算已经在每一行上正确执行：
- en: '|  | **Spent** | **Clicks** | **Impressions** | **CTR** | **CPC** | **CPI**
    |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|  | **花费** | **点击** | **展示** | **CTR** | **CPC** | **CPI** |'
- en: '| 0 | 29586 | 36632 | 500001 | 0.073264 | 0.807655 | 0.059172 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 29586 | 36632 | 500001 | 0.073264 | 0.807655 | 0.059172 |'
- en: '| 1 | 166010 | 67325 | 499999 | 0.134650 | 2.465800 | 0.332021 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 166010 | 67325 | 499999 | 0.134650 | 2.465800 | 0.332021 |'
- en: '| 2 | 125738 | 29989 | 499997 | 0.059978 | 4.192804 | 0.251478 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 125738 | 29989 | 499997 | 0.059978 | 4.192804 | 0.251478 |'
- en: 'We can also verify the accuracy of the results manually for the first row:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以手动验证第一行的结果准确性：
- en: '[PRE30]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This yields the following output:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出：
- en: '[PRE31]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The values match, confirming that our computations are correct. Of course, we
    would not normally need to do this, but we wanted to show you how can you perform
    such calculations. You can access a `Series` (a column) by passing its name to
    the `DataFrame` in square brackets (this is similar to looking up a key in a dictionary).
    You can then access each row in the column by its position, exactly as you would
    with a regular list or tuple.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 值匹配，确认我们的计算是正确的。当然，我们通常不需要这样做，但我们想向你展示如何执行此类计算。你可以通过将名称传递给方括号中的`DataFrame`来访问一个`Series`（一个列）。然后你可以通过其位置访问列中的每一行，就像你使用常规列表或元组一样。
- en: We are almost done with our `DataFrame` . All we are missing now is a column
    that tells us the duration of the campaign and a column that tells us which day
    of the week each campaign started on. The duration is important to have, since
    it allows us to relate data such as the amount spent or number of impressions
    to the duration of the campaign (we may expect longer-running campaigns to cost
    more and have more impressions). The day of the week can also be useful; for example,
    some campaigns may be tied to events that happen on particular days of the week
    (such as sports events that take place on weekends).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了我们的`DataFrame`。我们现在缺少的只是一个告诉我们活动持续时间的列，以及一个告诉我们每个活动开始是星期几的列。持续时间很重要，因为它允许我们将诸如花费金额或展示次数等数据与活动的持续时间联系起来（我们可能预计持续时间较长的活动花费更多，并且有更多的展示次数）。星期几也可能很有用；例如，一些活动可能与特定星期的某些事件相关联（例如在周末举行的体育赛事）。
- en: '[PRE32]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`get_day_of_the_week()` takes a `date` object and formats it as a string that
    only contains the name of the corresponding day of the week. `get_duration()`
    is more interesting. First, notice that it takes an entire row, not just a single
    value. This function subtracts a campaign’s start date from the end date. When
    you subtract `date` objects, the result is a `timedelta` object, which represents
    a given amount of time. We take the value of its `.days` property to get the duration
    in days.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_day_of_the_week()`接受一个`date`对象并将其格式化为只包含相应星期名称的字符串。`get_duration()`更有趣。首先，注意它接受整个行，而不仅仅是单个值。这个函数从活动的开始日期减去结束日期。当你减去`date`对象时，结果是`timedelta`对象，它表示给定的时间量。我们取其`.days`属性的值来获取以天为单位的时间长度。'
- en: We calculate the starting day of the week for each campaign by applying `get_day_of_the_week()`
    to the `Start` column (as a `Series` object); this is similar to what we did with
    `"user"` and `"cmp_name"` . Next, we apply `get_duration()` to the whole `DataFrame`
    . Note that we instruct `pandas` to operate on the rows by passing `axis="columns"`
    . This may seem counter-intuitive but think of it as passing all the columns to
    each call of `get_duration()` .
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将`get_day_of_the_week()`应用于`Start`列（作为一个`Series`对象）来计算每个活动的开始周，这与我们对`"user"`和`"cmp_name"`所做的是类似的。接下来，我们将`get_duration()`应用于整个`DataFrame`。请注意，我们通过传递`axis="columns"`来指示`pandas`在行上操作。这看起来可能有些反直觉，但把它想象成将所有列传递给`get_duration()`的每一次调用。
- en: 'We can verify the results as shown in the next cell:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像下面这样验证结果：
- en: '[PRE33]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This gives the following output:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '|  | **Start** | **End** | **Duration** | **Day of Week** |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '|  | **开始** | **结束** | **持续时间** | **星期** |'
- en: '| **0** | `2025-04-04` | `2025-09-16` | 165 | `Friday` |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| **0** | `2025-04-04` | `2025-09-16` | 165 | `星期五` |'
- en: '| **1** | `2024-01-30` | `2024-10-17` | 261 | `Tuesday` |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| **1** | `2024-01-30` | `2024-10-17` | 261 | `星期二` |'
- en: '| **2** | `2023-08-28` | `2025-01-15` | 506 | `Monday` |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| **2** | `2023-08-28` | `2025-01-15` | 506 | `星期一` |'
- en: So, we now know that there are 165 days between the 4th of April, 2025, and
    the 16th of September, 2025, and that the 15th of January, 2025, is a Monday.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们现在知道从2025年4月4日到2025年9月16日之间有165天，而2025年1月15日是星期一。
- en: Cleaning everything up
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清理一切
- en: 'Now that we have everything we want, it is time to do the final cleaning; remember
    we still have the `"cmp_name"` and `"user"` columns. Those are no longer needed,
    so we will remove them. We also want to reorder the columns in our `DataFrame`
    so that they are more relevant to the data it now contains. We can accomplish
    this by filtering `df` on the column list we want. The result is a new `DataFrame`
    that we can reassign to the name `df` :'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经拥有了我们想要的一切，现在是时候进行最后的清洁工作了；记住我们仍然有`"cmp_name"`和`"user"`列。这些不再需要，所以我们将移除它们。我们还想重新排列`DataFrame`中的列，以便它们与现在包含的数据更加相关。我们可以通过在想要的列上过滤`df`来实现这一点。结果是新的`DataFrame`，我们可以将其重新分配给名称`df`：
- en: '[PRE34]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We have grouped the campaign information at the beginning, then the measurements,
    and finally the user data at the end. Now our `DataFrame` is clean and ready for
    us to inspect.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在开始处将活动信息分组，然后是测量，最后是用户数据。现在我们的`DataFrame`已经干净，准备好供我们检查。
- en: Before we start creating some graphs, we want to take a snapshot of the `DataFrame`
    so that we can easily reconstruct it from a file without needing to redo all the
    steps we did to get here. Some analysts may want to have it in spreadsheet form,
    to do a different kind of analysis, so let us see how to save a `DataFrame` to
    a file.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始创建一些图表之前，我们想要对`DataFrame`进行快照，这样我们就可以轻松地从文件中重建它，而无需重新执行我们为了到达这里所做的一切步骤。一些分析师可能希望将其以电子表格的形式保存，以便进行不同类型的分析，所以让我们看看如何将`DataFrame`保存到文件。
- en: Saving the DataFrame to a file
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将DataFrame保存到文件
- en: We can save a `DataFrame` in several formats. You can type `df.to_` and then
    press *Tab* to make autocompletion pop up, so you can see all the options.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`DataFrame`保存为几种格式。你可以输入`df.to_`然后按*Tab*键，以使自动完成弹出，这样你就可以看到所有选项。
- en: 'We are going to save our `DataFrame` in three different formats. First, CSV:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们的`DataFrame`保存为三种不同的格式。首先，CSV：
- en: '[PRE35]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then JSON:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，JSON：
- en: '[PRE36]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'And finally, in an Excel spreadsheet:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在一个Excel电子表格中：
- en: '[PRE37]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The `to_excel()` method requires the `openpyxl` package to be installed. It
    is included in the `requirements.txt` file for this chapter, so if you used that
    to install the requirements, you should have it in your virtual environment.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`to_excel()`方法需要安装`openpyxl`包。它包含在本章的`requirements.txt`文件中，所以如果你使用它来安装需求，你应该在你的虚拟环境中拥有它。'
- en: 'As you can see, it is easy to save a `DataFrame` in many different formats.
    The good news is that the reverse is also true: it’s equally easy to load a spreadsheet
    into a `DataFrame` (just use the `pandas read_csv()` or `read_excel()` functions).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，保存`DataFrame`为多种格式很容易。好消息是，反过来也是如此：将电子表格加载到`DataFrame`中（只需使用`pandas read_csv()`或`read_excel()`函数）同样容易。
- en: Visualizing the results
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化结果
- en: In this section, we are going to visualize some results. From a data science
    perspective, we are not going to attempt an in-depth analysis of the data or try
    to draw any conclusions from it. It would not make much sense because the data
    is completely random. However, this example should still be enough to get you
    started with graphs and other features.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将可视化一些结果。从数据科学的角度来看，我们不会尝试对数据进行深入分析，或试图从中得出任何结论。这样做没有太多意义，因为数据是完全随机的。然而，这个例子应该足以让你开始使用图表和其他功能。
- en: One lesson that we have learned the hard way is that appearance makes a difference
    in how people perceive your work. If you want to be taken seriously, think carefully
    about how you present your data and try to make your graphs and tables look appealing.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过艰难的方式学到的教训之一是，外观会影响人们对你的工作的看法。如果你想得到重视，仔细考虑你如何展示你的数据，并尝试让你的图表和表格看起来吸引人。
- en: '`pandas` uses the Matplotlib plotting library to draw graphs. We will not be
    using it directly, except to configure the plot style and save plots to disk.
    You can learn more about this versatile plotting library at [https://matplotlib.org/](https://matplotlib.org/)
    .'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`使用Matplotlib绘图库来绘制图形。我们不会直接使用它，除非配置绘图样式并将图形保存到磁盘。你可以在[https://matplotlib.org/](https://matplotlib.org/)了解更多关于这个多功能绘图库的信息。'
- en: 'First, we will configure the Notebook to render Matplotlib graphs as interactive
    widgets in the cell output frame. We do it with the following:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将配置Notebook，以便将Matplotlib图表作为交互式小部件在单元格输出框架中渲染。我们通过以下方式完成：
- en: '[PRE38]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This will allow you to pan and zoom the figure and save a (low-resolution) snapshot
    to disk.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许你平移和缩放图形，并将一个（低分辨率）快照保存到磁盘。
- en: By default (without `%matplotlib widget` ), figures will be rendered as static
    images in the cell output frame. Using the interactive widget mode requires the
    `ipympl` package to be installed. It is included in the `requirements.txt` file
    for this chapter, so if you used that to install the requirements, you should
    have it in your virtual environment.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下（没有`%matplotlib widget`），图形将以静态图像的形式在单元格输出框架中渲染。使用交互式小部件模式需要安装`ipympl`包。它包含在本章的`requirements.txt`文件中，所以如果你使用它来安装需求，你应该在你的虚拟环境中拥有它。
- en: 'Then, we set up some styling for our plots:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为我们的绘图设置一些样式：
- en: '[PRE39]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We use the `matplotlib.pyplot` interface to set the plot style. We have chosen
    to use a combination of the `classic` and `ggplot` style sheets. Style sheets
    are applied from left to right, so here `ggplot` will override the `classic` style
    for any style items that are defined in both. We also set the font family used
    in the plots to `serif` . The `plt.rc("savefig", dpi=300)` call, configures the
    `savefig()` method to generate high-resolution image files that are suitable for
    printing.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `matplotlib.pyplot` 接口设置绘图样式。我们选择使用 `classic` 和 `ggplot` 样式表的组合。样式表是从左到右应用的，因此在这里
    `ggplot` 将覆盖在两者中定义的任何样式项。我们还设置了绘图中所使用的字体家族为 `serif`。调用 `plt.rc("savefig", dpi=300)`
    配置了 `savefig()` 方法以生成适合打印的高分辨率图像文件。
- en: 'Before we generate any graphs, let us run `df.describe()` ( `#26` ) again.
    The results should look like this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们生成任何图表之前，让我们再次运行 `df.describe()`（`#26`）。结果应该如下所示：
- en: '![img](img/B30992_13_03.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_03.png)'
- en: 'Figure 13.3: Some statistics for our cleaned-up data'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：我们清理后的数据的某些统计信息
- en: This kind of quick result is perfect for satisfying those managers who have
    20 seconds to dedicate to you and just want rough numbers.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这种快速的结果非常适合满足那些只有20秒时间可以用来关注你并且只想得到粗略数字的经理们。
- en: Once again, please keep in mind that our campaigns have different currencies,
    so these numbers are meaningless. The point here is to demonstrate the `DataFrame`
    capabilities, not to perform a correct or detailed analysis of real data.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，请注意我们的活动有不同的货币，所以这些数字没有意义。这里的目的是展示 `DataFrame` 的功能，而不是对真实数据进行正确或详细的分析。
- en: 'Alternatively, a graph is usually much better than a table with numbers because
    it is much easier to read, and it gives you immediate feedback. So, let us plot
    the four pieces of information we have on each campaign: `"Budget"` , `"Spent"`
    , `"Clicks"` , and `"Impressions"` :'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，通常来说，图表比数字表格要好得多，因为它更容易阅读，并且能立即给出反馈。所以，让我们绘制我们关于每个活动的四条信息：“预算”、"花费"、“点击量”和“展示次数”：
- en: '[PRE40]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We extract those four columns (this will give us another `DataFrame` made with
    only those columns) and call the `hist()` method to get a histogram plot. We give
    some arguments to specify the number of bins and figure sizes, and everything
    else is done automatically. The result looks as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提取这四个列（这将给我们另一个只包含这些列的 `DataFrame`）并调用 `hist()` 方法来获取直方图。我们给出一些参数来指定箱数和图形大小，其余的自动完成。结果如下所示：
- en: '![img](img/B30992_13_04.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_04.png)'
- en: 'Figure 13.4: Histogram plots of the campaign data'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4：活动数据的直方图
- en: We also call `plt.savefig("Figure13.4.png")` to save the image to a file named
    `Figure13.4.png` . This will use the `300dpi` setting we configured previously
    to generate a high-resolution image. Note that `plt.savefig()` will save the most
    recent image generated by Matplotlib. Calling it from the same cell where we generate
    the plot ensures that we save the correct image to the correct filename.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还调用 `plt.savefig("Figure13.4.png")` 将图像保存到名为 `Figure13.4.png` 的文件中。这将使用我们之前配置的
    `300dpi` 设置来生成高分辨率图像。请注意，`plt.savefig()` 将保存Matplotlib生成的最新图像。从生成图表的同一单元格中调用它确保我们保存了正确的图像到正确的文件名。
- en: Although it is meaningless to try to interpret plots of random data, we can
    at least verify that what we see matches what we might expect, given how the data
    was generated.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管尝试解释随机数据的图表没有意义，但我们至少可以验证我们看到的结果与我们根据数据生成方式可能预期的结果相匹配。
- en: '*Budget* is selected randomly from an interval, so we expect a uniform distribution.
    Looking at the graph, that is indeed what we see.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预算* 是从区间中随机选择的，所以我们期望一个均匀分布。从图表上看，这确实是我们所看到的。'
- en: '*Spent* is also uniformly distributed, but its upper limit is the budget, which
    is not constant. This means we should expect a logarithmic curve that decreases
    from left to right. Again, that matches what the graph shows.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*花费* 也是均匀分布的，但其上限是预算，这不是恒定的。这意味着我们应该期望一个从左到右递减的对数曲线。再次，这与图表显示的一致。'
- en: '*Clicks* was generated with a triangular distribution with a mean 20% of the
    interval size, and you can see that the peak is right there, at about 20% to the
    left.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*点击量* 是通过具有区间大小平均20%的三角分布生成的，你可以看到峰值就在那里，大约在左侧20%的位置。'
- en: '*Impressions* was a Gaussian distribution, which assumes the famous bell shape.
    The mean was exactly in the middle and we had a standard deviation of 2. You can
    see that the graph matches those parameters.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Impressions*呈高斯分布，这假设了著名的钟形形状。平均值正好在中间，我们有一个标准差为2。您可以看到图表与这些参数相匹配。'
- en: 'Let us also plot the metrics we calculated:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也绘制我们计算出的指标：
- en: '[PRE41]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here is the plot representation:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图表表示：
- en: '![img](img/B30992_13_05.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_05.png)'
- en: 'Figure 13.5: Histogram plots of computed measures'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5：计算出的度量值的直方图
- en: We can see that the *CPC* is highly skewed to the left, meaning that most of
    the *CPC* values are low. The *CPI* has a similar shape but is less extreme.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，*CPC*严重向左倾斜，这意味着大多数*CPC*值都很低。*CPI*具有相似的形状，但不太极端。
- en: 'Now, suppose you want to analyze only a particular segment of the data. We
    can apply a mask to the `DataFrame` so that we get a new `DataFrame` with only
    the rows that satisfy the mask condition. It is like applying a global, row-wise
    `if` clause:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设您只想分析数据的一个特定部分。我们可以对`DataFrame`应用一个掩码，以便我们得到一个新的`DataFrame`，其中只包含满足掩码条件的行。这就像应用一个全局的、按行操作的`if`子句：
- en: '[PRE42]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In this case, we prepared `selector` to filter out all the rows for which the
    amount spent is less than or equal to 75% of the budget. In other words, we will
    include only those campaigns for which we have spent at least three-quarters of
    the budget. Notice that in `selector` , we are showing you an alternative way
    of asking for a `DataFrame` column, by using direct property access ( `object.property_name`
    ), instead of dictionary-like access ( `object['property_name']` ). If `property_name`
    is a valid Python name, you can use both ways interchangeably.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们准备了`selector`来筛选出所有花费金额小于或等于预算75%的行。换句话说，我们只包括那些至少花费了预算四分之三的活动。请注意，在`selector`中，我们向您展示了一种获取`DataFrame`列的替代方法，即通过直接属性访问（`object.property_name`），而不是字典式访问（`object['property_name']`）。如果`property_name`是一个有效的Python名称，您可以使用这两种方式互换。
- en: '`selector` is applied in the same way that we access a dictionary with a key.
    When we apply `selector` to `df` , we get a new `DataFrame` . We select only the
    relevant columns from this and call `hist()` again. This time, we set `color`
    to `green` , just to show how that can be done.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`selector`的应用方式与访问字典时使用键的方式相同。当我们对`df`应用`selector`时，我们得到一个新的`DataFrame`。我们只从其中选择相关的列，并再次调用`hist()`。这次，我们将`color`设置为`green`，只是为了展示如何做到这一点。'
- en: '![img](img/B30992_13_06.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_06.png)'
- en: 'Figure 13.6: Histogram plots of campaign data where at least 75% of the budget
    was spent'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6：至少花费了75%预算的活动的直方图
- en: Note that the shapes of the graphs have not changed much, apart from the *Spent*
    graph, which is quite different. This is because we have selected only the rows
    where the amount spent is at least 75% of the budget. This means that we are including
    only the rows where the amount spent is close to the budget. The budget numbers
    come from a uniform distribution. Therefore, the *Spent* graph is now assuming
    that kind of shape. If you make the boundary even tighter and ask for 85% or more,
    you will see the *Spent* graph become increasingly similar to *Budget* .
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，除了*Spent*图表之外，图表的形状变化不大，*Spent*图表相当不同。这是因为我们只选择了花费金额至少为预算75%的行。这意味着我们只包括花费金额接近预算的行。预算数字来自均匀分布。因此，*Spent*图表现在呈现出这种形状。如果您将边界设置得更紧，要求85%或更多，您将看到*Spent*图表越来越接近*Budget*。
- en: Let us also look at a different kind of plot. We will plot the sums of `"Spent"`
    , `"Clicks"` , and `"` `Impressions"` for each day of the week.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看不同类型的图表。我们将绘制每天的花费`"Spent"`、`"Clicks"`和`"Impressions"`的总和。
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The first line creates a new `DataFrame` , `df_weekday` , by asking for a grouping
    by `"Day of Week"` on `df` . We then aggregate, by computing the sum within each
    group. Note that we must pass `numeric_only=True` to avoid errors when attempting
    to sum columns with non-numeric data. We could also have taken a different approach
    by selecting only the columns we need ( `"Day of Week"` , `"Impressions"` , `"Spent"`
    , and `"Clicks"` ) before grouping and summing.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行创建了一个新的`DataFrame`，名为`df_weekday`，通过在`df`上请求按`"Day of Week"`进行分组。然后我们通过在每个组内计算总和来进行聚合。请注意，我们必须传递`numeric_only=True`以避免在尝试对包含非数值数据的列求和时出错。我们也可以通过在分组和求和之前只选择我们需要的列（`"Day
    of Week"`、`"Impressions"`、`"Spent"`和`"Clicks"`）来采取不同的方法。
- en: 'Note that this time we call `plot()` instead of `hist()` . This will draw a
    line graph instead of a histogram. The `subplots=True` option makes `plot` draw
    three separate graphs:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这次我们调用 `plot()` 而不是 `hist()`。这将绘制一个折线图而不是直方图。`subplots=True` 选项使 `plot` 绘制三个单独的图表：
- en: '![img](img/B30992_13_07.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_07.png)'
- en: 'Figure 13.7: Plots of campaign data aggregated by day of the week'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7：按星期几汇总的活动数据图
- en: These plots show that campaigns that started on Thursdays got the most clicks
    and impressions, while campaigns that started on Saturdays spent the least money.
    If this were real data, this would potentially be important information to give
    to our clients.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表显示，周四开始的活动获得了最多的点击和印象，而周六开始的活动花费的钱最少。如果这是真实数据，这可能会是我们的客户需要的重要信息。
- en: Note that the days are sorted alphabetically, which makes the graph difficult
    to read. We will leave it to you as an exercise to find a way to fix this.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些天是按字母顺序排序的，这使得图表难以阅读。我们将把这个作为练习留给你，找到一种方法来解决这个问题。
- en: Let us finish this presentation section with a couple more things. First, a
    simple aggregation. We want to group by `"Target Gender"` and `"Target Age"` ,
    and compute the mean and the standard deviation `("std")` of `"Impressions"` and
    `"Spent"` within each grouping.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在结束这个演示部分之前再补充几点。首先，一个简单的聚合。我们希望按 `"Target Gender"` 和 `"Target Age"` 进行分组，并计算每个分组中
    `"Impressions"` 和 `"Spent"` 的平均值和标准差 `("std")`。
- en: '[PRE44]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We prepare a dictionary to use as the configuration. Then, we perform a grouping
    on the `"Target Gender"` and `"Target Age"` columns, and we pass our configuration
    dictionary to the `agg()` method. The output looks like this:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备了一个字典作为配置使用。然后，我们在 `"Target Gender"` 和 `"Target Age"` 列上执行分组，并将我们的配置字典传递给
    `agg()` 方法。输出看起来像这样：
- en: '|  |  | **Impressions** | **Spent** |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '|  |  | **Impressions** | **Spent** |'
- en: '|  |  | **mean** | **std** | **mean** | **std** |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '|  |  | **mean** | **std** | **mean** | **std** |'
- en: '| **Target Gender** | **Target Age** |  |  |  |  |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| **Target Gender** | **Target Age** |  |  |  |  |'
- en: '| **A** | 20-25 | 499999.245614 | 2.189918 | 217330.771930 | 204518.652595
    |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| **A** | 20-25 | 499999.245614 | 2.189918 | 217330.771930 | 204518.652595
    |'
- en: '| 20-30 | 499999.465517 | 2.210148 | 252261.637931 | 228932.088945 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 20-30 | 499999.465517 | 2.210148 | 252261.637931 | 228932.088945 |'
- en: '| 20-35 | 499998.564103 | 1.774006 | 218726.410256 | 215060.976707 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 20-35 | 499998.564103 | 1.774006 | 218726.410256 | 215060.976707 |'
- en: '| 20-40 | 499999.459016 | 1.971241 | 255598.213115 | 222697.755231 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 20-40 | 499999.459016 | 1.971241 | 255598.213115 | 222697.755231 |'
- en: '| 20-45 | 499999.574074 | 2.245346 | 216527.666667 | 190345.252888 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 20-45 | 499999.574074 | 2.245346 | 216527.666667 | 190345.252888 |'
- en: '| **...** | ... | ... | ... | ... | ... |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... | ... | ... |'
- en: '| **M** | 45-50 | 499999.480769 | 2.128153 | 276112.557692 | 226975.008137
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| **M** | 45-50 | 499999.480769 | 2.128153 | 276112.557692 | 226975.008137
    |'
- en: '| 45-55 | 499999.306122 | 2.053494 | 267137.938776 | 239249.474145 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 45-55 | 499999.306122 | 2.053494 | 267137.938776 | 239249.474145 |'
- en: '| 45-60 | 499999.500000 | 1.984063 | 236623.312500 | 223464.578371 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 45-60 | 499999.500000 | 1.984063 | 236623.312500 | 223464.578371 |'
- en: '| 45-65 | 499999.679245 | 1.503503 | 215634.528302 | 223308.046968 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 45-65 | 499999.679245 | 1.503503 | 215634.528302 | 223308.046968 |'
- en: '| 45-70 | 499998.870370 | 1.822773 | 310267.944444 | 242353.980346 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 45-70 | 499998.870370 | 1.822773 | 310267.944444 | 242353.980346 |'
- en: 'Let us do one more thing before we wrap this chapter up. We want to show you
    something called a **pivot table** . A pivot table is a way of grouping data,
    computing an aggregate value for each group, and displaying the result in table
    form. The pivot table is an essential tool for data analysis, so let us see a
    simple example:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束这一章之前，让我们再做一些事情。我们想向你展示一个叫做 **交叉表** 的东西。交叉表是一种分组数据、为每个组计算聚合值并在表格形式中显示结果的方法。交叉表是数据分析的一个基本工具，所以让我们看看一个简单的例子：
- en: '[PRE45]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We create a pivot table that shows us the correlation between `"Target Age"`
    and `"Impressions"` , `"Clicks"` , and `"Spent"` . These last three will be subdivided
    according to `"` `Target Gender"` . The `aggfunc` argument specifies the aggregation
    function to use, it can be a function object, the name of a function, a list of
    functions, or a dictionary that maps column names to functions. In this case,
    we use `"sum"` (the default, if no function is specified is to compute the `mean`
    ). The result is a new `DataFrame` containing the pivot table:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个交叉表，显示了 `"Target Age"` 与 `"Impressions"`、"Clicks" 和 `"Spent"` 之间的相关性。最后这三个将根据
    `"` `Target Gender"` 进行细分。`aggfunc` 参数指定要使用的聚合函数，它可以是函数对象、函数名、函数列表或映射列名到函数的字典。在这种情况下，我们使用
    `"sum"`（默认值，如果没有指定函数，则计算平均值）。结果是包含交叉表的新 `DataFrame`：
- en: '![img](img/B30992_13_08.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B30992_13_08.png)'
- en: 'Figure 13.8: A pivot table'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8：交叉表
- en: That brings us to the end of our data analysis project. We will leave you to
    discover more about the wonderful world of IPython, Jupyter, and data science.
    We strongly encourage you to get comfortable with the Notebook environment. It
    is much better than a console, it is practical and fun to use, and you can even
    create slides and documents with it.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们的数据分析项目。我们将让你去探索关于IPython、Jupyter和数据科学的奇妙世界。我们强烈建议你熟悉Notebook环境。它比控制台更好，实用且使用起来有趣，你甚至可以用它来创建幻灯片和文档。
- en: Where do we go from here?
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们接下来该去哪里？
- en: 'Data science is indeed a fascinating subject. As we said in the introduction,
    those who want to delve into its meanders need to have a solid foundation in mathematics
    and statistics. Working with data that has been interpolated incorrectly renders
    any result about it useless. The same goes for data that has been extrapolated
    incorrectly or sampled with the wrong frequency. To give you an example, imagine
    a population of individuals that are aligned in a queue. If, for some reason,
    the gender of that population alternated between male and female, the queue would
    look something like this: F-M-F-M-F-M-F-M-F...'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学确实是一个迷人的主题。正如我们在引言中所说，那些想要深入其迷宫的人需要具备扎实的数学和统计学基础。处理被错误插值的数据会使任何关于它的结果都变得无用。同样，对于被错误外推或以错误频率采样的数据也是如此。为了给你一个例子，想象一个排列成队列的个人群体。如果出于某种原因，这个群体的性别在男性和女性之间交替，队列看起来可能就像这样：F-M-F-M-F-M-F-M-F...
- en: If you sampled it, taking only the even elements, you would draw the conclusion
    that the population was made up only of males, while sampling the odd ones would
    tell you exactly the opposite.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只采样偶数元素，你会得出结论说这个群体只由男性组成，而采样奇数元素则会告诉你正好相反。
- en: Of course, this was just a silly example, but it is easy to make mistakes in
    this field, especially when dealing with big datasets where sampling is mandatory
    and, therefore, the quality of your analysis depends, first and foremost, on the
    quality of the sampling itself.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这只是一个愚蠢的例子，但在这个领域很容易出错，尤其是在处理需要采样的大数据集时，因此，你分析的质量首先取决于采样的质量。
- en: 'When it comes to data science and Python, these are the main tools you want
    to look at:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到数据科学和Python时，这些是你想要查看的主要工具：
- en: '**NumPy** ( [https://www.numpy.org/](https://www.numpy.org/) ): This is the
    main package for scientific computing with Python. It contains a powerful N-dimensional
    array object, sophisticated (broadcasting) functions, tools for integrating C/C++
    and Fortran code, useful linear algebra, the Fourier transform, random number
    capabilities, and much more.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy** ([https://www.numpy.org/](https://www.numpy.org/)): 这是使用Python进行科学计算的主要包。它包含一个强大的N维数组对象，复杂的（广播）函数，用于集成C/C++和Fortran代码的工具，有用的线性代数，傅里叶变换，随机数功能，以及更多。'
- en: '**scikit-learn** ( [https://scikit-learn.org/](https://scikit-learn.org/) ):
    This is one of the most popular machine learning libraries in Python. It has simple
    and efficient tools for data mining and data analysis, is accessible to everybody,
    and is reusable in various contexts. It is built on NumPy, SciPy, and Matplotlib.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scikit-learn** ([https://scikit-learn.org/](https://scikit-learn.org/)):
    这是Python中最受欢迎的机器学习库之一。它提供了简单高效的数据挖掘和分析工具，对每个人都是可访问的，并且可以在各种环境中重复使用。它是基于NumPy、SciPy和Matplotlib构建的。'
- en: '**pandas** ( [https://pandas.pydata.org/](https://pandas.pydata.org/) ): This
    is an open-source, BSD-licensed library providing high-performance, easy-to-use
    data structures and data analysis tools. We have used it throughout this chapter.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas** ([https://pandas.pydata.org/](https://pandas.pydata.org/)): 这是一个开源的BSD许可库，提供高性能、易于使用的数据结构和数据分析工具。我们在这章中一直使用它。'
- en: '**IPython** ( [https://ipython.org/](https://ipython.org/) )/ **Jupyter** (
    [https://jupyter.org/](https://jupyter.org/) ): These provide a rich architecture
    for interactive computing.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IPython** ([https://ipython.org/](https://ipython.org/)) / **Jupyter** ([https://jupyter.org/](https://jupyter.org/)):
    这些提供了丰富的交互式计算架构。'
- en: '**Matplotlib** ( [https://matplotlib.org/](https://matplotlib.org/) ): This
    is a Python 2D plotting library that produces publication-quality figures in a
    variety of hard-copy formats and interactive environments across platforms. Matplotlib
    can be used in Python scripts, the Python and IPython shell, a Jupyter Notebook,
    web application servers, and several graphical user interface toolkits.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib** ([https://matplotlib.org/](https://matplotlib.org/)): 这是一个Python
    2D绘图库，可以在多种硬拷贝格式和跨平台的交互式环境中生成出版物质量的图形。Matplotlib可用于Python脚本、Python和IPython shell、Jupyter
    Notebook、Web应用服务器以及多个图形用户界面工具包。'
- en: '**Seaborn** ( [https://seaborn.pydata.org/](https://seaborn.pydata.org/) ):
    This is a Python data visualization library based on Matplotlib. It provides a
    high-level interface for drawing attractive and informative statistical graphics.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seaborn** ([https://seaborn.pydata.org/](https://seaborn.pydata.org/)): 这是一个基于Matplotlib的Python数据可视化库。它提供了一个高级接口，用于绘制吸引人且信息丰富的统计图形。'
- en: '**Numba** ( [https://numba.pydata.org/](https://numba.pydata.org/) ): This
    gives you the power to speed up your applications with high-performance functions
    written directly in Python. With a few annotations, array-oriented and math-heavy
    Python code can be just-in-time compiled to native machine instructions, similar
    in performance to C, C++, and Fortran, without having to switch languages or Python
    interpreters.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Numba** ([https://numba.pydata.org/](https://numba.pydata.org/)): 这让你能够使用直接在Python中编写的性能函数来加速你的应用程序。通过一些注释，数组导向和数学密集型的Python代码可以被即时编译成本地机器指令，其性能与C、C++和Fortran相似，而无需切换语言或Python解释器。'
- en: '**Bokeh** ( [https://bokeh.pydata.org/](https://bokeh.pydata.org/) ): This
    is a Python-interactive visualization library that targets modern web browsers
    for presentation. Its goal is to provide elegant, concise construction of novel
    graphics in the style of D3.js, but also deliver this capability with high-performance
    interactivity over large or streaming datasets.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bokeh** ([https://bokeh.pydata.org/](https://bokeh.pydata.org/)): 这是一个针对现代Web浏览器的Python交互式可视化库，用于展示。它的目标是提供类似于D3.js风格的优雅、简洁的图形构建，同时也能在大型或流式数据集上提供高性能的交互性。'
- en: Other than these single libraries, you can also find ecosystems, such as **SciPy**
    ( [https://scipy.org/](https://scipy.org/) ) and the aforementioned **Anaconda**
    ( [https://anaconda.org/](https://anaconda.org/) ), that bundle several different
    packages to give you something that just works in an “out-of-the-box” fashion.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些单个库之外，你还可以找到生态系统，例如**SciPy** ([https://scipy.org/](https://scipy.org/))和前面提到的**Anaconda**
    ([https://anaconda.org/](https://anaconda.org/))，它们捆绑了多个不同的包，以便你能够以“开箱即用”的方式获得所需的功能。
- en: Installing all these tools and their several dependencies is hard on some systems,
    so we suggest that you try out ecosystems as well to see whether you are comfortable
    with them. It may be worth it.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些系统上安装所有这些工具及其依赖项可能很困难，因此我们建议你也尝试生态系统，看看你是否对他们感到舒适。这可能值得尝试。
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we talked about data science. Rather than attempting to explain
    anything about this broad subject, we delved into a project. We familiarized ourselves
    with the Jupyter Notebook, and with different libraries, such as `pandas` , `Matplotlib`
    , and `NumPy` .
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了数据科学。我们并没有试图解释这个广泛主题的任何内容，而是深入一个项目。我们熟悉了Jupyter Notebook，以及不同的库，如`pandas`、`Matplotlib`和`NumPy`。
- en: Of course, having to compress all this information into one single chapter means
    we could only touch briefly on the subjects we presented. We hope the project
    we have worked through together has been comprehensive enough to give you an idea
    of the workflow to follow when working in this field.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，必须将所有这些信息压缩到一章中意味着我们只能简要地涉及我们提出的主题。我们希望我们共同完成的项目足够全面，能够给你一个在这个领域工作时遵循的工作流程的思路。
- en: The next chapter is dedicated to API development.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将专门介绍API开发。
- en: Join our community on Discord
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://discord.com/invite/uaKmaz7FEC](Chapter_13.xhtml)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://discord.com/invite/uaKmaz7FEC](Chapter_13.xhtml)'
- en: '![img](img/QR_Code119001106417026468.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/QR_Code119001106417026468.png)'
