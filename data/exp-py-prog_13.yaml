- en: Chapter 13. Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章。并发
- en: Concurrency and one of its manifestations—parallel processing—is one of the
    broadest topics in the area of software engineering. Most of the chapters in this
    book also cover vast areas, and almost all of them could be big enough topics
    for a separate book. But the topic of concurrency by itself is so huge that it
    could take dozens of positions and we would still not be able to discuss all of
    its important aspects and models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 并发及其表现之一——并行处理——是软件工程领域中最广泛的主题之一。本书中的大部分章节也涵盖了广泛的领域，几乎所有这些章节都可以成为一本独立的书的大主题。但并发这个主题本身是如此庞大，以至于它可能需要数十个职位，我们仍然无法讨论其所有重要方面和模型。
- en: 'This is why I won''t try to fool you, and from the very beginning state that
    we will barely touch the surface of this topic. The purpose of this chapter is
    to show why concurrency may be required in your application, when to use it, and
    what are the most important concurrency models that you may use in Python:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我不会试图愚弄你，并且从一开始就声明我们几乎不会深入讨论这个话题。本章的目的是展示为什么你的应用程序可能需要并发，何时使用它，以及你可以在Python中使用的最重要的并发模型：
- en: Multithreading
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程
- en: Multiprocessing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多处理
- en: Asynchronous programming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步编程
- en: We will also discuss some of the language features, built-in modules, and third-party
    packages that allow you to implement these models in your code. But we won't cover
    them in much detail. Treat the content of this chapter as an entry point for your
    further research and reading. It is here to guide you through the basic ideas
    and help in deciding if you really need concurrency, and if so, which approach
    will best suit your needs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论一些语言特性、内置模块和第三方包，这些都可以让你在代码中实现这些模型。但我们不会详细讨论它们。把本章的内容当作你进一步研究和阅读的起点。它在这里是为了引导你了解基本的想法，并帮助你决定是否真的需要并发，以及哪种方法最适合你的需求。
- en: Why concurrency?
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要并发？
- en: Before we answer the question *why concurrency*, we need to ask *what is concurrency
    at all?*
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在回答“为什么要并发”之前，我们需要问“并发到底是什么？”
- en: And the answer to the second question may be surprising for some who used to
    think that this is a synonym for **parallel processing**. But concurrency is not
    the same as parallelism. Concurrency is not a matter of application implementation
    but only a property of a program, algorithm, or problem. And parallelism is only
    one of the possible approaches to problems that are concurrent.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对第二个问题的答案可能会让一些人感到惊讶，他们曾经认为这是**并行处理**的同义词。但并发不同于并行。并发不是应用程序实现的问题，而只是程序、算法或问题的属性。并行只是处理并发问题的可能方法之一。
- en: 'Leslie Lamport in his *Time, Clocks, and the Ordering of Events in Distributed
    Systems* paper from 1976, says:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 1976年，Leslie Lamport在他的《分布式系统中的时间、时钟和事件排序》一文中说：
- en: '*"Two events are concurrent if neither can causally affect the other."*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"如果两个事件互不影响，则它们是并发的。"*'
- en: By extrapolating events to programs, algorithms, or problems, we can say that
    something is concurrent if it can be fully or partially decomposed into components
    (units) that are order-independent. Such units may be processed independently
    from each other, and the order of processing does not affect the final result.
    This means that they can also be processed simultaneously or in parallel. If we
    process information this way, then we are indeed dealing with parallel processing.
    But this is still not obligatory.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将事件推广到程序、算法或问题，我们可以说如果某事物可以被完全或部分分解为无序的组件（单元），那么它就是并发的。这些单元可以相互独立地进行处理，处理的顺序不会影响最终结果。这意味着它们也可以同时或并行处理。如果我们以这种方式处理信息，那么我们确实在处理并行处理。但这并非强制性的。
- en: Doing work in a distributed manner, preferably using capabilities of multicore
    processors or computing clusters, is a natural consequence of concurrent problems.
    Anyway, it does not mean that this is the only way of efficiently dealing with
    concurrency. There are a lot of use cases where concurrent problems can be approached
    in other than synchronous ways, but without the need for parallel execution.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以分布式方式进行工作，最好利用多核处理器或计算集群的能力，是并发问题的自然结果。但这并不意味着这是处理并发的唯一有效方式。有很多用例，可以以非同步的方式处理并发问题，但不需要并行执行。
- en: So, once we know what concurrency really is, it is time to explain what the
    fuss is about. When the problem is concurrent, it gives you the opportunity to
    deal with it in a special, preferably more efficient, way.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一旦我们知道了并发到底是什么，就是时候解释这到底是怎么回事了。当问题是并发的时候，它给了你处理它的机会，以一种特殊的、更有效的方式。
- en: 'We often get used to deal with problems in a classical way by performing a
    sequence of steps. This is how most of us think and process information—using
    synchronous algorithms that do one thing at a time, step by step. But this way
    of processing information is not well suited for solving large-scale problems
    or when you need to satisfy the demands of multiple users or software agents simultaneously:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常习惯用经典的方式处理问题，通过一系列步骤来解决问题。这是我们大多数人思考和处理信息的方式——使用同步算法逐步进行。但这种信息处理方式并不适合解决大规模问题或需要同时满足多个用户或软件代理的需求：
- en: The time to process the job is limited by the performance of the single processing
    unit (single machine, CPU core, and so on)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理工作的时间受单个处理单元（单台机器、CPU核心等）性能的限制
- en: You are not able to accept and process new inputs until your program has finished
    processing the previous one
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在程序完成处理前，无法接受和处理新的输入
- en: 'So generally, approaching concurrent problems concurrently is the best approach
    when:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通常处理并发问题的最佳方法是同时处理：
- en: The scale of problems is so big that the only way to process them in an acceptable
    time or within the range of available resources is to distribute execution to
    multiple processing units that can handle the work in parallel
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的规模如此之大，以至于在可接受的时间范围内或在可用资源范围内处理它们的唯一方法是将执行分配给能够并行处理工作的多个处理单元。
- en: Your application needs to maintain responsiveness (accept new inputs) even if
    it has not finished processing the old ones
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的应用程序需要保持响应性（接受新输入），即使它还没有完成处理旧的输入
- en: This covers most of the situations where concurrent processing is a reasonable
    option. The first group of problems definitely needs the parallel processing solution
    so it is usually solved with multithreading and multiprocessing models. The second
    group does not necessarily need to be processed in parallel, so the actual solution
    really depends on the problem details. Note that this group also covers cases
    where the application needs to serve multiple clients (users or software agents)
    independently, without the need to wait for others to be successfully served.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了大多数情况下并发处理是一个合理选择的情况。第一组问题明显需要并行处理解决方案，因此通常使用多线程和多处理模型来解决。第二组问题不一定需要并行处理，因此实际解决方案取决于问题的细节。请注意，这组问题还涵盖了应用程序需要独立为多个客户（用户或软件代理）提供服务，而无需等待其他成功服务的情况。
- en: The other thing worth mentioning is that the preceding two groups are not exclusive.
    Very often you need to maintain application responsiveness and at the same time
    you are not able to handle the input on a single processing unit. This is the
    reason why different and seemingly alternative or conflicting approaches to concurrency
    may often be used at the same time. This is especially common in the development
    of web servers where it may be necessary to use asynchronous event loops, or threads
    with a conjunction of multiple processes, in order to utilize all the available
    resources and still maintain low latencies under high load.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件值得一提的事情是，前面两组并不是互斥的。很多时候，你需要保持应用程序的响应性，同时又无法在单个处理单元上处理输入。这就是为什么在并发性方面，不同的看似替代或冲突的方法经常同时使用的原因。这在开发Web服务器时尤其常见，可能需要使用异步事件循环，或者线程与多个进程的结合，以利用所有可用资源并在高负载下保持低延迟。
- en: Multithreading
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程
- en: Threading is often considered to be a complex topic by developers. While this
    statement is totally true, Python provides high-level classes and functions that
    ease the usage of threading. CPython's implementation of threads comes with some
    inconvenient details that make them less useful than in other languages. They
    are still completely fine for some set problems that you may want to solve, but
    not for as many as in C or Java. In this section, we will discuss the limitations
    of multithreading in CPython, as well as the common concurrent problems where
    Python threads are a viable solution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 线程通常被开发人员认为是一个复杂的话题。虽然这种说法完全正确，但Python提供了高级类和函数，简化了线程的使用。CPython对线程的实现带来了一些不便的细节，使它们比其他语言中的线程更少用。它们对于一些你可能想要解决的问题仍然完全合适，但不像在C或Java中那样多。在本节中，我们将讨论CPython中多线程的限制，以及Python线程是可行解决方案的常见并发问题。
- en: What is multithreading?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是多线程？
- en: Thread is short for a thread of execution. A programmer can split his or her
    work into threads that run simultaneously and share the same memory context. Unless
    your code depends on third-party resources, multithreading will not speed it up
    on a single-core processor, and will even add some overhead for thread management.
    Multi-threading will benefit from a multiprocessor or multi-core machine and will
    parallelize each thread execution on each CPU core, thus making the program faster.
    Note that this is a general rule that should hold true for most programming languages.
    In Python, the performance benefit from multithreading on multicore CPUs has some
    limits, but we will discuss that later. For simplicity, let's assume for now that
    this statement is true.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 线程是执行的线程的缩写。程序员可以将他或她的工作分成同时运行并共享相同内存上下文的线程。除非你的代码依赖于第三方资源，多线程在单核处理器上不会加快速度，甚至会增加一些线程管理的开销。多线程将受益于多处理器或多核机器，并将在每个CPU核心上并行执行每个线程，从而使程序更快。请注意，这是一个通用规则，对大多数编程语言都应该成立。在Python中，多核CPU上的多线程性能收益有一些限制，但我们将在后面讨论。为简单起见，现在假设这个说法是正确的。
- en: The fact that the same context is shared among threads means you must protect
    data from concurrent access. If two threads update the same data without any protection,
    a race condition occurs. This is called a **race hazard**, where unexpected results
    may happen because of the code run by each thread making false assumptions about
    the state of the data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 相同上下文被线程共享的事实意味着你必须保护数据免受并发访问。如果两个线程在没有任何保护的情况下更新相同的数据，就会发生竞争条件。这被称为**竞争危害**，因为每个线程运行的代码对数据状态做出了错误的假设，可能会导致意外的结果发生。
- en: Lock mechanisms help in protecting data, and thread programming has always been
    a matter of making sure that the resources are accessed by threads in a safe way.
    This can be quite hard and thread programming often leads to bugs that are hard
    to debug, since they are hard to reproduce. The worst problem occurs when, due
    to poor code design, two threads lock a resource and try to get the resource that
    the other thread has locked. They will wait for each other forever. This is called
    a **deadlock** and is quite hard to debug. **Reentrant locks** help a bit in this
    by making sure a thread doesn't get locked by attempting to lock a resource twice.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 锁机制有助于保护数据，线程编程一直是确保资源以安全方式被线程访问的问题。这可能非常困难，线程编程经常会导致难以调试的错误，因为它们很难重现。最糟糕的问题发生在由于糟糕的代码设计，两个线程锁定一个资源并尝试获取另一个线程已锁定的资源。它们将永远等待对方。这被称为**死锁**，非常难以调试。**可重入锁**通过确保线程不会尝试两次锁定资源来在一定程度上帮助解决这个问题。
- en: Nevertheless, when threads are used for isolated needs with tools that were
    built for them, they might increase the speed of the program.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当线程用于专门为它们构建的工具的孤立需求时，它们可能会提高程序的速度。
- en: Multithreading is usually supported at the system kernel level. When the machine
    has one single processor with a single core, the system uses a **timeslicing**
    mechanism. Here, the CPU switches from one thread to another so fast that there
    is an illusion of threads running simultaneously. This is done at the processing
    level as well. Parallelism without multiple processing units is obviously virtual
    and there is no performance gain from running multiple threads on such hardware.
    Anyway, sometimes it is still useful to implement code with threads even if it
    has to execute on a single core, and we will see a possible use case later.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程通常在系统内核级别得到支持。当计算机只有一个处理器和一个核心时，系统使用**时间片**机制。在这里，CPU从一个线程快速切换到另一个线程，以至于产生线程同时运行的错觉。这也是在处理级别上完成的。在没有多个处理单元的情况下，并行性显然是虚拟的，并且在这样的硬件上运行多个线程并不会带来性能提升。无论如何，有时即使必须在单个核心上执行代码，实现代码的多线程仍然是有用的，我们稍后将看到一个可能的用例。
- en: Everything changes when your execution environment has multiple processors or
    multiple CPU cores for its disposition. Even if timeslicing is used, processes
    and threads are distributed among CPUs, providing the ability to run your program
    faster.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行环境具有多个处理器或多个CPU核心时，一切都会发生变化。即使使用时间片，进程和线程也会分布在CPU之间，从而提供更快地运行程序的能力。
- en: How Python deals with threads
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python如何处理线程
- en: Unlike some other languages, Python uses multiple kernel-level threads that
    can each run any of the interpreter-level threads. But the standard implementation
    of the language—CPython—comes with major limitation that renders threads less
    usable in many contexts. All threads accessing Python objects are serialized by
    one global lock. This is done because much of the interpreter internal structures,
    as well as third-party C code, are not thread-safe and need to be protected.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他一些语言不同，Python使用多个内核级别的线程，每个线程都可以运行解释器级别的任何线程。但是，语言的标准实现——CPython——存在重大限制，使得在许多情况下线程的可用性降低。所有访问Python对象的线程都由一个全局锁串行化。这是因为解释器的许多内部结构以及第三方C代码都不是线程安全的，需要受到保护。
- en: This mechanism is called the **Global Interpreter Lock** (**GIL**) and its implementation
    details on the Python/C API level were already discussed in the *Releasing GIL*
    section of [Chapter 7](ch07.html "Chapter 7. Python Extensions in Other Languages"),
    *Python Extensions in Other Languages*. The removal of GIL is a topic that occasionally
    appears on the python-dev e-mail list and was postulated by developers multiple
    times. Sadly, until this time, no one ever managed to provide a reasonable and
    simple solution that would allow us to get rid of this limitation. It is highly
    improbable that we will see any progress in this area soon. It is safer to assume
    that GIL will stay in CPython forever. So we need to learn how to live with it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制称为**全局解释器锁**（**GIL**），其在Python/C API级别的实现细节已经在[第7章](ch07.html "第7章. 其他语言中的Python扩展")的*释放GIL*部分中讨论过，*其他语言中的Python扩展*。GIL的移除是python-dev电子邮件列表上偶尔出现的一个话题，并且被开发人员多次提出。遗憾的是，直到现在，没有人成功提供一个合理简单的解决方案，使我们能够摆脱这个限制。高度不可能在这个领域看到任何进展。更安全的假设是GIL将永远存在于CPython中。因此，我们需要学会如何与之共存。
- en: So what is the point of multithreading in Python?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在Python中使用多线程有什么意义呢？
- en: When threads contain only pure Python code, there is little point in using threads
    to speed up the program since the GIL will serialize it. But remember that GIL
    just enforces that only one thread can execute the Python code at any time. In
    practice, the global interpreter lock is released on a number of blocking system
    calls and can be released in sections of C extensions that do not use any Python/C
    API functions. This means, multiple threads can do I/O operations or execute C
    code in certain third-party extensions in parallel.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当线程只包含纯Python代码时，使用线程加速程序几乎没有意义，因为GIL会串行化它。但请记住，GIL只是强制只有一个线程可以在任何时候执行Python代码。在实践中，全局解释器锁会在许多阻塞系统调用上被释放，并且可以在不使用任何Python/C
    API函数的C扩展的部分中被释放。这意味着多个线程可以并行执行I/O操作或在某些第三方扩展中执行C代码。
- en: For nonpure code blocks where external resources are used or C code is involved,
    multithreading is useful for waiting for a third-party resource to return results.
    This is because a sleeping thread that has explicitly released the GIL can stand
    by and wake up when the results are back. Last, whenever a program needs to provide
    a responsive interface, multithreading is the answer even if it uses timeslicing.
    The program can interact with the user while doing some heavy computing in the
    so-called background.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用外部资源或涉及C代码的非纯代码块，多线程对等待第三方资源返回结果是有用的。这是因为一个明确释放了GIL的休眠线程可以等待并在结果返回时唤醒。最后，每当程序需要提供响应式界面时，多线程都是答案，即使它使用时间片。程序可以在进行一些繁重的计算的同时与用户交互，所谓的后台。
- en: Note that GIL does not exist in every implementation of the Python language.
    It is a limitation of CPython, Stackless Python, and PyPy, but does not exist
    in Jython and IronPython (see [Chapter 1](ch01.html "Chapter 1. Current Status
    of Python"), *Current Status of Python*). There is although some development of
    the GIL-free version of PyPy, but at the time of writing this book, it is still
    at an experimental stage and the documentation is lacking. It is based on Software
    Transactional Memory and is called PyPy-STM. It is really hard to say when (or
    if) it will be officially released as a production-ready interpreter. Everything
    seems to indicate that it won't happen soon.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，GIL并不是Python语言的每个实现都存在。这是CPython、Stackless Python和PyPy的限制，但在Jython和IronPython中并不存在（参见[第1章](ch01.html
    "第1章。Python的当前状态")，“Python的当前状态”）。尽管PyPy也在开发无GIL版本，但在撰写本书时，它仍处于实验阶段，文档不完善。它基于软件事务内存，称为PyPy-STM。很难说它何时（或是否）会正式发布为生产就绪的解释器。一切似乎表明这不会很快发生。
- en: When should threading be used?
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时应该使用线程？
- en: 'Despite the GIL limitation, threads can be really useful in some cases. They
    can help in:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有GIL的限制，但线程在某些情况下确实非常有用。它们可以帮助：
- en: Building responsive interfaces
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建响应式界面
- en: Delegating work
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 委托工作
- en: Building multiuser applications
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建多用户应用程序
- en: Building responsive interfaces
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建响应式界面
- en: Let's say you ask your system to copy files from a folder to another through
    a graphical user interface. The task will possibly be pushed into the background
    and the interface window will be constantly refreshed by the main thread. This
    way you get live feedback on the progress of the whole process. You will also
    be able to cancel the operation. This is less irritating than a raw `cp` or `copy`
    shell command that does not provide any feedback until all work is finished.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您要求系统通过图形用户界面将文件从一个文件夹复制到另一个文件夹。任务可能会被推送到后台，并且界面窗口将由主线程不断刷新。这样您就可以实时了解整个过程的进展。您还可以取消操作。这比原始的`cp`或`copy`
    shell命令少了一些烦恼，因为它在所有工作完成之前不提供任何反馈。
- en: A responsive interface also allows a user to work on several tasks at the same
    time. For instance, Gimp will let you play around with a picture while another
    one is being filtered, since the two tasks are independent.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式界面还允许用户同时处理多个任务。例如，Gimp可以让您在处理一张图片的同时处理另一张图片，因为这两个任务是独立的。
- en: When trying to achieve such responsive interfaces, a good approach is to try
    to push long running tasks into the background, or at least try to provide constant
    feedback to the user. The easiest way to achieve that is to use threads. In such
    a scenario, they are not intended to increase performance, but only to make sure
    that the user can still operate the interface even if it needs to process some
    data for a longer period of time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试实现这样的响应界面时，一个很好的方法是将长时间运行的任务推送到后台，或者至少尝试为用户提供持续的反馈。实现这一点的最简单方法是使用线程。在这种情况下，它们的目的不是为了提高性能，而只是确保用户即使需要处理一些数据较长时间，也可以继续操作界面。
- en: In case such background tasks perform a lot of I/O operations, you are able
    to still get some benefit from multicore CPUs. Then it's a *win-win* situation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这样的后台任务执行大量I/O操作，您仍然可以从多核CPU中获得一些好处。这是一个双赢的局面。
- en: Delegating work
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 委托工作
- en: If your process depends on third-party resources, threads might really speed
    up everything.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的进程依赖于第三方资源，线程可能会真正加快一切。
- en: Let's consider the case of a function that indexes files in a folder and pushes
    the built indexes into a database. Depending on the type of file, the function
    calls a different external program. For example, one is specialized in PDFs and
    another one in OpenOffice files.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个函数的情况，该函数索引文件夹中的文件并将构建的索引推送到数据库中。根据文件的类型，该函数调用不同的外部程序。例如，一个专门用于PDF，另一个专门用于OpenOffice文件。
- en: Instead of treating each file in a sequence, by executing the right program
    and then storing the result into the database, your function can set up a thread
    for each converter and push jobs to be done to each one of them through a queue.
    The overall time taken by the function will be closer to the processing time of
    the slowest converter than to the sum of all the work.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您的函数可以为每个转换器设置一个线程，并通过队列将要完成的工作推送给它们中的每一个，而不是按顺序处理每个文件，执行正确的程序，然后将结果存储到数据库中。函数所花费的总时间将更接近最慢转换器的处理时间，而不是所有工作的总和。
- en: Converter threads can be initialized from the start and the code in charge of
    pushing the result into the database can also be a thread that consumes available
    results in the queue.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器线程可以从一开始就初始化，并且负责将结果推送到数据库的代码也可以是一个消耗队列中可用结果的线程。
- en: Note that such an approach is somewhat a hybrid between multithreading and multiprocessing.
    If you delegate the work to external processes (for example, using the `run()`
    function from the `subprocess` module), you are in fact doing work in multiple
    processes, so this has symptoms of multiprocessing. But in our scenario, we are
    waiting for the processing results in separate threads, so it is still mostly
    multithreading from the view of the Python code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种方法在某种程度上是多线程和多进程的混合。如果您将工作委托给外部进程（例如，使用`subprocess`模块的`run()`函数），实际上是在多个进程中进行工作，因此具有多进程的特征。但在我们的情况下，我们在单独的线程中等待处理结果，因此从Python代码的角度来看，这仍然主要是多线程。
- en: The other common use case for threads is performing multiple HTTP requests to
    external services. For instance, if you want to fetch multiple results from a
    distant web API, it could take a lot of time to do that synchronously. If you
    wait for every previous response before making new requests, you will spend a
    lot of time just waiting for the external service to respond and additional roundtrip
    time delays will be added to every such request. If you are communicating with
    an efficient service (Google Maps API, for instance), it is highly probable that
    it can serve most of your requests concurrently without affecting response times
    of separate requests. It is then reasonable to perform multiple queries in separate
    threads. Remember that when doing an HTTP request, most of time is spent on reading
    from the TCP socket. This is a blocking I/O operation, so CPython will release
    the GIL when performing the `recv()` C function. This allows for great improvements
    in your application's performance.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的另一个常见用例是执行对外部服务的多个HTTP请求。例如，如果您想从远程Web API获取多个结果，同步执行可能需要很长时间。如果您在进行新请求之前等待每个先前的响应，您将花费大量时间等待外部服务的响应，并且每个请求都会增加额外的往返时间延迟。如果您正在与一个高效的服务（例如Google
    Maps API）通信，很可能它可以同时处理大部分请求而不影响单独请求的响应时间。因此，合理的做法是在单独的线程中执行多个查询。请记住，在进行HTTP请求时，大部分时间都花在从TCP套接字中读取数据上。这是一个阻塞的I/O操作，因此在执行`recv()`
    C函数时，CPython会释放GIL。这可以极大地提高应用程序的性能。
- en: Multiuser applications
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多用户应用程序
- en: Threading is also used as a concurrency base for multiuser applications. For
    instance, a web server will push a user request into a new thread and then will
    become idle, waiting for new requests. Having a thread dedicated to each request
    simplifies a lot of work, but requires the developer to take care of locking the
    resources. But this is not a problem when all the shared data is pushed into a
    relational database that takes care of concurrency matters. So threads in a multi-user
    application act almost like separate independent processes. They are under the
    same process only to simplify their management at the application level.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 线程也被用作多用户应用程序的并发基础。例如，Web 服务器将用户请求推送到一个新线程中，然后变为空闲状态，等待新的请求。每个请求都有一个专用的线程简化了很多工作，但需要开发人员注意锁定资源。但是，当所有共享数据都被推送到处理并发事项的关系型数据库中时，这就不是问题了。因此，在多用户应用程序中，线程几乎像独立的进程一样运行。它们在同一个进程下只是为了简化在应用程序级别的管理。
- en: 'For instance, a web server will be able to put all requests in a queue and
    wait for a thread to be available to send the work to it. Furthermore, it allows
    memory sharing that can boost some work and reduce the memory load. The two very
    popular Python WSGI-compliant webservers: **Gunicorn** (refer to [http://gunicorn.org/](http://gunicorn.org/))
    and **uWSGI** (refer to [https://uwsgi-docs.readthedocs.org](https://uwsgi-docs.readthedocs.org)),
    allow you to serve HTTP requests with threaded workers in a way that generally
    follows this principle.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Web 服务器可以将所有请求放入队列，并等待线程可用以将工作发送到线程。此外，它允许内存共享，可以提高一些工作并减少内存负载。两个非常流行的Python符合WSGI标准的Web服务器：**Gunicorn**（参考[http://gunicorn.org/](http://gunicorn.org/)）和**uWSGI**（参考[https://uwsgi-docs.readthedocs.org](https://uwsgi-docs.readthedocs.org)），允许您以符合这一原则的方式使用带有线程工作进程的HTTP请求。
- en: Using multithreading to enable concurrency in multiuser applications is less
    expensive than using multiprocessing. Separate processes cost more resources since
    a new interpreter needs to be loaded for each one of them. On the other hand,
    having too many threads is expensive too. We know that the GIL isn't such a problem
    for I/O extensive applications, but there is always a time where you will need
    to execute Python code. Since you cannot parallelize all of the application parts
    with bare threads, you will never be able to utilize all resources on machines
    with multicore CPUs and a single Python process. This is why often the optimal
    solution is a hybrid of multiprocessing and multithreading—multiple workers (processes)
    running with multiple threads. Fortunately, many of the WSGI-compliant web servers
    allow for such a setup.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在多用户应用程序中使用多线程实现并发性比使用多进程要便宜。单独的进程会消耗更多资源，因为每个进程都需要加载一个新的解释器。另一方面，拥有太多线程也是昂贵的。我们知道GIL对I/O密集型应用程序并不是问题，但总有一个时刻，您需要执行Python代码。由于无法仅使用裸线程并行化应用程序的所有部分，因此在具有多核CPU和单个Python进程的机器上，您永远无法利用所有资源。这就是为什么通常最佳解决方案是多进程和多线程的混合——多个工作进程（进程）与多个线程同时运行。幸运的是，许多符合WSGI标准的Web服务器都允许这样的设置。
- en: But before you marry multithreading with multiprocessing, consider if such an
    approach is really worth all the cost. Such an approach uses multiprocessing for
    better resource utilization and additionally multithreading for more concurrency,
    which should be lighter than running multiple processes. But it does not need
    to be true. Maybe getting rid of threads and increasing the number of processes
    is not as expensive as you think? When choosing the best setup, you always need
    to do load testing of your application (see the *Load and performance testing*
    section in [Chapter 10](ch10.html "Chapter 10. Test-Driven Development"), *Test-Driven
    Development*). Also, as a side effect of using multiple threads, you get a less
    safe environment where shared memory creates a risk of data corruption or dreadful
    deadlock. Maybe a better alternative would be using some asynchronous approach
    with event loops, green threads, or coroutines. We will cover such solutions later
    in the *Asynchronous programming* section. Again, without sensible load testing
    and experimentation, you cannot really tell what approach will work best in your
    context.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但在将多线程与多进程结合之前，要考虑这种方法是否真的值得所有的成本。这种方法使用多进程来更好地利用资源，另外使用多线程来实现更多的并发，应该比运行多个进程更轻。但这并不一定是真的。也许摆脱线程，增加进程的数量并不像你想象的那么昂贵？在选择最佳设置时，你总是需要对应用程序进行负载测试（参见[第10章](ch10.html
    "第10章.测试驱动开发")中的*负载和性能测试*部分，*测试驱动开发*）。另外，使用多线程的副作用是，你会得到一个不太安全的环境，共享内存会导致数据损坏或可怕的死锁。也许更好的选择是使用一些异步的方法，比如事件循环、绿色线程或协程。我们将在*异步编程*部分后面介绍这些解决方案。同样，如果没有合理的负载测试和实验，你无法真正知道哪种方法在你的情况下效果最好。
- en: An example of a threaded application
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个多线程应用的示例
- en: To see how Python threading works in practice, let's construct an example application
    that can take some benefit from implementing multithreading. We will discuss a
    simple problem that you may encounter from time to time in your professional practice—making
    multiple parallel HTTP queries. This problem was already mentioned as a common
    use case for multithreading.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解Python线程在实践中是如何工作的，让我们构建一个示例应用程序，可以从实现多线程中获益。我们将讨论一个简单的问题，你可能在职业实践中不时遇到——进行多个并行的HTTP查询。这个问题已经被提到作为多线程的常见用例。
- en: 'Let''s say we need to fetch data from some web service using multiple queries
    that cannot be batched into a single big HTTP request. As a realistic example,
    we will use geocoding endpoints from Google Maps API. The reasons for that choice
    are as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要使用多个查询从某个网络服务获取数据，这些查询不能被批量处理成一个大的HTTP请求。作为一个现实的例子，我们将使用Google Maps API的地理编码端点。选择这个服务的原因如下：
- en: It is very popular and a well-documented service
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它非常受欢迎，而且有很好的文档
- en: There is a free tier of this API that does not require any authentication keys
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个API有一个免费的层，不需要任何身份验证密钥
- en: There is a `python-gmaps` package available on PyPI that allows you to interact
    with various Google Maps API endpoints and is extremely easy to use
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在PyPI上有一个`python-gmaps`包，允许你与各种Google Maps API端点进行交互，非常容易使用
- en: 'Geocoding means simply the transformation of address or place into coordinates.
    We will try to geocode a predefined list of various cities into latitude/longitude
    tuples and display results on the standard output with `python-gmaps`. It is as
    simple as shown in the following code:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 地理编码简单地意味着将地址或地点转换为坐标。我们将尝试将预定义的各种城市列表转换为纬度/经度元组，并在标准输出上显示结果与`python-gmaps`。就像下面的代码所示一样简单：
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Since our goal is to show how a multithreaded solution to concurrent problems
    compares to standard synchronous solution, we will start with an implementation
    that does not use threads at all. Here is the code of a program that loops over
    the list of cities, queries the Google Maps API, and displays information about
    their addresses and coordinates in a text-formatted table:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标是展示多线程解决并发问题与标准同步解决方案相比的效果，我们将从一个完全不使用线程的实现开始。下面是一个循环遍历城市列表、查询Google
    Maps API并以文本格式表格显示有关它们地址和坐标的信息的程序代码：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Around the execution of the `main()` function, we added a few statements that
    are intended to measure how much time it took to finish the job. On my computer,
    this program usually takes around 2 to 3 seconds to complete its task:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`函数的执行周围，我们添加了一些语句，用于测量完成工作所花费的时间。在我的电脑上，这个程序通常需要大约2到3秒才能完成任务：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Every run of our script will always take a different amount of time because
    it mostly depends on a remote service accessible through a network connection.
    So there is a lot of nondeterministic factors affecting the final result. The
    best approach would be to make longer tests, repeat them multiple times, and also
    calculate some average from the measurements. But for the sake of simplicity,
    we won't do that. You will see later that this simplified approach is just enough
    for illustrational purposes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的脚本每次运行都会花费不同的时间，因为它主要取决于通过网络连接访问的远程服务。所以有很多不确定因素影响最终结果。最好的方法是进行更长时间的测试，多次重复，还要从测量中计算一些平均值。但为了简单起见，我们不会这样做。你将会看到，这种简化的方法对于说明目的来说已经足够了。
- en: Using one thread per item
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每个项目使用一个线程
- en: Now it is time for improvement. We don't do a lot of processing in Python and
    the long execution time is caused by communication with the external service.
    We send an HTTP request to the server, it calculates the answer, and then we wait
    until the response is transferred back. There is a lot of I/O involved, so multithreading
    seems like a viable option. We can start all the requests at once in separate
    threads and then just wait until they receive data. If the service that we are
    communicating with is able to process our request concurrently, we should definitely
    see a performance improvement.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候改进了。我们在Python中没有进行太多的处理，长时间执行是由与外部服务的通信引起的。我们向服务器发送HTTP请求，它计算答案，然后我们等待直到响应被传送回来。涉及了大量的I/O，因此多线程似乎是一个可行的选择。我们可以在单独的线程中同时启动所有请求，然后等待它们接收数据。如果我们正在通信的服务能够并发处理我们的请求，我们应该肯定会看到性能的提升。
- en: 'So let''s start with the easiest approach. Python provides clean and easy to
    use abstraction over system threads with the `threading` module. The core of this
    standard library is the `Thread` class that represents a single thread instance.
    Here is a modified version of the `main()` function, which creates and starts
    a new thread for every place to geocode and then waits until all the threads finish:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们从最简单的方法开始。Python提供了清晰且易于使用的抽象，通过`threading`模块可以轻松地操作系统线程。这个标准库的核心是`Thread`类，代表一个单独的线程实例。下面是`main()`函数的修改版本，它为每个地点创建并启动一个新线程，然后等待直到所有线程都完成：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It is quick-and-dirty change that has some serious issues that we will try
    to address later. It approaches the problem in a bit of a frivolous way, and it
    is not a way to write reliable software that will serve thousands or millions
    of users. But hey, it works:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个快速而肮脏的改变，它有一些严重的问题，我们稍后会试图解决。它以一种有点轻率的方式解决问题，并不是编写可为成千上万甚至百万用户提供服务的可靠软件的方式。但嘿，它起作用：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So when we know that threads have a beneficial effect on our application, it
    is time to use them in a slightly saner way. First we need to identify the issues
    in the preceding code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当我们知道线程对我们的应用有益时，是时候以稍微理智的方式使用它们了。首先我们需要找出前面代码中的问题：
- en: We start a new thread for every parameter. Thread initialization also takes
    some time but this minor overhead is not the only problem. Threads also consume
    other resources such as memory and file descriptors. Our example input has a strictly
    defined number of items, what if it did not have? You definitely don't want to
    run an unbound number of threads that depend on the arbitrary size of data input.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为每个参数启动一个新线程。线程初始化也需要一些时间，但这种小的开销并不是唯一的问题。线程还会消耗其他资源，比如内存和文件描述符。我们的示例输入有一个严格定义的项目数量，如果没有呢？你肯定不希望运行数量不受限制的线程，这取决于输入数据的任意大小。
- en: The `fetch_place()` function executed in threads calls the built-in `print()`
    function and in practice it is very unlikely that you would want to do that outside
    of the main application thread. At first, it is due to the fact how the standard
    output is buffered in Python. You can experience malformed output when multiple
    calls to this function interleave between threads. Also, the `print()` function
    is considered slow. If used recklessly in multiple threads, it can lead to serialization,
    which will undo all the benefits of multithreading.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程中执行的`fetch_place()`函数调用了内置的`print()`函数，实际上，你很少会想在主应用程序线程之外这样做。首先，这是因为Python中标准输出的缓冲方式。当多个线程之间交错调用这个函数时，你可能会遇到格式不正确的输出。另外，`print()`函数被认为是慢的。如果在多个线程中滥用使用，它可能导致串行化，这将抵消多线程的所有好处。
- en: Last but not least, by delegating every function call to a separate thread,
    we make it extremely hard to control the rate at which our input is processed.
    Yes, we want to do the job as fast as possible, but very often external services
    enforce hard limits on the rate of requests from a single client that they can
    process. Sometimes it is reasonable to design the program in a way that enables
    you to throttle the rate of processing, so your application won't be blacklisted
    by external APIs for abusing their usage limits.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，通过将每个函数调用委托给单独的线程，我们使得控制输入处理速率变得极其困难。是的，我们希望尽快完成工作，但很多时候外部服务会对单个客户端的请求速率设置严格限制。有时，合理设计程序以使其能够控制处理速率是很有必要的，这样你的应用就不会因滥用外部API的使用限制而被列入黑名单。
- en: Using a thread pool
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用线程池
- en: The first issue we will try to solve is the unbound limit of threads that are
    run by our program. A good solution would be to build a pool of threaded workers
    with strictly defined sizes that will handle all the parallel work and communicate
    with workers through some thread-safe data structure. By using this thread pool
    approach, we will also make it easier to solve the two other problems that we
    just mentioned.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要解决的第一个问题是程序运行的线程数量没有限制。一个好的解决方案是建立一个具有严格定义大小的线程工作池，它将处理所有并行工作，并通过一些线程安全的数据结构与工作线程进行通信。通过使用这种线程池方法，我们也将更容易解决刚才提到的另外两个问题。
- en: 'So the general idea is to start some predefined number of threads that will
    consume the work items from a queue until it is done. When there is no other work
    to do, the threads will return and we will be able to exit from the program. A
    good candidate for our structure to be used to communicate with the workers is
    the `Queue` class from the built-in `queue` module. It is a FIFO (First In First
    Out) queue implementation that is very similar to the `deque` collection from
    the `collections` module and was specifically designed to handle interthread communication.
    Here is a modified version of the `main()` function that starts only a limited
    number of worker threads with a new `worker()` function as a target, and communicates
    with them using a thread-safe queue:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一般的想法是启动一些预定义数量的线程，这些线程将从队列中消耗工作项，直到完成。当没有其他工作要做时，线程将返回，我们将能够退出程序。用于与工作线程通信的结构的一个很好的候选是内置`queue`模块中的`Queue`类。它是一个先进先出（FIFO）队列实现，非常类似于`collections`模块中的`deque`集合，并且专门设计用于处理线程间通信。以下是一个修改后的`main()`函数的版本，它只启动了有限数量的工作线程，并使用一个新的`worker()`函数作为目标，并使用线程安全的队列与它们进行通信：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result of running a modified version of our program is similar to the previous
    one:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 运行修改后的程序的结果与之前的类似：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The run time will be slower than in a situation with one thread per argument,
    but at least now it is not possible to exhaust all the computing resources with
    an arbitrary long input. Also, we can tweak the `THREAD_POOL_SIZE` parameter a
    for better resource/time balance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时间将比每个参数一个线程的情况慢，但至少现在不可能用任意长的输入耗尽所有的计算资源。此外，我们可以调整`THREAD_POOL_SIZE`参数以获得更好的资源/时间平衡。
- en: Using two-way queues
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用双向队列
- en: 'The other issue that we are now able to solve is the potentially problematic
    printing of the output in threads. It would be much better to leave such a responsibility
    to the main thread that started the other threads. We can handle that by providing
    another queue that will be responsible for collecting results from our workers.
    Here is the complete code that puts everything together with the main changes
    highlighted:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在能够解决的另一个问题是线程中输出的潜在问题。最好将这样的责任留给启动其他线程的主线程。我们可以通过提供另一个队列来处理这个问题，该队列将负责从我们的工作线程中收集结果。以下是将所有内容与主要更改放在一起的完整代码：
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This eliminates the risk of malformed output, which we could experience if
    the `present_result()` function does more `print()` statements or performs some
    additional computation. We don''t expect any performance improvement from this
    approach with small inputs, but in fact we also reduce the risk of thread serialization
    due to slow `print()` execution. Here is our final output:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这消除了输出格式不正确的风险，如果`present_result()`函数执行更多的`print()`语句或执行一些额外的计算，我们可能会遇到这种情况。我们不希望从这种方法中获得任何性能改进，但实际上，由于`print()`执行缓慢，我们还减少了线程串行化的风险。这是我们的最终输出：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Dealing with errors and rate limiting
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理错误和速率限制
- en: The last of the issues mentioned earlier that you may experience when dealing
    with such problems are rate limits imposed by external service providers. In the
    case of the Google Maps API, at the time of writing this book, the official rate
    limit for free and non-authenticated requests is 10 requests per second and 2,500
    requests per day. When using multiple threads, it is very easy to exhaust such
    a limit. The problem is even more serious due to the fact that we did not cover
    any failure scenarios yet, and dealing with exceptions in multithreaded Python
    code is a bit more complicated than usual.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的您在处理这些问题时可能遇到的最后一个问题是外部服务提供商施加的速率限制。在编写本书时，谷歌地图API的官方速率限制为每秒10次请求和每天2500次免费和非身份验证请求。使用多个线程很容易耗尽这样的限制。问题更加严重，因为我们尚未涵盖任何故障场景，并且在多线程Python代码中处理异常比通常要复杂一些。
- en: The `api.geocode()` function will raise an exception when the client exceeds
    Google's rate and this is good news. But this exception is raised separately and
    will not crash the entire program. The worker thread will of course exit immediately,
    but the main thread will wait for all tasks stored on `work_queue` to be finished
    (with the `work_queue.join()` call). This means that our worker threads should
    gracefully handle possible exceptions and make sure that all items from the queue
    are processed. Without further improvement, we may end up in a situation where
    some of the worker threads crashed and the program will never exit.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`api.geocode()` 函数在客户端超过谷歌速率时会引发异常，这是个好消息。但是这个异常会单独引发，并不会使整个程序崩溃。工作线程当然会立即退出，但主线程会等待所有存储在`work_queue`上的任务完成（使用`work_queue.join()`调用）。这意味着我们的工作线程应该优雅地处理可能的异常，并确保队列中的所有项目都被处理。如果没有进一步的改进，我们可能会陷入一种情况，其中一些工作线程崩溃，程序将永远不会退出。'
- en: 'Let''s make some minor changes to our code in order to be prepared for any
    issues that may occur. In the case of exceptions in the worker thread, we may
    put an error instance in the `results_queue` queue and mark the current task as
    done, the same as we would do if there was no error. That way we make sure that
    the main thread won''t lock indefinitely while waiting in `work_queue.join()`.
    The main thread might then inspect the results and re-raise any of the exceptions
    found on the results queue. Here are the improved versions of the `worker()` and
    `main()` functions that can deal with exceptions in a safer way:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对我们的代码进行一些微小的更改，以便为可能发生的任何问题做好准备。在工作线程中出现异常的情况下，我们可以将错误实例放入`results_queue`队列，并将当前任务标记为已完成，就像没有错误时一样。这样我们可以确保主线程在`work_queue.join()`中等待时不会无限期地锁定。然后主线程可能检查结果并重新引发在结果队列中找到的任何异常。以下是可以更安全地处理异常的`worker()`和`main()`函数的改进版本：
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When we are ready to handle exceptions, it is time to break our code and exceed
    the rate limit. We can do that easily by modifying some initial conditions. Let''s
    increase the number of places to geocode and the size of our thread pool:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们准备处理异常时，就是我们的代码中断并超过速率限制的时候了。我们可以通过修改一些初始条件来轻松实现这一点。让我们增加地理编码的位置数量和线程池的大小：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If your execution environment is fast enough, you should get a similar error
    soon:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的执行环境足够快，您应该很快就会收到类似的错误：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding exception is of course not the result of faulty code. This program
    simply is a bit too fast for this free service. It makes too many concurrent requests,
    and in order to work correctly, we need to have a way to limit their rate.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的异常当然不是由于错误的代码造成的。这个程序对于这个免费服务来说太快了。它发出了太多的并发请求，为了正确工作，我们需要有一种限制它们速率的方法。
- en: Limiting the pace of work is often called throttling. There are a few packages
    on PyPI that allow you to limit the rate of any kind of work and are really easy
    to use. But we won't use any external code here. Throttling is a good opportunity
    to introduce some locking primitives for threading, so we will try to build a
    solution from scratch.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 限制工作的速度通常被称为节流。PyPI上有一些包可以让您限制任何类型工作的速率，并且非常容易使用。但是我们不会在这里使用任何外部代码。节流是一个很好的机会，可以引入一些用于线程的锁原语，因此我们将尝试从头开始构建一个解决方案。
- en: 'The algorithm we will use is sometimes called token bucket and is very simple:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的算法有时被称为令牌桶，非常简单：
- en: There is a bucket with a predefined amount of tokens.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一个预定义数量的令牌的桶。
- en: Each token responds to a single permission to process one item of work.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个令牌对应于处理一个工作项的单个权限。
- en: 'Each time the worker asks for a single or multiple tokens (permission):'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次工作线程请求单个或多个令牌（权限）时：
- en: We measure how much time was spent from the last time we refilled the bucket
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们测量了从上次我们重新填充桶以来花费了多少时间
- en: If the time difference allows for it, we refill the bucket with the amount of
    tokens that respond to this time difference
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果时间差允许，我们将用与此时间差相应的令牌数量重新填充桶
- en: If the amount of stored tokens is bigger or equal to the amount requested, we
    decrease the number of stored tokens and return that value
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存储的令牌数量大于或等于请求的数量，我们会减少存储的令牌数量并返回该值
- en: If the amount of stored tokens is less than requested, we return zero
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存储的令牌数量少于请求的数量，我们返回零
- en: 'The two important things are to always initialize the token bucket with zero
    tokens and never allow it to fill with more tokens that is available by its rate,
    expressed in tokens, as per our standard quant of time. If we don''t follow these
    precautions, we can release the tokens in bursts that exceed the rate limit. Because
    in our situation the rate limit is expressed in requests per second, we don''t
    need to deal with arbitrary quants of time. We assume that the base for our measurement
    is one second, so we will never store more tokens than the number of requests
    allowed for that quant of time. Here is an example implementation of the class
    that allows for throttling with a token bucket algorithm:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 两个重要的事情是始终用零令牌初始化令牌桶，并且永远不允许它填充的令牌数量超过其速率可用的令牌数量，按照我们标准的时间量表达。如果我们不遵循这些预防措施，我们可能会以超过速率限制的突发方式释放令牌。因为在我们的情况下，速率限制以每秒请求的数量来表示，所以我们不需要处理任意的时间量。我们假设我们的测量基准是一秒，因此我们永远不会存储比该时间量允许的请求数量更多的令牌。以下是一个使用令牌桶算法进行节流的类的示例实现：
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The usage of this class is very simple. Assume that we created only one instance
    of `Throttle` (with `Throttle(10)` for instance) in the main thread and passed
    it to every worker thread as a positional argument. Using the same data structure
    in different threads is safe because we guarded manipulation of its internal state
    with the instance of `Lock` class from the `threading` module. We can now update
    the `worker()` function implementation to wait with every item until throttle
    releases a new token:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个类非常简单。假设我们在主线程中只创建了一个`Throttle`实例（例如`Throttle(10)`），并将其作为位置参数传递给每个工作线程。在不同的线程中使用相同的数据结构是安全的，因为我们使用`threading`模块中的`Lock`类的实例来保护其内部状态的操作。现在我们可以更新`worker()`函数的实现，以便在每个项目之前等待节流释放一个新的令牌：
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Multiprocessing
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程
- en: Let's be honest, multithreading is challenging—we have already seen that in
    the previous section. It's a fact that the simplest approach to the problem required
    only minimal effort. But dealing with threads in a sane and safe manner required
    a tremendous amount of code.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 坦率地说，多线程是具有挑战性的——我们在前一节已经看到了。最简单的方法只需要最少的工作。但是以明智和安全的方式处理线程需要大量的代码。
- en: We had to set up thread pool and communication queues, gracefully handle exceptions
    from threads, and also care about thread safety when trying to provide rate limiting
    capability. Tens lines of code only to execute one function from an external library
    in parallel! And we only assume that this is production-ready because there is
    a promise from the external package creator that his library is thread-safe. Sounds
    like a high price for a solution that is practically applicable only for doing
    I/O bound tasks.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须设置线程池和通信队列，优雅地处理来自线程的异常，并且在尝试提供速率限制功能时也要关心线程安全。只需十行代码就可以并行执行外部库中的一个函数！我们只是假设这是可以投入生产的，因为外部包的创建者承诺他的库是线程安全的。对于一个实际上只适用于执行I/O绑定任务的解决方案来说，这听起来像是一个很高的代价。
- en: An alternative approach that allows you to achieve parallelism is multiprocessing.
    Separate Python processes that do not constrain each other with GIL allow for
    better resource utilization. This is especially important for applications running
    on multicore processors that are performing really CPU-extensive tasks. Right
    now this is the only built-in concurrent solution available for Python developers
    (using the CPython interpreter) that allows you to take benefit from multiple
    processor cores.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 允许你实现并行的另一种方法是多进程。不受GIL约束的独立Python进程可以更好地利用资源。这对于在执行真正消耗CPU的任务的多核处理器上运行的应用程序尤为重要。目前，这是Python开发人员（使用CPython解释器）唯一可用的内置并发解决方案，可以让你利用多个处理器核心。
- en: The other advantage of using multiple processes is the fact that they do not
    share memory context. So it is harder to corrupt data and introduce deadlocks
    into your application. Not sharing the memory context means that you need some
    additional effort to pass the data between separate processes, but fortunately
    there are many good ways to implement reliable interprocess communication. In
    fact, Python provides some primitives that make communication between processes
    as easy as possible between threads.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多个进程的另一个优势是它们不共享内存上下文。因此，更难破坏数据并引入死锁到你的应用程序中。不共享内存上下文意味着你需要额外的工作来在独立的进程之间传递数据，但幸运的是有许多很好的方法来实现可靠的进程间通信。事实上，Python提供了一些原语，使进程间通信尽可能简单，就像线程之间一样。
- en: 'The most basic way to start new processes in any programming language is usually
    by **forking** the program at some point. On POSIX systems (Unix, Mac OS, and
    Linux) a fork is a system call exposed in Python through the `os.fork()` function,
    which will create a new child process. The two processes then continue the program
    on their own right after forking. Here is an example script that forks itself
    exactly once:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何编程语言中启动新进程的最基本的方法通常是在某个时候**fork**程序。在POSIX系统（Unix、Mac OS和Linux）上，fork是一个系统调用，在Python中通过`os.fork()`函数暴露出来，它将创建一个新的子进程。然后这两个进程在分叉后继续程序。下面是一个自我分叉一次的示例脚本：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And here is an example of running it in a terminal:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在终端中运行它的示例：
- en: '[PRE15]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice how both processes have exactly the same initial state of their data
    before the `os.fork()` call. They both have the same PID number (process identifier)
    as a first value of the `pid_list` collection. Later, both states diverge and
    we can see that the child process added the `21916` value while the parent duplicated
    its `21915` PID. This is because the memory contexts of these two processes are
    not shared. They have the same initial conditions but cannot affect each other
    after the `os.fork()` call.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`os.fork()`调用之前，这两个进程的数据状态完全相同。它们都有相同的PID号（进程标识符）作为`pid_list`集合的第一个值。后来，两个状态分歧，我们可以看到子进程添加了`21916`的值，而父进程复制了它的`21915`
    PID。这是因为这两个进程的内存上下文是不共享的。它们有相同的初始条件，但在`os.fork()`调用后不能相互影响。
- en: After the fork memory context is copied to the child, each process deals with
    its own address space. To communicate, processes need to work with system-wide
    resources or use low-level tools such as **signals**.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在分叉内存上下文被复制到子进程后，每个进程都处理自己的地址空间。为了通信，进程需要使用系统范围的资源或使用低级工具，比如**信号**。
- en: Unfortunately, `os.fork` is not available under Windows, where a new interpreter
    needs to be spawned in order to mimic the fork feature. So it needs to be different
    depending on the platform. The `os` module also exposes functions that allow you
    to spawn new processes under Windows, but eventually you will use them rarely.
    This is also true for `os.fork()`. Python provides great a `multiprocessing` module
    that creates a high-level interface for multiprocessing. The great advantage of
    this module is that it provides some of the abstractions that we had to code from
    scratch in *An example of a threaded application* section. It allows you to limit
    the amount of boilerplate code, so it improves application maintainability and
    reduces its complexity. Surprisingly, despite its name, the `multiprocessing`
    module also exposes a similar interface for threads, so you will probably want
    to use the same interface for both approaches.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在Windows下`os.fork`不可用，需要在新的解释器中生成一个新的进程来模拟fork功能。因此，它需要根据平台的不同而有所不同。`os`模块还公开了在Windows下生成新进程的函数，但最终你很少会使用它们。这对于`os.fork()`也是如此。Python提供了一个很棒的`multiprocessing`模块，它为多进程提供了一个高级接口。这个模块的巨大优势在于它提供了一些我们在*一个多线程应用程序示例*部分中不得不从头编写的抽象。它允许你限制样板代码的数量，因此提高了应用程序的可维护性并减少了其复杂性。令人惊讶的是，尽管它的名字是`multiprocessing`模块，但它也为线程暴露了类似的接口，因此你可能希望对两种方法使用相同的接口。
- en: The built-in multiprocessing module
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内置的multiprocessing模块
- en: '`multiprocessing` provides a portable way to work with processes as if they
    were threads.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`提供了一种可移植的方式来处理进程，就像它们是线程一样。'
- en: 'This module contains a `Process` class that is very similar to the `Thread`
    class, and can be used on any platform:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模块包含一个`Process`类，它与`Thread`类非常相似，可以在任何平台上使用：
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding script, when executed, gives the following result:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前述脚本将得到以下结果：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When the processes are created, the memory is forked (on POSIX systems). The
    most efficient usage of processes is to let them work on their own after they
    have been created to avoid overhead, and check on their states from the main thread.
    Besides the memory state that is copied, the `Process` class also provides an
    extra `args` argument in its constructor so that data can be passed along.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当进程被创建时，内存被分叉（在POSIX系统上）。进程的最有效使用方式是让它们在创建后独立工作，以避免开销，并从主线程检查它们的状态。除了复制的内存状态，`Process`类还在其构造函数中提供了额外的`args`参数，以便传递数据。
- en: 'The communication between process modules requires some additional work because
    their local memory is not shared by default. To simplify this, the multiprocessing
    module provides a few ways of communication between processes:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 进程模块之间的通信需要一些额外的工作，因为它们的本地内存默认情况下不是共享的。为了简化这一点，多进程模块提供了一些进程之间通信的方式：
- en: Using the `multiprocessing.Queue` class, which is a near clone of `queue.Queue`,
    which was used earlier for communication between threads
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`multiprocessing.Queue`类，它几乎与`queue.Queue`相同，之前用于线程之间通信
- en: Using `multiprocessing.Pipe`, which is a socket-like two-way communication channel
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`multiprocessing.Pipe`，这是一个类似套接字的双向通信通道
- en: Using the `multiprocessing.sharedctypes` module, which allows you to create
    arbitrary C types (from the `ctypes` module) in a dedicated pool of memory that
    is shared between processes
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`multiprocessing.sharedctypes`模块，允许您在进程之间共享的专用内存池中创建任意C类型（来自`ctypes`模块）
- en: The `multiprocessing.Queue` and `queue.Queue` classes have the same interface.
    The only difference is that the first is designed for use in multiple process
    environments, rather than with multiple threads, so it uses different internal
    transports and locking primitives. We already saw how to use Queue with multithreading
    in the *An example of a threaded application* section, so we won't do the same
    for multiprocessing. The usage stays exactly the same, so such an example would
    not bring anything new.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Queue`和`queue.Queue`类具有相同的接口。唯一的区别是，第一个是设计用于多进程环境，而不是多线程环境，因此它使用不同的内部传输和锁定原语。我们已经看到如何在*一个多线程应用程序的示例*部分中使用Queue，因此我们不会对多进程做同样的事情。使用方式完全相同，因此这样的例子不会带来任何新东西。'
- en: 'A more interesting pattern right now is provided by the `Pipe` class. It is
    a duplex (two-way) communication channel that is very similar in concept to Unix
    pipes. The interface of Pipe is also very similar to a simple socket from the
    built-in `socket` module. The difference from raw system pipes and sockets is
    that it allows you to send any pickable object (using the `pickle` module) instead
    of just raw bytes. This allows for a lot easier communication between processes
    because you can send almost any basic Python type:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在提供的更有趣的模式是`Pipe`类。它是一个双工（双向）通信通道，概念上与Unix管道非常相似。Pipe的接口也非常类似于内置`socket`模块中的简单套接字。与原始系统管道和套接字的区别在于它允许您发送任何可挑选的对象（使用`pickle`模块）而不仅仅是原始字节。这使得进程之间的通信变得更加容易，因为您可以发送几乎任何基本的Python类型：
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When looking at an example output of the preceding script, you will see that
    you can easily pass custom class instances and that they have different addresses
    depending on the process:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看前面脚本的示例输出时，您会发现您可以轻松传递自定义类实例，并且它们根据进程具有不同的地址：
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The other way to share a state between processes is to use raw types in a shared
    memory pool with the classes provided in `multiprocessing.sharedctypes`. The most
    basic ones are `Value` and `Array`. Here is an example code from the official
    documentation of the `multiprocessing` module:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在进程之间共享状态的另一种方法是使用`multiprocessing.sharedctypes`中提供的类在共享内存池中使用原始类型。最基本的是`Value`和`Array`。以下是`multiprocessing`模块官方文档中的示例代码：
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And this example will print the following output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子将打印以下输出：
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: When working with `multiprocessing.sharedctypes`, you need to remember that
    you are dealing with shared memory, so to avoid the risk of data corruption you
    need to use locking primitives. Multiprocessing provides some of the classes available
    in threading, such as `Lock`, `RLock`, and `Semaphore`, to do that. The downside
    of classes from `sharedctypes` is that they allow you only to share the basic
    C types from the `ctypes` module. If you need to pass more complex structures
    or class instances, you need to use Queue, Pipe, or other interprocess communication
    channels instead. In most cases, it is reasonable to avoid types from `sharedctypes`
    because they increase code complexity and bring all the dangers known from multithreading.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`multiprocessing.sharedctypes`时，您需要记住您正在处理共享内存，因此为了避免数据损坏的风险，您需要使用锁定原语。多进程提供了一些可用于线程的类，例如`Lock`、`RLock`和`Semaphore`，来做到这一点。`sharedctypes`类的缺点是它们只允许您共享`ctypes`模块中的基本C类型。如果您需要传递更复杂的结构或类实例，则需要使用Queue、Pipe或其他进程间通信通道。在大多数情况下，理应避免使用`sharedctypes`中的类型，因为它们会增加代码复杂性，并带来来自多线程的所有已知危险。
- en: Using process pools
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用进程池
- en: Using multiple processes instead of threads adds some substantial overhead.
    Mostly, it increases the memory footprint because each process has its own independent
    memory context. This means allowing for an unbound number of child processes is
    even more of a problematic issue than in multithreaded applications.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多进程而不是线程会增加一些实质性的开销。主要是因为它增加了内存占用，因为每个进程都有自己独立的内存上下文。这意味着允许无限数量的子进程甚至比在多线程应用程序中更加棘手。
- en: The best pattern to control resource usage in applications that rely on multiprocessing
    for better resource utilization is to build a process pool in a similar way as
    described for threads in the *Using a thread pool* section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在依赖多进程进行更好资源利用的应用程序中控制资源使用的最佳模式是以类似于*使用线程池*部分描述的方式构建进程池。
- en: 'And the best thing about the `multiprocessing` module is that it provides a
    ready-to-use `Pool` class that handles all the complexity of managing multiple
    process workers for you. This pool implementation greatly reduces the amount of
    boilerplate required and the number of issues related to two-way communication.
    You also are not required to use the `join()` method manually, as Pool can be
    used as the context manager (using the `with` statement). Here is one of our previous
    threading examples rewritten to use the `Pool` class from the `multiprocessing`
    module:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块最好的地方是它提供了一个现成的`Pool`类，可以为你处理管理多个进程工作者的所有复杂性。这个池实现大大减少了所需的样板代码量和与双向通信相关的问题数量。你也不需要手动使用`join()`方法，因为`Pool`可以作为上下文管理器使用（使用`with`语句）。以下是我们以前的一个线程示例，重写为使用`multiprocessing`模块中的`Pool`类：'
- en: '[PRE22]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, the code is now a lot shorter. It means that it is now easier
    to maintain and debug in case of issues. Actually, there are now only two lines
    of code that explicitly deal with multiprocessing. This is a great improvement
    over the situation where we had to build the processing pool from scratch. Now
    we don't even need to care about communication channels because they are created
    implicitly inside of the `Pool` implementation.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，现在代码要短得多。这意味着在出现问题时，现在更容易维护和调试。实际上，现在只有两行代码明确处理多进程。这是一个很大的改进，因为我们以前必须从头开始构建处理池。现在我们甚至不需要关心通信通道，因为它们是在`Pool`实现内部隐式创建的。
- en: Using multiprocessing.dummy as a multithreading interface
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用`multiprocessing.dummy`作为多线程接口
- en: The high-level abstractions from the `multiprocessing` module, such as the `Pool`
    class, are great advantages over the simple tools provided in the `threading`
    module. But no, it does not mean that multiprocessing is always a better approach
    than multithreading. There are a lot of use cases where threads may be a better
    solution than processes. This is especially true for situations where low latency
    and/or high resource efficiency is required.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块中的高级抽象，如`Pool`类，是比`threading`模块提供的简单工具更大的优势。但是，并不意味着多进程始终比多线程更好的方法。有很多情况下，线程可能是比进程更好的解决方案。特别是在需要低延迟和/或高资源效率的情况下。'
- en: But it does not mean that you need to sacrifice all the useful abstractions
    from the `multiprocessing` module whenever you want to use threads instead of
    processes. There is the `multiprocessing.dummy` module, which replicates the `multiprocessing`
    API but uses multiple threads instead of forking/spawning new processes.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不意味着每当你想要使用线程而不是进程时，你就需要牺牲`multiprocessing`模块中的所有有用抽象。有`multiprocessing.dummy`模块，它复制了`multiprocessing`的API，但使用多线程而不是forking/spawning新进程。
- en: 'This allows you to reduce the amount of boilerplate in your code and also make
    a more pluggable interface. For instance, let''s take yet another look at our
    `main()` function from the previous examples. If we wanted to give the user control
    over which processing backend he wants to use (processes or threads), we could
    do that simply by replacing the `Pool` class:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这使你可以减少代码中的样板，并且使接口更加可插拔。例如，让我们再次看一下我们以前示例中的`main()`函数。如果我们想要让用户控制他想要使用哪种处理后端（进程或线程），我们可以简单地替换`Pool`类：
- en: '[PRE23]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Asynchronous programming
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步编程
- en: Asynchronous programming has gained a lot of traction in recent years. In Python
    3.5, it finally got some syntax features that solidify concepts of asynchronous
    execution. But it does not mean that asynchronous programming is only possible
    starting from Python 3.5\. A lot of libraries and frameworks were provided a lot
    earlier, and most of them have origins in the old versions of Python 2\. There
    is even a whole alternate implementation of Python called Stackless (see [Chapter
    1](ch01.html "Chapter 1. Current Status of Python"), *Current Status of Python*),
    which concentrated on this single programming approach. Some of these solutions,
    such as Twisted, Tornado, or Eventlet, still have huge and active communities
    and are really worth knowing. Anyway, starting from Python 3.5, asynchronous programming
    is easier than ever before. So it is expected that its built-in asynchronous features
    will replace the bigger parts of older tools, or external projects will gradually
    transform into a kind of high-level frameworks based on Python built-ins.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，异步编程已经获得了很大的关注。在Python 3.5中，它最终获得了一些语法特性，巩固了异步执行的概念。但这并不意味着异步编程只能从Python
    3.5开始。很多库和框架早在很久以前就提供了，大部分都起源于Python 2的旧版本。甚至有一个名为Stackless的Python的整个替代实现（见[第1章](ch01.html
    "第1章。Python的当前状态")，“Python的当前状态”），它专注于这种单一的编程方法。其中一些解决方案，如Twisted、Tornado或Eventlet，仍然拥有庞大和活跃的社区，并且真的值得了解。无论如何，从Python
    3.5开始，异步编程比以往任何时候都更容易。因此，预计其内置的异步特性将取代较旧工具的大部分部分，或者外部项目将逐渐转变为基于Python内置的高级框架。
- en: When trying to explain what asynchronous programming is, the easiest way is
    to think about this approach as something similar to threads but without system
    scheduling involved. This means that an asynchronous program can concurrently
    process problems but its context is switched internally and not by a system scheduler.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当试图解释什么是异步编程时，最简单的方法是将这种方法视为类似于线程但不涉及系统调度。这意味着异步程序可以并发处理问题，但其上下文在内部切换，而不是由系统调度程序切换。
- en: 'But, of course, we don''t use threads to concurrently handle the work in an
    asynchronous program. Most of the solutions use a different kind of concept and,
    depending on the implementation, it is named differently. Some example names used
    to describe such concurrent program entities are:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，当然，我们不使用线程来同时处理异步程序中的工作。大多数解决方案使用一种不同的概念，根据实现的不同，它被命名为不同的名称。用来描述这种并发程序实体的一些示例名称是：
- en: Green threads or greenlets (greenlet, gevent, or eventlet projects)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色线程或greenlets（greenlet、gevent或eventlet项目）
- en: Coroutines (Python 3.5 native asynchronous programming)
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协程（Python 3.5原生异步编程）
- en: Tasklets (Stackless Python)
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务（Stackless Python）
- en: These are mainly the same concepts, but often implemented in a bit different
    way. For obvious reasons, in this section, we will concentrate only on coroutines
    that are natively supported by Python, starting from version 3.5.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主要是相同的概念，但通常以稍微不同的方式实现。出于明显的原因，在本节中，我们将只集中讨论Python从版本3.5开始原生支持的协程。
- en: Cooperative multitasking and asynchronous I/O
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合作式多任务处理和异步I/O
- en: '**Cooperative multitasking** is the core of asynchronous programming. In this
    style of computer multitasking, it''s not a responsibility of the operating system
    to initiate a context switch (to another process or thread), but instead every
    process voluntarily releases control when it is idle to enable simultaneous execution
    of multiple programs. This is why it is called *cooperative*. All processes need
    to cooperate in order to multitask smoothly.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**合作式多任务处理**是异步编程的核心。在这种计算机多任务处理风格中，操作系统不负责启动上下文切换（到另一个进程或线程），而是每个进程在空闲时自愿释放控制，以实现多个程序的同时执行。这就是为什么它被称为*合作式*。所有进程都需要合作才能实现平稳的多任务处理。'
- en: This model of multitasking was sometimes employed in operating systems, but
    now it is hardly ever found as a system-level solution. This is because there
    is a risk that one poorly designed service can easily break the whole system's
    stability. Thread and process scheduling with context switches managed directly
    by the operating system is now the dominant approach for concurrency on the system
    level. But cooperative multitasking is still a great concurrency tool on the application
    level.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这种多任务处理模型有时在操作系统中使用，但现在几乎不再作为系统级解决方案。这是因为一个设计不良的服务很容易破坏整个系统的稳定性。现在，线程和进程调度以及由操作系统直接管理的上下文切换是系统级并发的主要方法。但在应用程序级别，合作式多任务处理仍然是一个很好的并发工具。
- en: When speaking about cooperative multitasking on the application level, we do
    not deal with threads or processes that need to release control because all the
    execution is contained within a single process and thread. Instead, we have multiple
    tasks (coroutines, tasklets, and green threads) that release control to the single
    function that handles the coordination of tasks. This function is usually some
    kind of event loop.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序级别讨论合作式多任务处理时，我们不需要处理需要释放控制的线程或进程，因为所有执行都包含在一个单一的进程和线程中。相反，我们有多个任务（协程、任务和绿色线程），它们释放控制给处理任务协调的单个函数。这个函数通常是某种事件循环。
- en: To avoid confusion later (due to Python terminology), from now on we will refer
    to such concurrent tasks as *coroutines*. The most important problem in cooperative
    multitasking is when to release control. In most of asynchronous applications,
    control is released to the scheduler or event loop on I/O operations. No matter
    whether a program reads data from a filesystem or communicates through a socket,
    such I/O operation is always related to some waiting time when the process becomes
    idle. The waiting time depends on the external resource, so it is a good opportunity
    to release control so that other coroutines can do their work until they too would
    need to wait.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免以后混淆（由于Python术语），从现在开始我们将把这样的并发任务称为*协程*。合作式多任务处理中最重要的问题是何时释放控制。在大多数异步应用程序中，控制权在I/O操作时释放给调度器或事件循环。无论程序是从文件系统读取数据还是通过套接字进行通信，这样的I/O操作总是与进程变得空闲的等待时间相关。等待时间取决于外部资源，因此释放控制是一个很好的机会，这样其他协程就可以做他们的工作，直到它们也需要等待。
- en: This makes such an approach somewhat similar in behavior to how multithreading
    is implemented in Python. We know that GIL serializes Python threads but it is
    also released on every I/O operation. The main difference is that threads in Python
    are implemented as system-level threads, so the operating system can preempt the
    currently running thread and give control to another one at any point in time.
    In asynchronous programming, tasks are never preempted by the main event loop.
    This is why this style of multitasking is also called **non-preemptive multitasking**.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得这种方法在行为上与Python中的多线程实现方式有些相似。我们知道GIL会对Python线程进行串行化，但在每次I/O操作时会释放。主要区别在于Python中的线程是作为系统级线程实现的，因此操作系统可以在任何时间点抢占当前运行的线程，并将控制权交给另一个线程。在异步编程中，任务永远不会被主事件循环抢占。这就是为什么这种多任务处理风格也被称为**非抢占式多任务处理**。
- en: Of course every Python application runs on an operating system where there are
    other processes competing for resources. This means that the operating system
    always has the right to preempt the whole process and give control to another
    one. But when our asynchronous application is running back, it continues from
    the same place where it was paused when the system scheduler stepped in. This
    is why coroutines are still considered nonpreemptive.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，每个Python应用程序都在一个操作系统上运行，那里有其他进程竞争资源。这意味着操作系统始终有权剥夺整个进程的控制权，并将控制权交给另一个进程。但当我们的异步应用程序恢复运行时，它会从系统调度器介入时暂停的地方继续运行。这就是为什么协程仍然被认为是非抢占式的。
- en: Python async and await keywords
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python的async和await关键字
- en: The `async` and `await` keywords are the main building blocks in Python asynchronous
    programming.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`async`和`await`关键字是Python异步编程的主要构建模块。'
- en: 'The `async` keyword used before the `def` statement defines a new coroutine.
    The execution of the coroutine function may be suspended and resumed in strictly
    defined circumstances. Its syntax and behavior is very similar to generators (refer
    to [Chapter 2](ch02.html "Chapter 2. Syntax Best Practices – below the Class Level"),
    *Syntax Best Practices – below the Class Level*) In fact, generators need to be
    used in older versions of Python in order to implement coroutines. Here is an
    example of a function declaration that uses the `async` keyword:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在`def`语句之前使用的`async`关键字定义了一个新的协程。协程函数的执行可能在严格定义的情况下被暂停和恢复。它的语法和行为与生成器非常相似（参见[第2章](ch02.html
    "第2章。语法最佳实践-类级别下面")，“语法最佳实践-类级别下面”）。实际上，生成器需要在Python的旧版本中使用以实现协程。这是一个使用`async`关键字的函数声明的示例：
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Functions defined with the `async` keyword are special. When called, they do
    not execute the code inside but instead return a coroutine object:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`async`关键字定义的函数是特殊的。当调用时，它们不执行内部的代码，而是返回一个协程对象：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The coroutine object does not do anything until its execution is scheduled
    in the event loop. The `asyncio` module is available in order to provide the basic
    event loop implementation, as well as lot of other asynchronous utilities:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 协程对象在其执行被安排在事件循环中之前不会执行任何操作。`asyncio`模块可用于提供基本的事件循环实现，以及许多其他异步实用程序：
- en: '[PRE26]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Obviously, since we have created only one simple coroutine, there is no concurrency
    involved in our program. In order to see something really concurrent, we need
    to create more tasks that will be executed by the event loop.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，由于我们只创建了一个简单的协程，所以在我们的程序中没有涉及并发。为了真正看到一些并发，我们需要创建更多的任务，这些任务将由事件循环执行。
- en: 'New tasks can be added to the loop by calling the `loop.create_task()` method
    or by providing another object to wait for using the `asyncio.wait()` function.
    We will use the latter approach and try to asynchronously print a sequence of
    numbers generated with the `range()` function:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过调用`loop.create_task()`方法或使用`asyncio.wait()`函数提供另一个对象来等待来添加新任务到循环中。我们将使用后一种方法，并尝试异步打印使用`range()`函数生成的一系列数字：
- en: '[PRE27]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `asyncio.wait()` function accepts a list of coroutine objects and returns
    immediately. The result is a generator that yields objects representing future
    results (futures). As the name suggests, it is used to wait until all of the provided
    coroutines complete. The reason why it returns a generator instead of a coroutine
    object is backwards compatibility with previous versions of Python, which will
    be explained later. The result of running this script may be as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.wait()`函数接受一个协程对象的列表并立即返回。结果是一个生成器，产生表示未来结果（futures）的对象。正如其名称所示，它用于等待所有提供的协程完成。它返回生成器而不是协程对象的原因是为了与Python的先前版本向后兼容，这将在后面解释。运行此脚本的结果可能如下：'
- en: '[PRE28]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As we can see, the numbers are not printed in the same order as we created our
    coroutines. But this is exactly what we wanted to achieve.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，数字的打印顺序与我们创建协程的顺序不同。但这正是我们想要实现的。
- en: The second important keyword added in Python 3.5 is `await`. It is used to wait
    for the results of coroutine or a future (explained later) and release the control
    over execution to the event loop. To better understand how it works, we need to
    review a more complex example of code.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.5中添加的第二个重要关键字是`await`。它用于等待协程或未来结果（稍后解释）的结果，并将执行控制权释放给事件循环。为了更好地理解它的工作原理，我们需要回顾一个更复杂的代码示例。
- en: 'Let''s say we want to create two coroutines that will perform some simple task
    in a loop:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想创建两个协程，它们将在循环中执行一些简单的任务：
- en: Wait a random number of seconds
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待随机秒数
- en: Print some text provided as an argument and the amount of time spent in sleep
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印一些作为参数提供的文本和在睡眠中花费的时间
- en: 'Let''s start with a simple implementation that has some concurrency issues
    which we will later try to improve with the additional `await` usage:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的实现开始，它存在一些并发问题，我们稍后将尝试使用额外的`await`使用来改进它：
- en: '[PRE29]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'When executed in the terminal (with the `time` command to measure time), it
    might give the following output:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中执行（使用`time`命令来测量时间），可能会得到以下输出：
- en: '[PRE30]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As we can see, both the coroutines completed their execution but not in an asynchronous
    manner. The reason is that they both use the `time.sleep()` function that is blocking
    but not releasing the control to the event loop. This would work better in a multithreaded
    setup, but we don't want to use threads now. So how do we fix this?
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这两个协程都完成了它们的执行，但不是以异步的方式。原因是它们都使用了`time.sleep()`函数，这是阻塞的，但没有释放控制给事件循环。这在多线程设置中可能效果更好，但我们现在不想使用线程。那么我们该如何解决这个问题呢？
- en: 'The answer is to use `asyncio.sleep()`, which is the asynchronous version of
    `time.sleep()` and await its result using the `await` keyword. We already used
    this statement in the first version of the `main()` function, but it was only
    to improve clarity of code. It clearly did not make our implementation more concurrent.
    Let''s see an improved version of the `waiter()` coroutine that uses `await asyncio.sleep()`:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是使用`asyncio.sleep()`，这是`time.sleep()`的异步版本，并使用`await`关键字等待其结果。我们已经在`main()`函数的第一个版本中使用了这个语句，但这只是为了提高代码的清晰度。显然，这并没有使我们的实现更加并发。让我们看一个改进的`waiter()`协程的版本，它使用`await
    asyncio.sleep()`：
- en: '[PRE31]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'If we run the updated script, we can see how the output of two functions interleave
    with each other:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行更新后的脚本，我们可以看到两个函数的输出如何交错：
- en: '[PRE32]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The additional advantage of this simple improvement is that the code ran faster.
    The overall execution time was less than the sum of all sleeping times because
    coroutines were cooperatively releasing control.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单改进的额外优势是代码运行得更快。总体执行时间小于所有睡眠时间的总和，因为协程合作地释放控制。
- en: asyncio in older versions of Python
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 旧版本Python中的asyncio
- en: The `asyncio` module appeared in Python 3.4\. So it is the only version of Python
    that has serious support for asynchronous programming before Python 3.5\. Unfortunately,
    it looks like these two subsequent versions are just enough to introduce compatibility
    concerns.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`模块出现在Python 3.4中。因此，它是在Python 3.5之前唯一支持异步编程的版本。不幸的是，看起来这两个后续版本刚好足够引入兼容性问题。'
- en: Like it or not, the core of asynchronous programming in Python was introduced
    earlier than the syntax elements supporting this pattern. Better late than never,
    but this created a situation where there are two syntaxes available for working
    with coroutines.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 无论喜欢与否，Python中的异步编程核心早于支持此模式的语法元素。迟做总比不做好，但这造成了一种情况，即有两种语法可用于处理协程。
- en: 'Starting from Python 3.5, you can use `async` and `await`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从Python 3.5开始，你可以使用`async`和`await`：
- en: '[PRE33]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'But for Python 3.4, you need to use the `asyncio.coroutine` decorator and the
    `yield from` statement:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于Python 3.4，你需要使用`asyncio.coroutine`装饰器和`yield from`语句：
- en: '[PRE34]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The other useful fact is that the `yield from` statement was introduced in Python
    3.3 and there is an `asyncio` backport available on PyPI. This means that you
    can use this implementation of cooperative multitasking with Python 3.3 too.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的事实是，`yield from`语句是在Python 3.3中引入的，并且在PyPI上有一个`asyncio`的后备。这意味着你也可以在Python
    3.3中使用这个协作式多任务处理的实现。
- en: A practical example of asynchronous programming
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步编程的实际示例
- en: As has already been mentioned multiple times in this chapter, asynchronous programming
    is a great tool for handling I/O bound operations. So it's time to build something
    more practical than the simple printing of sequences or asynchronous waiting.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章中已经多次提到的那样，异步编程是处理I/O绑定操作的强大工具。所以现在是时候构建比简单打印序列或异步等待更实际的东西了。
- en: For the sake of consistency, we will try to handle the same problem we solved
    with the help of multithreading and multiprocessing. So we will try to asynchronously
    fetch some data from external resources through the network connection. It would
    be great if we could use the same `python-gmaps` package as in the previous sections.
    Unfortunately, we can't.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持一致，我们将尝试处理与多线程和多进程帮助解决的相同问题。因此，我们将尝试通过网络连接异步获取一些来自外部资源的数据。如果我们可以像在前面的部分中那样使用相同的`python-gmaps`包，那就太好了。不幸的是，我们不能。
- en: The creator of `python-gmaps` was a bit lazy and took a shortcut. In order to
    simplify development, he chose a `requests` package as his HTTP client library
    of choice. Unfortunately, `requests` do not support asynchronous I/O with `async`
    and `await`. There are some other projects that aim to provide some concurrency
    to the `requests` project, but they either rely on Gevent (`grequests`, refer
    to [https://github.com/kennethreitz/grequests](https://github.com/kennethreitz/grequests))
    or thread/process pool execution (`requests-futures`, refer to [https://github.com/ross/requests-futures](https://github.com/ross/requests-futures)).
    Neither of these solves our problem.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`python-gmaps`的创建者有点懒，走了捷径。为了简化开发，他选择了`requests`包作为他的首选HTTP客户端库。不幸的是，`requests`不支持`async`和`await`的异步I/O。还有一些其他项目旨在为`requests`项目提供一些并发性，但它们要么依赖于Gevent（`grequests`，参见[https://github.com/kennethreitz/grequests](https://github.com/kennethreitz/grequests)），要么依赖于线程/进程池执行（`requests-futures`，参见[https://github.com/ross/requests-futures](https://github.com/ross/requests-futures)）。这两者都不能解决我们的问题。'
- en: Note
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Before you get upset that I'm scolding an innocent open source developer, calm
    down. The person behind the `python-gmaps` package is me. Poor selection of dependencies
    is one of the issues of this project. I just like to publicly criticize myself
    from time to time. This should be a bitter lesson for me as `python-gmaps` in
    its most recent version (0.3.1 at the time of writing this book) cannot be easily
    integrated with Python's asynchronous I/O. Anyway, this may change in the future,
    so nothing is lost.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在你因为我在责备一个无辜的开源开发者而生气之前，冷静下来。`python-gmaps`包背后的人就是我。依赖项的选择不当是这个项目的问题之一。我只是喜欢偶尔公开批评自己。这对我来说应该是一个痛苦的教训，因为在我写这本书的时候，`python-gmaps`在其最新版本（0.3.1）中不能轻松地与Python的异步I/O集成。无论如何，这可能会在未来发生变化，所以一切都没有丢失。
- en: 'Knowing the limitations of the library that was so easy to use in the previous
    examples, we need to build something that will fill in the gap. The Google Maps
    API is really simple to use, so we will build a quick-and-dirty asynchronous utility
    only for illustration purposes. The standard library for Python in version 3.5
    still lacks a library that would make asynchronous HTTP requests as simple as
    calling `urllib.urlopen()`. We definitely don''t want to build the whole protocol
    support from scratch, so we will use a little help from the `aiohttp` package
    available on PyPI. It''s a really promising library that adds both client and
    server implementations for asynchronous HTTP. Here is a small module built on
    top of `aiohttp` that creates a single `geocode()` helper function which makes
    geocoding requests to the Google Maps API service:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 知道在前面的示例中很容易使用的库的限制，我们需要构建一些填补这一空白的东西。Google Maps API非常容易使用，所以我们将构建一个快速而简陋的异步实用程序，仅用于说明目的。Python
    3.5版本的标准库仍然缺少一个使异步HTTP请求像调用`urllib.urlopen()`一样简单的库。我们绝对不想从头开始构建整个协议支持，所以我们将从PyPI上可用的`aiohttp`包中得到一点帮助。这是一个非常有前途的库，为异步HTTP添加了客户端和服务器实现。这是一个建立在`aiohttp`之上的小模块，它创建了一个名为`geocode()`的辅助函数，用于向Google
    Maps API服务发出地理编码请求：
- en: '[PRE35]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s assume that this code is stored in a module named `asyncgmaps`, which
    we are going to use later. Now we are ready to rewrite the example used when discussing
    multithreading and multiprocessing. Previously, we used to split the whole operation
    into two separate steps:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这段代码存储在名为`asyncgmaps`的模块中，我们稍后会用到它。现在我们准备重写在讨论多线程和多进程时使用的示例。以前，我们习惯将整个操作分为两个独立的步骤：
- en: Perform all request to the external service in parallel using the `fetch_place()`
    function.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fetch_place()`函数并行执行对外部服务的所有请求。
- en: Display all the results in a loop using the `present_result()` function.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`present_result()`函数在循环中显示所有结果。
- en: 'But because cooperative multitasking is something completely different from
    using multiple processes or threads, we can slightly modify our approach. Most
    of the issues raised in the *Using one thread per item* section are no longer
    our concern. Coroutines are nonpreemptive, so we can easily display results immediately
    after HTTP responses are awaited. This will simplify our code and make it clearer:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，因为协作式多任务处理与使用多个进程或线程完全不同，我们可以稍微修改我们的方法。在“使用一个线程处理一个项目”部分提出的大部分问题不再是我们的关注点。协程是非抢占式的，因此我们可以在等待HTTP响应后立即显示结果。这将简化我们的代码并使其更清晰。
- en: '[PRE36]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Integrating nonasynchronous code with async using futures
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用期货将非异步代码与异步集成
- en: Asynchronous programming is great, especially for backend developers interested
    in building scalable applications. In practice, it is one of the most important
    tools for building highly concurrent servers.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 异步编程很棒，特别是对于对构建可扩展应用程序感兴趣的后端开发人员。实际上，这是构建高度并发服务器的最重要工具之一。
- en: 'But the reality is painful. A lot of popular packages that deal with I/O bound
    problems are not meant to be used with asynchronous code. The main reasons for
    that are:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 但现实是痛苦的。许多处理I/O绑定问题的流行软件包并不适用于异步代码。主要原因是：
- en: Still low adoption of Python 3 and some of its advanced features
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3及其一些高级功能的采用率仍然较低
- en: Low understanding of various concurrency concepts among Python beginners
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python初学者对各种并发概念的理解较低
- en: This means that very often migration of the existing synchronous multithreaded
    applications and packages is either impossible (due to architectural constraints)
    or too expensive. A lot of projects could benefit greatly from incorporating the
    asynchronous style of multitasking, but only a few of them will eventually do
    that.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着现有的同步多线程应用程序和软件包的迁移通常是不可能的（由于架构约束）或成本太高。许多项目可以从合并异步多任务处理方式中受益，但最终只有少数项目会这样做。
- en: This means that right now, you will experience a lot of difficulties when trying
    to build asynchronous applications from the start. In most cases, this will be
    something similar to the problem mentioned in the *A practical example of asynchronous
    programming* section—incompatible interfaces and nonasynchronous blocking of I/O
    operations.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着现在，当尝试从头开始构建异步应用程序时，您将遇到许多困难。在大多数情况下，这将类似于“异步编程的实际示例”部分中提到的问题 - 接口不兼容和I/O操作的非异步阻塞。
- en: Of course, you can sometimes resign from `await` when you experience such incompatibility
    and just fetch the required resources synchronously. But this will block every
    other coroutine from executing its code while you wait for the results. It technically
    works but also ruins all the gains of asynchronous programming. So in the end,
    joining asynchronous I/O with synchronous I/O is not an option. It is a kind of
    *all or nothing* game.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当您遇到这种不兼容性时，您有时可以放弃`await`并同步获取所需的资源。但这将在等待结果时阻止其他协程执行其代码。从技术上讲，这是有效的，但也破坏了异步编程的所有收益。因此，最终，将异步I/O与同步I/O结合起来不是一个选择。这是一种“全有或全无”的游戏。
- en: The other problem is long running CPU-bound operations. When you are performing
    an I/O operation, it is not a problem to release control from a coroutine. When
    writing/reading from a filesystem or socket, you will eventually wait, so calling
    using `await` is the best you can do. But what to do when you need to actually
    compute something and you know it will take a while? You can of course slice the
    problem into parts and release control every time you move the work forward a
    bit. But you will shortly find that this is not a good pattern. Such a thing may
    make the code a mess, and also does not guarantee good results. Timeslicing should
    be the responsibility of the interpreter or operating system.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是长时间运行的CPU绑定操作。当您执行I/O操作时，释放控制权不是一个问题。当从文件系统或套接字中读取/写入时，您最终会等待，因此使用`await`是您能做的最好的事情。但是当您需要实际计算某些东西并且知道这将需要一段时间时该怎么办？当然，您可以将问题切分成几部分，并在每次推进工作时释放控制权。但很快您会发现这不是一个好的模式。这样做可能会使代码混乱，也不能保证良好的结果。时间切片应该是解释器或操作系统的责任。
- en: So what to do if you have some code that makes long synchronous I/O operations
    that you can't or are unwilling to rewrite. Or what to do when you have to make
    some heavy CPU-bound operations in an application designed mostly with asynchronous
    I/O in mind? Well... you need to use a workaround. And by workaround I mean multithreading
    or multiprocessing.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果您有一些使长时间同步I/O操作的代码，而您无法或不愿意重写。或者当您需要在主要设计为异步I/O的应用程序中进行一些重型CPU绑定操作时该怎么办？嗯...您需要使用一种变通方法。我所说的变通方法是多线程或多进程。
- en: This may not sound nice, but sometimes the best solution may be the one that
    we tried to escape from. Parallel processing of CPU-extensive tasks in Python
    is always done better with multiprocessing. And multithreading may deal with I/O
    operations equally good (fast and without lot of resource overhead) as `async`
    and `await`, if set-up properly and handled with care.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能听起来不好，但有时最好的解决方案可能是我们试图逃避的解决方案。在Python中，对CPU密集型任务的并行处理总是使用多进程更好。如果设置正确并小心处理，多线程可以同样好地处理I/O操作（快速且没有太多资源开销）如`async`和`await`。
- en: So sometimes when you don't know what to do, when something simply does not
    fit your asynchronous application, use a piece of code that will defer it to separate
    thread or process. You can pretend that this was a coroutine, release control
    to the event loop and eventually process the results when they are ready. Fortunately
    for us, the Python standard library provides the `concurrent.futures` module,
    which is also integrated with the `asyncio` module. These two modules together
    allow you to schedule blocking functions executed in threads or additional processes
    as it were asynchronous nonblocking coroutines.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 所以有时当你不知道该怎么办，当某些东西简单地不适合你的异步应用程序时，使用一段代码将它推迟到单独的线程或进程。你可以假装这是一个协程，释放控制权给事件循环，最终在结果准备好时处理结果。幸运的是，Python标准库提供了`concurrent.futures`模块，它也与`asyncio`模块集成。这两个模块一起允许你安排在线程或额外进程中执行的阻塞函数，就像它们是异步非阻塞的协程一样。
- en: Executors and futures
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行者和未来
- en: Before we see how to inject threads or processes into an asynchronous event
    loop, we will take a closer look at the `concurrent.futures` module, which will
    later be the main ingredient of our so-called workaround.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们看到如何将线程或进程注入异步事件循环之前，我们将更仔细地看一下`concurrent.futures`模块，这将成为我们所谓的变通方法的主要组成部分。
- en: The most important classes in the `concurrent.futures` module are `Executor`
    and `Future`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.futures`模块中最重要的类是`Executor`和`Future`。'
- en: '`Executor` represents a pool of resources that may process work items in parallel.
    This may seem very similar in purpose to classes from the `multiprocessing` module—`Pool`
    and `dummy.Pool`—but has a completely different interface and semantics. It is
    a base class not intended for instantiation and has two concrete implementations:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`Executor`代表一个可以并行处理工作项的资源池。这在目的上似乎与`multiprocessing`模块的`Pool`和`dummy.Pool`类非常相似，但它有完全不同的接口和语义。它是一个不打算实例化的基类，并且有两个具体的实现：'
- en: '`ThreadPoolExecutor`: This is the one that represents a pool of threads'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ThreadPoolExecutor`：这个代表一个线程池'
- en: '`ProcessPoolExecutor`: This is the one that represents a pool of processes'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProcessPoolExecutor`：这个代表一个进程池'
- en: 'Every executor provides three methods:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 每个执行者提供三种方法：
- en: '`submit(fn, *args, **kwargs)`: This schedules the `fn` function for execution
    on a pool of resources and returns the `Future` object representing the execution
    of a callable'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`submit(fn, *args, **kwargs)`：这个方法安排`fn`函数在资源池上执行，并返回代表可调用执行的`Future`对象'
- en: '`map(func, *iterables, timeout=None, chunksize=1)`: This executes the func
    function over an iterable in a similar way to the `multiprocessing.Pool.map()`
    method'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`map(func, *iterables, timeout=None, chunksize=1)`：这个方法以类似于`multiprocessing.Pool.map()`方法的方式在可迭代对象上执行func函数'
- en: '`shutdown(wait=True)`: This shuts down the executer and frees all of its resources'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shutdown(wait=True)`：这个方法关闭执行者并释放它的所有资源'
- en: 'The most interesting method is `submit()` because of the `Future` object it
    returns. It represents the asynchronous execution of a callable and only indirectly
    represents its result. In order to obtain the actual return value of the submitted
    callable, you need to call the `Future.result()` method. And if the callable is
    already finished, the `result()` method will not block it and will just return
    the function output. If it is not true, it will block it until the result is ready.
    Treat it like a promise of a result (actually it is the same concept as a promise
    in JavaScript). You don''t need to unpack it immediately after receiving it (with
    the `result()` method), but if you try to do that it is guaranteed to eventually
    return something:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的方法是`submit()`，因为它返回一个`Future`对象。它代表一个可调用的异步执行，间接代表它的结果。为了获得提交的可调用的实际返回值，你需要调用`Future.result()`方法。如果可调用已经完成，`result()`方法不会阻塞它，只会返回函数的输出。如果不是这样，它会阻塞直到结果准备好。把它当作一个结果的承诺（实际上它和JavaScript中的promise概念是一样的）。你不需要立即在接收到它后解包它（用`result()`方法），但如果你试图这样做，它保证最终会返回一些东西：
- en: '[PRE37]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you want to use the `Executor.map()` method, it does not differ in usage
    from the `Pool.map()` method of the Pool class from `multiprocessing` module:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用`Executor.map()`方法，它在用法上与`multiprocessing`模块的`Pool`类的`map()`方法没有区别：
- en: '[PRE38]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Using executors in an event loop
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在事件循环中使用执行者
- en: The `Future` class instances returned by the `Executor.submit()` method is conceptually
    very close to the coroutines used in asynchronous programming. This is why we
    can use executors to make hybrid between cooperative multitasking and multiprocessing
    or multithreading.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`Executor.submit()`方法返回的`Future`类实例在概念上与异步编程中使用的协程非常接近。这就是为什么我们可以使用执行者来实现协作式多任务和多进程或多线程的混合。'
- en: The core of this workaround is the `BaseEventLoop.run_in_executor(executor,
    func, *args)` method of the event loop class. It allows you to schedule the execution
    of the `func` function in a process or thread pool represented by the `executor`
    argument. The most important thing about that method is that it returns a new
    *awaitable* (an object that can be *awaited* with the `await` statement). So thanks
    to this, you can execute a blocking function that is not a coroutine exactly as
    it were a coroutine, and it will not block no matter how long it takes to finish.
    It will stop only the function that is awaiting results from such a call, but
    the whole event loop will still keep spinning.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个变通方法的核心是事件循环类的`BaseEventLoop.run_in_executor(executor, func, *args)`方法。它允许你在由`executor`参数表示的进程或线程池中安排`func`函数的执行。这个方法最重要的一点是它返回一个新的*awaitable*（一个可以用`await`语句*await*的对象）。因此，由于这个方法，你可以执行一个阻塞函数，它不是一个协程，就像它是一个协程一样，无论它需要多长时间来完成，它都不会阻塞。它只会阻止等待这样一个调用结果的函数，但整个事件循环仍然会继续运转。
- en: And a useful fact is that you don't need to even create your executor instance.
    If you pass `None` as an executor argument, the `ThreadPoolExecutor` class will
    be used with the default number of threads (for Python 3.5 it is the number of
    processors multiplied by 5).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的事实是，您甚至不需要创建自己的执行器实例。如果将`None`作为执行器参数传递，将使用`ThreadPoolExecutor`类以默认线程数（对于Python
    3.5，它是处理器数量乘以5）。
- en: 'So, let''s assume that we did not want to rewrite the problematic part of the
    `python-gmaps` package that was the cause of our headache. We can easily defer
    the blocking call to a separate thread with the `loop.run_in_executor()` invocation
    while still leaving the `fetch_place()` function as an awaitable coroutine:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们假设我们不想重写导致我们头疼的`python-gmaps`包的有问题的部分。我们可以通过`loop.run_in_executor()`调用轻松地将阻塞调用推迟到单独的线程，同时将`fetch_place()`函数保留为可等待的协程：
- en: '[PRE39]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Such a solution is not as good as having a fully asynchronous library to do
    the job, but you know *half a loaf is better than no bread*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的解决方案并不像拥有完全异步库来完成工作那样好，但您知道*半瓶水总比没有水好*。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: It was a long journey, but we successfully struggled through the most basic
    approaches to concurrent programming available for Python programmers.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段漫长的旅程，但我们成功地克服了Python程序员可用的并发编程的最基本方法。
- en: After explaining what concurrency really is, we jumped into action and dissected
    one of the typical concurrent problems with the help of multithreading. After
    identifying the basic deficiencies of our code and fixing them, we turned to multiprocessing
    to see how it would work in our case.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释并发到底是什么之后，我们迅速行动起来，通过多线程的帮助解剖了典型的并发问题之一。在确定了我们代码的基本缺陷并加以修复后，我们转向了多进程，看看它在我们的情况下会如何运作。
- en: We found that multiple processes are much easier to use with the `multiprocessing`
    module than base threads with `threading`. But just after that, we have realized
    that we can use the same API with threads too, thanks to `multiprocessing.dummy`.
    So the choice between multiprocessing and multithreading is now only a matter
    of which solution better suits the problem and not which solution has a better
    interface.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，使用`multiprocessing`模块比使用`threading`的基本线程要容易得多。但就在那之后，我们意识到我们也可以使用相同的API来处理线程，多亏了`multiprocessing.dummy`。因此，现在在多进程和多线程之间的选择只是更适合问题的解决方案，而不是哪种解决方案具有更好的接口。
- en: And speaking about problem fit, we finally tried asynchronous programming, which
    should be the best solution for I/O bound applications, only to realize that we
    cannot completely forget about threads and processes. So we made a circle, back
    to the place where we started!
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 说到问题的适应性，我们最终尝试了异步编程，这应该是I/O密集型应用程序的最佳解决方案，只是意识到我们不能完全忘记线程和进程。所以我们又回到了起点！
- en: And this leads us to the final conclusion of this chapter. There is no silver
    bullet. There are some approaches that you may prefer or like more. There are
    some approaches that may fit better for a given set of problems, but you need
    to know them all in order to be successful. In realistic scenarios, you may find
    yourself using the whole arsenal of concurrency tools and styles in a single application
    and this is not uncommon.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了本章的最终结论。并没有银弹。有一些方法可能更受您喜欢。有一些方法可能更适合特定的问题集，但您需要了解它们，以便取得成功。在现实场景中，您可能会发现自己在单个应用程序中使用整套并发工具和风格，这并不罕见。
- en: The preceding conclusion is a great introduction to the topic of the next chapter,
    [Chapter 14](ch14.html "Chapter 14. Useful Design Patterns"), *Useful Design Patterns*.
    This is because there is no single pattern that will solve all of your problems.
    You should know as many as possible because eventually you will end up using all
    of them on a daily basis.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 上述结论是下一章[第14章](ch14.html "第14章。有用的设计模式")*有用的设计模式*主题的绝佳引言。这是因为没有单一的模式可以解决您所有的问题。您应该尽可能了解尽可能多的模式，因为最终您将每天都使用它们。
