- en: Dealing with Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理并发
- en: As we saw in the previous chapter, when working on any large-scale enterprise
    application, we deal with a lot of data. This data is processed in a synchronous
    manner and the results are sent only after the data processing for a particular
    process is complete. This kind of model is absolutely fine when the data being
    processed in individual requests is not large. But consider a situation where
    a lot of data needs to be processed before a response is generated. What happens
    then? The answer is, slow application response times.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中看到的，当处理任何大型企业应用程序时，我们会处理大量数据。这些数据以同步方式处理，并且只有在特定进程的数据处理完成后才发送结果。当处理的数据不大时，这种模型是完全可以接受的。但是考虑一种情况，需要在生成响应之前处理大量数据。那么会发生什么？答案是，应用程序响应时间变慢。
- en: We need a better solution. A solution that will allow us to process data in
    parallel, resulting in faster application responses. But how do we achieve this?
    The answer to the question is **concurrency ...**
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个更好的解决方案。一种允许我们并行处理数据，从而获得更快应用程序响应的解决方案。但是我们如何实现这一点呢？问题的答案是**并发...**
- en: Technical requirements
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code listings in this book can be found under `chapter04` directory at [https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python.](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码清单可以在[https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python](https://github.com/PacktPublishing/Hands-On-Enterprise-Application-Development-with-Python)的`chapter04`目录下找到。
- en: 'The code samples can be cloned by running the following command:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过运行以下命令克隆代码示例：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code samples mentioned in the chapter require Python 3.6 and above to run.
    A virtual environment is a preferred option to keep the dependencies segregated
    from the system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中提到的代码示例需要运行Python 3.6及以上版本。虚拟环境是将依赖项与系统隔离的首选选项。
- en: The need for concurrency
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发的需求
- en: Most of the time, when we are building fairly simple applications, we do not
    require concurrency. Simple, sequential programming works just fine, in which
    one step executes after the completion of another. But as application use cases
    become more and more complex, and there are an increased number of tasks that
    can easily be pushed into the background to improve the application's user experience,
    we end up revolving around the concept of concurrency.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，当我们构建相当简单的应用程序时，我们不需要并发。简单的顺序编程就可以很好地工作，一个步骤在另一个步骤完成后执行。但随着应用程序用例变得越来越复杂，并且有越来越多的任务可以轻松地推入后台以改善应用程序的用户体验，我们最终围绕并发的概念展开。
- en: Concurrency is a different beast in itself and makes the task of programming
    much more complex. But regardless of the added complexity, concurrency also brings
    a lot of features to improve the user experience of applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 并发本身就是一个不同的东西，并且使编程任务变得更加复杂。但是，尽管增加了复杂性，但并发也带来了许多功能，以改善应用程序的用户体验。
- en: Before we dive into the question of why we ...
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论为什么我们...
- en: Concurrency in GUI applications
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GUI应用程序中的并发
- en: The hardware we have become accustomed to using has became more and more powerful
    with each passing year. Today, even the CPUs inside our smartphones have quad-core
    or octa-core configurations. These configurations allow the running of multiple
    processes or threads in parallel. Not exploiting the power of concurrency would
    be a waste of the hardware improvements mentioned previously. Today, when we open
    applications on our smartphones, most of them have two or more threads running,
    though we are unaware of that most of the time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经习惯使用的硬件每年都变得越来越强大。如今，即使是我们智能手机内部的CPU也具有四核或八核的配置。这些配置允许并行运行多个进程或线程。不利用并发的硬件改进将是对之前提到的硬件改进的浪费。如今，当我们在智能手机上打开应用程序时，大多数应用程序都有两个或更多个线程在运行，尽管我们大部分时间都不知道。
- en: Let's consider a fairly simple example of opening up a photo gallery application
    on our device. As soon as we open the photo gallery, an application process is
    started. This process is responsible for loading up the GUI of the application.
    The GUI runs in the main thread and allows us to interact with the application.
    Now, this application also spawns another background thread, which is responsible
    for traversing through the filesystem of the OS and loading up the thumbnails
    of the photos. This loading up of thumbnails from the filesystem can be a tedious
    task and may take some time, depending on how many thumbnails need to be loaded.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个相当简单的例子，在我们的设备上打开一个照片库应用程序。当我们打开照片库时，一个应用程序进程就会启动。这个进程负责加载应用程序的GUI。GUI在主线程中运行，允许我们与应用程序进行交互。现在，这个应用程序还会生成另一个后台线程，负责遍历操作系统的文件系统并加载照片的缩略图。从文件系统加载缩略图可能是一个繁琐的任务，并且可能需要一些时间，这取决于需要加载多少缩略图。
- en: Though we do notice that the thumbnails are slowly loading, throughout this
    whole time, our application GUI remains responsive and we can interact with it,
    see the progress, and so on. All of this is made possible through the use of concurrent
    programming.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们注意到缩略图正在慢慢加载，但在整个过程中，我们的应用程序GUI仍然保持响应，并且我们可以与之交互，查看进度等。所有这些都是通过并发编程实现的。
- en: Imagine if concurrency hadn't been used here. The application would have been
    loading the thumbnails in the main thread itself. This would have caused the GUI
    to become unresponsive until the main thread finished loading the thumbnails.
    Not only would this have been very unintuitive, it also would have caused a bad
    user experience, which we avoided with the help of concurrent programming.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果这里没有使用并发。应用程序将在主线程中加载缩略图。这将导致GUI在主线程完成加载缩略图之前变得无响应。这不仅会非常不直观，而且还会导致糟糕的用户体验，而我们通过并发编程避免了这种情况。
- en: Now we have a fair idea of how concurrent programming can prove to be of great
    use, let's see how it can help us with the design and development of enterprise
    applications and what can be achieved with it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对并发编程如何证明其巨大用处有了一个大致的了解，让我们看看它如何帮助我们设计和开发企业应用程序，以及它可以实现什么。
- en: Concurrency in enterprise applications
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 企业应用程序中的并发
- en: Enterprise applications are large and usually deal with a lot of user-initiated
    actions such as data retrieval, updates, and so on. Now, let's take a short example
    scenario for our BugZot application, where a user may submit a graphic attachment
    along with their bug report. This is actually quite a common process when filing
    a bug that may affect the application UI or that displays an error on the UI.
    Now, every user may submit an image, which may differ in quality and hence their
    sizes may vary. This may involve images that are very small in size and  images
    that may have very large sizes and high resolutions. As an application developer,
    you may know that storing an image with 100% quality can, at ...
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 企业应用程序通常很大，通常涉及大量用户发起的操作，如数据检索、更新等。现在，让我们以我们的BugZot应用程序为例，用户可能会在提交错误报告时附上图形附件。这在提交可能影响应用程序UI或在UI上显示错误的错误时是一个常见的过程。现在，每个用户可能会提交图像，这些图像可能在质量上有所不同，因此它们的大小可能会有所不同。这可能涉及到非常小的尺寸的图像和尺寸非常大且分辨率很高的图像。作为应用程序开发人员，您可能知道以100%质量存储图像可能会...
- en: Concurrent programming with Python
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行并发编程
- en: Python provides a number of ways through which parallelism or concurrency can
    be achieved. All of these methods have their own pros and cons, and differ fundamentally
    in terms of how they are implemented, and a choice needs to be made about which
    method to use when, keeping the use case in mind.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了多种实现并行或并发的方法。所有这些方法都有各自的优缺点，在实现方式上有根本的不同，需要根据使用情况做出选择。
- en: One of the methods provided by Python for implementing concurrency is performed
    at the thread level by allowing the application to launch multiple threads, each
    executing a job. These threads provide an easy-to-use concurrency mechanism and
    execute inside a single Python interpreter process, and hence are lightweight.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供的实现并发的方法之一是在线程级别上进行，允许应用程序启动多个线程，每个线程执行一个任务。这些线程提供了一种易于使用的并发机制，并在单个Python解释器进程内执行，因此非常轻量级。
- en: Another mechanism for achieving parallelism is through the use of multiple processes
    in place of multiple threads. With this approach, every process performs a separate
    task inside its own separate Python interpreter process. This approach provides
    some workarounds to the problems that a multithreaded Python program may face
    in the presence of the **Global Interpreter Lock** (**GIL**), which we will discuss
    in later sections of the chapter, but may also add to the additional overhead
    of managing multiple processes and increased memory usage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种实现并行的机制是通过使用多个进程代替多个线程。通过这种方法，每个进程在其自己的独立Python解释器进程内执行一个单独的任务。这种方法为多线程Python程序在**全局解释器锁**（**GIL**）存在的情况下可能面临的问题提供了一些解决方法，但也可能增加管理多个进程和增加内存使用量的额外开销。
- en: So, first let's take a look at how we can achieve concurrency with the use of
    threads and discuss the benefits and drawbacks they come packaged with.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先看看如何使用线程实现并发，并讨论它们所附带的好处和缺点。
- en: Concurrency with multithreading
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程的并发
- en: In most modern processor systems, the use of multithreading is commonplace.
    With CPUs coming with more than one core and technologies such as hyper-threading,
    which allows a single core to run multiple threads at the same time, application
    developers do not waste a single chance to exploit the advantages provided by
    these technologies.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数现代处理器系统中，多线程的使用是司空见惯的。随着CPU配备多个核心和诸如超线程等技术的出现，允许单个核心同时运行多个线程，应用程序开发人员不会浪费任何一个利用这些技术提供的优势的机会。
- en: Python as a programming language supports the implementation of multithreading
    through the use of a threading module that allows developers to exploit thread-level
    parallelism in the application.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种编程语言，Python通过使用线程模块支持多线程的实现，允许开发人员在应用程序中利用线程级别的并行性。
- en: 'The following example showcases how a simple program can be built using the
    threading module in Python:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何使用Python中的线程模块构建一个简单的程序：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thread synchronization
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程同步
- en: As we explored in the previous section, although threads can be implemented
    quite easily in Python, they do come with their own gotchas, which need to be
    taken care of when trying to write an application that is being targeted for production
    use cases. If these gotchas are not taken care of at the time of application development,
    they will produce hard-to-debug behaviors, which concurrent programs are quite
    famous for.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中探讨的，虽然在Python中可以很容易地实现线程，但它们也有自己的陷阱，需要在编写面向生产用例的应用程序时予以注意。如果在应用程序开发时不注意这些陷阱，它们将产生难以调试的行为，这是并发程序所以闻名的。
- en: So, let's try to find out how we can work around the problem we discussed in
    the previous section. If we think hard, we can categorize the problem as a problem
    with the synchronization of multiple threads. The optimal behavior for the application
    would be to synchronize the writes to the file in such a way that only one thread
    is able to write to the file at any given point in time. This would enforce that
    no thread can start a write operation until one of the already-executing threads
    has completed its writes.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们试着找出如何解决前一节讨论的问题。如果我们仔细思考，我们可以将问题归类为多个线程同步的问题。应用程序的最佳行为是同步对文件的写入，以便在任何给定时间只有一个线程能够写入文件。这将强制确保在已经执行的线程完成其写入之前，没有线程可以开始写入操作。
- en: To implement such synchronization, we can leverage the power of locking. Locks
    provide a simple way to implement synchronization. For example, a thread that
    is going to start its write operation will first acquire a lock. If lock acquisition
    is successful, the thread can then progress to perform its write operation. Now,
    if a context switch happens in between and another thread is about to start a
    write operation, it will block, since the lock has already been taken. This will
    prevent the thread from writing the data in between an already-running write operation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种同步，我们可以利用锁的力量。锁提供了一种简单的实现同步的方法。例如，将要开始写操作的线程将首先获取锁。如果锁获取成功，线程就可以继续执行其写操作。现在，如果在中间发生上下文切换，并且另一个线程即将开始写操作，它将被阻塞，因为锁已经被获取。这将防止线程在已经运行的写操作之间写入数据。
- en: In Python multithreading, we can implement locks through the use of the `threading.Lock`
    class. The class provides two methods that facilitate the acquisition and release
    of locks. The `acquire()` method is called by the thread when it wants to acquire
    a lock before executing an operation. Once the lock is acquired, the thread continues
    with the execution of the operation. As soon as the operations of the threads
    are finished, the thread calls the `release()` method to release the lock such
    that the lock can be acquired by another thread that may be waiting for it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python多线程中，我们可以通过使用`threading.Lock`类来实现锁。该类提供了两种方法来方便地获取和释放锁。当线程想要在执行操作之前获取锁时，会调用`acquire()`方法。一旦锁被获取，线程就会继续执行操作。一旦线程的操作完成，线程调用`release()`方法释放锁，以便其他可能正在等待它的线程可以获取锁。
- en: 'Let''s see how we can use locks to synchronize the threaded operations in our
    JSON to YAML converter example. The following code sample showcases the use of
    locks:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用锁来同步我们的JSON到YAML转换器示例中的线程操作。以下代码示例展示了锁的使用：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, we first create a `lock` variable by creating an instance of
    the `threading.Lock` class. This instance is then passed to all our threads that
    need to be synchronized. When a thread has to do a write operation, it first proceeds
    by acquiring a lock and then starting the writes. Once these writes are completed,
    the thread releases the lock for acquisition by the other threads.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们首先通过创建`threading.Lock`类的实例来创建一个`lock`变量。然后将这个实例传递给所有需要同步的线程。当一个线程需要进行写操作时，它首先通过获取锁来开始写操作。一旦这些写操作完成，线程释放锁，以便其他线程可以获取锁。
- en: If a thread acquires a lock but forgets to release it, the program may get into
    a state of deadlock since no other thread will be able to proceed. Proper caution
    should be taken so that the acquired locks are released once the thread finishes
    its operations, to avoid deadlocks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个线程获取了锁但忘记释放它，程序可能会陷入死锁状态，因为没有其他线程能够继续。应该谨慎地确保一旦线程完成其操作，获取的锁就被释放，以避免死锁。
- en: Re-entrant locks
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可重入锁
- en: 'Beyond the `threading.Lock` class, which provides the general locking mechanism
    for multithreading, where a lock can only be acquired once until it is released,
    Python also provides another locking mechanism that might be useful for programs
    that implement recursive operations. This lock, known as a re-entrant lock and
    implemented using the `threading.RLock` class, can be used by recursive functions.
    The class provides similar methods to those provided by the lock class: `acquire()`
    and `release()`, which are to acquire and release the taken locks, respectively.
    The only difference occurs when a recursive function calls `acquire()` multiple
    times across the call stack. When the same function calls the acquire method again
    and again, ...'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供多线程的一般锁定机制的`threading.Lock`类之外，其中锁只能被获取一次直到释放，Python还提供了另一种可能对实现递归操作的程序有用的锁定机制。这种锁，称为可重入锁，使用`threading.RLock`类实现，可以被递归函数使用。该类提供了与锁类提供的类似方法：`acquire()`和`release()`，分别用于获取和释放已获取的锁。唯一的区别是当递归函数在调用堆栈中多次调用`acquire()`时发生。当相同的函数一遍又一遍地调用获取方法时，...
- en: Condition variables
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件变量
- en: 'Let''s imagine that somehow, we had a way through which we could tell our `Thread-1`
    to wait until `Thread-2` has made some data available for consumption. This is
    exactly what condition variables allow us to do. They allow us to synchronize
    two threads that depend on a shared resource. To understand more about this, let''s
    take a look at the following code sample, which creates two threads, one that
    feeds in the email ID and another thread that is responsible for sending the emails:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下，不知何故，我们有一种方法可以告诉我们的`Thread-1`等待，直到`Thread-2`提供了一些数据可供使用。这正是条件变量允许我们做的。它们允许我们同步依赖于共享资源的两个线程。为了更好地理解这一点，让我们看一下以下代码示例，它创建了两个线程，一个用于输入电子邮件ID，另一个负责发送电子邮件：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this code example, we defined two classes, namely, `EmailQueue`, which plays
    the role of producer and populates the email queue with email addresses on which
    the email needs to be sent. Then there is another class, `EmailSender`, which
    plays the role of the consumer and consumes the email addresses from the email
    queue and sends a mail to them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码示例中，我们定义了两个类，分别是`EmailQueue`，它扮演生产者的角色，并在电子邮件队列中填充需要发送电子邮件的电子邮件地址。然后还有另一个类`EmailSender`，它扮演消费者的角色，从电子邮件队列中获取电子邮件地址并发送邮件给它们。
- en: Now, inside the `__init__` method of `EmailQueue`, we take in a Python list
    that we will use as a queue as a parameter, a variable defining how many items
    the list should hold at most, and a condition variable.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`EmailQueue`的`__init__`方法中，我们接收一个Python列表作为参数，这个列表将作为队列使用，一个定义列表最多应该容纳多少项的变量，以及一个条件变量。
- en: Next, we have a method, `add_recipient`, which appends a new email ID inside
    an internal data structure of the `EmailQueue` to hold the email addresses temporarily
    until they are added to the sending queue.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一个方法`add_recipient`，它将一个新的电子邮件ID附加到`EmailQueue`的内部数据结构中，以临时保存电子邮件地址，直到它们被添加到发送队列中。
- en: Now, let's move inside the `run()`method where the actual magic happens. First,
    we start an infinite loop to keep the thread in always running mode. Next, we
    acquire a lock by calling the `acquire()`method of the condition variable. We
    do this so as to prevent any kind of corruption of our data structures if the
    thread switches the context at an unexpected time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入`run()`方法，这里发生了真正的魔术。首先，我们启动一个无限循环，使线程始终处于运行模式。接下来，我们通过调用条件变量的`acquire()`方法来获取锁。我们这样做是为了防止线程在意外时间切换上下文时对我们的数据结构进行任何形式的破坏。
- en: Once we have acquired the lock, we then check whether our email queue is full
    or not. If it is full, we print a message and make a call to the `wait()`method
    of the condition variable. The call to the `wait()`method releases the lock acquired 
    by the condition variable and makes the thread enter a blocking state. This blocking
    state will be over only when a `notify()` method is called on the condition variable.
    Now, when the thread receives a signal through `notify()`, it continues its operations,
    in which it first checks whether it has some data in the internal queue. If it
    finds some data in the internal queue, then it populates the email queue with
    that data and calls the `notify()`method of the conditional variable to inform
    the `EmailSender` consumer thread. Now, let's take a look at the `EmailSender`
    class.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了锁，我们就会检查我们的电子邮件队列是否已满。如果已满，我们会打印一条消息，并调用条件变量的`wait()`方法。对`wait()`方法的调用会释放条件变量获取的锁，并使线程进入阻塞状态。只有在条件变量上调用`notify()`方法时，这种阻塞状态才会结束。现在，当线程通过`notify()`接收到信号时，它会继续其操作，首先检查内部队列中是否有一些数据。如果它在内部队列中找到了一些数据，那么它会用这些数据填充电子邮件队列，并调用条件变量的`notify()`方法来通知`EmailSender`消费者线程。现在，让我们来看看`EmailSender`类。
- en: Without going through every single line here, let's keep our focus on the `run()`method
    of the `EmailSender` class. Since this thread needs to always be running, we first
    start an infinite loop to do that. Then, the next thing we do is, acquire a lock
    on the shared condition variable. Once we have acquired the lock, we are now ready
    to manipulate the shared `email_queue` data structure. So, the first thing our
    consumer does is, check whether the email queue is empty or not. If it finds the
    queue to be empty, our consumer will call the `wait()`method of the condition
    variable, effectively causing it to release the lock and go into a blocking state
    until there is some data inside the email queue. This causes the transfer of control
    to the `EmailQueue` class, which is responsible for populating the queue.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里不需要逐行阅读，让我们把重点放在`EmailSender`类的`run()`方法上。由于这个线程需要始终运行，我们首先启动一个无限循环来做到这一点。然后，我们要做的下一件事是，在共享条件变量上获取锁。一旦我们获得了锁，我们现在可以操作共享的`email_queue`数据结构。因此，我们的消费者首先要做的事情是检查电子邮件队列是否为空。如果发现队列为空，我们的消费者将调用条件变量的`wait()`方法，有效地释放锁并进入阻塞状态，直到电子邮件队列中有一些数据为止。这会导致控制权转移到负责填充队列的`EmailQueue`类。
- en: Now, once the email queue has some email IDs in it, the consumer will start
    sending the mails. Once it exhausts the queue, it signals the `EmailSender` class
    about that by calling the condition variables `notify` method. This will allow
    the `EmailSender` to continue its operation of populating the email queue.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一旦电子邮件队列中有一些电子邮件ID，消费者将开始发送邮件。一旦队列耗尽，它通过调用条件变量的`notify`方法向`EmailSender`类发出信号。这将允许`EmailSender`继续其操作，填充电子邮件队列。
- en: 'Let''s take a look at what happens when we try to execute the previous example
    program:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们尝试执行前面的示例程序时会发生什么：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: With this example, we now have an understanding of how condition variables can
    be used in Python to solve producer-consumer problems. With this knowledge in
    mind, now let's take a look at some of the issues that can may arise when performing
    multithreading in our applications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，我们现在了解了在Python中如何使用条件变量来解决生产者-消费者问题。有了这些知识，现在让我们来看看在我们的应用程序中进行多线程时可能出现的一些问题。
- en: Common pitfalls with multithreading
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程的常见陷阱
- en: Multithreading provides a lot of benefits but also comes with some pitfalls.
    These pitfalls, if not avoided, can prove to be a painful experience when the
    application goes into production. These pitfalls usually result in unexpected
    behaviors that may take place only once in a while, or may occur on every execution
    of a particular module. The painful thing about this is it is really hard to debug
    these problems when they are caused by the execution of multiple threads, since
    it is quite hard to predict when a particular thread will execute. So, it makes
    it worthwhile to discuss why these common pitfalls occur and how they can be avoided
    during the development stage itself.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程提供了许多好处，但也伴随着一些陷阱。如果不加以避免，这些陷阱在应用程序投入生产时可能会带来痛苦的经历。这些陷阱通常会导致意外行为，可能只会偶尔发生，也可能在特定模块的每次执行时都会发生。这其中令人痛苦的是，当这些问题是由多个线程的执行引起时，很难调试这些问题，因为很难预测特定线程何时执行。因此，在开发阶段讨论这些常见陷阱发生的原因以及如何在开发阶段避免它们是值得的。
- en: Some of the common reasons for ...
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的原因是...
- en: Race conditions
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争条件
- en: In the context of multithreading, a race condition is a situation where two
    or more threads try to modify a shared data structure at the same time, but due
    to the way the threads are scheduled and executed, the shared data structure is
    modified in a way that leaves it in an inconsistent state.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程的上下文中，竞争条件是指两个或更多个线程尝试同时修改共享数据结构的情况，但由于线程的调度和执行方式，共享数据结构被修改成一种使其处于不一致状态的方式。
- en: 'Is this statement confusing? No worries, let''s try to understand it with an
    example:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个声明是否令人困惑？别担心，让我们通过一个例子来理解它：
- en: 'Consider our previous example of the JSON to YAML converter problem. Now, let''s
    assume that we did not use locks when we were writing the converted YAML output
    to the file. Now consider this: we have two threads, named `writer-1` and `writer-2`
    which are responsible for writing to the common YAML file. Now, imagine both the
    `writer-1` and `writer-2`, threads have started their operations of writing to
    the file and, with the way the operating system scheduled the threads to execute,
    `writer-1` starts writing to the file. Now, while the `writer-1` thread was writing
    to the file, the operating system decided that the thread finished its quota of
    time and swaps that thread with the `writer-2` thread. Now, one thing to note
    here is that the `writer-1` thread had not completed writing all the data when
    it was swapped. Now, the `writer-2` thread starts executing and completes writing
    of data in the YAML file. Upon completion of the `writer-2` thread, the OS then
    starts executing the `writer-1` thread again which starts to write the remaining
    data again to the YAML file and then finishes.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们之前的JSON转YAML转换器问题的例子。现在，假设我们在将转换后的YAML输出写入文件时没有使用锁。现在假设我们有两个名为`writer-1`和`writer-2`的线程，它们负责向共同的YAML文件写入。现在，想象一下，`writer-1`和`writer-2`线程都开始了写入文件的操作，并且操作系统安排线程执行的方式是，`writer-1`开始写入文件。现在，当`writer-1`线程正在写入文件时，操作系统决定该线程完成了其时间配额，并将该线程与`writer-2`线程交换。现在，需要注意的一点是，当被交换时，`writer-1`线程尚未完成写入所有数据。现在，`writer-2`线程开始执行并完成了在YAML文件中的数据写入。在`writer-2`线程完成后，操作系统再次开始执行`writer-1`线程，它开始再次写入剩余的数据到YAML文件，然后完成。
- en: Now, when we open the YAML file, what we see is a file with data mingled up
    from two writer threads, and hence, leaves our file in an inconsistent state.
    A problem such as what happened between the `writer-1` and `writer-2` threads
    is known as a race condition.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们打开YAML文件时，我们看到的是一个文件，其中包含了两个写入线程混合在一起的数据，因此，使我们的文件处于不一致的状态。`writer-1`和`writer-2`线程之间发生的问题被称为竞争条件。
- en: Race conditions come under the category of problems that are very hard to debug,
    since the order in which the threads will execute depends on machine to machine
    and OS to OS. So, a problem that may occur on one deployment may not occur on
    another deployment.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争条件属于非常难以调试的问题类别，因为线程执行的顺序取决于机器和操作系统。因此，在一个部署上可能出现的问题在另一个部署上可能不会出现。
- en: 'So, how do we avoid race conditions? Well, we already have the answers to the
    question and we have just recently used them. So, let''s take a look at some of
    the ways in which race conditions can be prevented:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何避免竞争条件？嗯，我们已经有了问题的答案，而且我们最近刚刚使用过它们。所以，让我们来看看一些可以预防竞争条件发生的方法：
- en: '**Utilizing locks in critical regions**: Critical regions refer to those areas
    of code where a shared variable is being modified by a thread. To prevent race
    conditions from happening in critical regions, we can use locks. A lock essentially
    causes all the threads to block except the thread that holds the lock. All the
    other threads that need to modify the shared resource will execute only when the
    thread that is currently holding the lock releases it. Some of the categories
    of locks that can be used are mutex locks, which can only be held by a single
    thread at a time; re-entrant locks, which allow a recursive function to take multiple
    locks on the same shared resource; and condition objects, which can be used to
    synchronize execution in producer-consumer type environments.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在关键区域使用锁**：关键区域指的是代码中共享变量被线程修改的区域。为了防止竞争条件在关键区域发生，我们可以使用锁。锁本质上会导致除了持有锁的线程外，所有其他线程都会被阻塞。需要修改共享资源的所有其他线程只有在当前持有锁的线程释放锁时才能执行。可以使用的锁的类别包括互斥锁（一次只能由一个线程持有）、可重入锁（允许递归函数对同一共享资源进行多次锁定）和条件对象（可用于在生产者-消费者类型的环境中同步执行）。'
- en: '**Utilizing thread-safe data structures**: One other way of preventing race
    conditions is by using thread-safe data structures. A thread-safe data structure
    is one that will automatically manage the modifications being made to it by multiple
    threads and will serialize their operations. One of the thread-safe shared data
    structures that is provided by Python is a queue. A queue can be used easily when
    the operation involves multiple threads.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用线程安全的数据结构**：预防竞争条件的另一种方法是使用线程安全的数据结构。线程安全的数据结构是指能够自动管理多个线程对其所做修改并串行化其操作的数据结构。Python提供的一个线程安全的共享数据结构是队列。当操作涉及多个线程时，可以轻松地使用队列。'
- en: Now, we have an idea about what race conditions are, how they happen, and how
    they can be avoided. With this in mind, let's take a look at one of the other
    pitfalls that can arise due to the way we prevent race conditions from happening.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对竞争条件是什么，它是如何发生的，以及如何避免有了一个概念。有了这个想法，让我们来看看由于我们预防竞争条件而可能出现的其他问题之一。
- en: Deadlocks
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 死锁
- en: 'A deadlock is a situation when two or more threads are blocked forever because
    they depend on each other or a resource that never gets freed up. Let''s try to
    understand how a deadlock occurs by taking a simple example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 死锁是指两个或更多个线程永远被阻塞，因为它们彼此依赖或者一个资源永远不会被释放。让我们通过一个简单的例子来理解死锁是如何发生的：
- en: Consider our previous example of  the JSON to YAML converter. Now, let's assume
    we had used locks in our threads such that when a thread starts to write to the
    file, it first takes a mutex lock on the file. Now, until this mutex lock is freed
    up by the thread, other thread cannot execute.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们之前的JSON转YAML转换器的例子。现在，假设我们在线程中使用了锁，这样当一个线程开始向文件写入时，它首先对文件进行互斥锁定。现在，在线程释放这个互斥锁之前，其他线程无法执行。
- en: So, let's imagine the same situation with two threads, `writer-1` and `writer-2`,
    which are trying to write to the common output file. Now, when `writer-1` starts
    to execute, it first acquires a lock on the file and starts its operation. ...
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们想象一下有两个线程`writer-1`和`writer-2`，它们试图写入共同的输出文件。现在，当`writer-1`开始执行时，它首先在文件上获取锁并开始操作。...
- en: The story of GIL
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GIL的故事
- en: What if someone told you that, even though you have created a multithreaded
    program, only a single thread can execute at a time? This situation used to be
    true when systems consisted of a single core that could execute only one thread
    at a time, and the illusion of multiple running threads was created by the CPU
    switching between threads frequently.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人告诉你，即使你创建了一个多线程程序，只有一个线程可以同时执行？这种情况在系统只包含一个一次只能执行一个线程的单核心时是真实的，多个运行线程的幻觉是由CPU频繁地在线程之间切换而产生的。
- en: But this situation is also true in one of the implementations of Python. The
    original implementation of Python, also known as CPython consists of a global
    mutex also known as a GIL, which allows only one thread to execute the Python
    bytecode at a time. This effectively limits the application to executing only
    one thread at a time.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 但这种情况在Python的一个实现中也是真实的。Python的原始实现，也称为CPython，包括一个全局互斥锁，也称为GIL，它只允许一个线程同时执行Python字节码。这有效地限制了应用程序一次只能执行一个线程。
- en: The GIL was introduced in CPython because of the fact that the CPython interpreter
    wasn't thread-safe. The GIL proved to be an effective way to workaround the thread-safety
    issues by trading the properties of running multiple threads concurrently.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: GIL是在CPython中引入的，因为CPython解释器不是线程安全的。GIL通过交换运行多个线程的属性来有效地解决了线程安全问题。
- en: The existence of GIL has been a highly debated topic in the Python community
    and a lot of proposals have been made to eliminate it, but none of the proposals
    have made it to a production version of Python, for various reasons, which include
    the performance impact on single-threaded applications, breaking the backward
    compatibility of features that have grown to be dependent upon the presence of
    the GIL, and so on.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: GIL的存在在Python社区中一直是一个备受争议的话题，有很多提案旨在消除它，但由于各种原因，包括对单线程应用程序性能的影响、破坏对GIL存在依赖的功能的向后兼容性等，没有一个提案被纳入Python的生产版本。
- en: So, what does the presence of GIL mean for your multithreaded application? Effectively,
    if your applications exploit multithreading to perform I/O workloads, then you
    might not be impacted on that much in terms of performance loss due to GIL, since
    most of the I/O happens outside the GIL, and hence multiple threads can be multiplexed. The
    impact of GIL will be felt only when the application uses multiple threads to
    perform CPU-intensive tasks that require heavy manipulation of application-specific
    data structures. Since all data structure manipulation involves the execution
    of Python bytecode, the GIL will severely limit the performance of a multithreaded
    application by not allowing more than one thread to execute concurrently.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，GIL的存在对于你的多线程应用程序意味着什么呢？实际上，如果你的应用程序利用多线程来执行I/O工作负载，那么由于大部分I/O发生在GIL之外，你可能不会受到GIL的性能损失影响，因此多个线程可以被复用。只有当应用程序使用多个线程执行需要大量操作应用程序特定数据结构的CPU密集型任务时，GIL的影响才会被感知到。由于所有数据结构操作都涉及Python字节码的执行，GIL将通过不允许多个线程同时执行严重限制多线程应用程序的性能。
- en: 'So, is there a workaround for the problem that GIL causes? The answer to this
    is yes, but which solution should be adopted depends completely on the use case
    of the application. The following options can prove to be of help for avoiding
    the GIL:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，GIL引起的问题是否有解决方法？答案是肯定的，但应该采用哪种解决方案完全取决于应用程序的用例。以下选项可能有助于避免GIL：
- en: '**Switching the Python implementation:** If your application does not necessarily
    depend on the underlying Python implementation and a switch to another implementation
    can be made, then there are some Python implementations that do not come with
    GIL. Some of the implementations that do not have GIL in place are: Jython and
    IronPython, which can completely exploit multiprocessor systems to execute multithreaded
    applications.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**切换Python实现：**如果你的应用程序并不一定依赖于底层的Python实现，并且可以切换到另一个实现，那么有一些Python实现是没有GIL的。一些没有GIL的实现包括：Jython和IronPython，它们可以完全利用多处理器系统来执行多线程应用程序。'
- en: '**Utilizing multiprocessing:** Python has a lot of options when it comes to
    building programs with concurrency in mind. We explored multithreading, which
    is one of the options for implementing concurrency but is limited by the GIL.
    Another option for achieving concurrency is by using Python''s multiprocessing
    capabilities, which allow the launching of multiple processes to execute tasks
    in parallel. Since every process runs in its own instance of Python interpreter,
    the GIL doesn''t become an issue here and allows for the full exploitation of
    the multiprocessor systems.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用多进程：**Python在构建考虑并发的程序时有很多选择。我们探讨了多线程，这是实现并发的选项之一，但受到GIL的限制。实现并发的另一个选项是使用Python的多进程能力，它允许启动多个进程并行执行任务。由于每个进程在自己的Python解释器实例中运行，因此GIL在这里不成问题，并允许充分利用多处理器系统。'
- en: With the knowledge of how GIL impacts multithreaded applications, let's now
    discuss how multiprocessing can help you to overcome the limitations of concurrency.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 了解了GIL对多线程应用程序的影响，现在让我们讨论多进程如何帮助你克服并发的限制。
- en: Concurrency with multiprocessing
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程并发
- en: The Python language provides some quiet easy ways to achieve concurrency in
    applications. We saw this with the Python threading library and the same is true
    for the Python multiprocessing capabilities too.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Python语言提供了一些非常简单的方法来实现应用程序的并发。我们在Python线程库中看到了这一点，对于Python的多进程能力也是如此。
- en: If you want to build concurrency in your program with the help of multiprocessing,
    it is quite easy to achieve, all thanks to the Python multiprocessing library
    and the APIs exposed by the library.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要借助多进程在程序中构建并发，那么借助Python的多进程库和该库提供的API，实现起来非常容易。
- en: So, what do we mean when we say that we will implement concurrency by using
    multiprocessing. Let's try to answer this. Usually, when we talk about concurrency,
    there are two methods that can help us achieve it. One of those methods is running
    a single application instance and allowing it to use multiple threads. ...
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当我们说我们将使用多进程来实现并发时，我们是什么意思呢？让我们试着回答这个问题。通常，当我们谈论并发时，有两种方法可以帮助我们实现它。其中一种方法是运行单个应用程序实例，并允许其使用多个线程。...
- en: Python multiprocessing module
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python多进程模块
- en: Python provides an easy way to implement a multiprocess program. This ease of
    implementation is facilitated by the Python multiprocessing module, which provides
    important classes, such as the `Process` class to start new processes; the `Queue`, and `Pipe` classes
    to facilitate communication between multiple processes; and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了一种简单的方法来实现多进程程序。这种实现的便利性得益于Python的多进程模块，该模块提供了重要的类，如Process类用于启动新进程；Queue和Pipe类用于促进多个进程之间的通信；等等。
- en: 'The following example provides a quick overview of how to use Python''s multiprocessing
    library to create a URL loader that executes as a separate process to load a URL:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例快速概述了如何使用Python的多进程库创建一个作为单独进程执行的URL加载器：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this example, we created a simple program using the Python multiprocessing
    library, which loads a URL in the background and prints its information to `stdout`. The
    interesting bit here is understanding how easily we spawned a new process in our
    program. So, let's take a look. To achieve multiprocessing, we first import the `Process` class
    from Python's multiprocessing module. The next step is to create a function that
    takes the URL to load as a parameter and then loads that URL using Python's `urllib` module. Once
    the URL is loaded, we print the data from the URL to `stdout`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用Python的多进程库创建了一个简单的程序，它在后台加载一个URL并将其信息打印到stdout。有趣的地方在于理解我们如何轻松地在程序中生成一个新的进程。所以，让我们来看看。为了实现多进程，我们首先从Python的多进程模块中导入Process类。下一步是创建一个函数，该函数以要加载的URL作为参数，然后使用Python的urllib模块加载该URL。一旦URL加载完成，我们就将来自URL的数据打印到stdout。
- en: Next, we define the code that runs when the program starts executing. Here,
    we have first defined the URL we want to load with the `url` variable. The next
    bit is where we introduce the multiprocessing in our program by creating an object
    of the `Process` class. For this object, we provide the target parameter as the
    function we want to execute. This is similar to the target method we have grown
    accustomed to while using the Python `threading` library. The next parameter to
    the `Process` constructor is the `args` parameter, which takes in the arguments
    that need to be passed to the target function while calling it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义程序开始执行时运行的代码。在这里，我们首先定义了我们想要加载的URL，并将其存储在url变量中。接下来的部分是我们通过创建Process类的对象在程序中引入多进程。对于这个对象，我们将目标参数提供为我们想要执行的函数。这类似于我们在使用Python线程库时已经习惯的目标方法。Process构造函数的下一个参数是args参数，它接受在调用目标函数时需要传递给目标函数的参数。
- en: To spawn a new process, we make a call to the `start()`method of the `Process` object. This
    spawns a new process in which our target function starts executing and doing its
    magic. The last thing we do is to wait for this spawned process to exit by calling
    the `join()` method of the `Process` class.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成一个新的进程，我们调用Process对象的start()方法。这将在一个新的进程中启动我们的目标函数并执行其操作。我们做的最后一件事是等待这个生成的进程退出，通过调用Process类的join()方法。
- en: This is as simple as it gets to create a multiprocess application in Python.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是在Python中创建多进程应用程序的简单方法。
- en: 'Now, we know how to create a multiprocess application in Python, but how do
    we divide a particular set of tasks between multiple processes. Well, that''s
    quite easy. The following code sample modifies the entrypoint code from our previous
    example to exploit the power of the `Pool` class from the multiprocessing module
    to achieve this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们知道如何在Python中创建多进程应用程序，但是如何在多个进程之间分配特定的任务呢？嗯，这很容易。以下代码示例修改了我们之前示例中的入口代码，以利用多进程模块中的Pool类的功能来实现这一点：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this example, we used the `Pool` class from the multiprocessing library to
    create a pool of four processes that will execute our code. Using the `map` method
    of the `Pool` class, we then map the input data to the executing function in a
    separate process to achieve concurrency.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用多进程库中的Pool类创建了一个包含四个进程的进程池来执行我们的代码。然后使用Pool类的map方法，将输入数据映射到执行函数中的一个单独的进程中，以实现并发。
- en: Now, we have multiple processes churning through our tasks. But what if we wanted
    to make these processes communicate with each other. For example, in the previous
    problem of URL loading, instead of printing the data on `stdout`, we wanted the
    process to return that data instead? The answer to this lies in the use of *pipe*, which
    provides a two-way mechanism for the processes to communicate with each other.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有多个进程在处理我们的任务。但是，如果我们想让这些进程相互通信怎么办。例如，在之前的URL加载问题中，我们希望进程返回数据而不是在stdout上打印数据怎么办？答案在于使用管道，它为进程之间提供了双向通信的机制。
- en: 'The following example utilizes pipes to make the URL loader send the data loaded
    from the URL back to the parent process:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例利用管道使URL加载器将从URL加载的数据发送回父进程：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this example, we have used pipes to provide a two-way communication mechanism
    for the parent and child processes to talk to each other. When we make a call
    to the `pipe` constructor inside the `__main__` section of the code, the constructor
    returns a pair of connection objects. Each of these connection objects contains
    a `send()` and a `recv()` method facilitating communication between the ends. Data
    sent from the `child_pipe` using the `send()`method can be read by the `parent_pipe` using
    the `recv()`method of the `parent_pipe` and vice versa.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用管道为父进程和子进程提供双向通信机制。当我们在代码的`__main__`部分调用`pipe`构造函数时，构造函数返回一对连接对象。每个连接对象都包含一个`send()`和一个`recv()`方法，用于在两端之间进行通信。使用`send()`方法从`child_pipe`发送的数据可以通过`parent_pipe`的`recv()`方法读取，反之亦然。
- en: If two processes read or write from/to the same end of pipe at the same time,
    there is the potential for possible data corruption in the pipe. Although, if
    the processes are using two different ends or two different pipes, this does not
    become an issue. Only the data that can be pickled can be sent through the pipes.
    This is one of the limitations of the Python multiprocessing module.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个进程同时从管道的同一端读取或写入数据，可能会导致管道中的数据损坏。尽管，如果进程使用两个不同的端口或两个不同的管道，这就不成问题了。只有可以通过pickle序列化的数据才能通过管道发送。这是Python多进程模块的一个限制。
- en: Synchronizing processes
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步进程
- en: As much as synchronizing the actions of the threads was important, the synchronizing
    of actions inside the context of multiprocessing is also important. Since multiple
    processes may be accessing the same shared resource, their access to shared resource
    needs to be serialized. To help achieve this, we have the support of locks here
    too.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 与同步线程的操作一样重要的是，多进程上下文中的操作同步也很重要。由于多个进程可能访问相同的共享资源，它们对共享资源的访问需要进行序列化。为了帮助实现这一点，我们在这里也有锁的支持。
- en: 'The following example showcases how to use locks in the context of the multiprocessing
    module to synchronize the operations of multiple processes by fetching the HTML
    associated with the URLs and writing that HTML to a common local file:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何在多进程模块的上下文中使用锁来同步多个进程的操作，通过获取与URL相关联的HTML并将其写入一个共同的本地文件：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored how to achieve concurrency in Python applications
    and how it can be useful. During this exploration, we uncovered the capabilities
    of the Python multithreading module and how it can be used to spawn multiple threads
    to divide workloads on. We then moved on to understand how to synchronize the
    actions of those threads and learned about various issues that may crop up in
    a multithreaded application, if not taken care of. The chapter then moved on to
    explore the limitations that are imposed by the presence of the **global interpreter
    lock** (**GIL**)in some Python implementations and how it affects multithreaded
    workloads. To explore possible ways to overcome the restrictions imposed by the
    GIL, we moved on to understand the use of Python's multiprocessing module and
    how it can help us to leverage the full potential of a multiprocessor system by
    achieving parallelism powered by the use of multiple processes instead of multiple
    threads.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了如何在Python应用程序中实现并发以及它的用途。在这个探索过程中，我们揭示了Python多线程模块的功能，以及如何使用它来生成多个线程来分配工作负载。然后，我们继续了解如何同步这些线程的操作，并了解了多线程应用程序可能出现的各种问题，如果不加以处理。然后，本章继续探讨了全局解释器锁（GIL）在某些Python实现中所施加的限制，以及它如何影响多线程工作负载。为了探索克服GIL所施加的限制的可能方法，我们继续了解了Python的多进程模块的使用，以及它如何帮助我们利用多处理器系统的全部潜力，通过使用多个进程而不是多个线程来实现并行处理。
- en: Questions
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the different methods through which Python enables the building of
    concurrent applications?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python是通过哪些不同的方法实现并发应用程序的？
- en: What happens to an acquired lock if the thread that has acquired it terminates
    abruptly?
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果已经获得锁的线程突然终止会发生什么？
- en: How can we terminate executing threads when the application receives a termination
    signal?
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当应用程序接收到终止信号时，如何终止执行线程？
- en: How can we share state between multiple processes?
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在多个进程之间共享状态？
- en: Is there a way through which we can create a pool of processes that can then
    be used to work on the incoming set of tasks in a task queue?
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有没有一种方法可以创建一个进程池，然后用于处理任务队列中的任务？
