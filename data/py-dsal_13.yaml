- en: Implementations, Applications, and Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施方案、应用和工具
- en: Learning about algorithms without any real-life application remains a purely
    academic pursuit. In this chapter, we will explore data structures and algorithms
    that are shaping our world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有实际应用的情况下学习算法仍然是一种纯粹学术的追求。在本章中，我们将探讨塑造我们世界的各种数据结构和算法。
- en: One of the golden nuggets of this age is the abundance of data. E-mails, phone
    numbers, text, and image documents contain large amounts of data. In this data
    is found valuable information that makes the data become more important. But to
    extract this information from the raw data, we will have to use data structures,
    processes, and algorithms specialized for this task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这个时代的黄金法则之一是数据的丰富性。电子邮件、电话号码、文本和图像文档包含大量数据。在这些数据中找到了有价值的信息，使得数据变得更加重要。但要从原始数据中提取这些信息，我们必须使用专门为此任务设计的数据结构、过程和算法。
- en: Machine learning employs a significant number of algorithms to analyze and predict
    the occurrence of certain variables. Analyzing data on a purely numerical basis
    still leaves much of the latent information buried in the raw data. Presenting
    data visually thus enables one to understand and gain valuable insights too.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使用大量算法来分析和预测某些变量的发生。仅基于数值分析数据仍然会留下大量潜在信息隐藏在原始数据中。因此，以视觉方式呈现数据使人们能够理解和获得有价值的洞察。
- en: 'By the end of this chapter, you should be able to do the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该能够做到以下几件事情：
- en: Prune and present data accurately
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确修剪和呈现数据
- en: Use both supervised and unsupervised learning algorithms for the purposes of
    prediction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用监督学习和无监督学习算法进行预测
- en: Visually represent data in order to gain more insight
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以视觉方式呈现数据以获得更多洞察
- en: Tools of the trade
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行业工具
- en: In order to proceed with this chapter, you will need to install the following
    packages. These packages will be used to preprocess and visually represent the
    data being processed. Some of the packages also contain well-written and perfected
    algorithms that will operate on our data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续本章，你需要安装以下包。这些包将用于预处理和视觉呈现正在处理的数据。其中一些包还包含编写良好且经过优化的算法，将在我们的数据上运行。
- en: 'Preferably, these modules should be installed within a virtual environment
    such as `pip`:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最好在这些模块中安装虚拟环境，例如`pip`：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These packages may require other platform-specific modules to be installed
    first. Take note and install all dependencies:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包可能需要首先安装其他平台特定的模块。请注意并安装所有依赖项：
- en: '**Numpy**: A library with functions to operate on n-dimensional arrays and
    matrices.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Numpy**：一个具有操作n维数组和矩阵的函数库。'
- en: '**Scikit-learn**: A highly advanced module for machine learning. It contains
    a good number of algorithms for classification, regression, and clustering, among
    others.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**：一个高度先进的机器学习模块。它包含大量用于分类、回归和聚类等算法。'
- en: '**Matplotlib**: This is a plotting library that makes use of NumPy to graph
    a good variety of charts, including line plots, histograms, scatter plots, and
    even 3D graphs.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：这是一个利用NumPy绘制各种图表的绘图库，包括线图、直方图、散点图，甚至3D图表。'
- en: '**Pandas**: This library deals with data manipulation and analysis.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pandas**：这个库处理数据操作和分析。'
- en: Data preprocessing
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Collection of data from the real world is fraught with massive challenges. The
    raw data collected is plagued with a lot of issues, so much so that we need to
    adopt ways to sanitize the data to make it suitable for use in further studies.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从现实世界收集数据充满了巨大的挑战。收集到的原始数据存在许多问题，以至于我们需要采用方法来净化数据，使其适合进一步研究使用。
- en: Why process raw data?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么处理原始数据？
- en: Raw data as collected from the field is rigged with human error. Data entry
    is a major source of error when collecting data. Even technological methods of
    collecting data are not spared. Inaccurate reading of devices, faulty gadgetry,
    and changes in environmental factors can introduce significant margins of errors
    as data is collected.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从现场收集的原始数据充满了人为错误。数据录入是收集数据时的主要错误来源。即使是收集数据的技术方法也难以幸免。设备读取不准确、设备故障和环境因素的变化在收集数据时可以引入显著的误差范围。
- en: The data collected may also be inconsistent with other records collected over
    time. The existence of duplicate entries and incomplete records warrant that we
    treat the data in such a way as to bring out hidden and buried treasure. The raw
    data may also be shrouded in a sea of irrelevant data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 收集的数据也可能与其他随时间收集的记录不一致。存在重复条目和不完整记录的存在要求我们以这种方式处理数据，以便挖掘隐藏和埋藏的宝藏。原始数据也可能被无关的数据所掩盖。
- en: To clean the data up, we can totally discard irrelevant data, better known as
    noise. Data with missing parts or attributes can be replaced with sensible estimates.
    Also, where the raw data suffers from inconsistency, detecting and correcting
    them becomes necessary.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清理数据，我们可以完全丢弃无关的数据，这通常被称为噪声。具有缺失部分或属性的数据可以用合理的估计值替换。此外，如果原始数据存在不一致性，检测和纠正它们变得必要。
- en: Let us explore how we can use NumPy and pandas for data preprocessing techniques.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索如何使用NumPy和pandas进行数据预处理技术。
- en: Missing data
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失数据
- en: Data collection is tedious and, as such, once data is collected, it should not
    be easily discarded. Just because a dataset has missing fields or attributes does
    not mean it is not useful. Several methods can be used to fill up the nonexistent
    parts. One of these methods is by either using a global constant, using the mean
    value in the dataset, or supplying the data manually. The choice is based on the
    context and sensitivity of what the data is going to be used for.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集是繁琐的，因此一旦收集了数据，就不应该轻易丢弃。仅仅因为数据集有缺失字段或属性，并不意味着它没有用。可以使用几种方法来填补缺失的部分。这些方法之一是使用全局常数、使用数据集的平均值，或者手动提供数据。选择取决于数据的上下文和使用敏感性。
- en: 'Take, for instance, the following data:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以以下数据为例：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As we can see, the data elements `data[1][0]` and `data[1][1]` have values being
    `np.NAN`, representing the fact that they have no value. If the `np.NAN` values
    are undesired in a given dataset, they can be set to some constant figure.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，数据元素`data[1][0]`和`data[1][1]`的值为`np.NAN`，表示它们没有值。如果给定数据集中的`np.NAN`值是不希望的，可以将它们设置为某个常数数字。
- en: 'Let''s set data elements with the value `np.NAN` to 0.1:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将值为`np.NAN`的数据元素设置为0.1：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The new state of the data becomes the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的新状态变为以下：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To apply the mean values instead, we do the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用平均值，我们执行以下操作：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The mean value for each column is calculated and inserted in those data areas
    with the `np.NAN` value:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每列的平均值，并将其插入具有`np.NAN`值的数据区域：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For the first column, column `0`, the mean value was obtained by `(4 + 94)/2`.
    The resulting `49.0` is then stored at `data[1][0]`. A similar operation is carried
    out for columns `1` and `2`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一列，列`0`，平均值通过`(4 + 94)/2`获得。得到的`49.0`随后存储在`data[1][0]`中。对于列`1`和`2`，执行类似的操作。
- en: Feature scaling
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征缩放
- en: 'The columns in a data frame are known as its features. The rows are known as
    records or observations. Now examine the following data matrix. This data will
    be referenced in subsections so please do take note:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框中的列被称为其特征。行被称为记录或观察。现在检查以下数据矩阵。这些数据将在子节中引用，请务必注意：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Feature 1, with data `58`, `10`, `20`, has its values lying between `10` and
    `58`. For feature 2, the data lies between `1` and `200`. Inconsistent results
    will be produced if we supply this data to any machine learning algorithm. Ideally,
    we will need to scale the data to a certain range in order to get consistent results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 特征1，其数据为`58`、`10`、`20`，其值位于`10`和`58`之间。对于特征2，数据位于`1`和`200`之间。如果我们向任何机器学习算法提供这些数据，将会产生不一致的结果。理想情况下，我们需要将数据缩放到一定的范围内，以获得一致的结果。
- en: Once again, a closer inspection reveals that each feature (or column) lies around
    different mean values. Therefore, what we would want to do is to align the features
    around similar means.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 再次仔细检查，可以发现每个特征（或列）都围绕不同的平均值。因此，我们想要做的是将特征调整到相似的均值附近。
- en: One benefit of feature scaling is that it boosts the learning parts of machine
    learning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 特征缩放的一个好处是它能提升机器学习的学习部分。
- en: The `scikit` module has a considerable number of scaling algorithms that we
    shall apply to our data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit`模块有相当多的缩放算法，我们将将其应用于我们的数据。'
- en: Min-max scalar
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小-最大标度
- en: 'The min-max scalar form of normalization uses the mean and standard deviation
    to box all the data into a range lying between a certain min and max value. For
    most purposes, the range is set between 0 and 1\. At other times, other ranges
    may be applied but the 0 to 1 range remains the default:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化的最小-最大标量形式使用均值和标准差将所有数据框定在某个最小值和最大值之间。在大多数情况下，范围被设置为0到1之间。在其他时候，可能会应用其他范围，但0到1的范围仍然是默认值：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'An instance of the `MinMaxScaler` class is created with the range `(0,1)` and
    passed to the variable `scaled_values`. The `fit` function is called to make the
    necessary calculations that will be used internally to change the dataset. The
    `transform` function effects the actual operation on the dataset, returning the
    value to `results`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用范围`(0,1)`创建`MinMaxScaler`类的实例，并将其传递给变量`scaled_values`。调用`fit`函数进行必要的计算，这些计算将用于内部更改数据集。`transform`函数对数据集进行实际操作，并将值返回到`results`：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see from the preceding output that all the data is normalized and lies
    between 0 and 1\. This kind of output can now be supplied to a machine learning
    algorithm.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中我们可以看到，所有数据都进行了归一化，并且位于0和1之间。这种输出现在可以被提供给机器学习算法。
- en: Standard scalar
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准标量
- en: 'The mean values for the respective features in our initial dataset or table
    are 29.3, 92, and 38\. To make all the data have a similar mean, that is, a zero
    mean and a unit variance across the data, we shall apply the standard scalar algorithm:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始数据集或表中相应特征的均值分别是29.3、92和38。为了使所有数据具有相似的均值，即数据的均值为零且方差为1，我们将应用标准标量算法：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`data` is passed to the `fit` method of the object returned from instantiating
    the `StandardScaler` class. The `transform` method acts on the data elements in
    the data and returns the output to the results:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 将`data`传递给从实例化`StandardScaler`类返回的对象的`fit`方法。`transform`方法作用于数据中的数据元素，并将输出返回到结果：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Examining the results, we observe that all our features are now evenly distributed.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 检查结果，我们发现所有特征现在分布得都很均匀。
- en: Binarizing data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据二值化
- en: 'To binarize a given feature set, we make use of a threshold. If any value within
    a given dataset is greater than the threshold, the value is replaced by 1\. If
    the value is less than the threshold 1, we will replace it:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对给定的特征集进行二值化，我们使用一个阈值。如果给定数据集中的任何值大于阈值，则该值将被替换为1。如果值小于阈值1，我们将将其替换：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'An instance of `Binarizer` is created with the argument 50.0\. 50.0 is the
    threshold that will be used in the binarizing algorithm:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用参数50.0创建`Binarizer`实例。50.0是二值化算法中将使用的阈值：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: All values in the data that are less than 50 will have 0 in their stead. The
    opposite also holds true.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中所有小于50的值将用0代替。相反的情况也成立。
- en: Machine learning
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Machine learning is a subfield of artificial intelligence. We know that we can
    never truly create machines that actually "think" but we can supply machines with
    enough data and models by which sound judgment can be reached. Machine learning
    focuses on creating autonomous systems that can continue the process of decision
    making, with little or no human intervention.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子领域。我们知道我们永远无法真正创造出能够“思考”的机器，但我们可以通过提供足够的数据和模型来让机器做出合理的判断。机器学习专注于创建自主系统，这些系统能够继续决策过程，几乎不需要或不需要人为干预。
- en: In order to teach the machine, we need data drawn from the real world. For instance,
    to shift through which e-mails constitute spam and which ones don't, we need to
    feed the machine with samples of each. After obtaining this data, we have to run
    the data through models (algorithms) that will use probability and statistics
    to unearth patterns and structure from the data. If this is properly done, the
    algorithm by itself will be able to analyze e-mails and properly categorize them.
    Sorting e-mails is just one example of what machines can do if they are "trained".
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了教会机器，我们需要从现实世界中抽取数据。例如，为了区分哪些电子邮件是垃圾邮件，哪些不是，我们需要向机器提供每种类型的样本。在获得这些数据后，我们必须将这些数据通过使用概率和统计来挖掘数据中的模式和结构的模型（算法）。如果这样做得当，算法本身将能够分析电子邮件并将它们正确分类。对电子邮件进行分类只是机器“训练”后可以做到的一件事的例子。
- en: Types of machine learning
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: 'There are three broad categories of machine learning, as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习大致可以分为三个主要类别，如下所示：
- en: '**Supervised learning**: Here, an algorithm is fed a set of inputs and their
    corresponding outputs. The algorithm then has to figure out what the output will
    be for an unfamiliar input. Examples of such algorithms include naive Bayes, linear
    regression, and decision tree algorithms.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：在这里，算法被喂入一组输入及其相应的输出。然后，算法必须确定对未知输入的输出将会是什么。此类算法的例子包括朴素贝叶斯、线性回归和决策树算法。'
- en: '**Unsupervised learning**: Without using the relationship that exists between
    a set of input and output variables, the unsupervised learning algorithm uses
    only the inputs to unearth groups, patterns, and clusters within the data. Examples
    of such algorithms include hierarchical clustering and k-means clustering.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：不使用一组输入和输出变量之间存在的关联，无监督学习算法仅使用输入来挖掘数据中的组、模式和聚类。此类算法的例子包括层次聚类和k-means聚类。'
- en: '**Reinforcement learning**: The computer in this kind of learning dynamically
    interacts with its environment in such a way as to improve its performance.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**：在这种学习中，计算机与环境动态交互，以改善其性能。'
- en: Hello classifier
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hello分类器
- en: To invoke the blessing of the programming gods in our quest to understand machine
    learning, we begin with an hello world example of a text classifier. This is meant
    to be a gentle introduction to machine learning.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在理解机器学习的道路上祈求编程神灵的祝福，我们从一个文本分类器的hello world示例开始。这旨在对机器学习进行温和的介绍。
- en: This example will predict whether a given text carries a negative or positive
    connotation. Before this can be done, we need to train our algorithm (model) with
    some data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例将预测给定文本是否带有负面或正面含义。在这样做之前，我们需要用一些数据来训练我们的算法（模型）。
- en: The naive Bayes model is suited for text classification purposes. Algorithms
    based on naive Bayes models are generally fast and produce accurate results. The
    whole model is based on the assumption that features are independent from each
    other. To accurately predict the occurrence of rainfall, three conditions need
    to be considered. These are wind speed, temperature, and the amount of humidity
    in the air. In reality, these factors do have an influence on each other to tell
    the likelihood of rainfall. But the abstraction in naive Bayes is to assume that
    these features are unrelated in any way and thus independently contribute to chances
    of rainfall. Naive Bayes is useful in predicting the class of an unknown dataset,
    as we will see soon.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯模型适用于文本分类目的。基于朴素贝叶斯模型的算法通常运行速度快，结果准确。整个模型基于这样一个假设：特征之间相互独立。为了准确预测降雨的发生，需要考虑三个条件。这些条件是风速、温度和空气中的湿度量。在现实中，这些因素确实相互影响，以判断降雨的可能性。但朴素贝叶斯中的抽象假设是这些特征在某种程度上是无关的，因此独立地贡献于降雨的可能性。朴素贝叶斯在预测未知数据集的类别方面很有用，我们很快就会看到。
- en: 'Now back to our hello classifier. After we have trained our mode, its prediction
    will fall into either the positive or negative category:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到我们的hello分类器。在我们训练了我们的模型之后，其预测结果将落入正类或负类：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: First, we will import the `NaiveBayesClassifier` class from the `textblob` package.
    This classifier is very easy to work with and is based on the Bayes theorem.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从`textblob`包中导入`NaiveBayesClassifier`类。这个分类器非常易于使用，并且基于贝叶斯定理。
- en: The `train` variable consists of tuples that each holds the actual training
    data. Each tuple contains the sentence and the group it is associated with.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`变量由元组组成，每个元组都包含实际的训练数据。每个元组包含一个句子和与之相关的组。'
- en: 'Now, to train our model, we will instantiate a `NaiveBayesClassifier` object
    by passing the train to it:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了训练我们的模型，我们将通过传递train给它来实例化一个`NaiveBayesClassifier`对象：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The updated naive Bayesian model `cl` will predict the category that an unknown
    sentence belongs to. Up to this point, our model knows of only two categories
    that a phrase can belong to, `neg` and `pos`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的朴素贝叶斯模型`cl`将预测未知句子所属的类别。到目前为止，我们的模型只知道短语可以属于两个类别，`neg`和`pos`。
- en: 'The following code runs the following tests using our model:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用我们的模型运行以下测试：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output of our test is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试输出如下：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We can see that the algorithm has had some degree of success in classifying
    the input phrases into their categories well.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，该算法在将输入短语分类到其类别方面已经取得了一定的成功。
- en: This contrived example is overly simplistic but it does show promise that if
    given the right amounts of data and a suitable algorithm or model, it is possible
    for a machine to carry out tasks without any human help.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个人为的例子过于简单，但它确实显示出，如果提供正确数量的数据和合适的算法或模型，机器可以在没有任何人类帮助的情况下执行任务。
- en: The specialized class `NaiveBayesClassifier` also did some heavy lifting for
    us in the background so we could not appreciate the innards by which the algorithm
    arrived at the various predictions. Our next example will use the `scikit` module
    to predict the category that a phrase may belong to.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 专门的类`NaiveBayesClassifier`也在后台为我们做了很多工作，所以我们无法欣赏算法到达各种预测的内部机制。我们的下一个示例将使用`scikit`模块来预测一个短语可能属于的类别。
- en: A supervised learning example
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个监督学习示例
- en: Assume that we have a set of posts to categorize. As with supervised learning,
    we need to first train the model in order for it to accurately predict the category
    of an unknown post.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组要分类的帖子。与监督学习一样，我们需要首先训练模型，以便它能够准确预测未知帖子的类别。
- en: Gathering data
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'The `scikit` module comes with a number of sample data we will use for training
    our model. In this case, we will use the newsgroups posts. To load the posts,
    we will use the following lines of code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit`模块附带了一些样本数据，我们将使用这些数据来训练我们的模型。在这种情况下，我们将使用新闻组帖子。为了加载帖子，我们将使用以下代码行：'
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After we have trained our model, the results of a prediction must belong to
    one of the following categories:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们训练好模型后，预测结果必须属于以下类别之一：
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The number of records we are going to use as training data is obtained by the
    following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的训练数据记录数如下：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Machine learning algorithms do not mix well with textual attributes so the
    categories that each post belongs to are presented as numbers:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法与文本属性混合得不好，因此每个帖子所属的类别以数字形式呈现：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The categories have integer values that we can map back to the categories themselves
    with `print(training_data.target_names[0])`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 类别具有整数值，我们可以使用`print(training_data.target_names[0])`将其映射回类别本身。
- en: Here, 0 is a numerical random index picked from `set(training_data.target)`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，0是从`set(training_data.target)`中随机选择的数值索引。
- en: Now that the training data has been obtained, we must feed the data to a machine
    learning algorithm. The bag of words model will break down the training data in
    order to make it ready for the learning algorithm or model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练数据已经获得，我们必须将数据输入到机器学习算法中。词袋模型将分解训练数据，以便为学习算法或模型做好准备。
- en: Bag of words
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词袋
- en: The bag of words is a model that is used for representing text data in such
    a way that it does not take into consideration the order of words but rather uses
    word counts to segment words into regions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 词袋是一个模型，用于以这种方式表示文本数据，它不考虑单词的顺序，而是使用单词计数将单词分割成区域。
- en: 'Take the following sentences:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下句子：
- en: '[PRE21]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The bag of words enables us to decompose text into numerical feature vectors
    represented by a matrix.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 词袋模型使我们能够将文本分解成由矩阵表示的数值特征向量。
- en: 'To reduce our two sentences into the bag of words model, we need to obtain
    a unique list of all the words:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的两个句子简化为词袋模型，我们需要获得所有单词的唯一列表：
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This set will become our columns in the matrix. The rows in the matrix will
    represent the documents that are being used in training. The intersection of a
    row and column will store the number of times that word occurs in the document.
    Using our two sentences as examples, we obtain the following matrix:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集合将成为矩阵的列。矩阵的行将代表用于训练的文档。行和列的交集将存储单词在文档中出现的次数。以我们的两个句子为例，我们得到以下矩阵：
- en: '|  | **As** | **Fit** | **A** | **Fiddle** | **You** | **Like** | **it** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | **As** | **Fit** | **A** | **Fiddle** | **You** | **Like** | **it** |'
- en: '| **Sentence 1** | 2 | 1 | 1 | 1 | 0 | 0 | 0 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| **句子1** | 2 | 1 | 1 | 1 | 0 | 0 | 0 |'
- en: '| **Sentence 2** | 1 | 0 | 0 | 0 | 1 | 1 | 1 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| **句子2** | 1 | 0 | 0 | 0 | 1 | 1 | 1 |'
- en: The preceding data alone will not enable us to predict accurately the category
    that new documents or articles will belong to. The table has some inherent flaws.
    There may be situations where longer documents or words that occur in many of
    the posts reduce the precision of the algorithm. Stop words can be removed to
    make sure only relevant data is analyzed. Stop words include is, are, was, and
    so on. Since the bag of words model does not factor grammar into its analysis,
    the stop words can safely be dropped. It is also possible to add to the list of
    stop words that one feels should be exempted from final analysis.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭前面的数据，我们无法准确预测新文档或文章将属于哪个类别。表格本身存在一些固有的缺陷。可能存在这样的情况，较长的文档或出现在许多帖子中的单词会降低算法的精确度。可以通过移除停用词来确保只分析相关数据。停用词包括is、are、was等。由于词袋模型在分析中不考虑语法，因此可以安全地删除停用词。还可能需要将一些认为应该从最终分析中豁免的词添加到停用词列表中。
- en: 'To generate the values that go into the columns of our matrix, we have to tokenize
    our training data:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成进入矩阵列的值，我们必须对训练数据进行分词：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `training_matrix` has a dimension of (2257, 35788). This means that 2257
    corresponds to the dataset while 35788 corresponds to the number of columns that
    make up the unique set of words in all posts.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`training_matrix`的维度为（2257，35788）。这意味着2257对应于数据集，而35788对应于构成所有帖子中唯一单词集合的列数。'
- en: We instantiate the `CountVectorizer` class and pass the `training_data.data`
    to the `fit_transform` method of the `count_vect` object. The result is stored
    in `training_matrix`. The `training_matrix` holds all the unique words and their
    respective frequencies.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化了`CountVectorizer`类，并将`training_data.data`传递给`count_vect`对象的`fit_transform`方法。结果存储在`training_matrix`中。`training_matrix`包含所有唯一的单词及其相应的频率。
- en: 'To mitigate the problem of basing prediction on frequency count alone, we will
    import the `TfidfTransformer` that helps to smooth out the inaccuracies in our
    data:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻仅基于频率计数进行预测的问题，我们将导入`TfidfTransformer`，它有助于平滑我们数据中的不准确度：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`tfidf_data[1:4].todense()` only shows a truncated list of a three rows by
    35,788 columns matrix. The values seen are the term frequency--inverse document
    frequency that reduce the inaccuracy resulting from using a frequency count:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfidf_data[1:4].todense()`仅显示一个3行35,788列矩阵的截断列表。所看到的值是词频-逆文档频率，它减少了使用频率计数带来的不准确度：'
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`MultinomialNB` is a variant of the naive Bayes model. We pass the rationalized
    data matrix, `tfidf_data` and categories, `training_data.target`, to its `fit`
    method.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`MultinomialNB`是朴素贝叶斯模型的一个变体。我们将合理化的数据矩阵`tfidf_data`和类别`training_data.target`传递给其`fit`方法。'
- en: Prediction
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: 'To test whether our model has learned enough to predict the category that an
    unknown post is likely to belong to, we have the following sample data:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的模型是否已经学习到足够多的知识来预测一个未知帖子可能属于的类别，我们有以下样本数据：
- en: '[PRE26]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The list `test_data` is passed to the `count_vect.transform` function to obtain
    the vectorized form of the test data. To obtain the term frequency--inverse document
    frequency representation of the test dataset, we call the `transform` method of
    the `matrix_transformer` object.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 将`test_data`列表传递给`count_vect.transform`函数以获得测试数据的向量形式。为了获得测试数据集的词频-逆文档频率表示，我们调用`matrix_transformer`对象的`transform`方法。
- en: 'To predict which category the docs may belong to, we do the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测文档可能属于哪个类别，我们执行以下操作：
- en: '[PRE27]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The loop is used to iterate over the prediction, showing the categories they
    are predicted to belong to:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 循环用于遍历预测，显示它们预测属于的类别：
- en: '[PRE28]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'When the loop has run to completion, the phrase, together with the category
    that it may belong to, is displayed. A sample output is as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当循环运行完成后，将显示短语及其可能属于的类别。一个示例输出如下：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: All that we have seen up to this point is a prime example of supervised learning.
    We started by loading posts whose categories are already known. These posts were
    then fed into the machine learning algorithm most suited for text processing based
    on the naive Bayes theorem. A set of test post fragments were supplied to the
    model and the category was predicted.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止我们所看到的一切都是监督学习的典范。我们首先加载了已知类别的帖子。然后，根据朴素贝叶斯定理，将这些帖子输入到最适合文本处理的机器学习算法中。向模型提供了一组测试帖子片段，并预测了类别。
- en: To explore an example of an unsupervised learning algorithm, we shall study
    the k-means algorithm for clustering some data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索无监督学习算法的例子，我们将研究k-means算法对某些数据进行聚类。
- en: An unsupervised learning example
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个无监督学习示例
- en: A category of learning algorithms is able to discover inherent groups that may
    exist in a set of data. An example of these algorithms is the k-means algorithm.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一种学习算法类别能够发现数据集中可能存在的固有分组。这些算法的例子是k-means算法。
- en: K-means algorithm
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-means算法
- en: The k-means algorithm uses the mean points in a given dataset to cluster and
    discover groups within the dataset. K is the number of clusters that we want and
    are hoping to discover. After the k-means algorithm has generated the groupings,
    we can pass it additional but unknown data for it to predict to which group it
    will belong.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法使用给定数据集中的均值点来聚类并发现数据集中的分组。K是我们想要并希望发现的簇的数量。在k-means算法生成分组后，我们可以传递额外的未知数据给它，以预测它将属于哪个组。
- en: Note that in this kind of algorithm, only the raw uncategorized data is fed
    to the algorithm. It is up to the algorithm to find out if the data has inherent
    groups within it.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种算法中，只有未经分类的原始数据被输入到算法中。算法需要自行判断数据中是否存在固有的分组。
- en: To understand how this algorithm works, we will examine 100 data points consisting
    of x and y values. We will feed these values to the learning algorithm and expect
    that the algorithm will cluster the data into two sets. We will color the two
    sets so that the clusters are visible.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这个算法是如何工作的，我们将检查由x和y值组成的100个数据点。我们将将这些值输入到学习算法中，并期望算法将数据聚类成两组。我们将对这两组进行着色，以便簇是可见的。
- en: 'Let''s create a sample data of 100 records of *x* and *y* pairs:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含100个*x*和*y*对的样本数据：
- en: '[PRE30]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: First, we create 100 records with `-2 * np.random.rand(100, 2)`. In each of
    the records, we will use the data in it to represent x and y values that will
    eventually be plotted.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建100条记录，使用`-2 * np.random.rand(100, 2)`。在每条记录中，我们将使用其中的数据来表示最终将被绘制的x和y值。
- en: The last 50 numbers in `original_set` will be replaced by `1 + 2 * np.random.rand(50,
    2)`. In effect, what we have done is to create two subsets of data, where one
    set has numbers in the negative while the other set has numbers in the positive.
    It is now the responsibility of the algorithm to discover these segments appropriately.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`original_set`中的最后50个数字将被替换为`1 + 2 * np.random.rand(50, 2)`。实际上，我们所做的是创建了两个数据子集，其中一个子集包含负数，而另一个子集包含正数。现在，算法有责任适当地发现这些段。'
- en: 'We instantiate the `KMeans` algorithm class and pass it `n_clusters=2`. That
    makes the algorithm cluster all its data under only two groups. It is through
    a series of trial and error that this figure, `2`, is obtained. But for academic
    purposes, we already know this number. It is not at all obvious when working with
    unfamiliar datasets from the real world:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化了`KMeans`算法类，并传递了`n_clusters=2`。这使得算法将所有数据仅聚类到两个组中。这个数字`2`是通过一系列的试错得到的。但在学术目的上，我们已知这个数字。当处理来自现实世界的不熟悉数据集时，这一点并不明显：
- en: '[PRE31]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The dataset is passed to the `fit` function of `kmean`, `kmean.fit(original_set)`.
    The clusters generated by the algorithm will revolve around a certain mean point.
    The points that define these two mean points are obtained by `kmean.cluster_centers_`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集被传递到`kmean`的`fit`函数中，即`kmean.fit(original_set)`。算法生成的簇将围绕某个均值点旋转。定义这两个均值点的点是`kmean.cluster_centers_`。
- en: 'The mean points when printed appear as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出的均值点如下所示：
- en: '[PRE32]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Each data point in `original_set` will belong to a cluster after our k-means
    algorithm has finished its training. The k-mean algorithm represents the two clusters
    it discovers as 1s and 0s. If we had asked the algorithm to cluster the data into
    four, the internal representation of these clusters would have been 0, 1, 2, and
    3\. To print out the various clusters that each dataset belongs to, we do the
    following:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的k-means算法完成训练后，`original_set`中的每个数据点都将属于一个簇。k-means算法将其发现的两个簇表示为1和0。如果我们要求算法将数据聚类成四个簇，这些簇的内部表示将是0、1、2和3。为了打印出每个数据集所属的各种簇，我们执行以下操作：
- en: '[PRE33]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This gives the following output:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '[PRE34]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'There are 100 1s and 0s. Each shows the cluster that each data point falls
    under. By using `matplotlib.pyplot`, we can chart the points of each group and
    color it appropriately to show the clusters:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有100个1和0。每个数字表示每个数据点所属的簇。通过使用`matplotlib.pyplot`，我们可以绘制每个组的点并适当地着色以显示簇：
- en: '[PRE35]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`index = kmean.labels_ == i` is a nifty way by which we select all points that
    correspond to the group `i`. When `i=0`, all points belonging to the group 0 are
    returned to index. It''s the same for `index =1, 2` ... , and so on.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`index = kmean.labels_ == i` 是一种巧妙的方法，通过它我们可以选择所有对应于群体`i`的点。当`i=0`时，所有属于群体0的点都会返回到索引中。对于`index
    =1, 2` ... 等等，情况相同。'
- en: '`plt.plot(original_set[index,0], original_set[index,1], ''o'')` then plots
    these data points using o as the character for drawing each point.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`plt.plot(original_set[index,0], original_set[index,1], ''o'')` 然后使用“o”字符绘制这些数据点。'
- en: 'Next, we will plot the centroids or mean values around which the clusters have
    formed:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将绘制形成簇的质心或均值：
- en: '[PRE36]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Lastly, we show the whole graph with the two means illustrated by a star:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们用星号标示两个均值，展示整个图表：
- en: '[PRE37]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![](img/image_12_001.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_001.png)'
- en: The algorithm discovers two distinct clusters in our sample data. The two mean
    points of the two clusters are denoted with the red star symbol.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 算法在我们的样本数据中发现了两个不同的簇。两个簇的均值用红色星号符号表示。
- en: Prediction
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: With the two clusters that we have obtained, we can predict the group that a
    new set of data might belong to.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们获得的两个簇，我们可以预测一组新数据可能属于哪个群体。
- en: 'Let''s predict which group the points `[[-1.4, -1.4]]` and `[[2.5, 2.5]]` will
    belong to:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们预测点`[[-1.4, -1.4]]`和`[[2.5, 2.5]]`将属于哪个群体：
- en: '[PRE38]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is seen as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE39]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: At the barest minimum, we can expect the two test datasets to belong to different
    clusters. Our expectation is proved right when the `print` statement prints 1
    and 0, thus confirming that our test data does indeed fall under two different
    clusters.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，我们可以期待两个测试数据集属于不同的簇。当`print`语句打印出1和0时，我们的预期得到了证实，从而确认我们的测试数据确实属于两个不同的簇。
- en: Data visualization
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据可视化
- en: Numerical analysis does not sometimes lend itself to easy understanding. Indeed,
    a single image is worth 1,000 words and in this section, an image would be worth
    1,000 tables comprised of numbers only. Images present a quick way to analyze
    data. Differences in size and lengths are quick markers in an image upon which
    conclusions can be drawn. In this section, we will take a tour of the different
    ways to represent data. Besides the graphs listed here, there is more that can
    be achieved when chatting data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 数值分析并不总是容易理解。确实，一张图片胜过千言万语，在本节中，一张只包含数字的表格可能就相当于一千张表格。图片提供了一种快速分析数据的方法。大小和长度的差异是图像中的快速标记，可以根据这些标记得出结论。在本节中，我们将游览不同的数据表示方法。除了这里列出的图表之外，在数据交流中还可以实现更多。
- en: Bar chart
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条形图
- en: 'To chart the values 25, 5, 150, and 100 into a bar graph, we will store the
    values in an array and pass it to the `bar` function. The bars in the graph represent
    the magnitude along the *y*-axis:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要将值25、5、150和100绘制成条形图，我们将值存储在数组中，并将其传递给`bar`函数。图中的条形代表*y*轴上的幅度：
- en: '[PRE40]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`x_values` stores an array of values generated by `range(len(data))`. Also,
    `x_values` will determine the points on the *x*-axis where the bars will be drawn.
    The first bar will be drawn on the *x*-axis where x is 0\. The second bar with
    data 5 will be drawn on the *x*-axis where x is 1:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_values`存储由`range(len(data))`生成的值数组。`x_values`还将确定条形将在*x*轴上的哪些点绘制。第一个条形将在*x*为0的*x*轴上绘制。数据为5的第二个条形将在*x*为1的*x*轴上绘制：'
- en: '![](img/image_12_002.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_002.png)'
- en: 'The width of each bar can be changed by modifying the following line:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 每个条形的宽度可以通过修改以下行来改变：
- en: '[PRE41]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This should produce the following graph:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生以下图表：
- en: '![](img/image_12_003.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_003.png)'
- en: However, this is not visually appealing because there is no space anymore between
    the bars, which makes it look clumsy. Each bar now occupies one unit on the *x*-axis.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这看起来并不美观，因为条形之间没有空间了，这使得它看起来很笨拙。每个条形现在占据了*x*轴上的一个单位。
- en: Multiple bar charts
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多条形图
- en: 'In trying to visualize data, stacking a number of bars enables one to further
    understand how one piece of data or variable varies with another:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试可视化数据时，堆叠多个条形可以让人进一步理解一个数据点或变量如何与另一个变量变化：
- en: '[PRE42]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The y values for the first batch of data are `[8., 57., 22., 10.]`. The second
    batch is `[16., 7., 32., 40.]`. When the bars are plotted, 8 and 16 will occupy
    the same x position, side by side.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 第一批数据的y值为`[8., 57., 22., 10.]`。第二批是`[16., 7., 32., 40.]`。当条形绘制时，8和16将占据相同的x位置，并排在一起。
- en: '`x_values = np.arange(4)` generates the array with values `[0, 1, 2, 3]`. The
    first set of bars are drawn first at position `x_values + 0.30`. Thus, the first
    x values will be plotted at `0.00, 1.00, 2.00 and 3.00`.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_values = np.arange(4)` 生成包含值 `[0, 1, 2, 3]` 的数组。第一组条形首先在位置 `x_values + 0.30`
    绘制。因此，第一个 x 值将在 `0.00, 1.00, 2.00 和 3.00` 处绘制。'
- en: 'The second batch of `x_values` will be plotted at `0.30, 1.30, 2.30 and 3.30`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 第二批 `x_values` 将在 `0.30, 1.30, 2.30 和 3.30` 处绘制：
- en: '![](img/image_12_004.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_004.png)'
- en: Box plot
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 箱线图
- en: The box plot is used to visualize the median value and low and high ranges of
    a distribution. It is also referred to as a box and whisker plot.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图用于可视化分布的中位数值以及低和高范围。它也被称为箱线和触须图。
- en: Let's chart a simple box plot.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制一个简单的箱线图。
- en: 'We begin by generating 50 numbers from a normal distribution. These are then
    passed to `plt.boxplot(data)` to be charted:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从正态分布中生成 50 个数字。然后，将这些数字传递给 `plt.boxplot(data)` 以进行图表绘制：
- en: '[PRE43]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following figure is what is produced:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是生成的结果：
- en: '![](img/image_12_005.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_005.png)'
- en: 'A few comments on the preceding figure: the features of the box plot include
    a box spanning the interquartile range, which measures the dispersion; the outer
    fringes of the data are denoted by the whiskers attached to the central box; the
    red line represents the median.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对前面的图进行一些评论：箱线图的特征包括一个跨越四分位距的箱体，它衡量分散程度；数据的外围边缘由连接到中央箱体的触须表示；红色线代表中位数。
- en: The box plot is useful to easily identify the outliers in a dataset as well
    as determining in which direction a dataset may be skewed.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图有助于轻松识别数据集中的异常值以及确定数据集可能偏斜的方向。
- en: Pie chart
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 饼图
- en: 'The pie chart interprets and visually presents data as if to fit into a circle.
    The individual data points are expressed as sectors of a circle that add up to
    360 degrees. This chart is good for displaying categorical data and summaries
    too:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 饼图将数据解释并视觉上呈现为似乎适合圆圈。各个数据点表示为圆的扇区，总和为 360 度。此图表适用于显示分类数据和摘要：
- en: '[PRE44]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The sectors in the graph are labeled with the strings in the labels array:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中的各个部分用标签数组中的字符串标记：
- en: '![](img/image_12_006.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_12_006.png)'
- en: Bubble chart
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 气泡图
- en: 'Another variant of the scatter plot is the bubble chart. In a scatter plot,
    we only plot the x, y points of the data. Bubble charts add another dimension
    by illustrating the size of the points. This third dimension may represent sizes
    of markets or even profits:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图的另一种变体是气泡图。在散点图中，我们只绘制数据的 x，y 点。气泡图通过说明点的尺寸增加了另一个维度。这个第三维度可能代表市场的大小甚至利润：
- en: '[PRE45]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: With the variable `n`, we specify the number of randomly generated x and y values.
    This same number is used to determine the random colors for our x and y coordinates.
    Random bubble sizes are determined by `area = np.pi * (60 * np.random.rand(n))**2`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 使用变量 `n`，我们指定随机生成的 x 和 y 值的数量。这个相同的数字用于确定 x 和 y 坐标的随机颜色。随机气泡大小由 `area = np.pi
    * (60 * np.random.rand(n))**2` 确定。
- en: 'The following figure shows this bubble chart:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了此气泡图：
- en: '![](img/B05630_12_07.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05630_12_07.png)'
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have explored how data and algorithms come together to aid
    machine learning. Making sense of huge amounts of data is made possible by first
    pruning our data through normalization processes. Feeding this data to specialized
    algorithms, we are able to predict the categories and sets that our data will
    fall into.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了数据和算法如何结合以帮助机器学习。通过首先通过归一化过程修剪我们的数据，我们才能理解大量数据。将此数据输入专门的算法，我们能够预测数据将落入的类别和集合。
- en: Lastly, charting and plotting the condensed data helps to better understand
    and make insightful discoveries.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，绘制和图表化浓缩数据有助于更好地理解和做出有洞察力的发现。
