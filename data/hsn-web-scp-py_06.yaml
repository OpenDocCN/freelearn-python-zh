- en: Scraping Using pyquery – a Python Library
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pyquery进行抓取-一个Python库
- en: Starting from this chapter, we will be exploring scraping-related tools and
    techniques, as we will also be deploying some scraping code. Features related
    to web exploration, Python libraries, element identification, and traversing are
    the major concepts we have learned about so far.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章开始，我们将探索与抓取相关的工具和技术，同时还将部署一些抓取代码。与Web探索、Python库、元素识别和遍历相关的功能是我们迄今为止学到的主要概念。
- en: Web scraping is often a challenging and long process that requires an understanding
    of how the website is performing. A basic ability to understand and identify the
    backends or tools that are used to build a website will assist in any scraping
    task. This is also related to a process known as reverse engineering. For more
    information on such tools, please refer to [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XPath, and CSS Selectors*, and the *using web browser developer tools
    for accessing web content* section. In addition to this, identifying the tools
    for traversing and manipulating elements such as HTML tags is also required, and
    `pyquery` is one of them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Web抓取通常是一个具有挑战性和漫长过程，需要了解网站的运行方式。基本的理解和识别用于构建网站的后端或工具将有助于任何抓取任务。这也与一种称为逆向工程的过程有关。有关此类工具的更多信息，请参阅[第3章](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml)，*使用LXML、XPath和CSS选择器*，以及*使用Web浏览器开发工具访问Web内容*部分。除此之外，还需要识别用于遍历和操作HTML标记等元素的工具，`pyquery`就是其中之一。
- en: In the previous chapters, we explored XPath, CSS Selectors, and LXML. In this
    chapter, we will look into using `pyquery`, which has a jQuery-like ability that
    seems to be more efficient and, hence, easier to deal with when it comes to web
    scraping procedures.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们探索了XPath、CSS选择器和LXML。在本章中，我们将研究使用`pyquery`，它具有类似jQuery的能力，似乎更高效，因此在进行Web抓取过程时更容易处理。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习以下主题：
- en: Introduction to `pyquery`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pyquery简介
- en: Exploring `pyquery` (major methods and attributes)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索`pyquery`（主要方法和属性）
- en: Using `pyquery` for web scraping
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`pyquery`进行Web抓取
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'A web browser (Google Chrome or Mozilla Firefox) is required for this chapter.
    We will be using the following Python libraries:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要一个Web浏览器（Google Chrome或Mozilla Firefox）。我们将使用以下Python库：
- en: '`pyquery`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pyquery`'
- en: '`urllib`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urllib`'
- en: '`requests`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`请求`'
- en: If these libraries don't exist in your current Python setup, refer to [Chapter
    2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml), *Python and the Web – Using urllib
    and Requests*, and the *Setting things up* section, for installation and setup
    help.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您当前的Python设置中不存在这些库，请参阅[第2章](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml)，*Python和Web-使用urllib和Requests*，以及*设置*部分，获取安装和设置帮助。
- en: 'The code files for this chapter are available in this book''s GitHub repository:
    [https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter04](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter04).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter04](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python/tree/master/Chapter04)。
- en: Introduction to pyquery
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pyquery简介
- en: '`pyquery` is a jQuery-like library for Python that uses the `lxml` library.
    This provides an easy and interactive environment for dealing with markup elements
    in terms of manipulation and traversal purposes.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`是Python的类似jQuery的库，使用`lxml`库。这为处理标记元素提供了一个简单和交互式的环境，用于操作和遍历目的。'
- en: '`pyquery` expressions are also similar to `jquery`, and users with `jquery`
    knowledge will find it more convenient to use in Python.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`表达式也类似于`jquery`，具有`jquery`知识的用户将发现在Python中更方便使用。'
- en: The `pyquery` Python library, as its name suggests, enhances `query` writing
    procedures related to elements found in XML and HTML. `pyquery` shortens element
    processing and provides a more insightful scripting approach that is fit for scraping
    and DOM-based traversal and manipulation tasks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery` Python库，正如其名称所示，增强了与在XML和HTML中找到的元素相关的`query`编写过程。`pyquery`缩短了元素处理，并提供了更具洞察力的脚本编写方法，适用于抓取和基于DOM的遍历和操作任务。'
- en: '`pyquery` expressions use CSS selectors to perform queries, alongside additional
    features that it implements. For example, the following expression is used by
    `pyquery`:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`表达式使用CSS选择器执行查询，以及它实现的其他功能。例如，`pyquery`使用以下表达式：'
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following expression is used by `cssselect`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`cssselect` 使用以下表达式：'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: jQuery (write less, do more) is one of the most admired JavaScript libraries
    and is small, quick, and has lots of features that support DOM/HTML/CSS, and more.
    Web document-based traversing, manipulation, event handling, animation, AJAX,
    and more are some of its main features. Please visit [https://jquery.com/](https://jquery.com/)
    for more information.For more information on `pyquery` and its documentation,
    please visit [https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)
    or [https://github.com/gawel/pyquery/](https://github.com/gawel/pyquery/).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: jQuery（写得更少，做得更多）是最受欢迎的JavaScript库之一，体积小，速度快，具有许多支持DOM/HTML/CSS等功能。网页文档遍历、操作、事件处理、动画、AJAX等是其主要特点。请访问[https://jquery.com/](https://jquery.com/)获取更多信息。有关`pyquery`及其文档的更多信息，请访问[https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)或[https://github.com/gawel/pyquery/](https://github.com/gawel/pyquery/)。
- en: Exploring pyquery
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索pyquery
- en: 'Before we move on and explore `pyquery` and its features, let''s start by installing
    it by using `pip`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续探索`pyquery`及其特性之前，让我们先通过使用`pip`来安装它：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For more information on using `pip` and library installation, please refer to
    the *Setting things up* section in [Chapter 2](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml),
    *Python and the Web – Using urllib and Requests*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有关使用`pip`和库安装的更多信息，请参阅[第2章](b9919ebf-2d5c-4721-aa76-5c1378262473.xhtml)中的*设置*部分，*Python和Web-使用urllib和Requests*。
- en: 'The following libraries are installed on a successful installation of `pyquery`
    using `pip`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装`pyquery`后，使用`pip`安装了以下库：
- en: '`cssselect-1.0.3`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cssselect-1.0.3`'
- en: '`lxml-4.3.1`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lxml-4.3.1`'
- en: '`pyquery-1.4.0`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pyquery-1.4.0`'
- en: '`>>>` in the code represents the use of the Python IDE; it accepts the code
    or instructions and displays the output on the next line.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`>>>`在代码中表示使用Python IDE；它接受代码或指令，并在下一行显示输出。'
- en: 'Once the installation is completed and successful, we can use `pyquery`, as
    shown in the following code, to confirm the setup. We can explore the properties
    it contains by using the `dir()` function:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成并成功后，我们可以使用`pyquery`，如下面的代码所示，来确认设置。我们可以使用`dir()`函数来探索它包含的属性：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we will explore certain features from `pyquery` that are relevant to scraping
    concepts. For this purpose, we will be using a page source available from [https://www.python.org](https://www.python.org)
    that has been saved locally as `test.html` to provide real-world usability:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将探索与抓取概念相关的`pyquery`的某些功能。为此，我们将使用从[https://www.python.org](https://www.python.org)获取的页面源代码，已将其保存为`test.html`以提供真实世界的可用性：
- en: '![](assets/3ab8aac9-7322-44af-8a01-d3fd6723b621.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3ab8aac9-7322-44af-8a01-d3fd6723b621.png)'
- en: Page source obtained from https://www.python.orgIn Google Chrome, you can right-click
    on the web page and choose the View page source menu option or press *Ctrl* +
    *U* to obtain the page source.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从https://www.python.org获取的页面源代码在Google Chrome中，您可以右键单击网页，选择“查看页面源代码”菜单选项，或按*Ctrl*
    + *U*获取页面源代码。
- en: Obtaining the page source or HTML code only is not enough, though, as we need
    to load this content into the library to gain more tools to explore with. We'll
    be doing this in the upcoming section.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但仅仅获取页面源代码或HTML代码是不够的，因为我们需要将这些内容加载到库中，以获得更多的探索工具。我们将在接下来的部分中进行这样的操作。
- en: While testing or following the code, you might find or require changes to be
    done on the `pyquery` code expressions in order to obtain the real output. Page
    sources that are obtained now might be updated or changed. You are suggested to
    obtain the latest page source from the source URL ([https://www.python.org](https://www.python.org)).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试或跟踪代码时，您可能会发现或需要对`pyquery`代码表达式进行更改，以获得真实的输出。现在获取的页面源代码可能已更新或更改。建议您从源URL（[https://www.python.org](https://www.python.org)）获取最新的页面源代码。
- en: Loading documents
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载文档
- en: 'In most cases, a document''s content is obtained by using `requests` or `urllib`
    and is provided to `pyquery` as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，通过使用`requests`或`urllib`获取文档的内容，并将其提供给`pyquery`如下：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`pyquery` can also load URLs using the Python library, `urllib` (default),
    or requests. It also supports requests-based parameters:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`还可以使用Python库`urllib`（默认）或requests加载URL。它还支持基于requests的参数：'
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `pq` object we obtained from the preceding code is being parsed using the
    XML parser (default) that''s available from `lxml`, which can also be updated
    with the extra `parser` argument being passed to it:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从前面的代码中获得的`pq`对象正在使用XML解析器（默认）进行解析，该解析器可通过传递给它的额外`parser`参数进行更新：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Normally, HTML code from a page source or other sources, such as files, is
    provided as a string to `pyquery` for further processing, as shown in the following
    code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，HTML代码来自页面源代码或其他来源，比如文件，作为字符串提供给`pyquery`进行进一步处理，如下面的代码所示：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With the `PyQuery` object or `pq` that was received from the document or URL
    that was loaded, we can proceed and explore the features that are available from
    `pyquery`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用从已加载的文档或URL接收到的`PyQuery`对象或`pq`，我们可以继续并探索`pyquery`提供的功能。
- en: Element traversing, attributes, and pseudo-classes
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元素遍历、属性和伪类
- en: '`pyquery` has a large set of attributes and methods that can be deployed to
    obtain the desired content. In the following examples, we''ll identify the implementation
    from the code that''s found in this section:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`具有大量的属性和方法，可用于获取所需的内容。在以下示例中，我们将识别在本节中找到的代码的实现：'
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following are a few of their functions, along with a description, that
    can be seen in the preceding code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是它们的一些功能及其描述，可以在前面的代码中看到：
- en: '`find()`: Searches the provided element or evaluates the query expression build
    using CSS selectors'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`find()`: 搜索提供的元素或评估使用CSS选择器构建的查询表达式'
- en: '`text()`: Returns the element content as a string'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text()`: 返回元素内容作为字符串'
- en: '`attr()`: Identifies the attribute and returns its content'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attr()`: 识别属性并返回其内容'
- en: '`html()`: Returns the HTML content of the evaluated expression'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`html()`: 返回评估表达式的HTML内容'
- en: The `class` and `id` CSS attributes are represented with `.` and `#`, respectively,
    and are prefixed to the attribute's value. For example, `<a class="main" id="mainLink">`
    will be identified as `a.main` and `a#mainLink`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`class`和`id` CSS属性分别用`.`和`#`表示，并前缀于属性的值。例如，`<a class="main" id="mainLink">`将被识别为`a.main`和`a#mainLink`。'
- en: 'In the following code, we are listing all the identified `<ul>` elements with
    the `class` attribute and the `menu` value:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们列出了所有已识别的具有`class`属性和`menu`值的`<ul>`元素：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The expression was passed to a PyQuery object, which generated a list of evaluated
    elements. These elements are iterated for their exact values or their content.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式传递给PyQuery对象，生成了一个评估元素的列表。这些元素被迭代以获取其确切值或内容。
- en: 'PyQuery also contains pseudo classes or `:pseudo element`, and are used for
    indexing and obtaining predefined expression results. `:pseudo element` can also
    be appended to an existing selector query. The following code implements some
    of the pseudo elements that are common while traversing:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: PyQuery还包含伪类或`:pseudo element`，用于索引和获取预定义表达式的结果。`：pseudo element`也可以附加到现有的选择器查询中。以下代码实现了一些常见的伪元素遍历：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s go over the pseudo elements that were used in the preceding code:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下前面代码中使用的伪元素：
- en: '`:first`: Returns the first occurrence of an element from the content provided'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:first`：返回提供的内容中元素的第一个出现'
- en: '`:last`: Returns the last occurrence of an element from the content provided'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:last`: 返回提供的内容中元素的最后一次出现'
- en: 'Let''s look at a general implementation of a few more `:pseudo element` to
    list the HTML elements:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下几个更多的`:伪元素`的一般实现，以列出HTML元素：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following are the `:pseudo element` that we used in the preceding code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们在前面的代码中使用的`:伪元素`：
- en: '`:header`: Returns the header elements (*h1, h2,..., h5, h6*) found in the
    page.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:header`: 返回页面中找到的标题元素（*h1, h2,..., h5, h6*）。'
- en: '`:input`: Returns all the input elements. Large numbers of HTML `<form>`-based
    pseudo elements exist. Please refer to [https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)
    for more information.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:input`: 返回所有输入元素。存在大量基于HTML `<form>`的伪元素。请参考[https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)获取更多信息。'
- en: '`:empty`: Returns all the elements that don''t have any child element.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:empty`: 返回所有没有任何子元素的元素。'
- en: '`:odd`: Returns elements indexed as odd numbers. They can be used with other
    `:pseudo element` as `:empty:odd`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:odd`: 返回索引为奇数的元素。它们可以与其他`:伪元素`一起使用，如`:empty:odd`。'
- en: '`:even`: Similar to `:odd`, but returns evenly indexed elements.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:even`: 类似于`:odd`，但返回偶数索引的元素。'
- en: 'The following code demonstrates an expression for traversing, `:pseudo element`,
    and element attributes together:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码演示了遍历、`:伪元素`和元素属性的表达式：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following are a few more `:pseudo element`. We can use these to address
    the `index` of the elements:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些更多的`:伪元素`。我们可以使用这些来处理元素的`index`：
- en: '`:eq`: Selects the particular index number; evaluates to `equals to`.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:eq`: 选择特定的索引号；评估为`等于`。'
- en: '`:lt`: Evaluates to `less than` for the provided index number. For example, `page(''a:lt(2)'')`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:lt`: 对于提供的索引号，评估为`小于`。例如，`page(''a:lt(2)'')`。'
- en: '`:gt`: Evaluates to `greater than` for the provided index numbers. For example, `page(''a:gt(0)'')`.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:gt`: 对于提供的索引号，评估为`大于`。例如，`page(''a:gt(0)'')`。'
- en: 'Apart from the general features that are used to identify the index and find
    elements, `:pseudo element` can also be used to search the element with the provided
    text, as shown in the following code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用于识别索引和查找元素的一般特性之外，`:伪元素`也可以用于搜索包含提供的文本的元素，如下面的代码所示：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following list describe simple definitions of `:contains` and `eq()`, as
    used in the previous code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表描述了在前面的代码中使用的`:contains`和`eq()`的简单定义：
- en: '`:contains`: Matches all elements that contain the provided text.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:contains`: 匹配包含提供的文本的所有元素。'
- en: '`eq()`: Returns the element that was found for a particular index number. Evaluates
    as `equals to` and is similar to `:eq`.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eq()`: 返回找到的特定索引号的元素。评估为`等于`，类似于`:eq`。'
- en: '`pyquery` has a few functions that return a Boolean answer, which is quite
    effective in circumstances where you need to search for an element with attributes
    and also confirm the attribute''s value:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`有一些返回布尔答案的函数，在需要搜索具有属性并确认属性值的元素的情况下非常有效：'
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following are the functions that were used in the previous code, along
    with their definitions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在前面的代码中使用的函数，以及它们的定义：
- en: '`is_()`: Accepts a selector as an argument and returns `True` if the selector
    matches elements, otherwise, it returns `False`.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_()`: 接受选择器作为参数，如果选择器匹配元素则返回`True`，否则返回`False`。'
- en: '`has_class()`: Returns `True` if the selector matches the class that''s provided.
    It is useful for identifying elements with the `class` attribute.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`has_class()`: 如果选择器匹配提供的类，则返回`True`。它对于识别具有`class`属性的元素非常有用。'
- en: We have used a few important functions and tools with `pyquery` that enhance
    element identification and traversal-related properties. In the next section,
    we will learn about and demonstrate iteration.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了一些重要的函数和工具与`pyquery`一起，以增强元素识别和遍历相关属性。在下一节中，我们将学习和演示迭代。
- en: Iterating
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代
- en: In this section, we will be demonstrating the iterating (perform repeatedly)
    facility that's available with `pyquery`. It's effective and easy to process in
    many situations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示`pyquery`中可用的迭代（重复执行）功能。在许多情况下，这是一种有效且易于处理的方法。
- en: 'In the following code, we are searching for the `name` and `property` attributes
    that are found in the `<meta>` tags that contain the word `Python.org`. We are
    also using Python''s `List Comprehension` technique to demonstrate the one-line
    coding feature:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们正在搜索包含单词`Python.org`的`<meta>`标签中找到的`name`和`property`属性。我们还使用Python的`List
    Comprehension`技术来演示一行代码的特性：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As we can see in the preceding code, we are using the `items()` function in
    a loop with the element meta to iterate for the provided option. An expression
    resulting in iterable objects can be explored using `items()`. Results that return
    `None` are excluded from the list:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的代码中所看到的，我们正在使用`items()`函数在循环中与元素meta一起迭代提供的选项。可以使用`items()`来探索产生可迭代对象的表达式。返回`None`的结果将从列表中排除：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the preceding code, the `pyquery` object collects the names and links that
    are available from the social and web development section. These can be found
    under Use Python for... in the following screenshot. The object is iterated using
    the Python list comprehension technique:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`pyquery`对象收集了社交和网页开发部分提供的名称和链接。这些可以在下面的屏幕截图中的“Use Python for...”下找到。使用Python的列表推导技术对对象进行迭代：
- en: '![](assets/2fa561d2-c2e5-446b-9e2a-0fbc729fdb29.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2fa561d2-c2e5-446b-9e2a-0fbc729fdb29.png)'
- en: Upcoming events to be extracted using pyquery
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pyquery提取即将到来的活动
- en: 'In the following code, we will be exploring a few more details that were retrieved
    from the `upcomingevents` iteration:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将探索从`upcomingevents`迭代中检索到的一些更多细节：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`eventsList` contains extracted details from Upcoming Events, as shown in the
    preceding screenshot. The output from `eventsList` is provided here:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`eventsList`包含了从即将到来的活动中提取的详细信息，如前面的屏幕截图所示。`eventsList`的输出如下：'
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: DevTools can be used to identify a CSS selector for the particular section and
    can be further processed with the looping facility. For more information regarding
    the CSS Selector, please refer to [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XPath, and CSS Selectors*, *and the* *XPath and CSS selectors using
    DevTools* section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: DevTools可以用于识别特定部分的CSS选择器，并可以通过循环功能进一步处理。有关CSS选择器的更多信息，请参阅*第3章*的*使用LXML、XPath和CSS选择器*，*以及*
    *使用DevTools的XPath和CSS选择器*部分。
- en: 'The following code illustrates a few more examples of the `pyquery` iterating
    process via the use of `find()` and `items()`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码举例说明了通过使用`find()`和`items()`来迭代`pyquery`的过程：
- en: '[PRE19]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: For more information on features, attributes, and methods from `pyquery`, please
    refer to the [https://pythonhosted.org/pyquery/index.html](https://pythonhosted.org/pyquery/index.html).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`pyquery`的功能、属性和方法的更多信息，请参阅[https://pythonhosted.org/pyquery/index.html](https://pythonhosted.org/pyquery/index.html)。
- en: Web scraping using pyquery
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pyquery进行网页抓取
- en: In the previous section, we learned about using some important features that
    are available from `pyquery` and traversing or identifying elements using those
    features. In this section, we will be using most of these features from `pyquery`
    and we will be using them to scrape data from the web by providing examples with
    various use cases.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们学习了如何使用`pyquery`提供的一些重要功能，并使用这些功能来遍历或识别元素。在本节中，我们将使用`pyquery`的大部分功能，并将它们用于通过提供各种用例示例从网络上抓取数据。
- en: Example 1 – scraping data science announcements
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例1-抓取数据科学公告
- en: In this example, we will be scraping announcements-related details that are
    found within the data science category from [https://developer.ibm.com/announcements/category/data-science/](https://developer.ibm.com/announcements/category/data-science/).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将从[https://developer.ibm.com/announcements/category/data-science/](https://developer.ibm.com/announcements/category/data-science/)中的数据科学类别中抓取公告相关的详细信息。
- en: The same URL from [https://developer.ibm.com/](https://developer.ibm.com/) has
    also been used to collect data using `lxml.cssselect` under *Example 3*, in the
    *Web scraping using LXML* section from [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XPath, and CSS Selectors*. It is suggested that you explore both
    examples and compare the features that were used.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的URL[https://developer.ibm.com/](https://developer.ibm.com/)也被用于在*第3章*的*使用LXML、XPath和CSS选择器*中的*示例3*下使用`lxml.cssselect`来收集数据。建议您探索这两个示例并比较所使用的功能。
- en: 'To begin with, let''s import `pyquery` and `requests`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入`pyquery`和`requests`：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create `dataSet` so that you have an empty list to collect data that we will
    find from various pages, along with the libraries to be used. We have declared
    `read_url()`, which will be used to read the provided URL and return a `PyQuery`
    object. In this example, we will be using `sourceUrl`, that is, [https://developer.ibm.com/announcements/](https://developer.ibm.com/announcements/):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`dataSet`，以便您有一个空列表来收集我们将从各个页面找到的数据，以及要使用的库。我们声明了`read_url()`，它将用于读取提供的URL并返回一个`PyQuery`对象。在这个例子中，我们将使用`sourceUrl`，即[https://developer.ibm.com/announcements/](https://developer.ibm.com/announcements/)：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The information to be collected can be retrieved from [https://developer.ibm.com/announcements/category/data-science/?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/?fa=date:DESC&fb=)
    or obtained using `sourceUrl+"category/data-science/?fa=date:DESC&fb="`. Here,
    we will be looping through `pageUrls`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集的信息可以从[https://developer.ibm.com/announcements/category/data-science/?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/?fa=date:DESC&fb=)中检索，也可以使用`sourceUrl+"category/data-science/?fa=date:DESC&fb="`获取。在这里，我们将循环遍历`pageUrls`。
- en: '`pageUrls` results in the following page URLs. These were obtained by using
    list comprehension and `range()`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`pageUrls`导致以下页面URL。这些是通过使用列表推导和`range()`获得的：'
- en: '[https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=)'
- en: '[https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=)'
- en: 'As shown in the following code, `pageUrls` generates a list of page-based URLs
    that can be processed further via the use of the `get_details()` function. This
    is used to retrieve articles:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如下面的代码所示，`pageUrls`生成了一个基于页面的URL列表，可以通过`get_details()`函数进一步处理。这用于检索文章：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As we can see from the preceding code, the following URLs were listed:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述代码中可以看到，列出了以下URL：
- en: '[https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/1?fa=date:DESC&fb=)'
- en: '[https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=](https://developer.ibm.com/announcements/category/data-science/page/2?fa=date:DESC&fb=)'
- en: 'The URLs from `pageUrls` are iterated and passed to `get_details()` for further
    processing, as shown in the following code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 从`pageUrls`中迭代URL，并将其传递给`get_details()`进行进一步处理，如下面的代码所示：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The page URL that's passed to `get_details()` is read by `read_url()` and `response`
    from a `PyQuery` object is obtained. Information that contains blocks are identified
    as articles using CSS selectors. Since there's more than one `articles` iteration
    available, we use `items()`. Individual data elements are then processed with
    the help of cleaning, replacing, and merging activities before they are appended
    to the main dataset, which in this case is `dataSet`. PyQuery expressions can
    also be shortened via the use of `articlebody`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给`get_details()`的页面URL由`read_url()`读取，并从`PyQuery`对象中获得`response`。包含块的信息被识别为使用CSS选择器的文章。由于有多个`articles`迭代可用，我们使用`items()`。然后，通过清理、替换和合并活动处理单个数据元素，然后将其附加到主数据集中，本例中为`dataSet`。PyQuery表达式也可以通过使用`articlebody`来缩短。
- en: 'Also, the `remove()` `PyQuery` (manipulation) method is used to remove `.ibm--card__date`,
    which is found inside `<h5>`, in order to obtain `atype`. The `atype` content
    would also contain additional `.ibm--card__date` details if used without removing
    with the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用`remove()` `PyQuery`（操作）方法来删除`<h5>`中找到的`.ibm--card__date`，以获取`atype`。如果使用以下代码而不进行删除，`atype`内容还将包含额外的`.ibm--card__date`详细信息：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The final output that''s obtained from the preceding code is as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中获得的最终输出如下：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Example 2 – scraping information from nested links
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例2 - 从嵌套链接中提取信息
- en: 'In this example, we will be scraping details for quotes found in books from
    [http://quotes.toscrape.com/tag/books/](http://quotes.toscrape.com/tag/books/).
    Each individual quote contains certain information, plus a link to the author''s
    detail page, which will also be processed so that we can obtain information regarding
    the author:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将从[http://quotes.toscrape.com/tag/books/](http://quotes.toscrape.com/tag/books/)中提取书籍中的引用的详细信息。每个单独的引用包含某些信息，以及指向作者详细页面的链接，这也将被处理，以便我们可以获取有关作者的信息：
- en: '![](assets/baf63b98-caa9-42bd-9bb1-2a98431ed559.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/baf63b98-caa9-42bd-9bb1-2a98431ed559.png)'
- en: Main page from http://quotes.toscrape.com/tag/books/
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 来自http://quotes.toscrape.com/tag/books/的主页面
- en: 'In the following code, the elements in `keys` will be used as keys for output
    and will contain the Python dictionary. Basically, we will be collecting data
    for elements in keys:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，`keys`中的元素将被用作输出的键，并将包含Python字典。基本上，我们将收集`keys`中的元素的数据：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`read_url()` from the preceding code is also updated and is different in comparison
    to the libraries we used in the *Example 1 – scraping data science announcements*
    section. In this example, it returns the PyQuery object for the provided URL:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_url()`从前面的代码中也得到更新，并且与我们在*示例1 - 爬取数据科学公告*部分使用的库不同。在这个例子中，它返回提供的URL的PyQuery对象：'
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: There is an additional iteration being done with `dataSet` for certain values
    from the `info` dictionary, which is found inside `dataSet`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对`dataSet`进行了额外的迭代，以获取`dataSet`中的`info`字典的某些值。
- en: 'As shown in the following code, `get_details()` uses a `while` loop for pagination
    purposes, and is controlled by the `nextPage` value:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如下面的代码所示，`get_details()`使用`while`循环进行分页，并由`nextPage`值控制：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`:has()` returns the element that matches the selector that''s passed to it.
    In this example, we are confirming whether the `pager` class has an `<li>` element
    with the `next` class, that is, `ul.pager:has(''li.next'')`. If the expression
    is `true`, then a page link exists for another page, and `else` terminates the
    loop.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`:has()`返回与传递给它的选择器匹配的元素。在这个例子中，我们正在确认`pager`类是否有一个带有`next`类的`<li>`元素，即`ul.pager:has(''li.next'')`。如果表达式为`true`，则存在另一页的页面链接，`else`终止循环。'
- en: '`quotes` that are obtained are iterated using `items()` to obtain `title`, `author`, `tags`,
    and `authorLink`. The `authorLink` URL is further processed using the `read_url()`
    function in order to obtain author-related, specific information from the `.author-born-date`
    and `.author-born-location` classes for `born_date` and `born_location`, respectively.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`items()`迭代获得的`quotes`以获取`title`、`author`、`tags`和`authorLink`。使用`read_url()`函数进一步处理`authorLink`
    URL，以从`.author-born-date`和`.author-born-location`类中获取`born_date`和`born_location`的作者相关特定信息。
- en: 'The elements classes we used in the preceding code can be found in Page Source,
    as shown in the following screenshot:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的代码中使用的元素类可以在页面源中找到，如下面的屏幕截图所示：
- en: '![](assets/f47c0fb5-1f76-4c9e-913f-744b7e77353d.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f47c0fb5-1f76-4c9e-913f-744b7e77353d.png)'
- en: Inner page with author details
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 包含作者详细信息的内部页面
- en: The `zip()` Python function is used with *keys* and quotes fields, which is
    appended to `dataSet` as a Python Dictionary.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`zip()` Python函数与*keys*和引用字段一起使用，将其附加到`dataSet`作为Python字典。'
- en: 'The output for the preceding code is as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'An additional loop was run for the obtained `dataSet`, which results in a string,
    as shown here:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对获得的`dataSet`进行了额外的循环，结果是一个字符串，如下所示：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Example 3 – extracting AHL Playoff results
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例3 - 提取AHL季后赛结果
- en: 'In this example, we will be extracting data from **American Hockey League** (**AHL**)
    Playoff results, which are available from [http://www.flyershistory.com/cgi-bin/ml-poffs.cgi](http://www.flyershistory.com/cgi-bin/ml-poffs.cgi):
    [](http://www.flyershistory.com/cgi-bin/ml-poffs.cgi)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将从[http://www.flyershistory.com/cgi-bin/ml-poffs.cgi](http://www.flyershistory.com/cgi-bin/ml-poffs.cgi)提取**美国曲棍球联盟**（**AHL**）季后赛结果的数据：[](http://www.flyershistory.com/cgi-bin/ml-poffs.cgi)
- en: '![](assets/d25987e0-887b-486b-91a4-ef3741168acb.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d25987e0-887b-486b-91a4-ef3741168acb.png)'
- en: AHL Playoff results
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: AHL季后赛结果
- en: 'The preceding URL contains the Playoff results for the AHL. This page presents
    information about the results in tabular format. The portion of the page source
    that shows relevant information is shown in the following screenshot:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的URL包含AHL的季后赛结果。该页面以表格格式呈现有关结果的信息。显示相关信息的页面源的部分如下屏幕截图所示：
- en: '![](assets/18529f0b-9c17-4f1c-a590-e6395d50908c.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/18529f0b-9c17-4f1c-a590-e6395d50908c.png)'
- en: Page source from http://www.flyershistory.com/cgi-bin/ml-poffs.cgiThe preceding
    screenshot contains the top and bottom part of the tabular information from the
    source URL and presents two different formats of `<tr>` that are available in
    the page source. The number of `<td>` that are available in `<tr>` have different,
    extra information.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 来自http://www.flyershistory.com/cgi-bin/ml-poffs.cgi的页面源。前面的屏幕截图包含了来自源URL的表格信息的顶部和底部部分，并呈现了页面源中可用的两种不同格式的“<tr>”。在“<tr>”中可用的“<td>”数量有不同的额外信息。
- en: With the source format analyzed, it's also necessary to point out that `<td>`
    containing the desired values has no attributes that can be used to identify particular
    table cells. In this case, we can target the position of `<td>` or cell with data
    by using CSS selectors, that is, *pseudo selectors* such as `td:eq(0)` or `td:eq(1)`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 分析了源格式后，还需要指出的是包含所需值的“<td>”没有可用于识别特定表格单元的属性。在这种情况下，可以使用CSS选择器，即*伪选择器*，如“td:eq(0)”或“td:eq(1)”来定位包含数据的“<td>”或单元的位置。
- en: For more information on CSS selectors, please visit [Chapter 3](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml),
    *Using LXML, XPath, and CSS Selectors*, the *Introduction to XPath and CSS selector*
    section, in the *CSS Selectors* and *Pseudo Selectors* sub-section.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 有关CSS选择器的更多信息，请访问[第3章](9e1ad029-726f-4ed3-897a-c68bcd61f71e.xhtml)，*使用LXML、XPath和CSS选择器*，*XPath和CSS选择器简介*部分，在*CSS选择器*和*伪选择器*子部分。
- en: Since we will be using `pyquery` for this example, we will use the `eq()` method,
    which accepts the index and returns the element. For example, we could use `tr.find('td').eq(1).text()`
    for the chosen PyQuery object, `tr`, search for the element `td`, that is, `<td>`,
    with the index equal to `1`, and return the text of the element.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在此示例中使用“pyquery”，因此我们将使用“eq()”方法，该方法接受索引并返回元素。例如，我们可以使用“tr.find('td').eq(1).text()”来选择PyQuery对象“tr”，搜索索引为“1”的元素“td”，即“<td>”，并返回元素的文本。
- en: 'Here, we are interested in collecting data for the columns that are listed
    in `keys`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对“keys”中列出的列的数据感兴趣：
- en: '[PRE31]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, let''s import the code with `pyquery` and `re`. Regex will be used to
    separate the date that was obtained from the page source:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们导入带有“pyquery”和“re”的代码。将使用Regex来分隔从页面源获取的日期：
- en: '[PRE32]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Here, `read_url()` accepts one argument, that is, the link to the page, and
    returns the PyQuery object of the page source or `pageSource`. PyQuery automatically
    returns the page source for the provided URL. The page source can also be obtained
    by using other libraries, such as `urllib`, `urllib3`, `requests`, and LXML, and
    passed to create a PyQuery object:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“read_url()”接受一个参数，即页面链接，并返回页面源或“pageSource”的PyQuery对象。PyQuery会自动返回提供的URL的页面源。也可以使用其他库（如“urllib”、“urllib3”、“requests”和LXML）获取页面源，并传递给创建PyQuery对象：
- en: '[PRE33]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`tableRows` is a PyQuery object that will be used to traverse `<tr>` that exists
    inside `<table>`, which is located after `<h1>`. It contains the `AHL Playoff
    Results` text, which is obtained by using the `find()` function. As we can see
    in the following output, a total of `463` `<tr>` elements exist, but the actual
    number of records that were obtained might be lower, in terms of the number of
    available `<td>` with the actual data:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: “tableRows”是一个PyQuery对象，将用于遍历位于“<h1>”之后的“<table>”内存在的“<tr>”。它包含使用“find()”函数获取的“AHL
    Playoff Results”文本。如下面的输出所示，存在463个“<tr>”元素，但实际获取的记录数量可能较低，即实际数据的可用“<td>”数量可能较低：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let''s do some more processing. Each `<tr>` or `tr` element is an item of `tableRows`
    and is traversed with the help of the `items()` method to find the exact `<td>`
    or `td` by using their index and retrieving the data it contains:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行更多处理。每个“<tr>”或“tr”元素都是“tableRows”的一个项目，并且可以使用“items()”方法来通过使用它们的索引来查找确切的“<td>”或“td”并检索它包含的数据：
- en: '[PRE35]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'So far, the desired data from the targeted `<td>` has been collected and also
    formatted in the case of `year`. Regex has also been applied in the code and used
    with `dates` and `game_status`. Finally, the collected objects are appended as
    a list to `dataSet`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，已经收集了目标“<td>”中的所需数据，并且在“year”的情况下也进行了格式化。在代码中还应用了Regex，并与“dates”和“game_status”一起使用。最后，收集的对象被附加为列表到“dataSet”：
- en: '[PRE36]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output regarding the total record count and `dataSet` is as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 有关总记录数和“dataSet”的输出如下：
- en: '[PRE37]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Example 4 – collecting URLs from sitemap.xml
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例4-从sitemap.xml收集URL
- en: In this example, we will be extracting URLs that have been found for blogs in
    the `sitemap.xml` file from [https://webscraping.com/sitemap.xml](https://webscraping.com/sitemap.xml).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将提取在[https://webscraping.com/sitemap.xml](https://webscraping.com/sitemap.xml)中找到的博客的URL。
- en: In the preceding examples, we used HTML content, but PyQuery can also be used
    to traverse XML file content. By default, `pyquery` uses an LXML-based `xml` parser,
    which can be provided while creating a PyQuery object. We will be using both `lxml.html`
    and `xml` in the file's content.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用了HTML内容，但PyQuery也可以用于遍历XML文件内容。默认情况下，“pyquery”使用基于LXML的“xml”解析器，可以在创建PyQuery对象时提供。我们将在文件内容中同时使用“lxml.html”和“xml”。
- en: For more information on `pyquery` and `parser`, please visit the *Exploring
    pyquery* section of this chapter. For information regarding the site map, please
    visit [Chapter 1](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml), *Web Scraping Fundamentals*,
    the *Data finding techniques* *(seeking data from the web)* section, in the *Sitemaps*
    subsection.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 有关“pyquery”和“parser”的更多信息，请访问本章的*探索pyquery*部分。有关站点地图的信息，请访问[第1章](af7787bb-7fcf-4101-8680-9bad14bf22e1.xhtml)，*网络抓取基础知识*，*数据查找技术*（从网络中获取数据）部分，在*Sitemaps*子部分。
- en: 'The following screenshot shows the content that''s available in the `sitemap.xml`
    file:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了“sitemap.xml”文件中的内容：
- en: '![](assets/59bb93de-f744-4d15-acf0-5cc90a0e90f1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/59bb93de-f744-4d15-acf0-5cc90a0e90f1.png)'
- en: sitemap.xml file from https://webscraping.com
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 从https://webscraping.com获取sitemap.xml文件
- en: To begin with, let's import `pyquery` and read the file's content as `xmlFile`*:*
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入“pyquery”并将文件内容读取为“xmlFile”*：*
- en: '[PRE38]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Case 1 – using the HTML parser
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Case 1 – using the HTML parser
- en: 'Here, we will be using the `lxml.html` parser to parse `xmlFile` by passing
    an argument parser, `parser=''html''`, to PyQuery:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用`lxml.html`解析器通过向PyQuery传递解析器参数`parser='html'`来解析`xmlFile`：
- en: '[PRE39]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Using PyQuery''s `urlHTML` object allows us to check the count and the child
    elements that were obtained from the data, as shown in the following output:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyQuery的`urlHTML`对象允许我们检查从数据中获取的计数和子元素，如下所示的输出：
- en: '[PRE40]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As we can see, `urlHTML.children()` contains the required elements to look for
    the URL. We can process this data with the `items()` method, which traverses through
    each element that's obtained. Let's create `dataSet` (Python `list()`) that will
    be appended with the URLs that are extracted.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，`urlHTML.children()`包含了查找URL所需的元素。我们可以使用`items()`方法处理这些数据，该方法遍历获取的每个元素。让我们创建`dataSet`（Python
    `list()`），并将提取的URL附加到其中。
- en: 'Element-based iteration can be performed with `urlHTML.children().find(''loc:contains("blog")'').items()`
    by using a selector that contains the `blog` string:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 基于元素的迭代可以使用`urlHTML.children().find('loc:contains("blog")').items()`来执行，通过使用包含`blog`字符串的选择器：
- en: '[PRE41]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, we will receive the following output:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将收到以下输出：
- en: '[PRE42]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Case 2 – using the XML parser
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Case 2 – using the XML parser
- en: 'In this case, we will be processing XML content with the PyQuery `urlXML` object,
    which uses `parser=''xml''`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用PyQuery `urlXML`对象处理XML内容，该对象使用`parser='xml'`：
- en: '[PRE43]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The preceding code returns the length of the children''s count, that is, `137`
    total URLs:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码返回了子节点计数的长度，即`137`个总URL：
- en: '[PRE44]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'As shown in the following code, the first and inner children elements return
    the required URL content we are willing to extract:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示的代码，第一个和内部子元素返回了我们希望提取的所需URL内容：
- en: '[PRE45]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s proceed with the child elements by using a selector similar to the one
    we used in the *Case 1 – using the HTML parser* section:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用类似于*Case 1 – using the HTML parser*部分中使用的选择器来处理子元素：
- en: '[PRE46]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Here, we have received no output in `dataSet`, and it looks like the selector
    isn''t working like it did in *Case 1 – using the HTML parser*:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在`dataSet`中没有收到任何输出，看起来选择器的工作方式不像在*Case 1 – using the HTML parser*中那样：
- en: '[PRE47]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let''s verify this case by using the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码验证这种情况：
- en: '[PRE48]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The node that we received belongs to [https://www.sitemaps.org/schemas/sitemap/0.9](https://www.sitemaps.org/schemas/sitemap/0.9).
    Without removing the namespace selectors, it will not work.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到的节点属于[https://www.sitemaps.org/schemas/sitemap/0.9](https://www.sitemaps.org/schemas/sitemap/0.9)。如果不删除命名空间选择器，它将无法工作。
- en: 'The `remove_namespace()` function can be used on a PyQuery object and processed
    for its final output, as shown in the following code:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`remove_namespace()`函数可以用于PyQuery对象，并且可以处理其最终输出，如下所示的代码：'
- en: '[PRE49]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We receive the following output:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到以下输出：
- en: '[PRE50]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The PyQuery `remove_namespace()` and `xhtml_to_html()` methods remove the namespaces
    from XML and XHTML, respectively. Use of these two methods allows us to work with
    elements that use HTML-related properties.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: PyQuery `remove_namespace()`和`xhtml_to_html()`方法分别从XML和XHTML中删除命名空间。使用这两种方法允许我们处理使用HTML相关属性的元素。
- en: 'We can also process the same content with a different approach; that is, by
    using a regular expression and obtaining the output as required. Let''s proceed
    with the following code:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用不同的方法处理相同的内容；也就是说，通过使用正则表达式并获取所需的输出。让我们继续使用以下代码：
- en: '[PRE51]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The PyQuery `children()` object method returns all the child nodes, and `text()`
    will extract the text content, as shown here:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: PyQuery `children()`对象方法返回所有子节点，`text()`将提取文本内容，如下所示：
- en: '[PRE52]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'As shown in the preceding output, all the links from the child nodes are returned
    as a single string:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，所有子节点的链接都作为单个字符串返回：
- en: '[PRE53]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here, `re.split()` is used to split the string of URLs received with the space
    character, `\s`. This returns a total of `139` elements. Finally, `blogXML` is
    filtered using `re.findall()`, which finds the `blog` string in the `blogXML`
    elements and results in the following:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`re.split()`用于使用空格字符`\s`拆分收到的URL字符串。这返回了总共`139`个元素。最后，使用`re.findall()`过滤`blogXML`，该方法在`blogXML`元素中查找`blog`字符串，并得到以下结果：
- en: '[PRE54]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: In this section, we have used a few scraping techniques to extract the desired
    content from files and websites. Content identification and the requirement to
    scrape is pretty dynamic and is also based on the structure of the website. With
    libraries such as `pyquery`, we can obtain and deploy the necessary tools and
    techniques for scraping in an effective and efficient manner.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用了一些抓取技术来从文件和网站中提取所需的内容。内容识别和抓取需求非常动态，也取决于网站的结构。使用`pyquery`等库，我们可以以有效和高效的方式获取和部署抓取所需的工具和技术。
- en: Summary
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: '`pyquery` seems to be more efficient in dealing with CSS selectors and provides
    a lot of features related to LXML. Simple and readable code is always in demand,
    and `pyquery` provides these features for scraping purposes. In this chapter,
    we explored various cases that you may encounter while performing scraping tasks
    and successfully managed to get the desired outcome.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyquery`似乎更有效地处理CSS选择器，并提供了许多与LXML相关的功能。简单易读的代码总是受欢迎的，`pyquery`为抓取提供了这些功能。在本章中，我们探讨了在执行抓取任务时可能遇到的各种情况，并成功地实现了期望的结果。'
- en: In the next chapter, we will be exploring a few more libraries related to web
    scraping.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探索与网络抓取相关的几个其他库。
- en: Further reading
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'PyQuery complete API: [https://pyquery.readthedocs.io/en/latest/api.html](https://pyquery.readthedocs.io/en/latest/api.html)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyQuery完整API：[https://pyquery.readthedocs.io/en/latest/api.html](https://pyquery.readthedocs.io/en/latest/api.html)
- en: 'pyquery: a jquery-like library for Python: [https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pyquery：Python的类似jquery的库：[https://pythonhosted.org/pyquery/](https://pythonhosted.org/pyquery/)
- en: 'CSS Selector Reference: [https://www.w3schools.com/cssref/css_selectors.asp](https://www.w3schools.com/cssref/css_selectors.asp)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSS选择器参考：[https://www.w3schools.com/cssref/css_selectors.asp](https://www.w3schools.com/cssref/css_selectors.asp)
- en: 'CSS Pseudo Class and Elements: [https://www.w3schools.com/css/css_pseudo_elements.asp](https://www.w3schools.com/css/css_pseudo_elements.asp)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSS 伪类和元素：[https://www.w3schools.com/css/css_pseudo_elements.asp](https://www.w3schools.com/css/css_pseudo_elements.asp)
- en: 'CSS information: [http://www.css3.info/](http://www.css3.info/) and [https://developer.mozilla.org/en-US/docs/Web/CSS](https://developer.mozilla.org/en-US/docs/Web/CSS)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSS 信息：[http://www.css3.info/](http://www.css3.info/) 和 [https://developer.mozilla.org/en-US/docs/Web/CSS](https://developer.mozilla.org/en-US/docs/Web/CSS)
- en: 'Sitemaps: [https://www.sitemaps.org/](https://www.sitemaps.org/)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 站点地图：[https://www.sitemaps.org/](https://www.sitemaps.org/)
- en: XML*:* [https://www.w3schools.com/xml/](https://www.w3schools.com/xml/) and
    [https://www.w3.org/XML/](https://www.w3.org/XML/)
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XML*:* [https://www.w3schools.com/xml/](https://www.w3schools.com/xml/) 和 [https://www.w3.org/XML/](https://www.w3.org/XML/)
