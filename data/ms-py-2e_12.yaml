- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Performance – Tracking and Reducing Your Memory and CPU Usage
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能 - 跟踪和减少你的内存和CPU使用
- en: 'Before we talk about performance, there is a quote by *Donald Knuth* you need
    to consider first:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论性能之前，首先需要考虑的是Donald Knuth的一句话：
- en: “The real problem is that programmers have spent far too much time worrying
    about efficiency in the wrong places and at the wrong times; premature optimization
    is the root of all evil (or at least most of it) in programming”.
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “真正的问题在于程序员在错误的地方和错误的时间花费了太多的时间去担心效率；过早的优化是编程中所有邪恶（至少是大部分邪恶）的根源。”
- en: Donald Knuth is often called the father of algorithm analysis. His book series,
    *The Art of Computer Programming*, can be considered the Bible of all fundamental
    algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Donald Knuth 通常被称为算法分析的鼻祖。他的书系《计算机程序设计艺术》可以被认为是所有基本算法的圣经。
- en: As long as you pick the correct data structures with the right algorithms, performance
    should not be something to worry about. That does not mean you should ignore performance
    entirely, but just make sure you pick the right battles and optimize only when
    it is actually needed. Micro/premature optimizations can definitely be fun, but
    are only very rarely useful.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你选择正确的数据结构和合适的算法，性能就不应该是你担心的事情。这并不意味着你应该完全忽略性能，但只是确保你选择了正确的战斗，并且只有在真正需要的时候才进行优化。微/过早的优化确实很有趣，但只有非常少的情况下才有用。
- en: We have seen the performance characteristics of many data structures in *Chapter
    2*, *Pythonic Syntax and Common Pitfalls*, already, so we won’t discuss that,
    but we will show you how performance can be measured and how problems can be detected.
    There are cases where micro optimizations make a difference, but you won’t know
    until you measure the performance.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在第二章《Pythonic语法和常见陷阱》中看到了许多数据结构的性能特征，所以我们将不会讨论这一点，但我们会向你展示如何测量性能以及如何检测问题。在某些情况下，微优化会有所帮助，但你不知道直到你测量了性能。
- en: 'Within this chapter, we will cover:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Profiling CPU usage
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析CPU使用情况
- en: Profiling memory usage
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析内存使用情况
- en: Learning how to correctly compare performance metrics
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何正确比较性能指标
- en: Optimizing performance
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化性能
- en: Finding and fixing memory leaks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找和修复内存泄漏
- en: Globally, the chapter is split between CPU usage and/or CPU time, and memory
    usage. The first half of the chapter mainly concerns CPU/time; the second half
    covers memory usage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从全局来看，本章分为CPU使用和/或CPU时间以及内存使用。本章的前半部分主要关注CPU/时间；后半部分涵盖内存使用。
- en: What is performance?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是性能？
- en: Performance is a very broad term. It has many different meanings and, in many
    cases, it is defined incorrectly. Within this chapter, we will attempt to measure
    and improve performance in terms of CPU usage/time and memory usage. Many of the
    examples here are a trade-off between execution time and memory usage. Note that
    a fast algorithm that can only use a single CPU core can be outperformed in terms
    of execution time by a slower algorithm that is easily parallelizable given enough
    CPU cores.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 性能是一个非常广泛的概念。它有许多不同的含义，在许多情况下，它被错误地定义。在本章中，我们将尝试从CPU使用/时间和内存使用方面来测量和改进性能。这里的大多数例子都是执行时间和内存使用之间的权衡。请注意，一个只能使用单个CPU核心的快速算法，在执行时间上可能会被一个足够多的CPU核心就能轻松并行化的较慢算法所超越。
- en: 'When it comes to incorrect statements about performance, you have probably
    heard statements similar to “Language X is faster than Python.” That statement
    is inherently wrong. Python is neither fast nor slow; Python is a programming
    language, and a language has no performance metrics whatsoever. If you were to
    say that the CPython interpreter is faster or slower than interpreter Y for language
    X, that would be possible. The performance characteristics of code can vary greatly
    between different interpreters. Just take a look at this small test (which uses
    ZSH shell script):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到关于性能的错误陈述时，你可能已经听到了类似“语言X比Python快”这样的说法。这个说法本身是错误的。Python既不快也不慢；Python是一种编程语言，而一种语言根本没有任何性能指标。如果你要说CPython解释器比语言X的解释器Y快或慢，那是可能的。代码的性能特征在不同解释器之间可能会有很大的差异。只需看看这个小的测试（它使用ZSH
    shell脚本）：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Five different Python interpreters, each with a different performance! All are
    Python, but the interpreters obviously vary.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 五种不同的Python解释器，每个都有不同的性能！它们都是Python，但解释器显然各不相同。
- en: You might not have heard of the PyPy3 and Pyston interpreters yet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还没有听说过PyPy3和Pyston解释器。
- en: The PyPy3 interpreter is an alternative Python interpreter that uses JIT (Just-In-Time)
    compiling to perform much better than CPython in many, but certainly not all,
    cases. The big caveat of PyPy3 is that code that has speedups in C and depends
    on CPython extensions (which is a large portion of performance-critical libraries)
    either does not support PyPy3 or suffers a performance hit.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PyPy3解释器是一个替代Python解释器，它使用JIT（即时）编译，在许多情况下比CPython表现更好，但当然并非所有情况。PyPy3的一个大问题是，那些在C中有速度提升且依赖于CPython扩展（这是大量性能关键库的一部分）的代码要么不支持PyPy3，要么会遭受性能损失。
- en: Pyston attempts to be a drop-in replacement for CPython with JIT compiling added
    to it. While JIT compiling might be added to CPython pretty soon, as of Python
    3.10, that is not the case yet. This is why Pyston can offer a great performance
    benefit over CPython. The downside is that it is currently only supported on Unix/Linux
    systems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Pyston试图成为CPython的替代品，并添加了JIT编译。虽然JIT编译可能很快就会添加到CPython中，但截至Python 3.10，这还不是事实。这就是为什么Pyston可以提供比CPython更大的性能优势。缺点是它目前仅支持Unix/Linux系统。
- en: Looking at this benchmark, you might be tempted to drop the CPython interpreter
    completely and only use PyPy3\. The danger with benchmarks such as these is that
    they rarely offer any meaningful results. For this limited example, the Pypy interpreter
    was about 200 times faster than the CPython3.10 interpreter, but that has very
    little relevance for the general case. The only conclusion that can safely be
    drawn here is that this specific version of the PyPy3 interpreter is much faster
    than this specific version of CPython3 **for this exact test**. For any other
    test and interpreter version, the results could be vastly different.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这个基准测试，你可能想完全放弃CPython解释器，只使用PyPy3。这样的基准测试的危险在于，它们很少提供任何有意义的成果。在这个有限的例子中，Pypy解释器比CPython3.10解释器快了大约200倍，但这对于一般情况几乎没有相关性。可以安全得出的唯一结论是，这个特定版本的PyPy3解释器在这个特定测试中比这个特定版本的CPython3快得多。对于任何其他测试和解释器版本，结果可能会有很大不同。
- en: Measuring CPU performance and execution time
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量CPU性能和执行时间
- en: 'When talking about performance you can measure a great number of things. When
    it comes to CPU performance, we can measure:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论性能时，你可以测量许多事物。当涉及到CPU性能时，我们可以测量：
- en: The “wall time” (the absolute time on the clock).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “墙上的时间”（时钟上的绝对时间）。
- en: Relative time (when comparing multiple runs or multiple functions)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对时间（当比较多次运行或多个函数时）
- en: Used CPU time. Due to multithreading, multiprocessing, or asynchronous processing,
    this can be vastly different from the wall time.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CPU时间。由于多线程、多进程或异步处理，这可能与墙上的时间有很大差异。
- en: When inspecting really low-level performance, measuring the number of CPU cycles
    and loop counts.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当检查真正低级别的性能时，需要测量CPU周期数和循环计数。
- en: In addition to all these different measurement options, you should also consider
    the observer effect. Simply put, measuring takes time, and depending on how you
    are measuring the performance, the impact can be huge.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有这些不同的测量选项之外，你还应该考虑观察者效应。简单来说，测量需要时间，并且根据你如何测量性能，影响可能很大。
- en: Within this section, we will be exploring several methods to inspect the CPU
    performance and execution time of your code. Tricks to improve your performance
    after measuring will come later in the chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨几种检查代码CPU性能和执行时间的方法。在测量后提高性能的技巧将在本章后面介绍。
- en: Timeit – comparing code snippet performance
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Timeit – 比较代码片段性能
- en: 'Before we can start improving execution/CPU times, we need a reliable method
    to measure them. Python has a really nice module (`timeit`) with the specific
    purpose of measuring the execution times of bits of code. It executes a bit of
    code many times to make sure there is as little variation as possible and to make
    the measurement fairly clean. It’s very useful if you want to compare a few code
    snippets. Following are some example executions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始提高执行/CPU时间之前，我们需要一个可靠的方法来测量它们。Python有一个非常棒的模块（`timeit`），其特定目的是测量代码片段的执行时间。它多次执行一小段代码，以确保尽可能少的变异性，并使测量尽可能干净。如果你想要比较几个代码片段，这非常有用。以下是一些示例执行：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These few examples demonstrate the performance difference between `list.insert`,
    `list.append`, a list comprehension, and the `list` function. As we have seen
    in *Chapter 4*, doing `list.insert` is very inefficient and that quickly shows
    here, in this case being 30 times slower than `list.append`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这几个示例展示了 `list.insert`、`list.append`、列表推导式和 `list` 函数之间的性能差异。正如我们在 *第 4 章* 中所看到的，执行
    `list.insert` 非常低效，并且在这里很快就会显示出来，在这种情况下比 `list.append` 慢 30 倍。
- en: 'More importantly, however, the code demonstrates how we can use the `timeit`
    module and how it works. As you can see in the output, the `list.append` variant
    was executed only `10` times, whereas the `list` call was executed `10000` times.
    That is one of the most convenient features of the `timeit` module: it automatically
    figures out some useful parameters for you, and it shows the “best of 3” to try
    and reduce the amount of variance in your tests.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更重要的是，这段代码展示了我们如何使用 `timeit` 模块以及它是如何工作的。正如你在输出中可以看到的，`list.append` 变体只执行了
    `10` 次，而 `list` 调用执行了 `10000` 次。这是 `timeit` 模块最方便的特性之一：它自动为你计算出一些有用的参数，并显示“最佳
    3 次”以尝试减少测试中的方差。
- en: The `timeit` module is great at comparing the performance of similar bits of
    code within a code base. Comparing the execution time between different Python
    interpreters using `timeit` is generally useless because it is rarely representative
    of the performance of your whole application.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`timeit` 模块非常适合比较代码库中相似代码片段的性能。使用 `timeit` 比较不同 Python 解释器的执行时间通常是无用的，因为这很少能代表你整个应用程序的性能。'
- en: 'Naturally, the command can be used with regular scripts as well, but that won’t
    automatically determine the number of repetitions like the command-line interface
    does. So we will have to do that ourselves:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这个命令也可以与常规脚本一起使用，但它不会像命令行界面那样自动确定重复次数。因此，我们必须自己来做这件事：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When executing this, you will get something along the following lines:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行此操作时，你将得到以下类似的结果：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As you may have noticed, this script is still a bit basic. While the command-line
    version of `timeit` keeps trying until it reaches 0.2 seconds or more, this script
    just has a fixed number of executions. Since Python 3.6, we do have the option
    of using `timeit.Timer.autorange` to replicate this behavior, but it is a bit
    less convenient to use and would produce a lot more output in our current case.
    Depending on your use case, however, it could be useful to try this benchmark
    code instead:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所注意到的，这个脚本仍然有点基础。虽然命令行版本的 `timeit` 会一直尝试，直到达到 0.2 秒或更长时间，但这个脚本只有固定的执行次数。从
    Python 3.6 开始，我们确实有使用 `timeit.Timer.autorange` 来复制此行为的选项，但这使用起来不太方便，并且在我们的当前情况下会产生更多的输出。然而，根据你的使用情况，尝试这个基准代码可能是有用的：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you want to use `timeit` interactively, I would recommend using IPython,
    since it has a magic `%timeit` command that shows even more useful output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要交互式地使用 `timeit`，我建议使用 IPython，因为它有一个魔法命令 `%timeit`，可以显示更多有用的输出：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case, IPython automatically takes care of the string wrapping and passing
    of `globals()`. Still, this is all very limited and useful only for comparing
    multiple methods of doing the same thing. When it comes to full Python applications,
    there are more methods available, as we will see later in this chapter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，IPython 会自动处理字符串包装和 `globals()` 的传递。尽管如此，这仍然非常有限，并且仅适用于比较执行同一任务的不同方法。当涉及到完整的
    Python 应用程序时，还有更多可用的方法，我们将在本章后面看到。
- en: To view the source of both IPython functions and regular modules, entering `object??`
    in the IPython shell returns the source. In this case, just enter `timeit??` to
    view the `timeit` IPython function definition.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 IPython 函数和常规模块的源代码，在 IPython 命令行中输入 `object??` 会返回源代码。在这种情况下，只需输入 `timeit??`
    来查看 `timeit` IPython 函数的定义。
- en: 'The easiest way you can implement a function similar to the `%timeit` function
    is to call `timeit.main`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 实现类似于 `%timeit` 函数的最简单方法是通过调用 `timeit.main`：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This effectively does the same as:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上与以下操作相同：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The internals of the `timeit` module are nothing too special, but take care
    to minimize a few sources of inaccuracy, such as the setup and the teardown code.
    Additionally, the module reports the fastest run because other processes on your
    system can interfere with the measurement.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`timeit` 模块的内部结构并没有什么特别之处，但请注意尽量减少一些可能导致不准确的因素，例如设置和清理代码。此外，该模块报告的是最快的运行时间，因为系统上的其他进程可能会干扰测量。'
- en: 'A basic version can be implemented with a few calls to `time.perf_counter`
    (the highest resolution timer available in Python), which is also used by `timeit`
    internally. The `timeit.default_timer` function is simply a reference to `time.perf_counter`.
    This basic implementation of the `timeit` function is comparable to the internals
    of the `timeit` module:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基本版本可以通过调用几次`time.perf_counter`（Python中可用的最高分辨率计时器）来实现，该计时器也被`timeit`内部使用。`timeit.default_timer`函数仅仅是`time.perf_counter`的一个引用。`timeit`函数的基本实现与`timeit`模块的内部实现相当：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The actual `timeit` code is a bit more advanced in terms of checking the input,
    but this example roughly shows how the `timeit.timeit` function can be implemented,
    including several of the features added for more precision:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的`timeit`代码在检查输入方面要复杂一些，但这个例子大致展示了如何实现`timeit.timeit`函数，包括为提高精度而添加的几个特性：
- en: First, we can see that the code has a `number` parameter that defaults to 1
    million. This has been done to reduce the result variance a little, as we will
    see when running the code.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们可以看到代码有一个默认值为1百万的`number`参数。这样做是为了稍微减少结果的变化性，正如我们在运行代码时将看到的。
- en: Second, the code disables the Python garbage collector so we don’t get any slowdowns
    from Python deciding to clean up its memory.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，代码禁用了Python垃圾回收器，这样我们就不会因为Python决定清理其内存而出现任何减速。
- en: 'When we actually call this code, we will see why a high value for `number`
    can be important:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们实际调用这段代码时，我们将看到为什么`number`的高值可能很重要：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Even though we called the exact same code each time, the single repetition took
    more than two times as long in the first run and more than 10 times as long in
    the second run compared to the 1 million repetitions version. To make your results
    more consistent and reliable between runs, it is always good to repeat your tests
    several times and `timeit` can certainly help with that.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们每次都调用了完全相同的代码，但第一次运行的单次重复时间比1百万次重复版本多两倍以上，第二次运行则比1百万次重复版本多10倍以上。为了使你的结果在运行之间更加一致和可靠，总是重复测试几次是个好主意，而`timeit`可以在这方面提供帮助。
- en: 'The `timeit.repeat` function simply calls the `timeit.timeit` function several
    times and can be emulated using a list comprehension:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`timeit.repeat`函数简单地多次调用`timeit.timeit`函数，可以使用列表推导来模拟：'
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now that we know how to test simple code statements, let’s look at how to find
    slow statements in our code.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经知道了如何测试简单的代码语句，那么让我们看看如何找到代码中的慢速语句。
- en: cProfile – Finding the slowest components
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: cProfile – 寻找最慢的组件
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `profile` and `cProfile` modules offer the exact same interface, but the
    latter is written in C and is much faster. I would recommend using `cProfile`
    if it is available on your system. If not, you can safely replace any occurrence
    of `cProfile` with `profile` in the following examples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`profile`和`cProfile`模块提供了完全相同的接口，但后者是用C编写的，速度要快得多。如果系统上可用，我建议使用`cProfile`。如果不可用，你可以在以下示例中安全地将任何`cProfile`的出现替换为`profile`。'
- en: First profiling run
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 首次分析运行
- en: 'Let’s profile our Fibonacci function from *Chapter 6*, *Decorators – Enabling
    Code Reuse by Decorating*, both with and without the cache function. First, the
    code:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析第6章中的斐波那契函数，*装饰器 – 通过装饰实现代码重用*，既有缓存函数也有无缓存函数的情况。首先，代码：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For the sake of readability, all `cProfile` statistics will be stripped of the
    `percall` columns in all `cProfile` outputs. These columns contain the duration
    per function call, which is irrelevant for these examples since they will be either
    0 or identical to the `cumtime` (cumulative time) column in nearly all cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可读性，所有`cProfile`统计信息都将从所有`cProfile`输出中的`percall`列中去除。这些列包含每次函数调用的持续时间，在这些示例中，这些值几乎总是为0或与`cumtime`（累积时间）列相同，因此对于这些示例来说是不相关的。
- en: 'First, we’ll execute the function without cache:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将不使用缓存执行该函数：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We see `2692557` calls in total, which is quite a lot of calls. We called the
    `test_fibonacci` function nearly 3 million times. That is where the profiling
    modules provide a lot of insight. Let’s analyze the metrics a bit further, in
    the order they appear:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到总共有`2692557`次调用，这相当多。我们几乎调用了300万次`test_fibonacci`函数。这就是分析模块提供大量见解的地方。让我们进一步分析这些指标，按照它们出现的顺序：
- en: '`ncalls`: The number of calls that were made to the function.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ncalls`: 调用该函数的次数。'
- en: '`tottime`: The total time spent in this function, **excluding** the sub-functions.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tottime`: 该函数中花费的总时间，**不包括**子函数。'
- en: '`percall`: The time per call without sub-functions: `tottime / ncalls`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`percall`: 每次调用（不包括子函数）的时间：`tottime / ncalls`。'
- en: '`cumtime`: The total time spent in this function, **including** sub-functions.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cumtime`：在这个函数中花费的总时间，**包括**子函数。'
- en: '`percall`: The time per call including sub-functions: `cumtime / ncalls`. This
    is distinct from the `percall` metric above, despite having the same name.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`percall`：包括子函数的每次调用时间：`cumtime / ncalls`。这个指标与上面的`percall`指标名称相同，但含义不同。'
- en: 'Which is the most useful depends on your use case. It’s quite simple to change
    the sort order using the `-s` parameter within the default output. But now let’s
    see what the result is with the cached version. Once again, with stripped output:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个最有用取决于你的用例。使用默认输出中的`-s`参数更改排序顺序非常简单。但现在让我们看看使用缓存版本的结果。再次，使用去除输出的方式：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This time, we see a `tottime` of `0.000` because it’s just too fast to measure.
    But also, while the `fibonacci_cached` function is still the most executed function,
    it’s only being executed 31 times instead of 3 million times.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我们看到一个`tottime`为`0.000`，因为它太快而无法测量。此外，尽管`fibonacci_cached`函数仍然是执行次数最多的函数，但它只执行了31次，而不是300万次。
- en: Calibrating your profiler
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 校准剖析器
- en: 'To illustrate the difference between `profile` and `cProfile`, let’s try the
    uncached run again with the `profile` module instead. Just a heads up: this is
    much slower, so don’t be surprised if it stalls a little:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明`profile`和`cProfile`之间的区别，让我们再次尝试使用`profile`模块而不是缓存运行。提醒一下：这会慢得多，所以如果你发现它稍微卡顿，不要感到惊讶：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The code now runs nearly 10 times more slowly, and the only difference is using
    the pure Python `profile` module instead of the `cProfile` module. This does indicate
    a big problem with the `profile` module. The overhead from the module itself is
    great enough to skew the results, which means we should account for that offset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 代码现在运行速度慢了近10倍，唯一的区别是使用纯Python的`profile`模块而不是`cProfile`模块。这确实表明`profile`模块存在一个大问题。模块本身的开销足够大，足以扭曲结果，这意味着我们应该考虑到这个偏差。
- en: 'That’s what the `Profile.calibrate()` function takes care of, as it calculates
    the performance bias incurred by the profile module. To calculate the bias, we
    can use the following script:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是`Profile.calibrate()`函数负责的，因为它计算了剖析模块引起的性能偏差。为了计算偏差，我们可以使用以下脚本：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The numbers will vary slightly, but you should be able to get a fair estimate
    of the performance bias that the `profile` module introduces to your code. It
    effectively runs a bit of code both with and without profiling enabled and calculates
    a multiplier to apply to all results so they are closer to the actual duration.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 数字会有轻微的变化，但你应该能够得到一个关于`profile`模块引入到你的代码中的性能偏差的合理估计。它实际上在启用和禁用剖析的情况下运行了一小段代码，并计算一个乘数，将其应用于所有结果，使它们更接近实际持续时间。
- en: If the numbers still vary a lot, you can increase the trials from `100000` to
    something even larger.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数字仍然变化很大，你可以将试验次数从`100000`增加到更大。
- en: Note that with many modern processors, the burst CPU performance (the first
    few seconds) can vary greatly from the sustained CPU performance (2 minutes or
    more).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在许多现代处理器中，CPU的突发性能（前几秒）与持续性能（2分钟或更长时间）可能会有很大的差异。
- en: The CPU performance is also highly temperature-dependent, so if your system
    has a large CPU cooler or is water-cooled, it can take up to 20 minutes at 100%
    CPU load before the CPU performance becomes consistent. The bias after that 20
    minutes would be completely unusable as a bias for a cold CPU.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CPU性能也高度依赖于温度，所以如果你的系统有一个大型的CPU散热器或者水冷，在100% CPU负载下，它可能需要20分钟才能使CPU性能变得一致。那20分钟之后的偏差将完全无法作为冷CPU的偏差使用。
- en: 'This type of calibration only works for the `profile` module and should help
    a lot in achieving more accurate results. The bias can be set globally for all
    newly created profilers:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这种校准类型仅适用于`profile`模块，并且应该有助于实现更准确的结果。对于所有新创建的剖析器，偏差可以全局设置：
- en: '[PRE17]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Or for a specific `Profile` instance:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，对于特定的`Profile`实例：
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Note that in general, a smaller bias is better to use than a large one because
    a large bias could cause very strange results. If the bias is large enough, you
    will even get negative timings. Let’s give it a try for our Fibonacci code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一般来说，使用较小的偏差比使用较大的偏差更好，因为大的偏差可能会导致非常奇怪的结果。如果偏差足够大，你甚至可能会得到负的时间值。让我们在我们的斐波那契代码上试一试：
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'While running it, it indeed appears that we’ve used a bias that’s too large:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时，确实看起来我们使用了一个太大的偏差：
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Still, it shows how the code can be used properly. You can even incorporate
    the bias calculation within the script using a snippet like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，它仍然显示了代码的正确使用方法。您甚至可以在脚本中使用类似这样的片段将偏差计算包含在内：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Selective profiling using decorators
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用装饰器的选择性分析
- en: 'Calculating simple timings is easy enough using decorators, but profiling can
    show a lot more and can also be applied selectively using decorators or context
    wrappers. Let’s look at a `timer` and a `profiler` decorator:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用装饰器计算简单的计时很容易，但分析可以显示更多内容，并且也可以通过装饰器或上下文包装器有选择性地应用。让我们看看 `timer` 和 `profiler`
    装饰器：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now that we have created the decorators, we can profile and time our functions
    with them:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了装饰器，我们可以使用它们来分析和计时我们的函数：
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The code is simple enough: just a basic `timer` and `profiler` decorator printing
    some default statistics. Which functions best for you depends on your use case,
    of course. The `timer()` decorator is very useful for quick performance tracking
    and/or a sanity check while developing. The `profiler()` decorator is great while
    you are actively working on the performance characteristics of a function.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 代码很简单：只是一个基本的 `timer` 和 `profiler` 装饰器打印一些默认统计信息。哪个最适合您取决于您的用例，当然。`timer()`
    装饰器在开发过程中用于快速性能跟踪和/或合理性检查非常有用。`profiler()` 装饰器在您积极工作于函数的性能特征时非常出色。
- en: 'The added advantage of this selective profiling is that the output is more
    limited, which helps with readability, albeit still much more verbose than the
    `timer()` decorator:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选择性分析的附加优势是输出更有限，这有助于可读性，尽管仍然比 `timer()` 装饰器冗长得多：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, the profiler still makes the code about twice as slow, but it’s
    definitely usable.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，分析器仍然使代码大约慢了两倍，但绝对是可用的。
- en: Using profile statistics
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用配置文件统计信息
- en: To get slightly more interesting profiling results, we will profile using the
    `pyperformance.benchmarks.bm_float` script.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更有趣的分析结果，我们将使用 `pyperformance.benchmarks.bm_float` 脚本进行分析。
- en: The `pyperformance` library is the official Python benchmarks library optimized
    for the CPython interpreter. It contains a large (ever-growing) list of benchmarks
    to monitor the performance of the CPython interpreter under many scenarios.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyperformance` 库是针对 CPython 解释器优化的官方 Python 基准测试库。它包含大量（持续增长）的基准测试，以监控 CPython
    解释器在许多场景下的性能。'
- en: 'It can be installed through `pip`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 `pip` 进行安装：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'First, let’s create the statistics using this script:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用此脚本创建统计信息：
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When executing the script, you should get something like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行脚本时，您应该得到类似以下内容：
- en: '[PRE28]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: After running the script, you should have a `bm_float.profile` file containing
    the profiling results. As we can see in the script, these statistics can be viewed
    through the `pstats` module.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本后，您应该有一个包含分析结果的 `bm_float.profile` 文件。正如我们在脚本中所见，这些统计信息可以通过 `pstats` 模块查看。
- en: In some cases, it can be interesting to combine the results from multiple measurements.
    That is possible by specifying multiple files or by using `stats.add(*filenames)`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，结合多个测量的结果可能很有趣。这可以通过指定多个文件或使用 `stats.add(*filenames)` 实现。
- en: The main advantage of saving these profile results to files is that several
    applications support this output and can visualize it in a clearer way. One option
    is SnakeViz, which uses your web browser to render the profile results interactively.
    Also, we have QCacheGrind, a very nice visualizer for profile statistics, but
    which requires some manual compiling to get running or some searching for binaries
    of course.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些配置文件结果保存到文件中的主要优势是，多个应用程序支持这种输出，并且可以以更清晰的方式可视化它。一个选项是 SnakeViz，它使用您的网络浏览器以交互方式渲染配置文件结果。此外，我们还有
    QCacheGrind，这是一个非常好的配置文件统计信息可视化器，但需要一些手动编译才能运行，或者当然需要寻找二进制文件。
- en: Let’s look at the output from QCacheGrind. In the case of Windows, the QCacheGrindWin
    package provides a binary, whereas within Linux it is most likely available through
    your package manager, and with OS X you can try `brew install qcachegrind`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 QCacheGrind 的输出。在 Windows 的情况下，QCacheGrindWin 软件包提供了一个二进制文件，而在 Linux 中，它很可能通过您的软件包管理器提供，而在
    OS X 中，您可以尝试 `brew install qcachegrind`。
- en: 'However, there is one more package you will require: the `pyprof2calltree`
    package. It transforms the `profile` output into a format that QCacheGrind understands.
    So, after a simple `pip install pyprof2calltree`, we can now convert the `profile`
    file into a `callgrind` file:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您还需要一个额外的软件包：`pyprof2calltree` 软件包。它将 `profile` 输出转换为 QCacheGrind 可以理解的格式。因此，在简单的
    `pip install pyprof2calltree` 之后，我们现在可以将 `profile` 文件转换为 `callgrind` 文件：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This results in the running of the `QCacheGrind` application. After switching
    to the appropriate tabs, you should see something like the following screenshot:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致`QCacheGrind`应用程序的运行。切换到适当的标签后，你应该能看到以下截图类似的内容：
- en: '![](img/B15882_12_01.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15882_12_01.png)'
- en: 'Figure 12.1: QCacheGrind'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1：QCacheGrind
- en: For a simple script such as this, pretty much all output works. However, with
    full applications, a tool such as QCacheGrind is invaluable. Looking at the output
    generated by QCacheGrind, it is immediately obvious which process took the most
    time. The structure at the top right shows bigger rectangles if the amount of
    time taken was greater, which is a very useful visualization of the chunks of
    CPU time that were used. The list at the left is very similar to `cProfile` and
    therefore nothing new. The tree at the bottom right can be very valuable or very
    useless, as it is in this case. It shows you the percentage of CPU time taken
    in a function and, more importantly, the relationship of that function with the
    other functions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这样一个简单的脚本，几乎所有的输出都是有效的。然而，对于完整的应用程序，像QCacheGrind这样的工具是无价的。查看QCacheGrind生成的输出，可以立即看出哪个进程花费了最多时间。右上角的布局显示，如果花费的时间更多，则更大的矩形，这是对使用的CPU时间块非常有用的可视化。左边的列表与`cProfile`非常相似，因此没有什么新内容。右下角的树可能非常有价值，也可能毫无价值，就像在这个例子中一样。它显示了函数中占用的CPU时间百分比，更重要的是，该函数与其他函数的关系。
- en: Because these tools scale depending on the input, the results are useful for
    just about any application. Whether a function takes 100 milliseconds or 100 minutes
    makes no difference – the output will show a clear overview of the slow parts,
    which is what we will try to fix.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些工具根据输入进行扩展，因此结果对几乎所有应用程序都很有用。无论函数需要100毫秒还是100分钟，都没有区别——输出将清楚地显示慢的部分，这正是我们试图修复的部分。
- en: Line profiler – Tracking performance per line
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行性能分析器 – 按行跟踪性能
- en: '`line_profiler` is actually not a package that’s bundled with Python, but it’s
    far too useful to ignore. While the regular `profile` module profiles all (sub)functions
    within a certain block, `line_profiler` allows for profiling line *per line* within
    a function. The Fibonacci function is not best suited here, but we can use a prime
    number generator instead. But first, install `line_profiler`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`line_profiler`实际上不是一个与Python捆绑的包，但它非常实用，不能忽视。虽然常规的`profile`模块在某个块内对所有的（子）函数进行性能分析，但`line_profiler`允许对函数中的每一行进行逐行性能分析。斐波那契函数在这里并不适用，但我们可以使用素数生成器。但首先，安装`line_profiler`：'
- en: '[PRE30]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now that we have installed the `line_profiler` module (and with that the `kernprof`
    command), let’s test `line_profiler`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了`line_profiler`模块（以及`kernprof`命令），让我们测试`line_profiler`：
- en: '[PRE31]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You might be wondering where the `profile` decorator is coming from. It originates
    from the `line_profiler` module, which is why we have to run the script with the
    `kernprof` command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道`profile`装饰器是从哪里来的。它起源于`line_profiler`模块，这就是为什么我们必须使用`kernprof`命令运行脚本的原因：
- en: '[PRE32]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As the command says, the results have been written to the `T_08_line_profiler.py.lprof`
    file, so we can now look at the output of that file. For readability, we’ve skipped
    the `Line #` column:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '正如命令所说，结果已经写入`T_08_line_profiler.py.lprof`文件，因此我们现在可以查看该文件的输出。为了便于阅读，我们已跳过`Line
    #`列：'
- en: '[PRE33]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Wonderful output, isn’t it? It makes it trivial to find the slow part within
    a bit of code. Within this code, the slowness is obviously originating from the
    loop, but within other code it might not be that clear.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 多么棒的输出，不是吗？它使得在一段代码中找到慢的部分变得非常简单。在这段代码中，缓慢的原因显然来自循环，但在其他代码中可能并不那么明显。
- en: This module can be added as an IPython extension as well, which enables the
    `%lprun` command within IPython. To load the extension, the `load_ext` command
    can be used from the IPython shell, `%load_ext line_profiler`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块也可以作为IPython扩展添加，这将在IPython中启用`%lprun`命令。要从IPython shell中加载扩展，可以使用`load_ext`命令，`%load_ext
    line_profiler`。
- en: We have seen several methods of measuring CPU performance and execution time.
    Now it’s time to look at how to improve performance. Since this largely applies
    to CPU performance and not memory performance, we will cover that first. Later
    in this chapter, we will take a look at memory usage and leaks.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了几种测量CPU性能和执行时间的方法。现在是时候看看如何提高性能了。由于这主要适用于CPU性能而不是内存性能，我们将首先介绍这一点。在本章的后面部分，我们将探讨内存使用和泄漏。
- en: Improving execution time
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高执行时间
- en: Much can be said about performance optimization, but truthfully, if you have
    read the entire book up to this point, you know most of the Python-specific techniques
    for writing fast code. The most important factor in overall application performance
    will always be the choice of algorithms and, by extension, the data structures.
    Searching for an item within a `list (O(n))` is almost always a worse idea than
    searching for an item in a `dict` or `set (O(1))`, as we have seen in *Chapter
    4*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 关于性能优化可以有很多说法，但说实话，如果你已经阅读了这本书到目前为止的所有内容，你就知道大多数Python特定的快速代码编写技术。整体应用程序性能最重要的因素始终是算法的选择，以及由此扩展的数据结构。在`list`（`O(n)`）中搜索一个项目几乎总是比在`dict`或`set`（`O(1)`）中搜索一个项目更糟糕，正如我们在*第4章*中看到的。
- en: 'Naturally, there are more factors and tricks that can help make your application
    faster. The extremely abbreviated version of all performance tips is quite simple,
    however: do as little as possible. No matter how fast you make your calculations
    and operations, doing nothing at all will always be faster. The following sections
    cover some of the most common performance bottlenecks in Python and test a few
    common assumptions about performance, such as the performance of `try`/`except`
    blocks versus `if` statements, which can have a huge impact in many languages.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，还有更多因素和技巧可以帮助使你的应用程序更快。然而，所有性能提示的极度简略版本非常简单：尽可能少做。无论你使计算和操作多快，什么都不做总是最快的。以下章节将涵盖Python中最常见的性能瓶颈，并测试一些关于性能的常见假设，例如`try`/`except`块与`if`语句的性能，这在许多语言中可能产生巨大的影响。
- en: Some of the tricks in this section will be a trade-off between memory and execution
    time; others will trade readability with performance. When in doubt, go for readability
    by default and only improve performance if you have to.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的一些技巧将在内存和执行时间之间进行权衡；其他技巧则会在可读性和性能之间进行权衡。当不确定时，默认选择可读性，并且只有在必要时才提高性能。
- en: Using the right algorithm
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正确的算法
- en: 'Within any application, the right choice of algorithm is by far the most important
    performance characteristic, which is why I am repeating it to illustrate the results
    of a bad choice. Consider the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何应用程序中，选择正确的算法无疑是最重要的性能特征，这就是为什么我要重复强调这一点，以说明错误选择的结果。考虑以下情况：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Checking whether an item is within a `list` is an `O(n)` operation, and checking
    whether an item is within a `dict` is an `O(1)` operation. This makes a huge difference
    when `n=1000000`; in this simple test, we can see that for 1 million items, it’s
    300,000 times faster.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一个项目是否在`list`中是一个`O(n)`操作，而检查一个项目是否在`dict`中是一个`O(1)`操作。当`n=1000000`时，这会带来巨大的差异；在这个简单的测试中，我们可以看到对于一百万个项目，它快了300,000倍。
- en: The big-O notation ( `O(...)`) is covered in more detail in *Chapter 4*, but
    we can provide a quick recap.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 大O符号（`O(...)`）在*第4章*中有更详细的介绍，但我们可以提供一个快速回顾。
- en: '`O(n)` means that for a `list` with `len(some_list) = n`, it will take `n`
    steps to perform the operation. Consequently, `O(1)` means that it takes a constant
    amount of time regardless of the size of the collection.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`O(n)`表示对于`len(some_list) = n`的`list`，执行操作需要`n`步。因此，`O(1)`表示无论集合的大小如何，它都需要恒定的时间。'
- en: All other performance tips combined might make your code twice as fast, but
    using the right algorithm for the job can cause a much greater improvement. Using
    an algorithm that takes `O(n)` time instead of `O(n`²`)` time will make your code
    `1000` times faster for `n=1000`, and with a larger `n`, the difference only grows
    further.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他性能提示加在一起可能使你的代码速度提高一倍，但使用适合工作的正确算法可以带来更大的改进。使用一个需要`O(n)`时间而不是`O(n²)`时间的算法，当`n=1000`时，将使你的代码快`1000`倍，而对于更大的`n`，差异只会进一步扩大。
- en: Global interpreter lock
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全局解释器锁
- en: One of the most obscure components of the CPython interpreter is the **global
    interpreter lock** (**GIL**), a **mutual exclusion lock** (**mutex**) required
    to prevent memory corruption. The Python memory manager is not thread-safe, which
    is why the GIL is needed. Without the GIL, multiple threads might alter memory
    at the same time, causing all sorts of unexpected and potentially dangerous results.
    The GIL is covered in much more detail in *Chapter 14*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: CPython解释器中最神秘的部分之一是**全局解释器锁**（**GIL**），这是一个**互斥锁**（**mutex**），用于防止内存损坏。Python内存管理器不是线程安全的，这就是为什么需要GIL。没有GIL，多个线程可能会同时更改内存，导致各种意外和可能危险的结果。GIL在*第14章*中有更详细的介绍。
- en: What is the impact of the GIL in a real-life application? Within single-threaded
    applications, it makes no difference whatsoever and is actually an extremely fast
    method for memory consistency.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: GIL在现实生活中的应用有什么影响？在单线程应用程序中，它没有任何区别，实际上是一种非常快速的内存一致性方法。
- en: Within multithreaded applications, however, it can slow your application down
    a bit because only a single thread can access the GIL at a time. If your code
    has to access the GIL a lot, it might benefit from some restructuring.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在多线程应用程序中，这可能会稍微减慢你的应用程序，因为一次只能有一个线程访问GIL。如果你的代码需要频繁访问GIL，那么进行一些重构可能会有所帮助。
- en: Luckily, Python offers a few other options for parallel processing. The `asyncio`
    module, which we will see in *Chapter 13*, can help a lot by switching tasks whenever
    you are waiting for a slow operation. In *Chapter 14*, we will see the `multiprocessing`
    library, which allows us to use multiple processors simultaneously.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Python提供了一些其他并行处理选项。我们将在*第13章*中看到的`asyncio`模块，可以通过在等待慢速操作时切换任务来提供很大帮助。在第14章中，我们将看到`multiprocessing`库，它允许我们同时使用多个处理器。
- en: try versus if
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: try与if
- en: In many languages, a `try/except` type of block incurs quite a performance hit,
    but within Python, this is *not* the case as long as you don’t hit the `except`
    block. If you do hit an `except`, it will be slightly heavier than an `if` statement,
    but not enough to be noticeable in most cases.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多语言中，`try/except`类型的块会带来相当大的性能损失，但在Python中，只要你没有进入`except`块，这并不是问题。如果你触发了`except`，它可能比`if`语句稍微重一些，但在大多数情况下并不明显。
- en: It’s not that an `if` statement is heavy, but if you expect your `try/except`
    to succeed most of the time and only fail in rare cases, it is definitely a valid
    alternative. As always though, focus on readability and conveying the purpose
    of the code. If the intention of the code is clearer using an `if` statement,
    use the `if` statement. If `try`/`except` conveys the intention in a better way,
    use that.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 并非`if`语句本身很重，而是如果你预期你的`try/except`在大多数情况下都会成功，只有在罕见情况下才会失败，那么这绝对是一个有效的替代方案。但是，一如既往地，要关注可读性和传达代码的目的。如果代码的意图使用`if`语句更清晰，就使用`if`语句。如果`try`/`except`以更好的方式传达意图，就使用它。
- en: 'Most programming languages depend on the use of the **Look Before You Leap**
    (**LBYL**) ideology. This means that you always check before you try, so if you
    are getting `some_key` from a `dict`, you use:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编程语言都依赖于**LBYL（先检查后执行**）理念。这意味着你在尝试之前总是进行检查，所以如果你要从`dict`中获取`some_key`，你应该使用：
- en: '[PRE35]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Because you are always doing the `if`, it hints that `some_key` is usually not
    part of `some_dict`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你总是在做`if`，这暗示`some_key`通常不是`some_dict`的一部分。
- en: 'Within Python, it is common to use the **Easier to Ask for Forgiveness than
    Permission** (**EAFP**) ideology when applicable. This means that the code assumes
    everything will work, but still catches errors:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，当适用时，通常使用**EAFP（先做后检查**）理念。这意味着代码假设一切都会按预期工作，但仍然会捕获错误：
- en: '[PRE36]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: These two examples function mostly the same, but the latter gives the idea that
    you expect the key to be available and will catch errors if needed. This is one
    of the cases where the Zen of Python (explicit is better than implicit) applies.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个例子功能上大致相同，但后者给出了你期望键是可用的，并在需要时捕获错误的印象。这是Python的Zen（明确优于隐含）适用的一个案例。
- en: 'The only caveat of the code above is that you might accidentally catch a `KeyError`
    from `process_value()`, so if you want to avoid that you should use the following
    code instead:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的唯一缺点是，你可能会意外地捕获`process_value()`的`KeyError`，所以如果你想避免这种情况，你应该使用以下代码：
- en: '[PRE37]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Which one you use comes mostly down to personal preference, but the takeaway
    should be that, with Python, both options are perfectly valid and will perform
    similarly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用哪个主要取决于个人喜好，但应该记住的是，在Python中，这两种选项都是完全有效的，并且性能相似。
- en: Lists versus generators
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列表与生成器
- en: Evaluating code lazily using generators is almost always a better idea than
    calculating the entire dataset. The most important rule of performance optimization
    is probably that you shouldn’t calculate anything you’re not going to use. If
    you’re not sure that you are going to need it, don’t calculate it.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成器懒加载代码几乎总是比计算整个数据集更好。性能优化的最重要规则可能是你不应该计算你不会使用的东西。如果你不确定你是否需要它，就不要计算它。
- en: Don’t forget that you can easily chain multiple generators, so everything is
    calculated only when it’s actually needed. Do be careful that this won’t result
    in recalculation though; `itertools.tee()` is generally a better idea than recalculating
    your results completely.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记你可以轻松地链式多个生成器，这样只有在实际需要时才会进行计算。但务必小心，这不会导致重复计算；通常来说，使用`itertools.tee()`比完全重新计算结果更好。
- en: 'To recap `itertools.tee()` from *Chapter 7*, a regular generator can only be
    consumed once, so if you need to process the results two or more times, you can
    use `itertools.tee()` to store the intermediate results:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下*第7章*中提到的`itertools.tee()`，一个常规生成器只能被消费一次，所以如果你需要两次或更多次处理结果，可以使用`itertools.tee()`来存储中间结果：
- en: '[PRE38]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As you can see, if you forget to use `itertools.tee()` here, you would only
    process the results once, and both would process different values. The alternative
    fix is to use `list()` and store the intermediate results, but this can cost much
    more memory, and you are required to pre-calculate all items without knowing whether
    you actually need them all.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，如果你忘记在这里使用`itertools.tee()`，你只会处理一次结果，并且它们会处理不同的值。另一种修复方法是使用`list()`并存储中间结果，但这会消耗更多的内存，并且你需要预先计算所有项目，而不知道你是否真的需要它们。
- en: String concatenation
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字符串连接
- en: 'You might have seen benchmarks saying that using `+=` is much slower than joining
    strings because the `str` object (as is the case with `bytes`) is immutable. The
    result is that every time you do `+=` on a string, it will have to create a new
    object. At one point, this made quite a lot of difference indeed. With Python
    3, however, most of the differences have vanished:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能看到过基准测试说使用`+=`比连接字符串慢得多，因为`str`对象（就像`bytes`一样）是不可变的。结果是每次你在字符串上使用`+=`时，它都必须创建一个新的对象。在某个时刻，这确实造成了很大的差异。然而，在Python
    3中，大多数差异都已经消失了：
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: There are still some differences, of course, but they are so small that I recommend
    you simply ignore them and choose the most readable option instead.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有一些差异，但它们非常小，我建议你简单地忽略它们，并选择最易读的选项。
- en: Addition versus generators
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加与生成器的比较
- en: 'As is the case with string concatenation, addition from a loop was significantly
    slower with older Python versions, but the difference is now too small to consider:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 就像字符串连接一样，在较老的Python版本中，循环中的添加操作速度显著较慢，但现在差异已经小到可以忽略不计：
- en: '[PRE40]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: What does help, though, is letting Python handle everything internally using
    native functions, as can be seen in the last example.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，真正有帮助的是让Python使用原生函数内部处理所有操作，正如最后一个例子所示。
- en: Map versus generators and list comprehensions
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`map()`与生成器和列表推导式的比较'
- en: 'Once again, readability generally counts more than performance, so only rewrite
    for performance if it really makes a difference. There are a few cases where `map()`
    is faster than list comprehensions and generators, but only if the `map()` function
    can use a predefined function. As soon as you need to whip out `lambda`, it’s
    actually slower. Not that it matters much, since readability should be key anyhow.
    If `map()` makes your code more readable than a generator or list comprehension,
    feel free to use it. Otherwise, I would not recommend it:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，可读性通常比性能更重要，所以只有在确实有影响的情况下才进行重写。有些情况下`map()`比列表推导式和生成器快，但这仅限于`map()`函数可以使用预定义函数的情况。一旦你需要使用`lambda`，实际上会更慢。不过这并不重要，因为可读性应该是关键。如果`map()`使你的代码比生成器或列表推导式更易读，那么你可以自由使用它。否则，我不推荐使用它：
- en: '[PRE41]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: As you can see, the list comprehension is quite a bit faster than the generator.
    In many cases, I would still recommend the generator over the list comprehension,
    though, if only because of the memory usage and the potential laziness.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，列表推导式比生成器快得多。在许多情况下，我仍然会推荐使用生成器而不是列表推导式，这主要是因为内存使用和潜在的惰性。
- en: If, for some reason, you are only going to use the first 10 items when generating
    1,000 items, you’re still wasting a lot of resources by calculating the full list
    of items.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在生成1,000个项目时，你只打算使用前10个项目，那么计算完整的项目列表仍然会浪费很多资源。
- en: Caching
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存
- en: We have already covered the `functools.lru_cache` decorator in *Chapter 6*,
    *Decorators – Enabling Code Reuse by Decorating*, but its importance should not
    be underestimated. Regardless of how fast and smart your code is, not having to
    calculate results is always better and that’s what caching does. Depending on
    your use case, there are many options available. Within a simple script, `functools.lru_cache`
    is a very good contender, but between multiple executions of an application, the
    `cPickle` module can be a lifesaver as well.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 *第6章* 中介绍了 `functools.lru_cache` 装饰器，*装饰器 – 通过装饰实现代码重用*，但它的作用不容小觑。无论你的代码有多快、多聪明，不需要计算结果总是更好的，这正是缓存的作用。根据你的使用场景，有许多选项可供选择。在一个简单的脚本中，`functools.lru_cache`
    是一个非常好的选择，但在应用程序的多次执行之间，`cPickle` 模块也可以成为救命稻草。
- en: We have already seen the effects of this with the `fibonacci_cached` function
    in the `cProfile` section of this chapter, which uses `functools.lru_cache()`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的 `cProfile` 部分已经看到了 `fibonacci_cached` 函数的这种影响，该函数使用了 `functools.lru_cache()`。
- en: 'There are several scenarios where you need a more powerful solution, however:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有几个场景需要更强大的解决方案：
- en: If you need caching between multiple executions of a script
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要在脚本多次执行之间进行缓存
- en: If you need caching shared across multiple processes
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要跨多个进程共享缓存
- en: If you need caching shared across multiple servers
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要在多个服务器之间共享缓存
- en: At least for the first two scenarios, you could write the cache to a local pickle/CSV/JSON/YAML/DBM/etc.
    file. This is a perfectly valid solution that I use often.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 至少对于前两种场景，你可以将缓存写入本地 pickle/CSV/JSON/YAML/DBM 等文件。这是一个完全有效的解决方案，我经常使用。
- en: If you need a more powerful solution, however, I can highly recommend taking
    a look at **Redis**. The Redis server is a fully in-memory server that is extremely
    fast and has many useful data structures available. If you see articles or tutorials
    about improving performance using Memcached, simply replace Memcached with Redis
    everywhere. Redis is superior to Memcached in every way and, in its most basic
    form, the API is compatible.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要更强大的解决方案，我强烈建议查看 **Redis**。Redis 服务器是一个完全基于内存的服务器，速度极快，并提供许多有用的数据结构。如果你看到有关使用
    Memcached 提高性能的文章或教程，只需将 Memcached 替换为 Redis 即可。Redis 在各个方面都优于 Memcached，并且在其最基本的形式中，API
    是兼容的。
- en: Lazy imports
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 懒加载导入
- en: A common problem in application load times is that everything is loaded immediately
    at the start of the program while, with many applications, this is actually not
    needed and certain parts of the application only require loading when they are
    actually used. To facilitate this, you can occasionally move the imports inside
    of functions so they can be loaded on demand.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序加载时间的一个常见问题是，程序开始时立即加载所有内容，而实际上，对于许多应用程序来说，这实际上并不需要，应用程序的某些部分只有在实际使用时才需要加载。为了方便起见，你可以偶尔将导入移动到函数内部，以便按需加载。
- en: 'While it’s a valid strategy in some cases, I don’t generally recommend it for
    two reasons:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在某些情况下这是一个有效的策略，但我通常不推荐以下两个原因：
- en: It makes your code less clear; having all imports in the same style at the top
    of the file improves readability.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它会使你的代码更不清晰；将所有导入以相同风格放在文件顶部可以提高可读性。
- en: It doesn’t make the code faster as it just moves the load time to a different
    part.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它并不会使代码更快，因为它只是将加载时间移到了不同的部分。
- en: Using slots
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 slots
- en: 'The `__slots__` feature was written by Guido van Rossum to enhance Python performance.
    Effectively what the `__slots__` feature does is specify a fixed list of attributes
    for a class. When `__slots__` are used, several changes are made to a class and
    several (side-)effects must be considered:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`__slots__` 功能是由 Guido van Rossum 编写的，旨在提高 Python 性能。实际上，`__slots__` 功能的作用是为类指定一个固定的属性列表。当使用
    `__slots__` 时，会对类进行一些更改，并必须考虑一些（副作用）：'
- en: All attributes must be explicitly named in the `__slots__`. It is not possible
    to do `some_instance.some_variable = 123` if `some_variable` is not in `__slots__`.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有属性都必须在 `__slots__` 中显式命名。如果 `some_variable` 不在 `__slots__` 中，则无法执行 `some_instance.some_variable
    = 123`。
- en: Because the list of attributes is fixed in `__slots__`, there is no longer any
    need for a `__dict__` attribute, which saves memory.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 `__slots__` 中的属性列表是固定的，因此不再需要 `__dict__` 属性，这节省了内存。
- en: Attribute access is faster because there is no intermediate lookup through `__dict__`.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性访问更快，因为没有通过 `__dict__` 进行中间查找。
- en: It is not possible to use multiple inheritance if both parents have defined
    `__slots__`.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果两个父类都定义了 `__slots__`，则无法使用多重继承。
- en: 'So, how much performance benefit can `__slots__` give us? Well, let’s give
    it a test:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，`__slots__`能给我们带来多少性能上的好处呢？让我们来测试一下：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'When we actually run this code, we can definitely see some improvements from
    using `__slots__`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们实际运行这段代码时，我们可以肯定地看到使用`__slots__`带来的某些改进：
- en: '[PRE43]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: In most cases, I would argue that the 5-15% difference in performance isn’t
    going to help you that much. However, if it’s applied to a bit of code that is
    near the core of your application and executed very often, it can help.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，我会说5-15%的性能差异并不会对你有很大帮助。然而，如果它应用于接近应用程序核心且经常执行的一小段代码，它可能会有所帮助。
- en: Don’t expect miracles from this method, but use it when you need it.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 不要期望这种方法能带来奇迹，但当你需要时请使用它。
- en: Using optimized libraries
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用优化库
- en: This is actually a very broad tip, but useful nonetheless. If there’s a highly
    optimized library that suits your purpose, you most likely won’t be able to beat
    its performance without a significant amount of effort. Libraries such as `numpy`,
    `pandas`, `scipy`, and `sklearn` are highly optimized for performance and their
    native operations can be incredibly fast. If they suit your purpose, be sure to
    give them a try.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常广泛的建议，但仍然很有用。如果你有一个高度优化的库适合你的目的，你很可能无法在不付出大量努力的情况下超越其性能。例如`numpy`、`pandas`、`scipy`和`sklearn`等库在性能上高度优化，它们的原生操作可以非常快。如果它们适合你的目的，请务必尝试一下。
- en: 'Before you can use `numpy`, you need to install it: `pip3 install numpy.`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在你能够使用`numpy`之前，你需要安装它：`pip3 install numpy`。
- en: 'Just to illustrate how fast `numpy` can be compared to plain Python, refer
    to the following:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 仅为了说明`numpy`与纯Python相比有多快，请参考以下内容：
- en: '[PRE44]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `numpy` code does exactly the same as the Python code, except that it uses
    `numpy` arrays instead of Python lists. This little difference has made the code
    more than 25 times faster.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`numpy`代码与Python代码完全相同，只是它使用`numpy`数组而不是Python列表。这个小小的差异使得代码的速度提高了25倍以上。'
- en: Just-in-time compiling
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 即时编译
- en: '**Just-in-time** (**JIT**) compiling is a method of dynamically compiling (parts
    of) an application during runtime. Because there is much more information available
    at runtime, this can have a huge effect and make your application much faster.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**即时编译**（**JIT**）是一种在运行时动态编译（应用程序的）部分的方法。因为运行时可以提供更多信息，这可以产生巨大的影响，使你的应用程序运行得更快。'
- en: 'When it comes to JIT compiling, you currently have three options:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到即时编译时，你目前有三个选项：
- en: '**Pyston**: An alternative, currently Linux only, CPython-compatible Python
    interpreter.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pyston**：一个替代品，目前仅支持Linux，是CPython兼容的Python解释器。'
- en: '**Pypy**: A really fast alternative Python interpreter without full CPython
    compatibility.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pypy**：一个真正快速的替代Python解释器，但不完全兼容CPython。'
- en: '**Numba**: A package that allows for JIT compiling per function and execution
    on either the CPU or the GPU.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Numba**：一个允许按函数进行即时编译并在CPU或GPU上执行的包。'
- en: '**CPython 3.12 and 3.13**? At the time of writing, there is little concrete
    data about the upcoming Python releases, but there are plans to greatly increase
    the CPython interpreter performance. How much will be achieved and how well it
    will work is currently unknown, but the ambitious plan is to make CPython 5x faster
    over the next 5 releases (with 3.10 being the first in the series). The expectation
    is to add JIT compiling in CPython 3.12 and extend that further in 3.13\.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPython 3.12和3.13**？在撰写本文时，关于即将发布的Python版本的数据很少，但有计划大幅提高CPython解释器的性能。具体能实现多少以及效果如何目前尚不清楚，但雄心勃勃的计划是在接下来的5个版本中使CPython快5倍（3.10是该系列的第一版）。预期将在CPython
    3.12中添加即时编译，并在3.13中进一步扩展。'
- en: If you are looking for global JIT compiling in existing projects, I can currently
    recommend trying Pyston. It is a CPython fork that promises about a 30% performance
    increase without having to change any code. In addition, because it is CPython-compatible,
    you can still use regular CPython modules.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在寻找在现有项目中实现全局即时编译，我目前可以推荐尝试Pyston。它是一个CPython分支，承诺在不修改任何代码的情况下提高大约30%的性能。此外，因为它与CPython兼容，你仍然可以使用常规的CPython模块。
- en: The downside is that it currently only supports Linux systems and, as will always
    be the case with forks, it’s behind the current Python version. At the time of
    writing, CPython is at Python 3.10.1, whereas Pyston is at Python 3.8.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它的缺点是目前仅支持Linux系统，并且，正如分支通常的情况一样，它落后于当前的Python版本。在撰写本文时，CPython是Python 3.10.1，而Pyston是Python
    3.8。
- en: If compatibility with all CPython modules is not a requirement for you and you
    don’t require Python features that are too recent, PyPy3 can also offer amazing
    performance in many cases. They are up to Python 3.7, whereas the main Python
    release is at 3.10.1 at the time of writing. That makes PyPy roughly 2-3 years
    behind CPython in terms of features, but I doubt this is a big issue. The differences
    between Python 3.7, 3.8, 3.9, and 3.10 are largely incremental and Python 3.7
    is already a very well-rounded Python version.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不需要与所有 CPython 模块兼容，并且不需要 Python 中太新的功能，PyPy3 在许多情况下也可以提供惊人的性能。它们支持到 Python
    3.7，而主 Python 版本在撰写本文时是 3.10.1。这使得 PyPy 在功能上比 CPython 约落后 2-3 年，但我怀疑这不会是一个大问题。Python
    3.7、3.8、3.9 和 3.10 之间的差异主要是增量性的，而 Python 3.7 已经是一个非常完善的 Python 版本。
- en: The `numba` package provides selective JIT compiling for you, allowing you to
    mark the functions that are JIT compiler-compatible. Essentially, if your functions
    follow the functional programming paradigm of basing the calculations only on
    the input, then it will most likely work with the JIT compiler.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`numba` 包为你提供了选择性的 JIT 编译，允许你标记与 JIT 编译器兼容的函数。本质上，如果你的函数遵循仅基于输入进行计算的函数式编程范式，那么它很可能与
    JIT 编译器兼容。'
- en: 'Here is a basic example of how the `numba` JIT compiler can be used:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个如何使用 `numba` JIT 编译器的基本示例：
- en: '[PRE45]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If you are using `numpy` or `pandas`, you will most likely benefit from looking
    at `numba`.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 `numpy` 或 `pandas`，你很可能从查看 `numba` 中受益。
- en: Another very interesting fact to note is that `numba` supports not only CPU-optimized
    execution, but GPU as well. This means that for certain operations you can use
    the fast processor in your video card to process the results.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的有趣事实是，`numba` 不仅支持 CPU 优化的执行，还支持 GPU。这意味着对于某些操作，你可以使用显卡中的快速处理器来处理结果。
- en: Converting parts of your code to C
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将代码的部分转换为 C
- en: We will see more about this in *Chapter 17*, *Extensions in C/C++, System Calls,
    and C/C++ Libraries*, but if high performance is really required, then a native
    C function can help quite a lot. This doesn’t even have to be that difficult;
    the Cython module makes it trivial to write parts of your code with performance
    very close to native C code.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第 17 章“C/C++ 扩展、系统调用和 C/C++ 库”中了解更多关于这个内容，但如果确实需要高性能，那么一个本地的 C 函数可以非常有帮助。这甚至不必那么困难；Cython
    模块使得用接近原生 C 代码的性能编写代码的部分变得非常简单。
- en: 'The following is an example from the Cython manual to approximate the value
    of pi:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个来自 Cython 手册的示例，用于估算 π 的值：
- en: '[PRE46]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: While there are some small differences, such as `cdef` instead of `def` and
    type definitions such as `int i` instead of just `i` for the values and parameters,
    the code is largely the same as regular Python would be, but certainly much faster.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有一些小的差异，例如 `cdef` 而不是 `def`，以及类型定义，如 `int i` 而不是仅仅 `i` 用于值和参数，但代码在很大程度上与常规
    Python 相同，但肯定要快得多。
- en: Memory usage
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存使用
- en: So far, we have simply looked at the execution times and largely ignored the
    memory usage of the scripts. In many cases, the execution times are the most important,
    but memory usage should not be ignored. In almost all cases, CPU and memory are
    traded; an algorithm either uses a lot of CPU time or a lot of memory, which means
    that both do matter a lot.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只是简单地查看执行时间，而很大程度上忽略了脚本的内存使用。在许多情况下，执行时间是最重要的，但内存使用不应被忽视。在几乎所有情况下，CPU
    和内存都是可以互换的；一个算法要么使用大量的 CPU 时间，要么使用大量的内存，这意味着两者都很重要。
- en: 'Within this section, we are going to look at:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨以下内容：
- en: Analyzing memory usage
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析内存使用
- en: When Python leaks memory and how to avoid these scenarios
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 Python 泄露内存以及如何避免这些情况
- en: How to reduce memory usage
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何减少内存使用
- en: tracemalloc
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tracemalloc
- en: 'Monitoring memory usage used to be something that was only possible through
    external Python modules such as **Dowser** or **Heapy**. While those modules still
    work, they are partially obsolete now because of the `tracemalloc` module. Let’s
    give the `tracemalloc` module a try to see how easy memory usage monitoring is
    nowadays:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 监控内存使用曾经是通过外部 Python 模块，如 **Dowser** 或 **Heapy** 来实现的。虽然这些模块仍然有效，但现在由于 `tracemalloc`
    模块的存在，它们部分已经过时。让我们尝试一下 `tracemalloc` 模块，看看现在监控内存使用有多简单：
- en: '[PRE47]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This results in:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致：
- en: '[PRE48]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: You can easily see how every part of the code allocated memory and where it
    might be wasted. While it might still be unclear which part was actually causing
    the memory usage, there are options for that as well, as we will see in the following
    sections.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以很容易地看到代码的每一部分分配了多少内存，以及它可能在哪些地方被浪费。虽然可能仍然不清楚哪个部分实际上导致了内存使用，但也有一些选项，我们将在以下章节中看到。
- en: Memory Profiler
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存分析器
- en: 'The `memory_profiler` module is very similar to `line_profiler` discussed earlier,
    but for memory usage instead. Installing it is as easy as `pip install memory_profiler`,
    but the optional `pip install psutil` is also highly recommended (and required
    in the case of Windows) as it increases your performance by a large amount. To
    test `memory_profiler`, we will use the following script:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory_profiler` 模块与之前讨论的 `line_profiler` 非常相似，但用于内存使用。安装它就像 `pip install
    memory_profiler` 一样简单，但强烈推荐（在 Windows 上是必需的）安装可选的 `pip install psutil`，因为它可以大幅提高你的性能。为了测试
    `memory_profiler`，我们将使用以下脚本：'
- en: '[PRE49]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Note that we actually import `memory_profiler` here although that is not strictly
    required. It can also be executed through `python3 -m memory_profiler your_scripts.py`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在这里实际上导入了 `memory_profiler`，尽管这不是严格必要的。它也可以通过 `python3 -m memory_profiler
    your_scripts.py` 执行：
- en: '[PRE50]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Even though everything runs as expected, you might be wondering about the varying
    amounts of memory used by the lines of code here.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一切运行如预期，但你可能仍在想这里代码行使用的内存量为何会有所不同。
- en: Why does `e` take `9.8 MiB` and `f` `5.0 MiB`? This is caused by the Python
    memory allocation code; it reserves memory in larger blocks, which is subdivided
    and reused internally. Another problem is that `memory_profiler` takes snapshots
    internally, which results in memory being attributed to the wrong variables in
    some cases. The variations should be small enough not to make a large difference
    in the end, but some changes are to be expected.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么 `e` 占用 `9.8 MiB` 而 `f` 占用 `5.0 MiB`？这是由 Python 内存分配代码引起的；它以较大的块保留内存，这些块在内部细分并重复使用。另一个问题是
    `memory_profiler` 在内部进行快照，这导致在某些情况下内存被错误地分配给错误的变量。这些变化应该足够小，不会在最终结果中造成大的差异，但一些变化是可以预见的。
- en: 'This module can be added as an IPython extension as well, which enables the
    `%mprun` command within IPython. To load the extension, the `load_ext` command
    can be used from the IPython shell: `%load_ext memory_profiler`. Another very
    useful command is `%memit`, which is the memory equivalent of the `%timeit` command.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块也可以作为 IPython 扩展添加，这将在 IPython 中启用 `%mprun` 命令。要从 IPython 壳中加载扩展，可以使用 `load_ext`
    命令：`%load_ext memory_profiler`。另一个非常有用的命令是 `%memit`，它是 `%timeit` 命令的内存等效命令。
- en: Memory leaks
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存泄漏
- en: 'The usage of these modules will generally be limited to the search for memory
    leaks. In particular, the `tracemalloc` module has a few features to make that
    fairly easy. The Python memory management system is fairly straightforward; it
    has a simple reference counter to see whether an object is (still) used. While
    this works great in most cases, it can easily introduce memory leaks when circular
    references are involved. The basic premise of a memory leak with leak detection
    code looks like this:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模块的使用通常限于搜索内存泄漏。特别是，`tracemalloc` 模块有几个功能使得这变得相当容易。Python 内存管理系统相当简单；它有一个简单的引用计数器来查看对象是否（仍然）被使用。虽然这在大多数情况下工作得很好，但当涉及到循环引用时，它很容易引入内存泄漏。带有泄漏检测代码的内存泄漏的基本原理如下：
- en: '[PRE51]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The line numbers in the code above are provided as a reference for the `tracemalloc`
    output and are not functionally part of the code.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码中的行号提供为 `tracemalloc` 输出的参考，并且不是代码的功能部分。
- en: The big problem in this code is that we have two objects that are referencing
    each other. As we can see, `a.b` is referencing `b`, and `b.a` is referencing
    `a`. This loop makes it so that Python doesn’t immediately understand that the
    objects can be safely deleted from memory.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码中的大问题是，我们有两个相互引用的对象。正如我们所见，`a.b` 引用了 `b`，而 `b.a` 引用了 `a`。这个循环使得 Python 无法立即理解这些对象可以从内存中安全删除。
- en: 'Let’s see how badly this code is actually leaking:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这段代码实际上泄漏有多严重：
- en: '[PRE52]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This example shows a leak of 22.1 megabytes due to the nearly 200,000 instances
    of `SomeClass`. Python correctly lets us know that this memory was allocated at
    lines 24 and 25, which can really help when trying to ascertain what is causing
    the memory usage in your application.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子显示了由于近 200,000 个 `SomeClass` 实例而导致的 22.1 兆字节的泄漏。Python 正确地让我们知道，这段内存是在第
    24 行和第 25 行分配的，这真的有助于在尝试确定应用程序中导致内存使用的部分时。
- en: The Python garbage collector (`gc`) is smart enough to clean circular references
    like these eventually, but it won’t clean them until a certain limit is reached.
    More about that soon.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: Python垃圾回收器（`gc`）足够智能，最终会清理像这样的循环引用，但它不会在达到一定限制之前清理它们。关于这一点，我们稍后会详细介绍。
- en: Circular references
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环引用
- en: 'Whenever you want to have a circular reference that does not cause memory leaks,
    the `weakref` module is available. It creates references that don’t count toward
    the object reference count. Before we look at the `weakref` module, let’s take
    a look at the object references themselves through the eyes of the Python garbage
    collector (`gc`):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要有一个不会引起内存泄漏的循环引用时，`weakref`模块是可用的。它创建的引用不计入对象引用计数。在我们查看`weakref`模块之前，让我们通过Python垃圾回收器（`gc`）的眼睛来看看对象引用本身：
- en: '[PRE53]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: First, we create two instances of `SomeClass` and add some circular references
    between them. Once that is done, we delete them from memory, except that they
    are not actually deleted until the garbage collector runs.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了两个`SomeClass`的实例，并在它们之间添加了一些循环引用。一旦完成，我们就从内存中删除它们，但它们实际上并不会被删除，直到垃圾回收器运行。
- en: To verify this, we inspect the objects in memory through `gc.get_objects()`,
    and until we tell the garbage collector to manually collect, they stay in memory.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这一点，我们通过`gc.get_objects()`检查内存中的对象，直到我们告诉垃圾回收器手动收集，它们都会保留在内存中。
- en: 'Once we do run `gc.collect()` to manually call the garbage collector, the objects
    are gone from memory:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们运行`gc.collect()`来手动调用垃圾回收器，对象就会从内存中消失：
- en: '[PRE54]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Now, you might wonder, are you always required to manually call `gc.collect()`
    to remove these references? No, that is not needed, as the Python garbage collector
    will automatically collect once thresholds have been reached.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可能会想知道，您是否总是需要手动调用`gc.collect()`来删除这些引用？不，这不是必需的，因为Python垃圾回收器会在达到阈值时自动收集。
- en: By default, the thresholds for the Python garbage collector are set to `700,
    10, 10` for the three generations of collected objects. The collector keeps track
    of all the memory allocations and deallocations in Python, and as soon as the
    number of allocations minus the number of deallocations reaches `700`, the object
    is either removed if it’s not referenced anymore, or it is moved to the next generation
    if it still has a reference. The same is repeated for generations 2 and 3, albeit
    with the lower thresholds of 10.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Python垃圾回收器的阈值设置为`700, 10, 10`，用于收集三个代的对象。收集器跟踪Python中的所有内存分配和释放，一旦分配的数量减去释放的数量达到`700`，对象要么不再被引用时被移除，要么如果它仍然有引用，则移动到下一代。对于第2代和第3代也是如此，尽管阈值较低为10。
- en: 'This begs the question: where and when is it useful to manually call the garbage
    collector? Since the Python memory allocator reuses blocks of memory and only
    rarely releases it, for long-running scripts the garbage collector can be very
    useful. That’s exactly where I recommend its usage: long-running scripts in memory-strapped
    environments and, specifically, right before you **allocate** a large amount of
    memory. If you call the garbage collector before doing a memory-intensive operation,
    you can maximize the amount of reuse of the memory that Python has previously
    reserved.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了一个问题：在哪里以及何时手动调用垃圾回收器是有用的？由于Python内存分配器会重用内存块，并且很少释放它们，对于长时间运行的脚本，垃圾回收器非常有用。这正是我推荐使用它的地方：在内存受限的环境中长时间运行的脚本，以及在您**分配**大量内存之前。如果您在执行内存密集型操作之前调用垃圾回收器，您可以最大限度地提高Python之前预留的内存的重用率。
- en: Analyzing memory usage using the garbage collector
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用垃圾回收器分析内存使用情况
- en: 'The `gc` module can help you a lot when looking for memory leaks as well. The
    `tracemalloc` module can show you the parts that take the most memory in bytes,
    but the `gc` module can help you find the most commonly occurring object types
    (for example, `SomeClass`, `int`, and `list`). Just be careful when setting the
    garbage collector debug settings such as `gc.set_debug(gc.DEBUG_LEAK)`; this returns
    a large amount of output even if you don’t reserve any memory yourself. Let’s
    see the output for one of the most basic scripts you can get:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`gc`模块在查找内存泄漏时也能帮您很多忙。`tracemalloc`模块可以显示占用最多内存的字节数，但`gc`模块可以帮助您找到最常出现的对象类型（例如，`SomeClass`、`int`和`list`）。只是在设置垃圾回收器调试设置（如`gc.set_debug(gc.DEBUG_LEAK)`）时要小心；即使您没有预留任何内存，这也会返回大量的输出。让我们看看最基本脚本之一的结果：'
- en: '[PRE55]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now, when we run the code, you can see a bit of what has been added to our
    memory with such a simple script:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们运行代码时，你可以看到这样一个简单的脚本添加到我们的内存中的内容：
- en: '[PRE56]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: As you can see, there are actually 42 different types of objects that should
    have been shown here, but even without that, the number of different objects in
    memory is impressive, if you ask me. With just a little bit of extra code, the
    output can quickly explode and become unusable without significant filtering.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，实际上有42种不同的对象类型应该在这里显示，但即使没有这些，内存中不同对象的数量也相当惊人，至少在我看来。只需一点额外的代码，输出就可以迅速爆炸，如果没有显著的过滤，将变得无法使用。
- en: Weak references
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 弱引用
- en: An easy method to make the work easier for the garbage collector is to use **weak
    references**. These are references to variables that are not included when counting
    the references to a variable. Since the garbage collector removes an object from
    memory when its reference count gets to zero, this can help a lot with memory
    leaks.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让垃圾收集器的工作变得更简单的一个简单方法是使用**弱引用**。这些是对变量的引用，在计算变量的引用数时不会被包括在内。由于垃圾收集器在引用计数达到零时从内存中删除对象，这可以帮助大量减少内存泄漏。
- en: 'In the earlier example, we saw that the objects weren’t removed until we manually
    called `gc.collect()`. Now we will see what happens if we use the `weakref` module
    instead:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们看到对象直到我们手动调用`gc.collect()`才会被删除。现在我们将看到如果我们使用`weakref`模块会发生什么：
- en: '[PRE57]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now let’s see what remained this time:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看这次还剩下什么：
- en: '[PRE58]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Perfect – no instances of `SomeClass` exist in memory after `del`, which is
    exactly what we had hoped for.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 完美——在`del`之后，内存中不再存在`SomeClass`的实例，这正是我们希望看到的。
- en: Weakref limitations and pitfalls
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Weakref的限制和陷阱
- en: 'You might be wondering what happens when you still try to reference a since-removed
    `weakref`. As you would expect, the object is gone now, so you can no longer use
    it. What is more, not all objects can be used through weak references directly:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道当你仍然尝试引用已经删除的`weakref`时会发生什么。正如你所预期的那样，对象现在已经不存在了，所以你不能再使用它了。更重要的是，并不是所有对象都可以通过弱引用直接使用：
- en: '[PRE59]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We can use `weakref` for custom classes though, so we can subclass the types
    before we create the `weakref`:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们仍然可以使用`weakref`来为自定义类，因此我们可以在创建`weakref`之前对这些类型进行子类化：
- en: '[PRE60]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: For `dict` and `set` instances, the `weakref` library also has the `weakref.WeakKeyDictionary`,
    `weakref.WeakValueDictionary`, and `weakref.WeakSet` classes. These behave similarly
    to the regular instances of `dict` and `set`, but remove the values based on the
    key or value.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`dict`和`set`实例，`weakref`库还有`weakref.WeakKeyDictionary`、`weakref.WeakValueDictionary`和`weakref.WeakSet`类。这些行为与常规的`dict`和`set`实例类似，但基于键或值删除值。
- en: 'We need to be careful when using a `weakref`, of course. As soon as all regular
    references are deleted, the object will be inaccessible:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在使用`weakref`时，我们需要小心。一旦所有常规引用都被删除，对象将变得不可访问：
- en: '[PRE61]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: After deleting `a`, which is the only real reference to the `SomeClass` instance,
    we cannot use the instance anymore. While this is to be expected, you should be
    wary of this problem if your main reference has a chance to disappear.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在删除`a`之后，它是`SomeClass`实例的唯一实际引用，我们不能再使用该实例了。虽然这是可以预料的，但如果你的主要引用有可能消失，你应该对此问题保持警惕。
- en: Whenever you are working with large self-referencing data structures, it can
    be a good idea to use the `weakref` module. However, don’t forget to check if
    your instance still exists before using it.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理大型自引用数据结构时，使用`weakref`模块可能是个好主意。然而，在使用它之前，别忘了检查你的实例是否仍然存在。
- en: Reducing memory usage
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少内存使用
- en: In general, memory usage probably won’t be your biggest problem in Python, but
    it can still be useful to know what you can do to reduce it. When trying to reduce
    memory usage, it’s important to understand how Python allocates memory.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，内存使用可能不是Python中最大的问题，但了解你可以做什么来减少它仍然很有用。在尝试减少内存使用时，了解Python如何分配内存是非常重要的。
- en: 'There are four concepts that you need to know about within the Python memory
    manager:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python内存管理器中，你需要了解四个概念：
- en: First, we have the **heap**. The heap is the collection of all Python-managed
    memory. Note that this is separate from the regular heap and mixing the two could
    result in corrupt memory and crashes.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们有**堆**。堆是所有Python管理的内存的集合。请注意，这与常规堆是分开的，混合两者可能会导致内存损坏和崩溃。
- en: Second are the **arenas**. These are the chunks that Python requests from the
    system. These chunks have a fixed size of 256 KiB each and they are the objects
    that make up the heap.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二是**区域**。这些是 Python 从系统请求的块。每个块的大小固定为 256 KiB，它们是构成堆的对象。
- en: Third we have the **pools**. These are the chunks of memory that make up the
    arenas. These chunks are 4 KiB each. Since the pools and arenas have fixed sizes,
    they are simple arrays.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三是**池**。这些是构成区域（arenas）的内存块。这些块的大小是 4 KiB。由于池和区域有固定的大小，它们是简单的数组。
- en: Fourth and last, we have the **blocks**. The Python objects get stored within
    these and every block has a specific format depending on the data type. Since
    an integer takes up more space than a character, for efficiency, a different block
    size is used.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四和最后，我们有**块**。Python 对象存储在这些块中，每个块都有特定的格式，这取决于数据类型。由于整数比字符占用更多空间，为了效率，使用了不同的块大小。
- en: Now that we know how the memory is allocated, we can also understand how it
    can be returned to the operating system and why this is often very hard to do.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了内存是如何分配的，我们也可以理解它如何返回到操作系统，以及为什么这通常非常困难。
- en: 'Releasing a block back to the pool is easy enough: a simple `del some_variable`
    followed by a `gc.collect()` should do the trick. The problem is that this is
    no guarantee that the memory will be released back to the operating system yet.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个块返回到池中是足够简单的：一个简单的 `del some_variable` 后跟一个 `gc.collect()` 就应该可以解决问题。问题是这并不能保证内存会返回到操作系统。
- en: 'To illustrate what needs to happen in order for the memory to release to the
    operating system:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明内存释放到操作系统的必要条件：
- en: All blocks in a pool need to be released before the pool can be released
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在池可以释放之前，池中的所有块都需要被释放。
- en: All pools in an arena need to be released before the arena can be released
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在区域可以释放之前，区域中的所有池都需要被释放。
- en: Once the arena has been released to the heap, memory *might* be released to
    the operating system, but that depends on the C runtime and/or operating system
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦区域被释放到堆中，内存*可能*会被释放到操作系统，但这取决于 C 运行时和/或操作系统。
- en: That is why I would always recommend running `gc.collect()` in long-running
    scripts right before you start allocating large blocks of memory.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，我总是建议在开始分配大块内存之前，在长时间运行的脚本中运行 `gc.collect()`。
- en: It is a common and incorrect misconception that Python never releases any memory
    to the system. Before Python 2.5, this was indeed the case because arenas were
    never freed to the heap.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常见且错误的误解，即 Python 从不向系统释放任何内存。在 Python 2.5 之前，这确实是事实，因为区域从未被释放到堆中。
- en: 'Let’s illustrate the effects of allocating and releasing memory by allocating
    and releasing twice:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过两次分配和释放内存来阐述分配和释放内存的影响：
- en: '[PRE62]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'You might expect that the memory usage after the second block has been released
    will be near identical to after the first block has been released, or even back
    to the original state. Let’s see what actually happens:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会预期在第二个块被释放后，内存使用量将与第一个块释放后几乎相同，或者甚至回到原始状态。让我们看看实际上会发生什么：
- en: '[PRE63]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: That’s odd, isn’t it? The memory usage has grown between the two allocations.
    The truth is that I cherry-picked the result somewhat and that the output changes
    between each run, because releasing memory back to the operating system is not
    a guarantee that the operating system will immediately handle it. In some other
    cases, the memory had properly returned to 17 MiB.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这很奇怪，不是吗？两次分配之间的内存使用量增加了。事实是，我稍微挑选了一些结果，并且输出在每次运行之间都会变化，因为将内存释放回操作系统并不是操作系统会立即处理它的保证。在某些其他情况下，内存已经正确地返回到
    17 MiB。
- en: The astute among you might wonder if the results are skewed because I forgot
    the `gc.collect()`. In this case, the answer is no because the memory allocation
    is large enough to immediately trigger the garbage collector by itself and the
    difference is negligible.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 中间的一些人可能会怀疑结果是否因为忘记了 `gc.collect()` 而有偏差。在这种情况下，答案是不会有偏差，因为内存分配足够大，可以立即触发垃圾收集器，而且差异是可以忽略不计的。
- en: This is roughly the best case, however – just a few contiguous blocks of memory.
    The real challenge is when you have many variables so only parts of the pools/arenas
    are used. Python uses some heuristics to find space in an empty arena so it doesn’t
    have to allocate new arenas when you are storing new variables, but that does
    not always succeed, of course. This is a case where running `gc.collect()` before
    allocation can help because it can tell Python which pools are now free.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这大约是最佳情况，即只有几个连续的内存块。真正的挑战在于当你有许多变量时，只有部分池/区域被使用。Python使用一些启发式方法在空区域中找到空间，这样在存储新变量时就不需要分配新的区域，但当然并不总是成功。在这种情况下，在分配之前运行`gc.collect()`可能会有所帮助，因为它可以告诉Python哪些池现在是空闲的。
- en: It is important to note that the regular heap and Python heap are maintained
    separately, as mixing them can result in corruption and/or the crashing of applications.
    Unless you write your own Python extensions in C/C++, you will probably never
    have to worry about manual memory allocation though.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，常规堆和Python堆是分开维护的，因为混合它们可能会导致损坏和/或应用程序崩溃。除非你用C/C++编写自己的Python扩展，否则你很可能永远不需要担心手动内存分配。
- en: Generators versus lists
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成器与列表的比较
- en: The most important tip is to use generators whenever possible. Python 3 has
    come a long way in replacing lists with generators already, but it really pays
    to keep that in mind as it saves not only memory, but CPU as well, when not all
    of that memory needs to be kept at the same time.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的提示是尽可能使用生成器。Python 3已经在用生成器替换列表方面取得了很大的进步，但记住这一点确实很有好处，因为它不仅节省了内存，还节省了CPU，因为不需要同时保留所有内存。
- en: 'To illustrate the difference:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这种差异：
- en: '[PRE64]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The `range()` generator takes such little memory that it doesn’t even register,
    whereas the list of numbers takes `38.6 MiB`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '`range()`生成器占用的内存如此之少，以至于甚至无法检测到，而数字列表则占用`38.6 MiB`。'
- en: Recreating collections versus removing items
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重新创建集合与移除项的比较
- en: 'One very important detail about collections in Python is that many of them
    can only grow; they won’t just shrink by themselves. To illustrate:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Python中的集合的一个非常重要的细节是，其中许多只能增长；它们不会自行缩小。为了说明：
- en: '[PRE65]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Even after removing all items from the `dict`, the memory usage remains the
    same. This is one of the most common memory usage mistakes made with lists and
    dictionaries. The only way to reclaim the memory is by recreating the object.
    Or, never allocate the memory at all by using generators.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 即使从`dict`中移除了所有项，内存使用量仍然保持不变。这是使用列表和字典时最常见的内存使用错误之一。唯一恢复内存的方法是重新创建对象。或者，通过使用生成器根本不分配内存。
- en: Using slots
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用槽位
- en: In addition to the performance benefits of using `__slots__` that we saw earlier
    in this chapter, `__slots__` can also help to reduce memory usage. As a recap,
    `__slots__` allows you to specify which fields you want to store in a class and
    it skips all the others by not implementing `instance.__dict__`.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 除了本章前面提到的使用`__slots__`的性能优势外，`__slots__`还可以帮助减少内存使用。回顾一下，`__slots__`允许你指定你想要在类中存储的字段，并且通过不实现`instance.__dict__`来跳过所有其他字段。
- en: While this method does save a little bit of memory in your class definitions,
    the effect is often limited. For a nearly empty class with just a single/tiny
    attribute such as a `bool` or `byte`, this can make quite a bit of difference.
    For classes that actually store a bit of data, the effect can diminish quickly.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法确实可以在类定义中节省一点内存，但效果通常有限。对于一个几乎为空且只有一个极小的属性，如`bool`或`byte`，这可以产生很大的差异。对于实际存储一些数据的类，效果可能会迅速减弱。
- en: The biggest caveat of `__slots__` is that multiple inheritance is impossible
    if both parent classes have `__slots__` defined. Beyond that, it can be used in
    nearly all cases.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '`__slots__`的最大缺点是，如果父类都定义了`__slots__`，则多重继承是不可能的。除此之外，它几乎可以用在所有情况下。'
- en: You might wonder if `__slots__` will limit dynamic attribute assignments, effectively
    blocking you from doing `Spam.eggs = 123` if `eggs` was not part of `__slots__`.
    And you are right – partially, at least. With a standard fixed list of attributes
    in `__slots__`, you cannot dynamically add new attributes – but you can if you
    add `__dict__` to `__slots__`.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道`__slots__`是否会限制动态属性赋值，实际上阻止你执行`Spam.eggs = 123`，如果`eggs`不是`__slots__`的一部分。你是对的——至少部分正确。在有标准固定属性列表的`__slots__`中，你不能动态添加新属性——但如果你将`__dict__`添加到`__slots__`中，你可以。
- en: I’m embarrassed to say that it took me about 15 years before I found out about
    this feature, but knowing about this feature makes `__slots__` so much more versatile
    that I really feel like I should mention it.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我很尴尬地说，我大约花了15年才了解到这个特性，但了解这个特性使得`__slots__`变得如此多功能，我真的觉得我应该提到它。
- en: 'Let’s now illustrate the difference in memory usage:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来展示内存使用量的差异：
- en: '[PRE66]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'And the memory usage:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 还有内存使用情况：
- en: '[PRE67]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: You might argue that this is not a fair comparison since they both store a lot
    of data, which skews the results. And you would indeed be right because the “bare”
    comparison, storing only `index` and nothing else, gives `2 MiB` versus `4.5 MiB`.
    But, let’s be honest, if you’re not going to store data, then what’s the point
    in creating class instances? I’m not saying that `__slots__` have no purpose,
    but don’t go overboard because the advantages are generally limited.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会争辩说这不是一个公平的比较，因为它们都存储了大量的数据，这扭曲了结果。你确实是对的，因为“裸”比较，只存储`index`而不存储其他内容，给出的是`2
    MiB`对`4.5 MiB`。但是，让我们说实话，如果你不打算存储数据，那么创建类实例有什么意义呢？我并不是说`__slots__`没有用途，但不要过分，因为优势通常是有限的。
- en: 'There is one more structure that’s even more memory-efficient: the `array`
    module. It stores the data in pretty much the same way a bare memory array in
    C would do. Note that this is generally slower than lists and much less convenient
    to use. If you need to store large amounts of numbers, I would suggest looking
    at `numpy.array` or `scipy.sparse` instead.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种结构甚至更节省内存：`array`模块。它以几乎与C语言中的裸内存数组相同的方式存储数据。请注意，这通常比列表慢，并且使用起来不那么方便。如果你需要存储大量的数字，我建议查看`numpy.array`或`scipy.sparse`。
- en: Performance monitoring
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能监控
- en: So far, we have seen how to measure and improve both CPU and memory performance,
    but there is one part we have completely skipped over. Performance changes due
    to external factors such as growing amounts of data are very hard to predict.
    In real-life applications, bottlenecks aren’t constant. They change all the time
    and code that was once extremely fast might bog down as soon as more load is applied.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何衡量和改进CPU和内存性能，但有一部分我们完全跳过了。由于外部因素（如数据量的增加）引起的性能变化非常难以预测。在实际应用中，瓶颈不是恒定的。它们一直在变化，曾经非常快的代码一旦应用更多的负载，可能会变得缓慢。
- en: Because of that, I recommend implementing a monitoring solution that tracks
    the performance of anything and everything over time. The big problem with performance
    monitoring is that you can’t know what will slow down in the future and what the
    cause is going to be. I’ve even had websites slow down because of Memcached and
    Redis calls. These are memory-only caching servers that respond well within a
    millisecond, which makes slowdowns highly unlikely, until you do over 100 cache
    calls and the latency toward the cache server increases from 0.1 milliseconds
    to 2 milliseconds, and all of a sudden those 100 calls take 200 milliseconds instead
    of 10 milliseconds. Even though 200 milliseconds still sounds like very little,
    if your total page load time is generally below 100 milliseconds, that is, all
    of a sudden, an enormous increase and definitely noticeable.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，我建议实施一个监控解决方案，该方案可以随着时间的推移跟踪任何事物和一切的性能。性能监控的大问题在于你无法知道未来什么会变慢以及原因是什么。我甚至有过网站因为Memcached和Redis调用而变慢的情况。这些是仅存储内存的缓存服务器，响应速度极快，通常在毫秒内完成，这使得变慢的可能性非常低，直到你做了超过100次缓存调用，并且向缓存服务器的延迟从0.1毫秒增加到2毫秒，突然间这100次调用需要200毫秒而不是10毫秒。尽管200毫秒听起来仍然非常少，但如果你的总页面加载时间通常低于100毫秒，那么这突然之间就是一个巨大的增加，并且肯定是可以注意到的。
- en: 'To monitor performance and to be able to track changes over time and find the
    responsible components, I can personally recommend several systems for monitoring
    performance:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 为了监控性能，能够跟踪随时间的变化并找到负责的组件，我可以个人推荐几个用于性能监控的系统：
- en: For simple short-term (up to a few weeks) application performance tracking,
    the **Prometheus** monitoring system is very easy to set up and when paired with
    **Grafana**, you can create the prettiest charts to monitor your performance.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于简单的短期（最多几周）应用性能跟踪，**Prometheus** 监控系统非常容易设置，并且与 **Grafana** 配对时，你可以创建最漂亮的图表来监控你的性能。
- en: 'If you want a more long-term performance tracking solution that scales well
    to large numbers of variables, you might be interested in **InfluxDB** instead.
    It can also be paired with Grafana for really useful interactive charting:'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要一个更长期的性能跟踪解决方案，该解决方案可以很好地扩展到大量变量，那么你可能对**InfluxDB**更感兴趣。它还可以与Grafana配合使用，以实现非常有用的交互式图表：
- en: '![](img/B15882_12_02.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15882_12_02.png)'
- en: 'Figure 12.2: Grafana heatmap of response times'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2：Grafana响应时间热图
- en: '![](img/B15882_12_03.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15882_12_03.png)'
- en: 'Figure 12.3: Grafana chart of request latency'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3：Grafana请求延迟图表
- en: To enter data into systems like these, you have several options. You can use
    the native APIs, but you can also use an intermediate system such as **StatsD**.
    The StatsD system doesn’t store data itself, but it makes it really easy to fire
    and forget performance metrics from your system without having to worry whether
    the monitoring system is still up and running. Because the system commonly uses
    UDP to send the information, even if the monitoring server is completely down
    and unreachable, your application won’t notice the difference.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 要将这些系统中的数据输入，你有几种选择。你可以使用本机API，但也可以使用一个中间系统，例如**StatsD**。StatsD系统本身不存储数据，但它使得从你的系统中触发和忘记性能指标变得非常容易，而无需担心监控系统是否仍在运行。因为该系统通常使用UDP发送信息，即使监控服务器完全关闭且无法访问，你的应用程序也不会察觉到任何差异。
- en: To be able to use these, you will have to send the metrics from your application
    to the StatsD server. To do just that, I have written the Python-StatsD ([https://pypi.org/project/python-statsd/](Chapter_12.xhtml))
    and Django-StatsD ([https://pypi.org/project/django-statsd/](Chapter_12.xhtml))
    packages. These packages allow you to monitor your application from beginning
    to end and, in the case of Django, you will be able to monitor your performance
    per application or view, and within those see all of the components, such as the
    database, template, and caching layers. This way, you know exactly what is causing
    the slowdowns in your website (or application). And best of all, it is in (near)
    real time.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些工具，你必须将应用程序的指标发送到StatsD服务器。为此，我编写了Python-StatsD ([https://pypi.org/project/python-statsd/](Chapter_12.xhtml))
    和 Django-StatsD ([https://pypi.org/project/django-statsd/](Chapter_12.xhtml))
    包。这些包允许你从开始到结束监控你的应用程序，在Django的情况下，你将能够按应用程序或视图监控性能，并在其中查看所有组件，例如数据库、模板和缓存层。这样，你就可以确切地知道是什么导致了你的网站（或应用程序）的减速。而且最好的是，它是（近）实时进行的。
- en: Exercises
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Now that you have learned about many of the available tools for performance
    measuring and optimization, try and create a few useful decorators or context
    wrappers that will help you prevent issues:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了许多性能测量和优化的可用工具，尝试创建一些有用的装饰器或上下文包装器，以帮助你防止问题：
- en: Try to create a decorator that monitors each run of a function and warns you
    if the memory usage grows each run.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试创建一个装饰器来监控函数的每次运行，如果每次运行内存使用量增加，则警告你。
- en: Try to create a decorator that monitors the runtime of a function and warns
    you if it deviates too much from the previous run. Optionally, you could make
    the function generate a (running) average runtime as well.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试创建一个装饰器来监控函数的运行时间，如果它偏离上一次运行太多，则警告你。可选地，你还可以让该函数生成（运行中的）平均运行时间。
- en: Try to create a memory manager for your classes that warns you when more than
    a configured number of instances remain in memory. If you never expect more than
    5 instances of a certain class, you can warn the user when that number is exceeded.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试为你的类创建一个内存管理器，当超过配置的实例数量时警告你。如果你从未期望某个类的实例超过5个，当这个数字超过时，你可以警告用户。
- en: 'Example answers for these exercises can be found on GitHub: [https://github.com/mastering-python/exercises](Chapter_12.xhtml).
    You are encouraged to submit your own solutions and learn about alternative solutions
    from others.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的示例答案可以在GitHub上找到：[https://github.com/mastering-python/exercises](Chapter_12.xhtml)。你被鼓励提交自己的解决方案，并从他人的解决方案中学习其他替代方案。
- en: Summary
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: When it comes to performance, there is no holy grail, no single thing you can
    do to ensure peak performance in all cases. This shouldn’t worry you, however,
    as in most cases, you will never need to tune the performance and, if you do,
    a single tweak could probably fix your problem. You should be able to find performance
    problems and memory leaks in your code now, which is what matters most, so just
    try to contain yourself and only tweak when it’s actually needed.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到性能时，没有神圣的秘诀，没有单一的事情可以确保在所有情况下都能达到最佳性能。然而，这不应该让你担心，因为在大多数情况下，你永远不会需要调整性能，如果你确实需要，一次微调可能就能解决问题。你现在应该能够找到代码中的性能问题和内存泄漏，这是最重要的，所以只要尽力控制自己，只在真正需要时进行微调。
- en: 'Here is a quick recap of the tools in this chapter:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是本章工具的快速回顾：
- en: 'Measuring CPU performance: `timeit`, `profile`/`cProfile`, and `line_profiler`'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量CPU性能：`timeit`、`profile`/`cProfile` 和 `line_profiler`
- en: 'Analyzing profiling results: SnakeViz, `pyprof2calltree`, and QCacheGrind'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析性能分析结果：SnakeViz、`pyprof2calltree` 和 QCacheGrind
- en: 'Measuring memory usage: `tracemalloc`, `memory_profiler`'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量内存使用：`tracemalloc`、`memory_profiler`
- en: 'Reducing memory usage and leaks: `weakref` and `gc` (garbage collector)'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少内存使用和泄漏：`weakref` 和 `gc`（垃圾收集器）
- en: If you know how to use these tools, you should be able to track down and fix
    most performance issues in your code.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道如何使用这些工具，你应该能够追踪并修复代码中的大多数性能问题。
- en: 'The most important takeaways from this chapter are:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 本章最重要的收获是：
- en: Test before you invest any effort. Making some functions faster seems like a
    great achievement, but it is only rarely needed.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在投入任何努力之前进行测试。使一些函数更快似乎是一项伟大的成就，但这通常很少需要。
- en: Choosing the correct data structure/algorithm is much more effective than any
    other performance optimization.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择正确的数据结构/算法比任何其他性能优化都更有效。
- en: Circular references drain the memory until the garbage collector starts cleaning.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环引用会消耗内存，直到垃圾收集器开始清理。
- en: Slots come with several caveats, so I would recommend limited usage.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 槽位有一些注意事项，所以我建议限制使用。
- en: The next chapter will properly introduce us to working asynchronously using
    the `asyncio` module. This module makes it possible to “background” the waiting
    for external I/O. Instead of keeping your foreground thread busy, it can switch
    to a different thread when your code is waiting for endpoints such as TCP, UDP,
    files, and processes.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将正确介绍我们如何使用 `asyncio` 模块异步工作。此模块使得在等待外部 I/O 时可以“后台”运行。而不是让你的前台线程保持忙碌，当你的代码等待
    TCP、UDP、文件和进程等端点时，它可以切换到不同的线程。
- en: Join our community on Discord
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers: [https://discord.gg/QMzJenHuJf](Chapter_12.xhtml)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：[https://discord.gg/QMzJenHuJf](Chapter_12.xhtml)
- en: '![](img/QR_Code156081100001293319171.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code156081100001293319171.png)'
