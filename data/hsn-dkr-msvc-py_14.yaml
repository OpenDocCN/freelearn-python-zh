- en: Monitoring Logs and Metrics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控日志和指标
- en: In real-life operations, the ability to quickly detect and debug a problem is
    critical. In this chapter, we will discuss the two most important tools we can
    use to discover what's happening in a production cluster processing a high number
    of requests. The first tool is logs, which help us to understand what's happening
    within a single request, while the other tool is metrics, which categorizes the
    aggregated performance of the system.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际运营中，快速检测和调试问题的能力至关重要。在本章中，我们将讨论我们可以用来发现在处理大量请求的生产集群中发生了什么的两个最重要的工具。第一个工具是日志，它帮助我们了解单个请求中发生了什么，而另一个工具是指标，它对系统的聚合性能进行分类。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Observability of a live system
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时系统的可观测性
- en: Setting up logs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置日志
- en: Detecting problems through logs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过日志检测问题
- en: Setting up metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置指标
- en: Being proactive
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 积极主动
- en: By the end of this chapter, you'll know how to add logs so that they are available
    to detect problems and how to add and plot metrics and understand the differences
    between both of them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解如何添加日志以便检测问题，以及如何添加和绘制指标，并了解它们之间的区别。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using the example system for this chapter and tweaking it to include
    centralized logging and metrics. The code for this chapter can be found in this
    book''s GitHub repository: [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用示例系统，并对其进行调整，包括集中式日志记录和指标。本章的代码可以在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10)。
- en: 'To install the cluster, you need to build each individual microservice:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装集群，您需要构建每个单独的微服务：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The microservices in this chapter are the same ones that we introduced previously,
    but they add extra log and metrics configuration.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的微服务与之前介绍的相同，但它们增加了额外的日志和指标配置。
- en: 'Now, we need to create the example namespace and start the Kubernetes cluster
    using the `find` configuration in the `Chapter10/kubernetes` subdirectory:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要创建示例命名空间，并使用`Chapter10/kubernetes`子目录中的`find`配置启动Kubernetes集群：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To be able to access the different services, you need to update your `/etc/hosts`
    file so that it includes the following lines of code:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够访问不同的服务，您需要更新您的`/etc/hosts`文件，以便包含以下代码行：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With that, you will be able to access the logs and metrics for this chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，您将能够访问本章的日志和指标。
- en: Observability of a live system
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时系统的可观测性
- en: Observability is the capability of knowing what's going on in a live system.
    We can deal with low-observability systems, where we have no way of knowing what's
    going on, or high-observability systems, where we can infer the events and internal
    state from the outside through tools.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是了解实时系统发生情况的能力。我们可能会遇到低可观测性系统，我们无法了解其中发生了什么，或者高可观测性系统，我们可以通过工具从外部推断事件和内部状态。
- en: Observability is a property of the system itself. Typically, monitoring is the
    action of obtaining information about the current or past state of the system.
    It's all a bit of a naming debate, but you monitor the system to collect the observable
    parts of it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是系统本身的属性。通常，监控是获取有关系统当前或过去状态的信息的行为。这有点命名上的争议，但你要监控系统以收集其中可观测的部分。
- en: For the most part, monitoring is easy. There are great tools out there that
    can help us capture and analyze information and present it in all kinds of ways.
    However, the system needs to expose the relevant information so that it can be
    collected.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，监控是很容易的。有很多出色的工具可以帮助我们捕获和分析信息，并以各种方式呈现。但是，系统需要暴露相关信息，以便可以收集。
- en: Exposing the correct amount of information is difficult. Too much information
    will produce a lot of noise that will hide the relevant signal. Too little information
    will not be enough to detect problems. In this chapter, we will look at different
    strategies to combat this, but every system will have to explore and discover
    this on its own. Expect to experiment and make changes in your own system!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 暴露正确数量的信息是困难的。太多信息会产生很多噪音，会掩盖相关信号。信息太少将不足以检测问题。在本章中，我们将探讨不同的策略来解决这个问题，但每个系统都必须自行探索和发现。期望在自己的系统中进行实验和更改！
- en: Distributed systems, such as the ones that follow a microservice architecture,
    also present problems as the complexity of the system can make it difficult to
    understand its internal state. Behavior can be also unpredictable in some circumstances.
    This kind of system at scale is inherently never completely healthy; there will
    always be minor problems here and there. You need to develop a priority system
    to determine what problems require immediate action and which ones can be solved
    at a later stage.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统，例如遵循微服务架构的系统，也会出现问题，因为系统的复杂性可能会使其内部状态难以理解。在某些情况下，行为也可能是不可预测的。这种规模的系统本质上永远不会完全健康；总会有一些小问题。您需要制定一个优先级系统，以确定哪些问题需要立即解决，哪些可以在以后解决。
- en: The main tools for the observability of microservices are **logs** and **metrics**.
    They are well-understood and used by the community, and there are plenty of tools
    that greatly simplify their usage, both as packages that can be installed locally
    and as cloud services that can help with data retention and the reduction of maintenance
    costs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务可观测性的主要工具是**日志**和**指标**。它们为社区所熟知，并且有许多工具大大简化了它们的使用，既可以作为可以在本地安装的软件包，也可以作为云服务，有助于数据保留和降低维护成本。
- en: Using cloud services for monitoring will save you from maintenance costs. We
    will talk about this later in the *Setting up logs* and *Setting up metrics* sections.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云服务进行监控将节省您的维护成本。我们将在*设置日志*和*设置指标*部分稍后讨论这一点。
- en: Another alternative when it comes to observability is services such as Data
    Dog ([https://www.datadoghq.com/](https://www.datadoghq.com/)) and New Relic ([https://newrelic.com/](https://newrelic.com/)).
    They receive events – normally logs – and are able to derive metrics from there.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在可观察性方面的另一种选择是诸如Data Dog（[https://www.datadoghq.com/](https://www.datadoghq.com/)）和New
    Relic（[https://newrelic.com/](https://newrelic.com/)）等服务。它们接收事件——通常是日志——并能够从中推导出指标。
- en: The most important details of the state of the cluster can be checked through
    `kubectl`, as we saw in previous chapters. This will include details such as the
    versions that have been deployed, restarts, pulling images, and so on.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 集群状态的最重要细节可以通过`kubectl`进行检查，就像我们在之前的章节中看到的那样。这将包括已部署的版本、重启、拉取镜像等详细信息。
- en: 'For production environments, it may be good to deploy a web-based tool to display
    this kind of information. Check out Weave Scope, an open source tool that shows
    data in a web page similar to the one that can be obtained with `kubectl`, but
    in a nicer and more graphical way. You can find out more about this tool here:
    [https://www.weave.works/oss/scope/](https://www.weave.works/oss/scope/).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产环境，部署一个基于Web的工具来显示这种信息可能是一个好主意。查看Weave Scope，这是一个开源工具，可以在网页上显示数据，类似于可以使用`kubectl`获得的数据，但以更美观和更图形化的方式。您可以在这里了解更多关于这个工具的信息：[https://www.weave.works/oss/scope/](https://www.weave.works/oss/scope/)。
- en: Logs and metrics have different objectives, and both can be intricate. We will
    look at some common usages of them in this book.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 日志和指标有不同的目标，两者都可能很复杂。我们将在本书中看一些它们的常见用法。
- en: Understanding logs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解日志
- en: Logs track unique events that occur in the system. Each log stores a message,
    which is produced when a specific part of the code is executed. Logs can be totally
    generic (*function X is called*) or include specific details (*function X is called
    with parameter A*).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 日志跟踪系统中发生的唯一事件。每个日志都存储一个消息，当代码的特定部分被执行时产生。日志可以是完全通用的（*调用函数X*）或包含特定细节（*使用参数A调用函数X*）。
- en: The most common format for logs is to generate them as plain strings. This is
    very flexible, and normally log-related tools work with text searches.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 日志的最常见格式是将它们生成为纯文本。这非常灵活，通常与与日志相关的工具一起使用文本搜索。
- en: Each log includes some metadata about who produced the log, what time it was
    created, and more. This is also normally encoded as text, at the beginning of
    the log. A standard format helps with sorting and filtering.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每个日志都包含一些关于谁产生了日志、创建时间等元数据。这通常也被编码为文本，出现在日志的开头。标准格式有助于排序和过滤。
- en: Logs also include a severity level. This allows for categorization so that we
    can capture the importance of the messages. The severity level can be, in order
    of importance, `DEBUG`, `INFO`, `WARNING`, or `ERROR`. This severity allows us
    to filter out unimportant logs and determine actions that we should take. The
    logging facility can be configured to set a threshold; less severe logs are ignored.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 日志还包括严重级别。这允许对消息的重要性进行分类。严重级别可以按重要性顺序为`DEBUG`、`INFO`、`WARNING`或`ERROR`。这种严重性允许我们过滤掉不重要的日志，并确定我们应该采取的行动。日志记录设施可以配置为设置阈值；较不严重的日志将被忽略。
- en: There are many severity levels, and you can define custom intermediate levels
    if you wish. However, this isn't very useful except in very specific situations.
    Later in this chapter, in the *Detecting problems through logs* section, we will
    describe how to set a strategy per level; too many levels can add confusion.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多严重级别，如果您愿意，可以定义自定义中间级别。然而，除非在非常特定的情况下，否则这并不是非常有用。在本章后面的*通过日志检测问题*部分，我们将描述如何针对每个级别设置策略；太多级别会增加混乱。
- en: 'In a web service environment, most of the logs will be generated as part of
    the response for a web request. This means that a request will arrive at the system,
    be processed, and return a value. Several logs will be generated along the way.
    Keep in mind that, in a system under load, multiple requests will be happening
    simultaneously, so the logs from multiple requests will also be generated simultaneously.
    For example, note how the second log comes from a different IP:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web服务环境中，大多数日志将作为对Web请求的响应的一部分生成。这意味着请求将到达系统，被处理，并返回一个值。沿途将生成多个日志。请记住，在负载下的系统中，多个请求将同时发生，因此多个请求的日志也将同时生成。例如，注意第二个日志来自不同的IP：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A common request ID can be added to group all the related logs that have been
    produced for a single request. We will see how to do this later in this chapter.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的请求ID可以添加到所有与单个请求相关的日志中。我们将在本章后面看到如何做到这一点。
- en: Each individual log can be relatively big and, in aggregate, use significant
    disk space. Logs can quickly grow out of proportion in a system under load. The
    different log systems allow us to tweak their retention time, which means that
    we only keep them for a certain amount of time. Finding the balance between keeping
    logs to see what happened in the past and using a sane amount of space is important.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每个单独的日志可能相对较大，并且在聚合时会占用大量磁盘空间。在负载下的系统中，日志可能会迅速膨胀。不同的日志系统允许我们调整其保留时间，这意味着我们只保留它们一段时间。在保留日志以查看过去发生的事情和使用合理的空间之间找到平衡是很重要的。
- en: Be sure to check the retention policies when enabling any new log service, whether
    it be local or cloud-based. You won't be able to analyze what happened before
    the time window. Double-check that the progress rate is as expected – you don't
    want to find out that you went unexpectedly over quota while you were tracking
    a bug.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用任何新的日志服务时，请务必检查保留策略，无论是本地还是基于云的。您将无法分析发生在时间窗口之前的情况。仔细检查进度是否符合预期——您不希望在跟踪错误时意外超出配额。
- en: Some tools allow us to use raw logs to generate aggregated results. They can
    count the number of times a particular log appears and generate the average times
    per minute or other statistics. This is expensive, though, as each log takes space.
    To observe this aggregated behavior, it is better to use a specific metrics system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工具允许我们使用原始日志生成聚合结果。它们可以计算特定日志出现的次数，并生成每分钟的平均时间或其他统计信息。但这很昂贵，因为每个日志都占用空间。要观察这种聚合行为，最好使用特定的指标系统。
- en: Understanding metrics
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解指标
- en: Metrics deal with aggregated information. They show information related not
    to a single event, but a group of them. This allows us to check the general status
    of the cluster in a better way than using logs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 指标处理聚合信息。它们显示与单个事件无关的信息，而是一组事件的信息。这使我们能够以比使用日志更好的方式检查集群的一般状态。
- en: We will use typical examples related to web services, mainly dealing with requests
    metrics, but don't feel restricted by them. You can generate your own metrics
    that are specific to your service!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与网络服务相关的典型示例，主要涉及请求指标，但不要感到受限。您可以生成特定于您的服务的指标！
- en: Where a log keeps information about each individual event, metrics reduce the
    information to the number of times the event happens or reduce them to a value
    that can then be averaged or aggregated in a certain way.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录每个单独事件的信息，而指标将信息减少到事件发生的次数，或将其减少到可以进行平均或以某种方式聚合的值。
- en: This makes metrics much more lightweight than logs and allows us to plot them
    against time. Metrics present information such as the number of requests per minute,
    the average time for a request during a minute, the number of queued requests,
    the number of errors per minute, and so on.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得指标比日志更轻量，并且可以根据时间绘制它们。指标呈现的信息包括每分钟的请求次数，每分钟请求的平均时间，排队请求的数量，每分钟的错误数量等。
- en: The resolution of the metrics may depend on the tool that was used to aggregate
    them. Keep in mind that a higher resolution will require more resources. A typical
    resolution is 1 minute, which is small enough to present detailed information
    unless you have a very active system that receives 10 or more requests per second.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 指标的分辨率可能取决于用于聚合它们的工具。请记住，更高的分辨率将需要更多的资源。典型的分辨率是1分钟，这足够小以呈现详细信息，除非您的系统非常活跃，每秒接收10次或更多请求。
- en: Capturing and analyzing information related to performance, such as the average
    request time, allows us to detect possible bottlenecks and act quickly in order
    to improve the performance of the system. This is much easier to deal with on
    average since a single request may not capture enough information for us to see
    the big picture. It also helps us predict future bottlenecks.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获和分析与性能相关的信息，如平均请求时间，使我们能够快速检测可能的瓶颈并迅速采取行动以改善系统的性能。这通常更容易处理，因为单个请求可能无法捕获足够的信息让我们看到整体情况。它还有助于我们预测未来的瓶颈。
- en: 'There are many different kinds of metrics, depending on the tool that''s used.
    The most commonly supported ones are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据所使用的工具，有许多不同类型的指标。最常见的支持包括以下内容：
- en: '**Counter**: A trigger is generated each time something happens. This will
    be counted and aggregated. An example of this is the number of requests and the
    number of errors.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**: 每次发生事件时都会生成一个触发器。这将被计数和聚合。这的一个例子是请求的数量和错误的数量。'
- en: '**Gauge**: A single number that is unique. It can go up or down, but the last
    value overwrites the previous. An example of this is the number of requests in
    the queue and the number of available workers.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量规**: 一个唯一的单一数字。它可以增加或减少，但最后一个值会覆盖之前的值。这的一个例子是队列中的请求数量和可用工作者的数量。'
- en: '**Measure**: Events that have a number associated with them. These numbers
    can be averaged, summed, or aggregated in some way. Compared with gauges, the
    difference is that previous measures are still independent; for example, when
    we request time in milliseconds and request size in bytes. Measures can also work
    as counters since their number can be important; for example, tracking the request
    time also counts the number of requests.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量**: 与之相关的事件具有数字。这些数字可以被平均、求和或以某种方式聚合。与量规相比，前面的度量仍然是独立的；例如，当我们以毫秒为单位请求时间和以字节为单位请求大小时。度量也可以作为计数器工作，因为它们的数量可能很重要；例如，跟踪请求时间还计算请求的数量。'
- en: 'There are two main ways in which metrics work:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 指标有两种主要工作方式：
- en: Each time something happens, an event gets *pushed* toward the metrics collector.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次发生事件时，事件都会被*推送*到指标收集器。
- en: Each system maintains their own metrics, which are then *pulled* from the metrics
    system periodically.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个系统都维护自己的指标，然后定期从指标系统中*拉取*它们。
- en: Each way has its own pros and cons. Pushing events produces higher traffic as
    every event needs to be sent; this can cause bottlenecks and delays. Pulling events
    will only sample the information and miss exactly what happened between the samples,
    but it's inherently more scalable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每种方式都有其优缺点。推送事件会产生更高的流量，因为每个事件都需要发送；这可能会导致瓶颈和延迟。拉取事件只会对信息进行抽样，并且会错过样本之间发生的确切情况，但它本质上更具可扩展性。
- en: While both approaches are used, the trend is moving toward pulling systems for
    metrics. They reduce the maintenance that's required for pushing systems and are
    much more easier to scale.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然两种方法都在使用，但趋势是向拉取系统转移。它们减少了推送系统所需的维护工作，并且更容易扩展。
- en: We will set up Prometheus, which uses the second approach. The most used exponent
    of the first approach is Graphite.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置使用第二种方法的Prometheus。第一种方法最常用的指标系统是Graphite。
- en: Metrics can also be combined to generate other metrics; for example, we can
    divide the number of requests that return errors by the total number of requests
    that generate error requests. Such derived metrics can help us present information
    in a meaningful way.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 指标也可以组合以生成其他指标；例如，我们可以将返回错误的请求次数除以生成错误请求的总请求数。这样的派生指标可以帮助我们以有意义的方式呈现信息。
- en: 'Multiple metrics can be displayed in dashboards so that we can understand the
    status of a service or cluster. At a glance, these graphical tools allow us to
    detect the general state of the system. We will set Grafana so that it displays
    graphical information:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 多个指标可以显示在仪表板上，这样我们就可以了解服务或集群的状态。通过这些图形工具，我们可以一目了然地检测系统的一般状态。我们将设置Grafana，以显示图形信息：
- en: '![](img/1d334374-d1df-4f9f-a7ac-07ccd296c87a.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d334374-d1df-4f9f-a7ac-07ccd296c87a.png)'
- en: Compared to logs, metrics take up much less space and they can capture a bigger
    window of time. It's even possible to keep metrics for the system's life. This
    differs compared to logs, which can never be stored for that long.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与日志相比，指标占用的空间要少得多，可以捕获更长的时间窗口。甚至可以保留系统的生命周期内的指标。这与日志不同，日志永远无法存储那么长时间。
- en: Setting up logs
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置日志
- en: We will centralize all the logs that are generated by the system into a single
    pod. In local development, this pod will expose all the received logs through
    a web interface.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把系统生成的所有日志集中到一个单独的pod中。在本地开发中，这个pod将通过Web界面公开所有接收到的日志。
- en: The logs will be sent over the `syslog` protocol, which is the most standard
    way of transmitting them. There's native support for `syslog` in Python, as well
    as in virtually any system that deals with logging and has Unix support.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 日志将通过`syslog`协议发送，这是传输日志的最标准方式。Python中有`syslog`的原生支持，几乎任何处理日志并具有Unix支持的系统都有。
- en: Using a single container makes it easy to aggregate logs. In production, this
    system should be replaced with a container that relays the received logs to a
    cloud service such as Loggly or Splunk.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个容器可以轻松聚合日志。在生产环境中，应该用一个容器来替换这个系统，将接收到的日志传送到Loggly或Splunk等云服务。
- en: There are multiple `syslog` servers that are capable of receiving logs and aggregating
    them; `syslog-ng` ([https://www.syslog-ng.com/](https://www.syslog-ng.com/)) and
    `rsyslog` ([https://www.rsyslog.com/](https://www.rsyslog.com/)) are the most
    common ones. The simplest method is to receive the logs and to store them in a
    file. Let's start a container with an `rsyslog` server, which will store the received
    logs.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个`syslog`服务器可以接收日志并进行聚合；`syslog-ng` ([https://www.syslog-ng.com/](https://www.syslog-ng.com/))和`rsyslog`
    ([https://www.rsyslog.com/](https://www.rsyslog.com/))是最常见的。最简单的方法是接收日志并将其存储在文件中。让我们启动一个带有`rsyslog`服务器的容器，它将存储接收到的日志。
- en: Setting up an rsyslog container
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置rsyslog容器
- en: In this section, we will create our own `rsyslog` server. This is a very simple
    container, and you can check `docker-compose` and `Dockerfile` on GitHub for more
    information regarding logs ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将创建自己的`rsyslog`服务器。这是一个非常简单的容器，您可以在GitHub上查看有关日志的`docker-compose`和`Dockerfile`的更多信息([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs))。
- en: We will set up logs using the UDP protocol. This is the standard protocol for
    `syslog`, but it's less common than the usual HTTP over TCP that's used for web
    development.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用UDP协议设置日志。这是`syslog`的标准协议，但比用于Web开发的通常的TCP上的HTTP要少见。
- en: The main difference is that UDP is connectionless, so the log is sent and no
    confirmation that it has been delivered is received. This makes UDP lighter and
    faster, but also less reliable. If there's a problem in the network, some logs
    may disappear without warning.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 主要区别在于UDP是无连接的，因此日志被发送后不会收到已传递的确认。这使得UDP更轻更快，但也更不可靠。如果网络出现问题，一些日志可能会无预警地消失。
- en: This is normally an adequate trade-off since the number of logs is high and
    the implications of losing a few isn't big. `syslog` can also work over TCP, thus
    increasing reliability but also reducing the performance of the system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是一个合理的权衡，因为日志数量很大，丢失一些日志的影响并不大。`syslog`也可以通过TCP工作，从而增加可靠性，但也降低了系统的性能。
- en: 'The Dockerfile installs `rsyslog` and copies its configuration file:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile安装了`rsyslog`并复制了其配置文件：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The configuration file mainly starts the server at port `5140` and stores the
    received files in `/var/log/syslog`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件主要是在端口`5140`启动服务器，并将接收到的文件存储在`/var/log/syslog`中：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With log rotation, we set a limit on the side of the `/var/log/syslog` file
    so that it doesn't grow without limits.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过日志轮换，我们设置了`/var/log/syslog`文件的大小限制，以防止其无限增长。
- en: 'We can build the container with the usual `docker-compose` command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用通常的`docker-compose`命令构建容器：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will create a combination of a pod, a service, and an Ingress, as we did
    with the other microservices, to collect logs and allow external access from a
    browser.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个pod、一个服务和一个Ingress的组合，就像我们对其他微服务所做的那样，以收集日志并允许从浏览器进行外部访问。
- en: Defining the syslog pod
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义syslog pod
- en: The `syslog` pod will contain the `rsyslog` container and another container
    to display the logs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`syslog` pod将包含`rsyslog`容器和另一个用于显示日志的容器。'
- en: To display the logs, we will use front rail, an application that streams log
    files to a web server. We need to share the file across both containers in the
    same pod, and the simplest way to do this is through a volume.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了显示日志，我们将使用front rail，这是一个将日志文件流式传输到Web服务器的应用程序。我们需要在同一个pod中的两个容器之间共享文件，最简单的方法是通过卷。
- en: We control the pod using a deployment. You can check the deployment configuration
    file at [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml).
    Let's take a look at its most interesting parts in the following subsections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用部署来控制pod。您可以在[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml)中检查部署配置文件。让我们在以下小节中看一下它最有趣的部分。
- en: log-volume
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: log-volume
- en: '`log-volume` creates an empty directory that is shared across both containers:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`log-volume`创建了一个空目录，该目录在两个容器之间共享：'
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This allows the containers to communicate while storing information in a file.
    The `syslog` container will write to it while the front rail one will read from
    it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许容器在存储信息的同时进行通信。`syslog`容器将向其中写入，而前端容器将从其中读取。
- en: syslog container
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: syslog容器
- en: 'The `syslog` container starts an `rsyslogd` process:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`syslog`容器启动了一个`rsyslogd`进程：'
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `rsyslogd -n -f /etc/rsyslog.d/rsyslog.conf` command starts the server with
    the configured file we described previously. The `-n` parameter keeps the process
    in the foreground, thereby keeping the container running.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`rsyslogd -n -f /etc/rsyslog.d/rsyslog.conf`命令使用我们之前描述的配置文件启动服务器。`-n`参数将进程保持在前台，从而保持容器运行。'
- en: The UDP port `5140`, which is the defined port to receive logs, is specified,
    and `log-volume` is mounted to `/var/log`. Later in the file, `log-volume` will
    be defined.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 指定了UDP端口`5140`，这是接收日志的定义端口，并且将`log-volume`挂载到`/var/log`。文件的后面将定义`log-volume`。
- en: The front rail container
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前端容器
- en: 'The front rail container is started from the official container image:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前端容器是从官方容器镜像启动的：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We start it with the `frontrail /var/log/syslog` command, specify port `9001`
    (which is the one we use to access `frontrail`), and mount `/var/log`, just like
    we did with the `syslog` container, to share the log file.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`frontrail /var/log/syslog`命令启动它，指定端口`9001`（这是我们用来访问`frontrail`的端口），并挂载`/var/log`，就像我们用`syslog`容器一样，以共享日志文件。
- en: Allowing external access
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 允许外部访问
- en: As we did with the other microservices, we will create a service and an Ingress.
    The service will be used by other microservices so they can send their logs. The
    Ingress will be used to access the web interface so that we can see the logs as
    they arrive.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他微服务一样，我们将创建一个服务和一个Ingress。服务将被其他微服务使用，以便它们可以发送它们的日志。Ingress将用于访问Web界面，以便我们可以在日志到达时查看日志。
- en: The YAML files are on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs))
    in the `service.yaml` and `ingress.yaml` files, respectively.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: YAML文件位于GitHub上（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs)），分别是`service.yaml`和`ingress.yaml`文件。
- en: 'The service is very straightforward; the only peculiarity is that it has two
    ports – one TCP port and one UDP port – and each one connects to a different container:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 服务非常简单；唯一的特殊之处在于它有两个端口 - 一个TCP端口和一个UDP端口 - 每个端口连接到不同的容器：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The Ingress only exposes the front rail port, which means we can access it
    through the browser. Remember that the DNS needs to be added to your `/etc/host`
    file, as described at the start of this chapter:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress只暴露了前端端口，这意味着我们可以通过浏览器访问它。请记住，DNS需要添加到您的`/etc/host`文件中，就像本章开头所描述的那样：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Going to `http://syslog.example.local` in your browser will allow you to access
    the front rail interface:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中输入`http://syslog.example.local`将允许您访问前端界面：
- en: '![](img/f6ccd237-8812-48f4-90a1-b5c971772d3a.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f6ccd237-8812-48f4-90a1-b5c971772d3a.png)'
- en: You can filter the logs using the box in the top-right corner.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用右上角的框来过滤日志。
- en: Remember that, most of the time, logs reflect the readiness and liveness probes,
    as shown in the preceding screenshot. The more health checks you have in your
    system, the more noise you'll get.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，大多数时候，日志反映了就绪和存活探针，如前面的屏幕截图所示。您的系统中有更多的健康检查，您将会得到更多的噪音。
- en: You can filter them out at the `syslog` level by configuring the `rsyslog.conf`
    file, but be careful not to leave out any relevant information.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过配置`rsyslog.conf`文件在`syslog`级别上将其过滤掉，但要小心不要遗漏任何相关信息。
- en: Now, we need to see how the other microservices configure and send their logs
    here.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要看看其他微服务如何配置并将它们的日志发送到这里。
- en: Sending logs
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送日志
- en: We need to configure the microservices in uWSGI so that we can forward the logs
    to the logging service. We will use the Thoughts Backend as an example, even though
    the Frontend and Users Backend, which can be found under the `Chapter10/microservices`
    directory, also have this configuration enabled.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在uWSGI中配置微服务，以便我们可以将日志转发到日志服务。我们将使用Thoughts Backend作为示例，即使Frontend和Users
    Backend也有这个配置，可以在`Chapter10/microservices`目录下找到。
- en: 'Open the `uwsgi.ini` configuration file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini)).
    You''ll see the following line:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`uwsgi.ini`配置文件（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini)）。您将看到以下行：
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This sends the logs, in `rsyslog` format, toward the `syslog` service at port
    `5140`. We also add the *facility*, which is where the logs come from. This adds
    the string to all the logs coming from this service, which helps with sorting
    and filtering. Each `uwsgi.ini` file should have its own facility to help with
    filtering.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以`rsyslog`格式发送日志到端口`5140`的`syslog`服务。我们还添加了*facility*，这是日志来源的地方。这将为来自此服务的所有日志添加字符串，有助于排序和过滤。每个`uwsgi.ini`文件应该有自己的facility以帮助过滤。
- en: In old systems that support the `syslog` protocol, the facility needs to fit
    predetermined values such as `KERN`, `LOCAL_7`, and more. But in most modern systems,
    this is an arbitrary string that can take any value.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持`syslog`协议的旧系统中，facility需要符合预定值，例如`KERN`，`LOCAL_7`等。但在大多数现代系统中，这是一个任意的字符串，可以取任何值。
- en: Automatic logs by uWSGI are interesting, but we also need to set up our own
    logs for custom tracking. Let's see how.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: uWSGI自动记录很有趣，但我们还需要为自定义跟踪设置自己的日志。让我们看看如何做。
- en: Generating application logs
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成应用程序日志
- en: 'Flask automatically configures a logger for the app. We need to add a log in
    the following way, as shown in the `api_namespace.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102)):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Flask自动为应用程序配置了一个记录器。我们需要以以下方式添加日志，如`api_namespace.py`文件中所示（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102)）：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`app.logger` can call `.debug`, `.info`, `.warning`, or `.error` to generate
    a log. Note that `app` can be retrieved by importing `current_app`.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`app.logger`可以调用`.debug`、`.info`、`.warning`或`.error`来生成日志。请注意，可以通过导入`current_app`来检索`app`。'
- en: The logger follows the standard `logging` module in Python. It can be configured
    in different ways. Take a look at the `app.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py))
    to view the different configuration we'll be going through in the following subsections.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 记录器遵循Python中的标准`logging`模块。它可以以不同的方式进行配置。查看`app.py`文件（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py)）以查看我们将在以下子部分中进行的不同配置。
- en: Dictionary configuration
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字典配置
- en: 'The first level of logging goes through the default `dictConfig` variable.
    This variable is automatically defined by Flask and allows us to configure the
    logs in the way that''s defined in the Python documentation ([https://docs.python.org/3.7/library/logging.config.html](https://docs.python.org/3.7/library/logging.config.html)).
    You can check the definition of logging in the `app.py` file:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第一级别的日志记录通过默认的`dictConfig`变量。这个变量由Flask自动定义，并允许我们按照Python文档中定义的方式配置日志（[https://docs.python.org/3.7/library/logging.config.html](https://docs.python.org/3.7/library/logging.config.html)）。您可以在`app.py`文件中查看日志的定义：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `dictConfig` dictionary has three main levels:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`dictConfig`字典有三个主要级别：'
- en: '`formatters`: This checks how the log is formatted. To define the format, you
    can use the automatic values that are available in the Python documentation ([https://docs.python.org/3/library/logging.html#logrecord-attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)).
    This gathers information for every log.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`formatters`：这检查日志的格式。要定义格式，可以使用Python文档中提供的自动值（[https://docs.python.org/3/library/logging.html#logrecord-attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)）。这收集每个日志的信息。'
- en: '`handlers`: This checks where the log goes to. You can assign one or more to
    the loggers. We defined a handler called `wsgi` and configured it so that it goes
    up, toward uWSGI.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handlers`：这检查日志的去向。您可以将一个或多个分配给记录器。我们定义了一个名为`wsgi`的处理程序，并对其进行了配置，以便将其发送到uWSGI。'
- en: '`root`: This is the top level for logs, so anything that wasn''t previously
    logged will refer to this level. We configure the `INFO` logging level here.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`root`：这是日志的顶层，因此以前未记录的任何内容都将参考此级别。我们在这里配置`INFO`日志级别。'
- en: This sets up default configuration so that we don't miss any logs. However,
    we can create even more complex logging handlers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置默认配置，以便我们不会错过任何日志。但是，我们可以创建更复杂的日志处理程序。
- en: Logging a request ID
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录请求ID
- en: One of the problems when analyzing a large number of logs is correlating them.
    We need to see which ones are related to each other. One possibility is to filter
    logs by the pod that's generating them, which is stored at the start of the log
    (for example, `10-1-0-27.frontend-service.example.svc.cluster.local`). This is
    analogous to the host generating the logs. This process, however, is cumbersome
    and, in some cases, a single container can process two requests simultaneously.
    We need a unique identifier per request that gets added to all the logs for a
    single request.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析大量日志时的一个问题是对其进行关联。我们需要看到哪些日志彼此相关。一种可能性是通过生成它们的pod来过滤日志，该pod存储在日志的开头（例如，`10-1-0-27.frontend-service.example.svc.cluster.local`）。这类似于生成日志的主机。然而，这个过程很繁琐，并且在某些情况下，单个容器可以同时处理两个请求。我们需要为每个请求添加一个唯一标识符，该标识符将添加到单个请求的所有日志中。
- en: To do so, we will use the `flask-request-id-header` package ([https://pypi.org/project/flask-request-id-header/](https://pypi.org/project/flask-request-id-header/)).
    This adds an `X-Request-ID` header (if not present) that we can use to log each
    individual request.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用`flask-request-id-header`包（[https://pypi.org/project/flask-request-id-header/](https://pypi.org/project/flask-request-id-header/)）。这将添加一个`X-Request-ID`头（如果不存在），我们可以用它来记录每个单独的请求。
- en: Why do we set up a header instead of storing a randomly generated value in memory
    for the request? This is a common pattern that allows us to inject the request
    ID into the backend. The request ID allows us to carry over the same request identifier
    through the life cycle of a request for different microservices. For example,
    we can generate it on the Frontend and pass it over to the Thoughts Backend so
    that we can trace several internal requests that have the same origin.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们设置一个头部而不是将随机生成的值存储在内存中以供请求使用？这是一种常见的模式，允许我们将请求ID注入到后端。请求ID允许我们在不同微服务的请求生命周期中传递相同的请求标识符。例如，我们可以在前端生成它并将其传递到Thoughts后端，以便我们可以跟踪具有相同来源的多个内部请求。
- en: Although we won't be including this in our example for simplicity, as a microservices
    system grows, this becomes crucial for determining flows and origins. Generating
    a module so that we can automatically pass it over internal calls is a good investment.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管出于简单起见，我们不会在示例中包含这一点，但是随着微服务系统的增长，这对于确定流程和来源变得至关重要。生成一个模块，以便我们可以自动传递内部调用，这是一个很好的投资。
- en: 'The following diagram shows the flow between a **frontend** and two services.
    Note that the `X-Request-ID` header is not set up for the **frontend** service
    upon arrival and that it needs to be forwarded to any call:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了**前端**和两个服务之间的流程。请注意，**前端**服务在到达时未设置`X-Request-ID`头，并且需要转发到任何调用：
- en: '![](img/158370df-bab7-416c-ab69-63d258408159.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/158370df-bab7-416c-ab69-63d258408159.png)'
- en: We need to also send the logs straight toward the `syslog` service so that we
    can create a handler that does this for us.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要将日志直接发送到`syslog`服务，以便我们可以创建一个为我们执行此操作的处理程序。
- en: When executing code from a script, compared to running the code in a web server,
    we don't use this handler. When running a script directly, we want our logs to
    go to the default logger we defined previously. In `create_app`, we will set up
    a parameter to differentiate between them.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当从脚本执行代码时，与在web服务器中运行代码相比，我们不使用此处理程序。直接运行脚本时，我们希望日志记录到我们之前定义的默认记录器。在`create_app`中，我们将设置一个参数来区分它们。
- en: The Python logging module has a lot of interesting features. Check out the Python
    documentation for more information ([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Python日志模块具有许多有趣的功能。查看Python文档以获取更多信息（[https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)）。
- en: Setting logs properly is trickier than it looks. Don't be discouraged and keep
    tweaking them until they work.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 正确设置日志比看起来更加棘手。不要灰心，继续调整它们直到它们起作用。
- en: 'We will set up all the logging configuration in the `app.py` file. Let''s break
    up each part of the configuration:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`app.py`文件中设置所有日志配置。让我们分解配置的每个部分：
- en: 'First, we will generate a formatter that appends the `request_id` so that it''s
    available when generating logs:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将生成一个格式化程序，以便在生成日志时附加`request_id`，使其在生成日志时可用：
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, the `HTTP_X_REQUEST_ID` header is available in the `request.environ`
    variable.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`HTTP_X_REQUEST_ID`头在`request.environ`变量中可用。
- en: 'Later, in `create_app`, we will set up the handler that we append to the `application`
    logger:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 稍后，在`create_app`中，我们将设置附加到`application`记录器的处理程序：
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We only set up the handler if the run happens out of a script. `SysLogHandler`
    is included in Python. After this, we set up the format, which includes `request_id`.
    The formatter uses the `RequestFormatter` that we defined previously.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在脚本外运行时才设置处理程序。`SysLogHandler`包含在Python中。之后，我们设置格式，其中包括`request_id`。格式化程序使用我们之前定义的`RequestFormatter`。
- en: Here, we are hardcoding the values of the logger level to `INFO` and the `syslog`
    host to `syslog`, which corresponds to the service. Kubernetes will resolve this
    DNS correctly. Both values can be passed through environment variables, but we
    didn't do this here for the sake of simplicity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将记录器级别的值硬编码为`INFO`，`syslog`主机为`syslog`，这对应于服务。Kubernetes将正确解析此DNS。这两个值都可以通过环境变量传递，但出于简单起见，我们没有在这里这样做。
- en: The logger hasn't been propagated, so avoid sending it to the `root` logger,
    which will duplicate the log.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 记录器尚未传播，因此避免将其发送到`root`记录器，这将重复记录。
- en: Logging each request
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录每个请求
- en: There are common elements in every request that we need to capture. Flask allows
    us to execute code before and after a request, so we can use that to log the common
    elements of each request. Let's learn how to do this.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 每个请求中都有一些常见元素需要捕获。Flask允许我们在请求之前和之后执行代码，因此我们可以使用它来记录每个请求的常见元素。让我们学习如何做到这一点。
- en: 'From the `app.py` file, we will define the `logging_before` function:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从`app.py`文件中，我们将定义`logging_before`函数：
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This creates a log with the word `REQUEST` and two essential parts of each request
    – the method and the URI – which come from `request.environ`. Then, they're added
    to an `INFO` log with the app logger.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个带有单词`REQUEST`和每个请求的两个基本部分（方法和URI）的日志，这些部分来自`request.environ`。然后，它们将添加到应用程序记录器的`INFO`日志中。
- en: We also use the `g` object to store the time when the request is started.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用`g`对象来存储请求开始时的时间。
- en: The `g` object allows us to store values through a request. We will use it to
    calculate the time the request is going to take.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`g`对象允许我们通过请求存储值。我们将使用它来计算请求将花费的时间。'
- en: 'There''s the corresponding `logging_after` function as well. It gathers the
    time at the end of the request and calculates the difference in milliseconds:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 还有相应的`logging_after`函数。它在请求结束时收集时间并计算毫秒数的差异：
- en: '[PRE18]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will allow us to detect requests that are taking longer and will be stored
    in metrics, as we will see in the following section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们能够检测到需要更长时间的请求，并将其存储在指标中，我们将在下一节中看到。
- en: 'Then, the functions are enabled in the `create_app` function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在“create_app”函数中启用了这些功能：
- en: '[PRE19]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This creates a set of logs each time we generate a request.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 每次生成请求时都会创建一组日志。
- en: With the logs generated, we can search for them in the `frontrail` interface.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 有了生成的日志，我们可以在“frontrail”界面中搜索它们。
- en: Searching through all the logs
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索所有日志
- en: All the different logs from different applications will be centralized and available
    to search for at `http://syslog.example.local`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 来自不同应用程序的所有不同日志将被集中并可在`http://syslog.example.local`上搜索。
- en: 'If you make a call to `http://frontend.example.local/search?search=speak` to
    search for thoughts, you will see the corresponding Thoughts Backend in the logs,
    as shown in the following screenshot:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您调用`http://frontend.example.local/search?search=speak`来搜索想法，您将在日志中看到相应的Thoughts
    Backend，如下图所示：
- en: '![](img/1254a0cc-90d6-4340-b901-95536a0a34e0.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1254a0cc-90d6-4340-b901-95536a0a34e0.png)'
- en: We can filter by the request ID, that is, `63517c17-5a40-4856-9f3b-904b180688f6`,
    to get the Thoughts Backend request logs. Just after this are the `thoughts_backend_uwsgi`
    and `frontend_uwsgi` request logs, which show the flow of the request.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按请求ID进行过滤，即“63517c17-5a40-4856-9f3b-904b180688f6”，以获取Thoughts Backend请求日志。紧接着是“thoughts_backend_uwsgi”和“frontend_uwsgi”请求日志，显示了请求的流程。
- en: 'Here, you can see all the elements we talked about previously:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到我们之前谈到的所有元素：
- en: The `REQUEST` log before the request
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求之前的“REQUEST”日志
- en: The `api_namespace` request, which contains app data
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含应用数据的“api_namespace”请求
- en: The after `RESPONSE` logs, which contain the result and time
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含结果和时间的“RESPONSE”日志
- en: Within the code for the Thoughts Backend, we left an error on purpose. It will
    be triggered if a user tries to share a new thought. We will use this to learn
    how to debug issues through logs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在Thoughts Backend的代码中，我们故意留下了一个错误。如果用户尝试分享新的想法，它将被触发。我们将使用这个来学习如何通过日志调试问题。
- en: Detecting problems through logs
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过日志检测问题
- en: 'For any problem in your running system, there are two kinds of errors that
    can occur: expected errors and unexpected errors.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在您运行的系统中，可能会出现两种类型的错误：预期错误和意外错误。
- en: Detecting expected errors
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测预期错误
- en: Expected errors are errors that are raised by explicitly creating an `ERROR`
    log in the code. If an error log is being generated, this means that it reflects
    a situation that has been planned in advance; for example, you can't connect to
    the database, or there is some data stored in an old, deprecated format. We don't
    want this to happen, but we saw the possibility of it happening and prepared the
    code to deal with it. They normally describe the situation well enough that the
    issue is obvious, even if the solution isn't.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 预期错误是通过在代码中显式创建“ERROR”日志而引发的错误。如果生成了错误日志，这意味着它反映了事先计划的情况；例如，无法连接到数据库，或者某些数据存储在旧的废弃格式中。我们不希望这种情况发生，但我们看到了它发生的可能性，并准备好了代码来处理它。它们通常描述得足够清楚，以至于问题是显而易见的，即使解决方案不明显。
- en: They are relatively easy to deal with since they describe foreseen problems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 它们相对容易处理，因为它们描述了预见的问题。
- en: Capturing unexpected errors
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 捕获意外错误
- en: Unexpected errors are the other types of errors that can occur. Things break
    in unforeseen ways. Unexpected errors are normally produced by Python exceptions
    being raised at some point in the code and not being captured.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 意外错误是可能发生的其他类型的错误。事情以意想不到的方式出错。意外错误通常是由于代码中某些地方引发了Python异常而未被捕获。
- en: If logging has been properly configured, any exceptions or errors that haven't
    been caught will trigger an `ERROR` log, which will include the stack trace. These
    errors may not be immediately obvious and will require further investigation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果日志已经正确配置，任何未被捕获的异常或错误都会触发一个“ERROR”日志，其中包括堆栈跟踪。这些错误可能不会立即显而易见，需要进一步调查。
- en: To help explain these errors, we introduced an exception in the code for the
    Thoughts Backend in the `Chapter10` code. You can check the code on GitHub ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend)).
    This simulates an unexpected exception.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助解释这些错误，我们在“Chapter10”代码的Thoughts Backend中引入了一个异常。您可以在GitHub上检查代码([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend))。这模拟了一个意外的异常。
- en: 'While trying to post a new thought for a logged user, we get a weird behavior
    and see the following error in the logs. As shown in the top-right corner of the
    following screenshot, we are filtering by `ERROR` to filter for problems:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试为已登录用户发布新想法时，我们会遇到奇怪的行为，并在日志中看到以下错误。如下图右上角所示，我们正在按“ERROR”进行过滤以查找问题：
- en: '![](img/3bad0ee5-9505-4648-8158-cf878d1969ad.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3bad0ee5-9505-4648-8158-cf878d1969ad.png)'
- en: As you can see, the stack trace is displayed in a single line. This may depend
    on how you capture and display the logs. Flask will automatically generate an
    HTTP response with a status code of 500\. This may trigger more errors along the
    path if the caller isn't ready to receive a 500 response.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，堆栈跟踪显示在单行中。这可能取决于您如何捕获和显示日志。Flask将自动生成一个状态码为500的HTTP响应。如果调用者没有准备好接收500响应，这可能会在路径上触发更多错误。
- en: Then, the stack trace will let you know what broke. In this case, we can see
    that there's a `raise Exception` command in the `api_namespace.py` file at line
    80\. This allows us to locate the exception.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，堆栈跟踪将让您知道出了什么问题。在这种情况下，我们可以看到在第80行的“api_namespace.py”文件中有一个“raise Exception”命令。这使我们能够定位异常。
- en: Since this is a synthetic error that's been generated specifically as an example,
    it is actually easy to find out the root cause. In the example code, we are explicitly
    raising an exception, which produces an error. This may not be the case in a real
    use case, where the exception could be generated in a different place than the
    actual error. Exceptions can be also originated in a different microservice within
    the same cluster.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个特意生成的合成错误示例，实际上很容易找到根本原因。在示例代码中，我们明确引发了一个异常，这会产生一个错误。在实际用例中可能不是这种情况，异常可能在与实际错误不同的地方生成。异常也可能来自同一集群中的不同微服务。
- en: After detecting the error, the objective should be to replicate it with a unit
    test in the microservice in order to generate the exception. This will allow us
    to replicate the conditions in a controlled environment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到错误后，目标应该是在微服务中使用单元测试复制错误以生成异常。这将使我们能够在受控环境中复制条件。
- en: 'If we run the tests for the Thoughts Backend code that''s available in `Chapter10`,
    we will see errors because of this. Note that the logs are being displayed in
    failing tests:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行 `Chapter10` 中可用的 Thoughts Backend 代码的测试，我们将看到由于此原因而出现错误。请注意，日志将显示在失败的测试中。
- en: '[PRE20]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once the error has been reproduced in unit tests, fixing it will often be trivial.
    Add a unit test to capture the set of conditions that trigger the error and then
    fix it. The new unit test will detect whether the error has been reintroduced
    on each automated build.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在单元测试中重现了错误，修复它通常会很简单。添加一个单元测试来捕获触发错误的条件，然后修复它。新的单元测试将检测每次自动构建中是否重新引入了错误。
- en: To fix the example code, remove the `raise` line of code. Then, things will
    work again.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 要修复示例代码，请删除 `raise` 代码行。然后，事情将再次正常工作。
- en: Sometimes, the problem cannot be solved as it may be external. Maybe there's
    a problem in some of the rows in our database or maybe another service is returning
    incorrectly formatted data. In those cases, we can't completely avoid the root
    cause of the error. However, it's possible to capture the problem, do some remediation,
    and move from an unexpected error to an expected error.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，问题无法解决，因为可能是外部问题。也许我们的数据库中的某些行存在问题，或者另一个服务返回的数据格式不正确。在这些情况下，我们无法完全避免错误的根本原因。但是，可以捕获问题，进行一些补救，并从意外错误转变为预期错误。
- en: Note that not every detected unexpected error is worth spending time on. Sometimes,
    uncaptured errors provide enough information on what the problem is, which is
    out of the realm of what the web service should handle; for example, there may
    be a network problem and the web service can't connect to the database. Use your
    judgment when you want to spend time on development.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，并非每个检测到的意外错误都值得花时间处理。有时，未捕获的错误提供了足够的信息，超出了Web服务应该处理的范围；例如，可能存在网络问题，Web服务无法连接到数据库。在开发时，要根据自己的判断来决定是否要花时间处理。
- en: Logging strategy
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录策略
- en: There's a problem when we're dealing with logs. What is the adequate level for
    a particular message? Is this a `WARNING` or an `ERROR`? Should this be an `INFO`
    statement?
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 处理日志时存在问题。对于特定消息，什么是适当的级别？这是 `WARNING` 还是 `ERROR`？这应该是一个 `INFO` 语句吗？
- en: Most of the log level descriptions use definitions such as *the program shows
    a potentially harmful situation* or *the program highlights the progress of the
    request*. These are vague and not very useful in a real-life environment. Instead,
    try to define each log level by relating them to the expected follow-up action.
    This helps provide clarity on what to do when a log of a particular level is found.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数日志级别描述使用定义，例如“程序显示潜在的有害情况”或“程序突出显示请求的进展”。这些定义模糊且在实际环境中并不是很有用。相反，尝试通过将每个日志级别与预期的后续操作联系起来来定义每个日志级别。这有助于明确发现特定级别的日志时应该采取的行动。
- en: 'The following table shows some examples of the different levels and what action
    should be taken:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了不同级别的一些示例以及应该采取的行动：
- en: '| **Log level** | **Action to take** | **Comments** |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| **日志级别** | **采取的行动** | **评论** |'
- en: '| `DEBUG` | Nothing. | Not tracked. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| `DEBUG` | 无。 | 不跟踪。'
- en: '| `INFO` | Nothing. | The `INFO` logs show generic information about the flow
    of the request to help track problems. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| `INFO` | 无。 | `INFO` 日志显示有关请求流程的通用信息，以帮助跟踪问题。'
- en: '| `WARNING` | Track number. Alert on raising levels. | The `WARNING` logs track
    errors that have been automatically fixed, such as retries to connect (but finally
    connecting) or fixable formatting errors in the database''s data. A sudden increase
    may require investigation. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| `WARNING` | 跟踪数量。在提高级别时发出警报。 | `WARNING` 日志跟踪已自动修复的错误，例如重试连接（但最终连接成功）或数据库数据中可修复的格式错误。突然增加可能需要调查。'
- en: '| `ERROR` | Track number. Alert on raising levels. Review all. | The `ERROR`
    logs track errors that can''t be fixed. A sudden increase may require immediate
    action so that this can be remediated. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| `ERROR` | 跟踪数量。在提高级别时发出警报。审查所有。 | `ERROR` 日志跟踪无法修复的错误。突然增加可能需要立即采取行动以进行补救。'
- en: '| `CRITICAL` | Immediate response. | A `CRITICAL` log indicates a catastrophic
    failure in the system. Even one will indicate that the system is not working and
    can''t recover. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| `CRITICAL` | 立即响应。 | `CRITICAL` 日志表示系统发生了灾难性故障。即使一个 `CRITICAL` 日志也表明系统无法正常工作且无法恢复。'
- en: This is just a recommendation, but it sets clear expectations on how to respond.
    Depending on how your teams and your expected level of service work, you can adapt
    them to your use case.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个建议，但它为如何做出响应设定了明确的期望。根据团队和期望的服务水平的工作方式，可以将其调整为自己的用例。
- en: Here, the hierarchy is very clear, and there's an acceptance that a certain
    number of `ERROR` logs will be generated. Not everything needs to be fixed immediately,
    but they should be noted and reviewed.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，层次结构非常清晰，并且人们接受一定数量的 `ERROR` 日志将被生成。并非所有问题都需要立即修复，但应该记录并进行审查。
- en: In real life, `ERROR` logs will be typically categorized as "we're doomed" or
    "meh." Development teams should actively either fix or remove "mehs" to reduce
    them as much as possible. That may include lowering the level of logs if they
    aren't covering actual errors. You want as few `ERROR` logs as possible, but all
    of them need to be meaningful.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中，`ERROR`日志通常被归类为“我们注定要失败”或“无所谓”。开发团队应该积极修复或删除“无所谓”的错误，以尽量减少它们。这可能包括降低日志级别，如果它们没有涵盖实际错误的话。您希望尽可能少的`ERROR`日志，但所有这些日志都需要有意义。
- en: Be pragmatic, though. Sometimes, errors can't be fixed straight away and time
    is best utilized in other tasks. However, teams should reserve time to reduce
    the number of errors that occur. Failing to do so will compromise the reliability
    of the system in the medium term.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，务实一点。有时，错误无法立即修复，时间最好用在其他任务上。然而，团队应该保留时间来减少发生的错误数量。不这样做将会损害系统的中期可靠性。
- en: '`WARNING` logs are indications that something may not be working as smoothly
    as we expected, but there''s no need to panic unless the numbers grow. `INFO`
    is just there to give us context if there''s a problem, but otherwise should be
    ignored.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`WARNING`日志表明某些事情可能不像我们预期的那样顺利，但除非数字增长，否则无需惊慌。`INFO`只是在出现问题时为我们提供上下文，但在其他情况下应该被忽略。'
- en: Avoid the temptation to produce an `ERROR` log when there's a request returning
    a 400 BAD REQUEST status code. Some developers will argue that if the customer
    sent a malformed request, it is actually an error. But this isn't something that
    you should care about if the request has been properly detected and returned.
    This is business as usual. If this behavior can lead to indicate something else,
    such as repeated attempts to send incorrect passwords, you can set a `WARNING`
    log. There's no point in generating `ERROR` logs when your system is behaving
    as expected.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在请求返回400 BAD REQUEST状态代码时产生`ERROR`日志的诱惑。一些开发人员会认为，如果客户发送了格式不正确的请求，那实际上就是一个错误。但是，如果请求已经被正确检测并返回，这并不是你应该关心的事情。这是业务惯例。如果这种行为可能表明其他问题，比如重复尝试发送不正确的密码，您可以设置`WARNING`日志。当系统表现如预期时，生成`ERROR`日志是没有意义的。
- en: As a rule of thumb, if a request is not returning some sort of 500 error (500,
    502, 504, and so on), it should not generate an `ERROR` log. Remember the categorization
    of 400 errors as *you (customer) have a problem* versus 500 errors, which are
    categorized as *I have a problem*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个经验法则，如果一个请求没有返回某种500错误（500、502、504等），它不应该生成`ERROR`日志。记住将400错误归类为*您（客户）有问题*，而将500错误归类为*我有问题*。
- en: This is not absolute, though. For example, a spike in authentication errors
    that are normally 4XX errors may indicate that users cannot create logs due to
    a real internal problem.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并非绝对。例如，通常为4XX错误的认证错误激增可能表明用户由于真正的内部问题而无法创建日志。
- en: With these definitions in mind, your development and operations teams will have
    a shared understanding that will help them take meaningful actions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些定义，您的开发和运维团队将有一个共同的理解，这将帮助他们采取有意义的行动。
- en: Expect to tweak the system and change some of the levels of the logs as your
    system matures.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统的成熟，预计需要调整系统并更改日志级别。
- en: Adding logs while developing
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在开发过程中添加日志
- en: As we've already seen, properly configuring `pytest` will make any errors in
    tests display the captured logs.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经看到的，正确配置`pytest`将使测试中的任何错误显示捕获的日志。
- en: This is an opportunity to check that the expected logs are being generated while
    a feature is in development. Any test that checks error conditions should also
    add its corresponding logs and check that they are being generated during the
    development of the feature.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个机会，可以在开发功能时检查是否生成了预期的日志。检查错误条件的任何测试也应该添加相应的日志，并在开发功能期间检查它们是否生成。
- en: You can check the logs as part of testing with a tool such as `pytest-catchlog`
    ([https://pypi.org/project/pytest-catchlog/](https://pypi.org/project/pytest-catchlog/))
    to enforce that the proper logs are being produced.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以检查日志作为测试的一部分，使用诸如`pytest-catchlog`（[https://pypi.org/project/pytest-catchlog/](https://pypi.org/project/pytest-catchlog/)）这样的工具来强制执行正确的日志生成。
- en: Typically, though, just taking a bit of care and checking during development
    that logs are produced is enough for most cases. However, be sure that developers
    understand why it's useful to have logs while they're developing.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，在开发过程中，只需稍加注意并检查是否生成了日志就足够了。但是，确保开发人员了解在开发过程中拥有日志的用处。
- en: During development, `DEBUG` logs can be used to show extra information about
    the flow that will be too much for production. This may fill in the gaps between
    `INFO` logs and help us develop the habit of adding logs. A `DEBUG` log may be
    promoted to `INFO` if, during tests, it's discovered that it will be useful for
    tracking problems in production.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，`DEBUG`日志可用于显示关于流程的额外信息，这些信息对于生产环境来说可能过多。这可以填补`INFO`日志之间的空白，并帮助我们养成添加日志的习惯。如果在测试期间发现`DEBUG`日志对于在生产环境中跟踪问题有用，可以将其提升为`INFO`。
- en: Potentially, `DEBUG` logs can be enabled in production in controlled cases to
    track some difficult problems, but be aware of the implications of having a large
    number of logs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在受控情况下，可能会在生产环境中启用`DEBUG`日志以跟踪一些困难的问题，但要注意拥有大量日志的影响。
- en: Be sensible with the information that's presented in `INFO` logs. In terms of
    the information that's displayed, avoid sensible data such as passwords, secret
    keys, credit card numbers, or personal information. This is the same for the number
    of logs.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在`INFO`日志中呈现的信息要明智。在显示的信息方面，避免敏感数据，如密码、密钥、信用卡号或个人信息。日志数量也是如此。
- en: Keep an eye on any size limitations and how quickly logs are being generated.
    Growing systems may have a log explosion while new features are being added, more
    requests are flowing through the system, and new workers are being added.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意任何大小限制以及日志生成的速度。随着新功能的添加、更多请求通过系统流动以及新的工作人员的加入，不断增长的系统可能会导致日志爆炸。
- en: Also, double-check that the logs are being generated and captured correctly
    and that they work at all the different levels and environments. All of this configuration
    may take a bit of time, but you need to be very sure that you can capture unexpected
    errors in production and that all the plumbing is set correctly.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还要仔细检查日志是否被正确生成和捕获，并且它们在所有不同级别和环境中是否起作用。所有这些配置可能需要一些时间，但您需要非常确定您能够在生产环境中捕获意外错误，并且所有的管道都设置正确。
- en: 'Let''s take a look at the other key element when it comes to observability:
    metrics.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看可观察性的另一个关键要素：指标。
- en: Setting up metrics
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置指标
- en: To set up metrics with Prometheus, we need to understand how the process works.
    Its key component is that each service that's measured has its own Prometheus
    client that keeps track of the metrics. The data in the Prometheus server will
    be available for a Grafana service that will plot the metrics.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Prometheus设置指标，我们需要了解该过程的工作原理。其关键组件是，每个受测量的服务都有自己的Prometheus客户端，用于跟踪指标。Prometheus服务器中的数据将可供Grafana服务绘制指标。
- en: 'The following diagram shows the general architecture:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了一般架构：
- en: '![](img/5b14900d-d4cd-4768-a10b-7a918425d553.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b14900d-d4cd-4768-a10b-7a918425d553.png)'
- en: The Prometheus server pulls information at regular intervals. This method of
    operation is very lightweight since registering metrics just updates the local
    memory of the service and scales well. On the other hand, it shows sampled data
    at certain times and doesn't register each individual event. This has certain
    implications in terms of storing and representing data and imposes limitations
    on the resolution of the data, especially for very low rates.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus服务器定期拉取信息。这种操作方法非常轻量级，因为注册指标只是更新服务的本地内存并且能够很好地扩展。另一方面，它在特定时间显示采样数据，并且不会注册每个单独的事件。这在存储和表示数据方面有一定的影响，并且对数据的分辨率施加了限制，特别是对于非常低的速率。
- en: 'There are lots of available metrics exporters that will expose standard metrics
    in different systems, such as databases, hardware, HTTP servers, or storage. Check
    out the Prometheus documentation for more information: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的指标导出器，它们将在不同系统中公开标准指标，如数据库、硬件、HTTP服务器或存储。查看Prometheus文档以获取更多信息：[https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)。
- en: This means that each of our services needs to install a Prometheus client and
    expose its collected metrics in some way. We will use standard clients for Flask
    and Django.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们的每个服务都需要安装一个Prometheus客户端，并以某种方式公开其收集的指标。我们将使用Flask和Django的标准客户端。
- en: Defining metrics for the Thoughts Backend
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思想后端的指标定义
- en: For Flask applications, we will use the `prometheus-flask-exporter` package
    ([https://github.com/rycus86/prometheus_flask_exporter](https://github.com/rycus86/prometheus_flask_exporter)),
    which has been added to `requirements.txt`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Flask应用程序，我们将使用`prometheus-flask-exporter`包（[https://github.com/rycus86/prometheus_flask_exporter](https://github.com/rycus86/prometheus_flask_exporter)），已添加到`requirements.txt`中。
- en: It gets activated in the `app.py` file ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95))
    when the application is created.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序创建时，它会在`app.py`文件中激活（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L95)）。
- en: 'The `metrics` object is set up with no app, and is then instantiated in the
    `created_app` function:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`metrics`对象没有设置应用程序，然后在`created_app`函数中实例化：'
- en: '[PRE21]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This generates an endpoint in the `/metrics` service endpoint, that is, `http://thoughts.example.local/metrics`,
    which returns the data in Prometheus format. The Prometheus format is plain text,
    as shown in the following screenshot:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成`/metrics`服务端点中的一个端点，即`http://thoughts.example.local/metrics`，它以Prometheus格式返回数据。Prometheus格式是纯文本，如下截图所示：
- en: '![](img/81ba132d-890c-4b57-96db-46bbfca38f44.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/81ba132d-890c-4b57-96db-46bbfca38f44.png)'
- en: The default metrics that are captured by `prometheus-flask-exporter` are request
    calls based on the endpoint and the method (`flask_http_request_total`), as well
    as the time they took (`flask_http_request_duration_seconds`).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`prometheus-flask-exporter`捕获的默认指标是基于端点和方法的请求调用（`flask_http_request_total`），以及它们所花费的时间（`flask_http_request_duration_seconds`）。'
- en: Adding custom metrics
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加自定义指标
- en: We may want to add more specific metrics when it comes to application details.
    We also added some extra code at the end of the request so that we can store similar
    information to the metric that `prometheus-flask-exporter` allows us to.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及应用程序细节时，我们可能希望添加更具体的指标。我们还在请求结束时添加了一些额外的代码，以便我们可以存储与`prometheus-flask-exporter`允许我们存储的类似信息。
- en: In particular, we added this code to the `logging_after` function ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72))
    using the lower-level `prometheus_client`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们在`logging_after`函数中添加了此代码（[https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72)），使用较低级别的`prometheus_client`。
- en: 'This code creates `Counter` and `Histogram`:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建了`Counter`和`Histogram`：
- en: '[PRE22]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, we''ve created two metrics: a counter called `requests` and a histogram
    called `req_time`. A histogram is a Prometheus implementation of measures and
    events that have a specific value, such as the request time (in our case).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了两个指标：一个名为`requests`的计数器和一个名为`req_time`的直方图。直方图是Prometheus对具有特定值的度量和事件的实现，例如请求时间（在我们的情况下）。
- en: The histogram stores the values in buckets, thereby making it possible for us
    to calculate quantiles. Quantiles are very useful to determine metrics such as
    the 95% value for times, such as the aggregate time, where 95% comes lower than
    it. This is much more useful than averages since outliers won't pull from the
    average.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图将值存储在桶中，从而使我们能够计算分位数。分位数对于确定诸如时间的95%值非常有用，例如聚合时间，其中95%低于它。这比平均值更有用，因为异常值不会影响平均值。
- en: There's another similar metric called summary. The differences are subtle, but
    generally, the metric we should use is a histogram. Check out the Prometheus documentation
    for more details ([https://prometheus.io/docs/practices/histograms/](https://prometheus.io/docs/practices/histograms/)).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个类似的指标叫做摘要。差异是微妙的，但通常，我们应该使用直方图。查看Prometheus文档以获取更多详细信息([https://prometheus.io/docs/practices/histograms/](https://prometheus.io/docs/practices/histograms/))。
- en: The metrics are defined in `METRIC_REQUESTS` and `METRIC_REQ_TIME` by their
    name, their measurement, and the labels they define. Each label is an extra dimension
    of the metric, so you will be able to filter and aggregate by them. Here, we define
    the endpoint, the HTTP method, and the resulting HTTP status code.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 指标由它们的名称、测量和它们定义的标签`METRIC_REQUESTS`和`METRIC_REQ_TIME`定义。每个标签都是指标的额外维度，因此您将能够通过它们进行过滤和聚合。在这里，我们定义了端点、HTTP方法和生成的HTTP状态码。
- en: For each request, the metric is updated. We need to set up the labels, the counter
    calls, that is, `.inc()`, and the histogram calls, that is, `.observe(time)`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个请求，指标都会更新。我们需要设置标签、计数器调用，即`.inc()`，以及直方图调用，即`.observe(time)`。
- en: You can find the documentation for the Prometheus client at [https://github.com/prometheus/client_python](https://github.com/prometheus/client_python).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/prometheus/client_python](https://github.com/prometheus/client_python)找到Prometheus客户端的文档。
- en: We can see the `request` and `req_time` metrics on the metrics page.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在指标页面上看到`request`和`req_time`指标。
- en: '**Setting up metrics for the Users Backend follows a similar pattern.** The
    Users Backend is a similar Flask application, so we install `prometheus-flask-exporter`
    as well, but no custom metrics. You can access these metrics at `http://users.example.local/metrics`.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为用户后端设置指标遵循类似的模式。用户后端是一个类似的Flask应用程序，因此我们也安装了`prometheus-flask-exporter`，但没有自定义指标。您可以在`http://users.example.local/metrics`上访问这些指标。
- en: The next stage is to set up a Prometheus server so that we can collect the metrics
    and aggregate them properly.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 下一阶段是设置一个Prometheus服务器，以便我们可以正确地收集和聚合指标。
- en: Collecting the metrics
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集指标。
- en: For this, we need to deploy the metrics using Kubernetes. We prepared a YAML
    file with everything set up already in the `Chapter10/kubernetes/prometheus.yaml`
    file.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要使用Kubernetes部署指标。我们已经在`Chapter10/kubernetes/prometheus.yaml`文件中准备好了一切。
- en: This YAML file contains a deployment, a `ConfigMap`, which contains the configuration
    file, a service, and an Ingress. The service and Ingress are pretty standard,
    so we won't comment on them here.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这个YAML文件包含一个部署、一个包含配置文件的`ConfigMap`、一个服务和一个Ingress。服务和Ingress都是非常标准的，所以我们在这里不会对它们进行评论。
- en: 'The `ConfigMap` allows us to define a file:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConfigMap`允许我们定义一个文件：'
- en: '[PRE23]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note how the `prometheus.yaml` file is generated after the `|` symbol. This
    is a minimal Prometheus configuration scraping from the `thoughts-service`, `users-service`,
    and `frontend-service` servers. As we know from the previous chapters, these names
    access the services and will connect to the pods that are serving the applications.
    They will automatically search for the `/metrics` path.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`prometheus.yaml`文件是在`|`符号之后生成的。这是一个最小的Prometheus配置，从`thoughts-service`、`users-service`和`frontend-service`服务器中抓取。正如我们从前面的章节中所知，这些名称访问服务，并将连接到提供应用程序的pod。它们将自动搜索`/metrics`路径。
- en: There is a small caveat here. From the point of view of Prometheus, everything
    behind the service is the same server. If you have more than one pod being served,
    the metrics that are being accessed by Prometheus will be load balanced and the
    metrics won't be correct.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个小注意事项。从Prometheus的角度来看，服务后面的一切都是相同的服务器。如果有多个正在提供服务的pod，那么Prometheus访问的指标将被负载平衡，指标将不正确。
- en: This is fixable with a more complicated Prometheus setup whereby we install
    the Prometheus operator, but this is out of the scope of this book. However, this
    is highly recommended for a production system. In essence, it allows us to annotate
    each of the different deployments so that the Prometheus configuration is dynamically
    changed. This means we can access all the metrics endpoints exposed by the pods
    automatically once this has been set up. Prometheus Operator annotations make
    it very easy for us to add new elements to the metrics system.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过更复杂的Prometheus设置来解决，其中我们安装Prometheus操作员，但这超出了本书的范围。但是，这对于生产系统非常推荐。实质上，它允许我们注释每个不同的部署，以便动态更改Prometheus配置。这意味着一旦设置完成，我们就可以自动访问由pod公开的所有指标端点。Prometheus操作员注释使我们非常容易向指标系统添加新元素。
- en: 'Check out the following article if you want to learn how to do this: [https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3](https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3).'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解如何执行此操作，请查看以下文章：[https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3](https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3)。
- en: 'The deployment creates a container from the public Prometheus image in `prom/prometheus`,
    as shown in the following code:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 部署将从`prom/prometheus`中的公共Prometheus镜像创建一个容器，如下所示：
- en: '[PRE24]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It also mounts `ConfigMap` as a volume, and then as a file in `/etc/prometheus/prometheus.yml`.
    This starts the Prometheus server with that configuration. The container opens
    port `9090`, which is the default for Prometheus.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 它还将`ConfigMap`挂载为卷，然后作为文件挂载到`/etc/prometheus/prometheus.yml`中。这将使用该配置启动Prometheus服务器。容器打开端口`9090`，这是Prometheus的默认端口。
- en: 'At this point, note how we delegated for the Prometheus container. This is
    one of the advantages of using Kubernetes: we can use standard available containers
    to add features to our cluster with minimal configuration. We don''t even have
    to worry about the operating system or the packaging of the Prometheus container.
    This simplifies operations and allows us to standardize the tools we use.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，请注意我们委托了Prometheus容器。这是使用Kubernetes的优势之一：我们可以使用标准可用的容器，以最小的配置为我们的集群添加功能。我们甚至不必担心操作系统或Prometheus容器的打包。这简化了操作，并允许我们标准化我们使用的工具。
- en: The deployed Prometheus server can be accessed at `http://prometheus.example.local/`,
    as described in the Ingress and service.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的Prometheus服务器可以通过`http://prometheus.example.local/`访问，如Ingress和service中所述。
- en: 'This displays a graphic interface that can be used to plot the graphs, as shown
    in the following screenshot:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了一个图形界面，可用于绘制图形，如下面的屏幕截图所示：
- en: '![](img/98c116d8-05e9-461b-b13b-d8a24a240609.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98c116d8-05e9-461b-b13b-d8a24a240609.png)'
- en: The Expression search box will also autocomplete metrics, helping with the discovery
    process.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式搜索框还将自动完成指标，有助于发现过程。
- en: 'The interface also displays other elements from Prometheus that are interesting,
    such as the configuration or the statuses of the targets:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 该界面还显示了来自Prometheus的其他有趣元素，例如配置或目标的状态：
- en: '![](img/4a164941-5d6b-4364-903e-5123751f6476.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a164941-5d6b-4364-903e-5123751f6476.png)'
- en: The graphs in this interface are usable, but we can set up more complicated
    and useful dashboards through Grafana. Let's see how this setup works.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 此界面中的图形可用，但我们可以通过Grafana设置更复杂和有用的仪表板。让我们看看这个设置是如何工作的。
- en: Plotting graphs and dashboards
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制图形和仪表板
- en: The required Kubernetes configuration, `grafana.yaml`, is available in this
    book's GitHub repository in the `Chapter10/kubernetes/metrics` directory. Just
    like we did with Prometheus, we used a single file to configure Grafana.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的Kubernetes配置`grafana.yaml`可在本书的GitHub存储库的`Chapter10/kubernetes/metrics`目录中找到。就像我们使用单个文件配置Prometheus一样，我们也使用单个文件配置Grafana。
- en: 'We won''t show the Ingress and service for the same reason we explained previously.
    The deployment is simple, but we mount two volumes instead of one, as shown in
    the following code:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 出于与之前解释的相同原因，我们不会显示Ingress和service。部署很简单，但我们挂载了两个卷而不是一个，如下面的代码所示：
- en: '[PRE25]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `volume-config` volume shares a single file that configures Grafana. The
    `volume-dashboard` volume adds a dashboard. The latter mounts a directory that
    contains two files. Both mounts are in the default location that Grafana expects
    for configuration files.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '`volume-config`卷共享一个配置Grafana的单个文件。`volume-dashboard`卷添加了一个仪表板。后者挂载了一个包含两个文件的目录。这两个挂载点都在Grafana期望的配置文件的默认位置。'
- en: 'The `volume-config` volume sets up the data source in the place where Grafana
    will receive the data to plot:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`volume-config`卷设置了Grafana将接收数据以绘制的数据源的位置：'
- en: '[PRE26]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The data comes from `http://prometheus-service` and points to the Prometheus
    service we configured previously.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自`http://prometheus-service`，指向我们之前配置的Prometheus服务。
- en: '`volume-dashboard` defines two files, `dashboard.yaml` and `dashboard.json`:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`volume-dashboard`定义了两个文件，`dashboard.yaml`和`dashboard.json`：'
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`dashboard.yaml` is a simple file that points to the directory where we can
    find JSON files describing the available dashboards for the system. We point to
    the same directory to mount everything with a single volume.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`dashboard.yaml`是一个简单的文件，指向我们可以找到描述系统可用仪表板的JSON文件的目录。我们指向相同的目录以挂载所有内容到单个卷。'
- en: '`dashboard.json` is redacted here to save space; check out this book''s GitHub
    repository for the data.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`dashboard.json`在此处被编辑以节省空间；查看本书的GitHub存储库以获取数据。'
- en: '`dashboard.json` describes a dashboard in JSON format. This file can be automatically
    generated through the Grafana UI. Adding more `.json` files will create new dashboards.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`dashboard.json`以JSON格式描述了一个仪表板。通过Grafana用户界面可以自动生成此文件。添加更多`.json`文件将创建新的仪表板。'
- en: Grafana UI
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Grafana用户界面
- en: 'By accessing `http://grafana.example.local` and using your login/password details,
    that is, `admin/admin` (the default values), you can access the Grafana UI:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 通过访问`http://grafana.example.local`并使用您的登录/密码详细信息，即`admin/admin`（默认值），您可以访问Grafana用户界面：
- en: '![](img/e0ed3527-9a22-4a49-8356-5e58795741ac.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0ed3527-9a22-4a49-8356-5e58795741ac.png)'
- en: 'From there, you can check the dashboard, which can be found in the left central
    column:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，您可以检查仪表板，该仪表板可以在左侧中央列中找到：
- en: '![](img/15311ba9-bf88-4c0c-8b8b-15a29b88edf3.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15311ba9-bf88-4c0c-8b8b-15a29b88edf3.png)'
- en: 'This captures the calls to Flask, both in terms of numbers and in *95^(th)*
    percentile time. Each individual graph can be edited so that we can see the recipe
    that produces it:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这捕捉了对Flask的调用，无论是数量还是*95^(th)*百分位时间。每个单独的图形都可以进行编辑，以便我们可以看到生成它的配方：
- en: '![](img/bfba98e1-1532-46a9-8bbd-126745e3ee24.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bfba98e1-1532-46a9-8bbd-126745e3ee24.png)'
- en: The icons on the left allow us to change the queries that are running in the
    system, change the visualization (units, colors, bars or lines, kind of scale
    to plot, and so on), add general information such as name, and create alerts.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的图标允许我们更改系统中运行的查询，更改可视化（单位、颜色、条形或线条、绘图的类型等），添加名称等一般信息，并创建警报。
- en: The Grafana UI allows us to experiment and so is highly interactive. Take some
    time to try out the different options and learn how to present the data.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana用户界面允许我们进行实验，因此非常互动。花些时间尝试不同的选项，并学习如何呈现数据。
- en: The Query section allows us to add and display metrics from Prometheus. Note
    the Prometheus logo near default, which is the data source.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 查询部分允许我们从Prometheus添加和显示指标。请注意默认附近的Prometheus徽标，这是数据源。
- en: Each of the queries has a Metrics section that extracts data from Prometheus.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询都有一个从Prometheus中提取数据的指标部分。
- en: Querying Prometheus
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询Prometheus
- en: Prometheus has its own query language called PromQL. The language is very powerful,
    but it presents some peculiarities.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus有自己的查询语言称为PromQL。这种语言非常强大，但它也有一些特殊之处。
- en: The Grafana UI helps by autocompleting the query, which makes it easy for us
    to search for metric names. You can experiment directly in the dashboard, but
    there's a page on Grafana called Explore that allows you to make queries out of
    any dashboard and has some nice tips, including basic elements. This is denoted
    by a compass icon in the left sidebar.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana UI通过自动完成查询来帮助我们，这使我们可以轻松搜索指标名称。您可以直接在仪表板中进行实验，但是Grafana上有一个名为Explore的页面，允许您从任何仪表板进行查询，并提供一些不错的提示，包括基本元素。这在左侧边栏中用一个指南针图标表示。
- en: The first thing to keep in mind is understanding the Prometheus metrics. Given
    its sampling approach, most of them are monotonically increasing. This means that
    plotting the metrics will show a line going up and up.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要记住的是了解Prometheus指标。鉴于其采样方法，大多数指标是单调递增的。这意味着绘制指标将显示一条不断上升的线。
- en: 'To get the rate at which the value changes over a period of time, you need
    to use `rate`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得值在一段时间内变化的速率，需要使用`rate`：
- en: '[PRE28]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This generates the requests per second, on average, with a moving window of
    `5` minutes. The rate can be further aggregated using `sum` and `by`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成每秒的请求率，平均使用`5`分钟的移动窗口。速率可以进一步使用`sum`和`by`进行聚合：
- en: '[PRE29]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To calculate the times, you can use `avg` instead. You can also group by more
    than one label:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算时间，可以使用`avg`。您还可以按多个标签进行分组：
- en: '[PRE30]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'However, you can also set up quantiles, just like we can in graphs. We multiply
    by 100 to get the time in milliseconds instead of seconds and group by `method`
    and `path`. Now, `le` is a special tag that''s created automatically and divides
    the data into multiple buckets. The `histogram_quantile` function uses this to
    calculate the quantiles:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，您也可以设置分位数，就像我们在图表中可以做的那样。我们乘以100以获得以毫秒为单位的时间，而不是秒，并按`method`和`path`进行分组。现在，`le`是一个特殊的标签，会自动创建并将数据分成多个桶。`histogram_quantile`函数使用这个来计算分位数：
- en: '[PRE31]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Metrics can be filtered so that only specific labels are displayed. They can
    also be used for different functions, such as division, multiplication, and so
    on.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 可以对指标进行过滤，以便仅显示特定的标签。它们还可以用于不同的功能，例如除法，乘法等。
- en: Prometheus queries can be a bit long and complicated when we're trying to display
    the result of several metrics, such as the percentage of successful requests over
    the total. Be sure to test that the result is what you expect it to be and allocate
    time to tweak the requests, later.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们试图显示几个指标的结果时，例如成功请求占总数的百分比时，Prometheus查询可能会有点长而复杂。一定要测试结果是否符合您的预期，并留出时间来调整请求。
- en: 'Be sure to check out the Prometheus documentation if you want to find out more:
    [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/).'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多，请务必查看Prometheus文档：[https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)。
- en: Updating dashboards
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新仪表板
- en: Dashboards can be interactively changed and saved, but in our Kubernetes configuration,
    we set up the volumes that contain the files as non-persistent. Due to this, restarting
    Grafana will discard any changes and reapply the defined configuration in `volume-dashboard`
    in the `Chapter10/kubernetes/metrics/grafana.yaml` file.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板可以进行交互式更改和保存，但在我们的Kubernetes配置中，我们设置了包含文件的卷为非持久性。因此，重新启动Grafana将丢弃任何更改，并重新应用`Chapter10/kubernetes/metrics/grafana.yaml`文件中`volume-dashboard`中定义的配置。
- en: This is actually a good thing since we apply the same GitOps principles to store
    the full configuration in the repository under Git source control.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是一件好事，因为我们将相同的GitOps原则应用于将完整配置存储在Git存储库中。
- en: However, as you can see, the full JSON description of the dashboard contained
    in the `grafana.yaml` file is very long, given the number of parameters and the
    difficulty to change them manually.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，正如您所看到的，包含在`grafana.yaml`文件中的仪表板的完整JSON描述非常长，因为参数的数量以及手动更改它们的困难。
- en: 'The best approach is to change the dashboard interactively and then export
    it into a JSON file with the Share file button at the top of the menu. Then, the
    JSON file can be added to the configuration:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的方法是交互式地更改仪表板，然后使用菜单顶部的共享文件按钮将其导出为JSON文件。然后，可以将JSON文件添加到配置中：
- en: '![](img/e3802571-88e1-4692-85bb-4560de9d23ea.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3802571-88e1-4692-85bb-4560de9d23ea.png)'
- en: The Grafana pod can then be redeployed and will contain the saved changes in
    the dashboard. The Kubernetes configuration can then be updated in Git through
    the usual process.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以重新部署Grafana pod，并且仪表板中的保存更改将包含在内。然后可以通过常规流程在Git中更新Kubernetes配置。
- en: 'Be sure to explore all the possibilities for dashboards, including the option
    to set up variables so that you can use the same dashboard to monitor different
    applications or environments and the different kinds of visualization tools. See
    the full Grafana documentation for more information: [https://grafana.com/docs/reference/](https://grafana.com/docs/reference/).'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 一定要探索仪表板的所有可能性，包括设置变量的选项，以便您可以使用相同的仪表板监视不同的应用程序或环境以及不同类型的可视化工具。有关更多信息，请参阅完整的Grafana文档：[https://grafana.com/docs/reference/](https://grafana.com/docs/reference/)。
- en: Having metrics available allows us to use them to proactively understand the
    system and anticipate any problems.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 有了可用的指标，我们可以利用它们来积极主动地了解系统并预测任何问题。
- en: Being proactive
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 积极主动
- en: Metrics show an aggregated point of view for the status of the whole cluster.
    They allow us to detect trending problems, but it's difficult to find a single
    spurious error.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 指标显示了整个集群状态的聚合视图。它们使我们能够检测趋势问题，但很难找到单个的偶发错误。
- en: Don't underestimate them, though. They are critical for successful monitoring
    because they tell us whether the system is healthy. In some companies, the most
    critical metrics are prominently displayed in screens on the wall so that the
    operations team can see them at all times and quickly react.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 不要低估它们。它们对于成功的监控至关重要，因为它们告诉我们系统是否健康。在一些公司，最关键的指标会在墙上的屏幕上显著显示，以便运维团队可以随时看到并迅速做出反应。
- en: 'Finding the proper balance for metrics in a system is not a straightforward
    task and will require time and trial and error. There are four metrics for online
    services that are always important, though. These are as follows:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统中找到指标的适当平衡并不是一项简单的任务，需要时间和反复试验。然而，对于在线服务来说，总有四个重要的指标。它们分别是：
- en: '**Latency**: How many milliseconds the system takes to respond to a request.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：系统响应请求所需的毫秒数。'
- en: Depending on the times, a different time unit, such as seconds or microseconds,
    can be used. From my experience, milliseconds is adequate since most of the requests
    in a web application system should take between 50 ms and 1 second to respond.
    Here, a system that takes 50 ms is too slow and one that takes 1 second is a very
    performant one.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 根据不同的时间，可以使用不同的时间单位，比如秒或微秒。根据我的经验，毫秒是足够的，因为在Web应用系统中，大多数请求的响应时间应该在50毫秒到1秒之间。在这里，花费50毫秒的系统速度太慢，而花费1秒的系统则是非常高效的。
- en: '**Traffic**: The number of requests flowing through the system per unit of
    time, that is, requests per second or per minute.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量**：单位时间内通过系统的请求数，即每秒或每分钟的请求数。'
- en: '**Errors**: The percentage of requests received that return an error.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误**：收到的返回错误的请求的百分比。'
- en: '**Saturation**: Whether the capacity of the cluster has enough headroom. This
    includes elements such as hard drive space, memory, and so on. For example, there
    is 20% available RAM memory.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**饱和度**：集群的容量是否有足够的余地。这包括诸如硬盘空间、内存等元素。例如，有20%的可用RAM内存。'
- en: To measure saturation, remember to install the available exporters that will
    collect most of the hardware information (memory, hard disk space, and so on)
    automatically. If you use a cloud provider, normally, they expose their own set
    of related metrics as well, for example, CloudWatch for AWS.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量饱和度，请记住安装可用的导出器，它们将自动收集大部分硬件信息（内存、硬盘空间等）。如果您使用云提供商，通常他们也会公开一套相关的指标，例如AWS的CloudWatch。
- en: These metrics can be found in the Google SRE Book as *the Four Golden Signals*
    and are recognized as the most important high-level elements for successful monitoring.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标可以在Google SRE Book中找到，被称为*四个黄金信号*，被认为是成功监控的最重要的高级元素。
- en: Alerting
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警报
- en: When problems arise in metrics, an automatic alert should be generated. Prometheus
    has an included alert system that will trigger when a defined metric fulfills
    the defined condition.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 当指标出现问题时，应该生成自动警报。Prometheus有一个包含的警报系统，当定义的指标满足定义的条件时会触发警报。
- en: 'Check out the Prometheus documentation on alerting for more information: [https://prometheus.io/docs/alerting/overview/](https://prometheus.io/docs/alerting/overview/).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 查看有关警报的Prometheus文档以获取更多信息：[https://prometheus.io/docs/alerting/overview/](https://prometheus.io/docs/alerting/overview/)。
- en: Prometheus' Alertmanager can perform certain actions, such as sending emails
    to be notified based on rules. This system can be connected to an integrated incident
    solution such as OpsGenie ([https://www.opsgenie.com](https://www.opsgenie.com))
    in order to generate all kinds of alerts and notifications, such as emails, SMS,
    calls, and so on.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus的Alertmanager可以执行某些操作，比如根据规则发送电子邮件进行通知。该系统可以连接到集成的事件解决方案，如OpsGenie（[https://www.opsgenie.com](https://www.opsgenie.com)），以生成各种警报和通知，如电子邮件、短信、电话等。
- en: Logs can also be used to create alerts. There are certain tools that allow us
    to create an entry when an `ERROR` is raised, such as **Sentry**. This allows
    us to detect problems and proactively remediate them, even if the health of the
    cluster hasn't been compromised.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 日志也可以用来创建警报。有一些工具允许我们在引发`ERROR`时创建一个条目，比如**Sentry**。这使我们能够检测问题并积极地进行补救，即使集群的健康状态没有受到影响。
- en: Some commercial tools that handle logs, such as Loggly, allow us to derive metrics
    from the logs themselves, plotting graphs either based on the kind of log or extracting
    values from them and using them as values. While not as complete as a system such
    as Prometheus, they can monitor some values. They also allow us to notify if thresholds
    are reached.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 一些商业工具可以处理日志，比如Loggly，允许我们从日志中派生指标，根据日志的类型绘制图表，或者从日志中提取值并将其用作数值。虽然不如Prometheus这样的系统完整，但它们可以监视一些数值。它们还允许我们在达到阈值时发出通知。
- en: The monitoring space is full of products, both free and paid, that can help
    us to handle this. While it's possible to create a completely in-house monitoring
    system, being able to analyze whether commercial cloud tools will be of help is
    crucial. The level of features and their integration with useful tools such as
    external alerting systems will be difficult to replicate and maintain.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 监控领域充满了各种产品，有免费的也有付费的，可以帮助我们处理这些问题。虽然可以创建一个完全内部的监控系统，但能够分析商业云工具是否有帮助是至关重要的。功能的水平以及它们与有用工具的集成，比如外部警报系统，将很难复制和维护。
- en: Alerting is also an ongoing process. Some elements will be discovered down the
    line and new alerts will have to be created. Be sure to invest time so that everything
    works as expected. Logs and metrics will be used while the system is unhealthy,
    and in those moments, time is critical. You don't want to be guessing about logs
    because the host parameter hasn't been configured correctly.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 警报也是一个持续的过程。一些元素将在后续发现，新的警报将不得不被创建。务必投入时间，以确保一切都按预期工作。在系统不健康的时候，日志和指标将被使用，而在那些时刻，时间至关重要。您不希望因为主机参数配置不正确而猜测日志。
- en: Being prepared
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: In the same way that a backup is not useful unless the recovery process has
    been tested and is working, be proactive when checking that the monitoring system
    is producing useful information.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 备份如果没有经过测试和工作的恢复过程是没有用的，当检查监控系统是否产生有用信息时要采取主动措施。
- en: In particular, try to standardize the logs so that there's a good expectation
    about what information to include and how it's structured. Different systems may
    produce different logs, but it's good to make all the microservices log in the
    same format. Double-check that any parameters, such as client references or hosts,
    are being logged correctly.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，尝试标准化日志，以便对包含什么信息以及其结构有一个良好的期望。不同的系统可能产生不同的日志，但最好让所有微服务以相同的格式记录日志。仔细检查任何参数，例如客户端引用或主机，是否被正确记录。
- en: The same applies to metrics. Having a set of metrics and dashboards that everyone
    understands will save a lot of time when you're tracking a problem.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 同样适用于指标。拥有一组所有人都理解的指标和仪表板将在跟踪问题时节省大量时间。
- en: Summary
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to work with logs and metrics, as well as how
    to set up logs and send them to a centralized container using the `syslog` protocol.
    We described how to add logs to different applications, how to include a request
    ID, and how to raise custom logs from the different microservices. Then, we learned
    how to define a strategy to ensure that the logs are useful in production.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何处理日志和指标，以及如何设置日志并使用`syslog`协议将其发送到集中式容器。我们描述了如何向不同的应用程序添加日志，如何包含请求ID，以及如何从不同的微服务中生成自定义日志。然后，我们学习了如何制定策略，以确保日志在生产中是有用的。
- en: We also described how to set up standard and custom Prometheus metrics in all
    the microservices. We started a Prometheus server and configured it so that it
    collects metrics from our services. We started a Grafana service so that we can
    plot the metrics and created dashboards so that we can display the status of the
    cluster and the different services that are running.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还描述了如何在所有微服务中设置标准和自定义的Prometheus指标。我们启动了一个Prometheus服务器，并对其进行配置，以便从我们的服务收集指标。我们启动了一个Grafana服务，以便我们可以绘制指标，并创建了仪表板，以便我们可以显示集群的状态和正在运行的不同服务。
- en: Then, we introduced you to the alert system in Prometheus and how it can be
    used so that it notifies us of problems. Remember that there are commercial services
    to help you with logs, metrics, and alerts. Analyze your options as they can save
    you a lot of time and money in terms of maintenance costs.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们向您介绍了Prometheus中的警报系统以及如何使用它来通知我们问题。请记住，有商业服务可以帮助您处理日志、指标和警报。分析您的选择，因为它们可以在维护成本方面为您节省大量时间和金钱。
- en: In the next chapter, we will learn how to manage changes and dependencies that
    affect several microservices and how to handle configurations and secrets.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何管理影响多个微服务的更改和依赖关系，以及如何处理配置和秘密。
- en: Questions
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the observability of a system?
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统的可观察性是什么？
- en: What are the different severity levels that are available in logs?
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志中有哪些不同的严重级别可用？
- en: What are metrics used for?
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标用于什么？
- en: Why do you need to add a request ID to logs?
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么需要向日志中添加请求ID？
- en: What are the available kinds of metrics in Prometheus?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus有哪些可用的指标类型？
- en: What is the 75th percentile in a metric and how does it differ from the average?
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标中的第75百分位是什么，它与平均值有何不同？
- en: What are the four golden signals?
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 四个黄金信号是什么？
- en: Further reading
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: You can learn more about monitoring with different tools and techniques while
    using Docker by reading *Monitoring Docker* ([https://www.packtpub.com/virtualization-and-cloud/monitoring-docker](https://www.packtpub.com/virtualization-and-cloud/monitoring-docker)).
    To find out more about Prometheus and Grafana, including how to set up alerts,
    please read *Hands-On Infrastructure Monitoring with Prometheus* ([https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过阅读*监控Docker*（[https://www.packtpub.com/virtualization-and-cloud/monitoring-docker](https://www.packtpub.com/virtualization-and-cloud/monitoring-docker)）来了解如何使用Docker使用不同工具和技术进行监控。要了解有关Prometheus和Grafana的更多信息，包括如何设置警报，请阅读*使用Prometheus进行基础设施监控*（[https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus)）。
- en: Monitoring is only the starting point of successfully running services reliably.
    To find out how to successfully improve your operations, check out *Real-World
    SRE* ([https://www.packtpub.com/web-development/real-world-sre](https://www.packtpub.com/web-development/real-world-sre)).
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 监控只是成功运行服务的起点。要了解如何成功改进您的运营，请查看*真实世界SRE*（[https://www.packtpub.com/web-development/real-world-sre](https://www.packtpub.com/web-development/real-world-sre)）。
