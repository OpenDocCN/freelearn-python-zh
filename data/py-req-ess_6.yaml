- en: Chapter 6. Web Scraping with Python Requests and BeautifulSoup
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用Python Requests和BeautifulSoup进行网页抓取
- en: We have become experts in how to communicate with the Web through `Requests`.
    Everything progressed flamboyantly while working with the APIs. However, there
    are some conditions where we need to be aware of API folklore.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成为了如何通过 `Requests` 与网络进行通信的专家。在与 API 一起工作时，一切进展得非常热烈。然而，有些情况下我们需要注意 API
    传说。
- en: The first thing that concerns us is not all web services have built an API for
    the sake of their third-party customers. Also, there is no statute that the API
    should be maintained perfectly. Even tech giants such as Google, Facebook, and
    Twitter tend to change their APIs abruptly without prior notice. So, it's better
    to understand that it is not always the API that comes to the rescue when we are
    looking for some vital information from a web resource.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先关注的问题是并非所有网络服务都为第三方客户构建了API。此外，也没有法律规定API必须得到完美的维护。即使是像谷歌、Facebook和Twitter这样的技术巨头，也倾向于在没有事先通知的情况下突然更改他们的API。因此，我们最好理解，当我们从网络资源中寻找一些关键信息时，并不总是API会及时伸出援手。
- en: The concept of **web scraping** stands as a savior when we really turn imperative
    to access some information from a web resource that does not maintain an API.
    In this chapter, we will discuss tricks of the trade to extract information from
    web resources by following all the principles of web scraping.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**网络爬虫**这一概念在我们迫切需要从没有提供API的网页资源中获取信息时，就像一位救星。在本章中，我们将讨论如何遵循网络爬虫的所有原则，从网页资源中提取信息的技巧。'
- en: 'Before we begin, let''s get to know some important concepts that will help
    us to reach our goal. Take a look at the response content format of a request,
    which will introduce us to a particular type of data:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们了解一些重要的概念，这些概念将帮助我们实现目标。看看请求的响应内容格式，这将向我们介绍一种特定的数据类型：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the preceding example, the response content is rendered in the form of semistructured
    data, which is represented using HTML tags; this in turn helps us to access the
    information about the different sections of a web page individually.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，响应内容以半结构化数据的形式呈现，使用HTML标签进行表示；这反过来又帮助我们分别访问网页不同部分的信息。
- en: Now, let's get to know the different types of data that the Web generally deals
    with.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解网络通常处理的不同类型的数据。
- en: Types of data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'In most cases, we deal with three types of data when working with web sources.
    They are as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理网络资源时，我们通常会遇到三种类型的数据。具体如下：
- en: Structured data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据
- en: Unstructured data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: Semistructured Data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半结构化数据
- en: Structured data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构化数据
- en: Structured data is a type of data that exists in an organized form. Normally,
    structured data has a predefined format and it is machine readable. Each piece
    of data that lies in structured data has a relation with every other data as a
    specific format is imposed on it. This makes it easier and faster to access different
    parts of data. The structured data type helps in mitigating redundant data while
    dealing with huge amounts of data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据是一种以组织形式存在的数据类型。通常，结构化数据具有预定义的格式，并且是机器可读的。结构化数据中的每一份数据都与其它数据以特定格式相关联。这使得访问数据的不同部分更加容易和快捷。处理大量数据时，结构化数据类型有助于减少冗余数据。
- en: Databases always contain structured data, and SQL techniques can be used to
    access data from them. We can regard census records as an example of structured
    data. They contain information about the date of birth, gender, place, income,
    and so on, of the people of a country.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库总是包含结构化数据，可以使用SQL技术来访问这些数据。我们可以将人口普查记录视为结构化数据的例子。它们包含关于一个国家人民出生日期、性别、地点、收入等信息。
- en: Unstructured data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: In contrast to structured data, unstructured data either misses out on a standard
    format or stays unorganized even though a specific format is imposed on it. Due
    to this reason, it becomes difficult to deal with different parts of the data.
    Also, it turns into a tedious task. To handle unstructured data, different techniques
    such as text analytics, Natural Language Processing (NLP), and data mining are
    used. Images, scientific data, text-heavy content (such as newspapers, health
    records, and so on), come under the unstructured data type.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与结构化数据相比，非结构化数据要么缺少标准格式，要么即使施加了特定格式也保持无序。由于这个原因，处理数据的各个部分变得困难。此外，它变成了一项繁琐的任务。为了处理非结构化数据，使用了不同的技术，如文本分析、自然语言处理（NLP）和数据挖掘。图像、科学数据、内容繁多的文本（如报纸、健康记录等）都属于非结构化数据类型。
- en: Semistructured data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半结构化数据
- en: Semistructured data is a type of data that follows an irregular trend or has
    a structure which changes rapidly. This data can be a self described one, it uses
    tags and other markers to establish a semantic relationship among the elements
    of the data. Semistructured data may contain information that is transferred from
    different sources. **Scraping** is the technique that is used to extract information
    from this type of data. The information available on the Web is a perfect example
    of semistructured data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 半结构化数据是一种遵循不规则趋势或具有快速变化结构的数据类型。这种数据可以是自我描述的，它使用标签和其他标记来建立数据元素之间的语义关系。半结构化数据可能包含来自不同来源的信息。"抓取"是用于从这类数据中提取信息的技巧。网络上的信息是半结构化数据的完美例子。
- en: What is web scraping?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是网络爬取？
- en: In simple words, web scraping is the process of extracting desired data from
    a web resource. This method involves different procedures such as interacting
    with the web resource, choosing the appropriate data, obtaining information from
    the data, and converting the data to the desired format. With all the previous
    methods considered, a major spotlight will be thrown on the process of pulling
    the required data from the semistructured data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，网络爬虫是从网络资源中提取所需数据的过程。这种方法涉及不同的步骤，如与网络资源交互、选择合适的数据、从数据中获取信息，以及将数据转换为所需格式。在考虑了所有之前的方法之后，主要关注点将集中在从半结构化数据中提取所需数据的过程。
- en: Dos and don'ts of web scraping
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络爬取的注意事项与禁忌
- en: 'Scraping a web resource is not always welcomed by the owners. Some companies
    put a restriction on using bots against them. It''s etiquette to follow certain
    rules while scraping. The following are the dos and don''ts of web scraping:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 爬取网络资源并不总是受到所有者的欢迎。一些公司会对使用针对他们的机器人进行限制。在爬取时遵循某些规则是一种礼仪。以下是一些关于网络爬取的应该做和不应该做的事情：
- en: '**Do refer to the terms and conditions**: The first thing that should come
    to our mind before we begin scraping is terms and conditions. Do visit the website''s
    terms and conditions page and get to know whether they prohibit scraping from
    their site. If so, it''s better to back off.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**请务必查阅条款和条件**：在我们开始抓取数据之前，应该首先想到的是条款和条件。请访问网站的条款和条件页面，了解他们是否禁止从其网站抓取数据。如果是这样，最好是退而求其次。'
- en: '**Don''t bombard the server with a lot of requests**: Every website runs on
    a server that can serve only a specific amount of workload. It is equivalent to
    being rude if we bombard the server with lots of requests in a specific span of
    time, which may result in sever breakdown. Wait for some time between requests
    instead of bombarding the server with too many requests at once.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要向服务器发送大量请求**：每个网站都运行在只能处理特定工作量负载的服务器上。如果在特定时间段内向服务器发送大量请求，这相当于是一种无礼行为，可能会导致服务器崩溃。请等待一段时间后再发送请求，而不是一次性向服务器发送过多请求。'
- en: Note
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意事项
- en: Some sites put a restriction on the maximum number of requests processed per
    minute and will ban the request sender's IP address if this is not adhered to.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些网站对每分钟处理的最大请求数量有限制，如果不遵守这一规定，将会禁止请求发送者的IP地址。
- en: '**Do track the web resource from time to time**: A website doesn''t always
    stay the same. According to its usability and the requirement of users, they tend
    to change from time to time. If any alteration has taken place in the website,
    our code to scrape may fail. Do remember to track the changes made to the site,
    modify the scrapper script, and scrape accordingly.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期跟踪网络资源**：一个网站并不总是保持不变。根据其可用性和用户需求，它们往往会不时地进行更改。如果网站有任何变动，我们用于抓取的代码可能会失效。请务必跟踪网站所做的更改，修改抓取脚本，并相应地进行抓取。'
- en: Predominant steps to perform web scraping
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行网络爬取的主要步骤
- en: 'Generally, the process of web scraping requires the use of different tools
    and libraries such as the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，网络爬取的过程需要使用以下不同的工具和库：
- en: '**Chrome DevTools or FireBug Add-on**: This can be used to pinpoint the pieces
    of information in an HTML/XML page.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Chrome DevTools 或 FireBug 插件**：这可以用来定位 HTML/XML 页面中的信息片段。'
- en: '**HTTP libraries**: These can be used to interact with the server and to pull
    a response document. An example of this is `python-requests`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP库**：这些库可以用来与服务器交互并获取响应文档。一个例子是`python-requests`。'
- en: '**Web scraping tools**: These are used to pull data from a semistructured document.
    Examples include `BeautifulSoup` or `Scrappy`.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网页抓取工具**：这些工具用于从半结构化文档中提取数据。例如包括 `BeautifulSoup` 或 `Scrappy`。'
- en: 'The overall picture of web scraping can be observed in the following steps:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 网络爬取的整体流程可以观察以下步骤：
- en: Identify the URL(s) of the web resource to perform the web scraping task.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定执行网络爬取任务的网页资源的URL（s）。
- en: Use your favorite HTTP client/library to pull the semistructured document.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您喜欢的HTTP客户端/库来提取半结构化文档。
- en: Before extracting the desired data, discover the pieces of data that are in
    semistructured format.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在提取所需数据之前，发现那些处于半结构化格式的数据片段。
- en: Utilize a web scraping tool to parse the acquired semistructured document into
    a more structured one.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网络爬虫工具将获取的半结构化文档解析成更结构化的形式。
- en: Draw the desired data that we are hoping to use. That's all, we are done!
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制我们希望使用的所需数据。这就完成了！
- en: Key web scraping tasks
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键网络爬取任务
- en: 'While pulling the required data from a semistructured document, we perform
    various tasks. The following are the basic tasks that we adopt for scraping:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在从半结构化文档中提取所需数据时，我们执行各种任务。以下是我们采用的抓取的基本任务：
- en: '**Searching a semistructured document:** Accessing a particular element or
    a specific type of element in a document can be accomplished using its `tag` name
    and `tag` attributes, such as `id`, `class`, and so on.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索半结构化文档：** 在文档中访问特定元素或特定类型的元素可以通过使用其`标签`名称和`标签`属性，例如`id`、`class`等来实现。'
- en: '**Navigating within a semistructured document**: We can navigate through a
    web document to pull different types of data in four ways, which are navigating
    down, navigating sideways, navigating up, and navigating back and forth. We can
    get to know more about these in detail later in this chapter.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在半结构化文档中导航**：我们可以通过四种方式在网页文档中导航以获取不同类型的数据，这包括向下导航、横向导航、向上导航以及来回导航。我们将在本章后面详细了解这些内容。'
- en: '**Modifying a semistructured document:** By modifying the `tag` name or the
    `tag` attributes of a document, we can streamline and pull the required data.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改半结构化文档：** 通过修改文档的`标签`名称或`标签`属性，我们可以使文档更加简洁并提取所需的数据。'
- en: What is BeautifulSoup?
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 BeautifulSoup？
- en: The `BeautifulSoup` library is a simple yet powerful web scraping library. It
    has the capability to extract the desired data when provided with an HTML or XML
    document. It is charged with some superb methods, which help us to perform web
    scraping tasks effortlessly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`BeautifulSoup` 库是一个简单而强大的网页抓取库。它能够在提供 HTML 或 XML 文档时提取所需数据。它配备了一些出色的方法，这些方法帮助我们轻松地执行网页抓取任务。'
- en: Document parsers
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档解析器
- en: Document parsers aid us in parsing and serializing the semistructured documents
    that are written using HTML5, lxml, or any other markup language. By default,
    `BeautifulSoup` has Python's standard `HTMLParser` object. If we are dealing with
    different types of documents, such as HTML5 and lxml, we need to install them
    explicitly.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 文档解析器帮助我们解析和序列化使用HTML5、lxml或其他任何标记语言编写的半结构化文档。默认情况下，`BeautifulSoup`拥有Python的标准的`HTMLParser`对象。如果我们处理的是不同类型的文档，例如HTML5和lxml，我们需要明确地安装它们。
- en: In this chapter, our prime focus will be laid only on particular parts of the
    library, which help us to understand the techniques to develop a practical scraping
    bot that we will build at the end of this chapter.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们的主要关注点将仅放在图书馆的特定部分，这些部分帮助我们理解开发将在本章末尾构建的实用爬虫的技术。
- en: Installation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: 'Installing `BeautifulSoup` is pretty straightforward. We can use `pip` to install
    it with ease:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 `BeautifulSoup` 非常简单。我们可以使用 `pip` 轻松地安装它：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Whenever we intend to scrape a web resource using `BeautifulSoup`, we need
    to create a `BeautifulSoup` object for it. The following are the commands to do
    this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们打算使用 `BeautifulSoup` 抓取网页资源时，我们需要为它创建一个 `BeautifulSoup` 对象。以下是为此执行的命令：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Objects in BeautifulSoup
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BeautifulSoup中的对象
- en: The `BeautifulSoup` object parses the given HTML/XML document and converts it
    into a tree of Python objects, which are discussed in the following sections.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`BeautifulSoup` 对象解析给定的 HTML/XML 文档，并将其转换为以下章节中讨论的 Python 对象树。'
- en: Tags
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标签
- en: 'The word "tag" represents an HTML/XML tag in the provided document. Each `tag`
    object has a name and a lot of attributes and methods. The following example showcases
    the way to deal with a `tag` object:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 单词“tag”代表在提供的文档中的HTML/XML标签。每个`tag`对象都有一个名称以及许多属性和方法。以下示例展示了处理`tag`对象的方式：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In order to access the type, name, and attributes of the `BeautifulSoup` object,
    with `soup`, that we created in the preceding example, use the following commands:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了访问我们在前一个示例中创建的`BeautifulSoup`对象`soup`的类型、名称和属性，请使用以下命令：
- en: 'For accessing the `tag type`:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于访问`标签类型`：
- en: '[PRE4]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For accessing the `tag name`:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要访问`标签名`：
- en: '[PRE5]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For accessing the `tag` attribute (`'id'` in the given html string)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了访问`tag`属性（在给定的HTML字符串中为`'id'`）
- en: '[PRE6]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: BeautifulSoup
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BeautifulSoup
- en: 'The object that gets created when we intend to scrape a web resource is called
    a `BeautifulSoup` object. Put simply, it is the complete document that we are
    planning to scrape. This can be done using the following commands:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打算抓取网络资源时创建的对象被称为`BeautifulSoup`对象。简单来说，这是我们计划抓取的完整文档。这可以通过以下命令完成：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: NavigableString
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可导航字符串
- en: 'A `NavigableString` object represents the contents of `tag`. We use the `.string`
    attribute of the `tag` object to access it:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `NavigableString` 对象表示 `tag` 的内容。我们使用 `tag` 对象的 `.string` 属性来访问它：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Comments
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评论
- en: 'The `comment` object illustrates the comment part of the web document. The
    following lines of code exemplify a `comment` object:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`comment` 对象说明了网页文档的注释部分。以下代码行展示了 `comment` 对象：'
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Web scraping tasks related to BeautifulSoup
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 BeautifulSoup 相关的网页抓取任务
- en: 'As cited in the previous section of *Key web scraping tasks*, `BeautifulSoup`
    always follows those basic tasks in the process of web scraping. We can get to
    know these tasks in detail with the help of a practical example, using an HTML
    document. We will be using the following HTML document that is `scraping_example.html`,
    as an example through out the chapter:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文 *关键网络爬取任务* 部分所述，`BeautifulSoup` 在网络爬取过程中始终遵循那些基本任务。我们可以通过一个实际例子，使用 HTML
    文档来详细了解这些任务。在本章中，我们将使用以下 HTML 文档 `scraping_example.html` 作为示例：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To give a crystal clear understanding of the preceding web document, we showcased
    it as a document tree. The following diagram represents the preceding HTML document:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对前面的网页文档有一个清晰明确的理解，我们将其展示为一个文档树。以下图表代表了前面的HTML文档：
- en: '![Web scraping tasks related to BeautifulSoup](img/B03661_06_01.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![与 BeautifulSoup 相关的网页抓取任务](img/B03661_06_01.jpg)'
- en: When we create the `BeautifulSoup` object for the previously shown web document,
    it will result in a tree of Python objects.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为之前展示的网页文档创建`BeautifulSoup`对象时，它将生成一个Python对象的树形结构。
- en: 'To perform different tasks with the previous document, `scraping_example.html`,
    we need to create a `BeautifulSoup` object. To create it, open the Python shell
    and run the following commands:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用之前的文档`scraping_example.html`执行不同的任务，我们需要创建一个`BeautifulSoup`对象。为了创建它，打开Python交互式命令行并运行以下命令：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From now, we will use the preceding `BeautifulSoup` object to execute different
    tasks. Let's perform the web scraping tasks on the `scraping_example.html` document
    and get an overall idea on all the tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将使用前面的 `BeautifulSoup` 对象来执行不同的任务。让我们对 `scraping_example.html` 文档进行网络爬取操作，并对所有任务有一个整体的了解。
- en: Searching the tree
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索树
- en: To identify the different tags in an HTML/XML document, we need to search the
    whole document. In similar situations, we can use `BeautifulSoup` methods such
    as `find`, `find_all`, and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要识别 HTML/XML 文档中的不同标签，我们需要搜索整个文档。在类似情况下，我们可以使用 `BeautifulSoup` 的方法，如 `find`、`find_all`
    等等。
- en: 'Here is the syntax to search the whole document to identify the tags:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是搜索整个文档以识别标签的语法：
- en: '`find(name, attributes, recursive, text, **kwargs)`'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`find(name, attributes, recursive, text, **kwargs)`'
- en: '`name`: This is the first occurring tag name that appears in the process of
    discovery. It can be a string, a regular expression, a list, a function, or the
    value `True`.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`: 这是发现过程中首次出现的标签名称。它可以是字符串、正则表达式、列表、函数或值 `True`。'
- en: '`find_all(name, attributes, recursive, text, limit, **kwargs)`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`find_all(name, attributes, recursive, text, limit, **kwargs)`'
- en: '`name`: This is used to access specific types of tags with their name. It can
    be a string, a regular expression, a list, a function, or the value `True`.'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`: 这用于通过名称访问特定类型的标签。它可以是字符串、正则表达式、列表、函数或值 `True`。'
- en: '`limit`: This is the maximum number of results in the output.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit`: 这是输出结果中的最大结果数。'
- en: 'The common attributes for the preceding two methods are as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前两种方法的共同属性如下：
- en: '`attributes`: These are the attributes of an HTML/XML tag.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attributes`: 这些是 HTML/XML 标签的属性。'
- en: '`recursive`: This takes a Boolean value. If it is set to `True`, the `BeautifulSoup`
    library checks all the children of a specific tag. Vice versa, if it is set to
    `false`, the `BeautifulSoup` library checks the child at the next level only.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recursive`: 这接受一个布尔值。如果设置为 `True`，`BeautifulSoup` 库会检查特定标签的所有子标签。反之，如果设置为
    `false`，`BeautifulSoup` 库只会检查下一级的子标签。'
- en: '`text`: This parameter identifies tags that consist of the string content.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`: 此参数用于标识由字符串内容组成的标签。'
- en: Navigating within the tree
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在树结构中导航
- en: Different tasks are involved in navigating the document tree with the `Beautifulsoup4`
    module; they are discussed in the following section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Beautifulsoup4`模块在文档树中进行导航涉及不同的任务；它们将在下一节中进行讨论。
- en: Navigating down
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 导航向下
- en: We can access a particular element's data by moving down in a document. If we
    consider the document tree in the previous figure, we can access different elements
    by moving downward from the top element—`html`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在文档中向下移动来访问特定元素的数据。如果我们考虑前一个图中的文档树，我们可以通过从顶级元素——`html`向下移动来访问不同的元素。
- en: 'Every element can be accessed using its `tag` name. Here is a way to access
    the contents of the `html` attribute:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 每个元素都可以通过其`标签`名称进行访问。以下是通过`html`属性访问内容的方法：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here are the ways in which we can access the elements of the preceding document
    tree by navigating down. In order to access the `title` element, we should go
    from top to bottom, that is, from `html` to `head` and from `head` to `title`,
    as shown in the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里介绍了我们通过向下导航访问前一个文档树元素的方法。为了访问`title`元素，我们应该从上到下进行，即从`html`到`head`，再从`head`到`title`，如下面的命令所示：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similarly, you can access the `meta` element, as shown in the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以访问`meta`元素，如下命令所示：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Navigating sideways
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 横向导航
- en: To access the siblings in a document tree, we should navigate sideways. The
    `BeautifulSoup` library provides various `tag` object properties such as `.next_sibling`,
    `.previous_sibling`, `.next_siblings`, and `.previous_siblings`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问文档树中的兄弟节点，我们应该横向导航。`BeautifulSoup`库提供了各种`tag`对象属性，例如`.next_sibling`、`.previous_sibling`、`.next_siblings`和`.previous_siblings`。
- en: 'If you look at the preceding diagram containing the document tree, the different
    siblings at different levels of the tree, when navigated sideways, are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看包含文档树的上一张图，树中不同层级的不同兄弟节点，在横向导航时如下所示：
- en: '`head` and `body`'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`头部` 和 `主体`'
- en: '`div1`, `div2`, and `div3`'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`div1`、`div2` 和 `div3`'
- en: 'In the document tree, the `head` tag is the first child of `html`, and `body`
    is the next child of `html`. In order to access the children of the `html` tag,
    we can use its `children` property:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在文档树中，`head` 标签是 `html` 的第一个子元素，而 `body` 是 `html` 的下一个子元素。为了访问 `html` 标签的子元素，我们可以使用它的
    `children` 属性：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To access the next sibling of `head` element we can use `.find_next_sibling`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问`head`元素的下一个兄弟元素，我们可以使用`.find_next_sibling`：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To access the previous sibling of `body`, we can use `.find_previous_sibling`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问`body`的上一级兄弟元素，我们可以使用`.find_previous_sibling`方法：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Navigating up
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向上导航
- en: We can access a particular element's parent by moving toward the top of the
    document tree. The `BeautifulSoup` library provides two properties—`.parent` and
    `.parents`—to access the first parent of the `tag` element and all its ancestors,
    respectively.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向文档树顶部移动来访问特定元素的父亲元素。`BeautifulSoup` 库提供了两个属性——`.parent` 和 `.parents`——分别用于访问
    `tag` 元素的第一级父元素及其所有祖先元素。
- en: 'Here is an example:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Navigating back and forth
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在导航中来回切换
- en: 'To access the previously parsed element, we navigate back in the node of a
    tree, and to access the immediate element that gets parsed next, we navigate forward
    in the node of a tree. To deal with this, the `tag` object provides the `.find_previous_element`
    and `.find_next_element` properties, as shown in the following example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问之前解析的元素，我们需要在树的节点中回溯，而要访问下一个即将解析的元素，我们需要在树的节点中前进。为了处理这种情况，`tag`对象提供了`.find_previous_element`和`.find_next_element`属性，如下例所示：
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Modifying the Tree
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修改树结构
- en: The BeautifulSoup library also facilitates us to make changes to the web document
    according to our requirements. We can alter a tag's properties using its attributes,
    such as the `.name`, `.string`, and `.append()` method. We can also add new tags
    and strings to an existing tag with the help of the `.new_string()` and `.new_tag()`
    methods. There are also other methods, such as `.insert()`, `.insert_before()`,
    `.insert_after()`, and so on, to make various modifications to the document tree.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: BeautifulSoup 库还使我们能够根据我们的需求对网页文档进行修改。我们可以通过其属性来更改标签的属性，例如 `.name`、`.string`
    和 `.append()` 方法。我们还可以借助 `.new_string()` 和 `.new_tag()` 方法向现有标签添加新的标签和字符串。此外，还有一些其他方法，如
    `.insert()`、`.insert_before()`、`.insert_after()` 等，用于对文档树进行各种修改。
- en: 'Here is an example of changing the `title` tag''s `.string` attribute:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个更改`title`标签的`.string`属性的示例：
- en: 'Before modifying the `title` tag the title contents are:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在修改`title`标签之前，标题内容如下：
- en: '[PRE20]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is the way to modify the contents of a `title` tag:'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是修改`标题`标签内容的方法：
- en: '[PRE21]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'After the modifications the contents of the `tilte` tag looks like this:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改后，`tilte` 标签的内容看起来是这样的：
- en: '[PRE22]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Building a web scraping bot – a practical example
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个网络爬虫机器人——一个实用示例
- en: At this point of time, our minds got enlightened with all sorts of clues to
    scrape the Web. With all the information acquired, let's look at a practical example.
    Now, we will create a web scraping bot, which will pull a list of words from a
    web resource and store them in a JSON file.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时间点，我们的思维被各种线索启发，以刮取网络信息。收集了所有信息后，让我们来看一个实际例子。现在，我们将创建一个网络爬虫，它将从网络资源中提取单词列表并将它们存储在一个JSON文件中。
- en: Let's turn on the scraping mode!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开启抓取模式！
- en: The web scraping bot
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络爬虫机器人
- en: Here, the web scraping bot is an automated script that has the capability to
    extract words from a website named majortests.com. This website consists of various
    tests and **Graduate Record Examinations** (**GRE**) word lists. With this web
    scraping bot, we will scrape the previously mentioned website and create a list
    of GRE words and their meanings in a JSON file.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，网络爬虫是一个自动脚本来提取名为majortests.com的网站上的单词。这个网站包含各种测试和**研究生入学考试**（GRE）单词列表。使用这个网络爬虫，我们将爬取之前提到的网站，并在JSON文件中创建一个GRE单词及其含义的列表。
- en: 'The following image is the sample page of the website that we are going to
    scrape:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片是我们将要抓取的网站样本页面：
- en: '![The web scraping bot](img/B03661_06_03.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![网络爬虫机器人](img/B03661_06_03.jpg)'
- en: 'Before we kick start the scraping process, let''s revise the dos and don''t
    of web scraping as mentioned in the initial part of the chapter. Believe it or
    not they will definitely leave us in peace:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始爬取过程之前，让我们回顾一下章节开头提到的网络爬取的注意事项和禁忌。信不信由你，它们肯定会让我们安心的：
- en: '**Do refer to the terms and conditions**: Yes, before scraping majortests.com,
    refer to the terms and conditions of the site and obtain the necessary legal permissions
    to scrape it.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**请务必查阅条款和条件**：是的，在抓取majortests.com之前，请查阅该网站的条款和条件，并获取抓取所需的必要法律许可。'
- en: '**Don''t bombard the server with a lot of requests**: Keeping this in mind,
    for every request that we are going to send to the website, a delay has been instilled
    using Python''s `time.sleep` function.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要向服务器发送大量请求**：牢记这一点，对于我们将要发送到网站的每一个请求，我们都使用了 Python 的 `time.sleep` 函数来引入延迟。'
- en: '**Do track the web resource from time to time**: We ensured that the code runs
    perfectly with the website that is running on the server. Do check the site once
    before starting to scrape, so that it won''t break the code. This can be made
    possible by running some unit tests, which conform to the structure we expected.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期跟踪网络资源**：我们确保代码与服务器上运行的网站完美兼容。在开始抓取之前，请检查网站一次，以免破坏代码。这可以通过运行一些符合我们预期结构的单元测试来实现。'
- en: Now, let's start the implementation by following the steps to scrape that we
    discussed previously.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们按照之前讨论的步骤开始实施抓取操作。
- en: Identifying the URL or URLs
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别 URL 或 URLs
- en: 'The first step in web scraping is to identify the URL or a list of URLs that
    will result in the required resources. In this case, our intent is to find all
    the URLs that result in the expected list of GRE words. The following is the list
    of the URLs of the sites that we are going to scrape:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 网络爬取的第一步是确定要获取所需资源的URL或URL列表。在这种情况下，我们的目的是找到所有导致预期GRE单词列表的URL。以下是我们将要爬取的网站的URL列表：
- en: '[http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01),'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01)'
- en: '[http://www.majortests.com/gre/wordlist_02](http://www.majortests.com/gre/wordlist_02),'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.majortests.com/gre/wordlist_02](http://www.majortests.com/gre/wordlist_02)'
- en: '[http://www.majortests.com/gre/wordlist_03](http://www.majortests.com/gre/wordlist_03),
    and so on'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.majortests.com/gre/wordlist_03](http://www.majortests.com/gre/wordlist_03)，等等'
- en: 'Our aim is to scrape words from nine such URLs, for which we found a common
    pattern. This will help us to crawl all of them. The common URL pattern for all
    those URLs is written using Python''s `string` object, as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是从九个这样的URL中抓取单词，我们发现了一个共同的模式。这将帮助我们爬取所有这些URL。所有这些URL的共同URL模式是用Python的`string`对象编写的，如下所示：
- en: '`http://www.majortests.com/gre/wordlist_0%d`'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://www.majortests.com/gre/wordlist_0%d`'
- en: 'In our implementation, we defined a method called `generate_urls`, which will
    generate the required list of URLs using the preceding URL string. The following
    snippet demonstrates the process in a Python shell:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实现中，我们定义了一个名为 `generate_urls` 的方法，该方法将使用前面的 URL 字符串生成所需的 URL 列表。以下代码片段展示了在
    Python 命令行中执行此过程的方法：
- en: '[PRE23]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using an HTTP client
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 HTTP 客户端
- en: 'We will use the `requests` module as an HTTP client to get the web resources:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`requests`模块作为HTTP客户端来获取网络资源：
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding code, the `get_resource` function takes `url` as an argument
    and uses the `requests` module to get the resource.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`get_resource` 函数接受 `url` 作为参数，并使用 `requests` 模块获取资源。
- en: Discovering the pieces of data to scrape
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现需要抓取的数据片段
- en: Now, it is time to analyze and classify the contents of the web page. The content
    in this context is a list of words with their definitions. In order to identify
    the elements of the words and their definitions, we used Chrome DevTools. The
    perceived information of the elements (HTML elements) can help us to identify
    the word and its definition, which can be used in the process of scraping.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候分析和分类网页的内容了。在这个上下文中，内容是一系列带有定义的单词列表。为了识别单词及其定义的元素，我们使用了Chrome DevTools。元素的感知信息（HTML元素）可以帮助我们识别单词及其定义，这些信息可以在抓取过程中使用。
- en: 'To carry this out open the URL ([http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01))
    in the Chrome browser and access the **Inspect element** option by right-clicking
    on the web page:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此操作，请在 Chrome 浏览器中打开 URL ([http://www.majortests.com/gre/wordlist_01](http://www.majortests.com/gre/wordlist_01))，并通过右键点击网页来访问**检查元素**选项：
- en: '![Discovering the pieces of data to scrape](img/B03661_06_02.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![发现可抓取的数据片段](img/B03661_06_02.jpg)'
- en: 'From the preceding image, we can identify the structure of the word list, which
    appears in the following manner:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图像中，我们可以识别出单词列表的结构，它以以下方式呈现：
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'By looking at the parts of the previously referred to web page, we can interpret
    the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看之前提到的网页部分，我们可以解读如下：
- en: Each web page consists of a word list
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个网页都包含一个单词列表
- en: Every word list has many word groups that are defined in the same `div` tag
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个单词列表都包含许多在相同`div`标签中定义的单词组
- en: All the words in a word group are described in a table having the class attribute—`wordlist`
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个词组中的所有单词都描述在一个具有类属性—`wordlist`的表中
- en: Each and every table row (`tr`) in the table represents a word and its definition
    using the `th` and `td` tags, respectively
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格中的每一行(`tr`)都分别使用`th`和`td`标签代表一个单词及其定义
- en: Utilizing a web scraping tool
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用网络爬虫工具
- en: 'Let''s use `BeautifulSoup4` as a web scraping tool to parse the obtained web
    page contents that we received using the `requests` module in one of the previous
    steps. By following the preceding interpretations, we can direct `BeautifulSoup`
    to access the required content of the web page and deliver it as an object:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`BeautifulSoup4`作为网络爬虫工具来解析我们在前一步骤中使用`requests`模块获取到的网页内容。通过遵循前面的解释，我们可以指导`BeautifulSoup`访问网页所需的内容，并将其作为对象提供：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the preceding lines of code, the `make_soup` method takes the `html` content
    in the form of a string and returns a `BeautifulSoup` object.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码行中，`make_soup` 方法接收以字符串形式的 `html` 内容，并返回一个 `BeautifulSoup` 对象。
- en: Drawing the desired data
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 绘制所需数据
- en: 'The `BeautifulSoup` object that we obtained in the previous step is used to
    extract the required words and their definitions from it. Now, with the methods
    available in the `BeautifulSoup` object, we can navigate through the obtained
    HTML response, and then we can extract the list of words and their definitions:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步中我们获得的 `BeautifulSoup` 对象用于从中提取所需的单词及其定义。现在，利用 `BeautifulSoup` 对象中可用的方法，我们可以遍历获取到的
    HTML 响应，然后我们可以提取单词列表及其定义：
- en: '[PRE27]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the preceding lines of code, `get_words_from_soup` takes a `BeautifulSoup`
    object and then looks for all the words contained in the `wordlists` class using
    the instance's `find_all()` method, and then returns a dictionary of words.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码行中，`get_words_from_soup` 函数接收一个 `BeautifulSoup` 对象，然后使用实例的 `find_all()`
    方法查找 `wordlists` 类中包含的所有单词，并返回一个单词的字典。
- en: 'The dictionary of words obtained previously will be saved in a JSON file using
    the following `helper` method:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 之前获得的单词字典将使用以下`helper`方法保存到JSON文件中：
- en: '[PRE28]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'On the whole, the process can be depicted in the following program:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这个过程可以用以下程序来描述：
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here is the content of the `words.json` file:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是`words.json`文件的内容：
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Summary
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about different types of data that we encountered
    with web sources and tweaked some ideas. We came to know about the need for web
    scraping, the legal issues, and the goodies that it offers. Then, we jumped deep
    into web scraping tasks and their potential. You learned about a new library called
    `BeautifulSoup`, and its ins and outs, with examples.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了我们在网络资源中遇到的不同类型的数据，并对一些想法进行了调整。我们认识到了网络爬取的必要性、法律问题以及它所提供的便利。然后，我们深入探讨了网络爬取任务及其潜力。你学习了一个名为
    `BeautifulSoup` 的新库，以及它的功能和细节，并伴随着示例。
- en: We came to know the capabilities of `BeautifulSoup` in depth and worked on some
    examples to get a clear idea on it. At last, we created a practical scraping bot
    by applying the knowledge that we gained from the previous sections, which enlightened
    us with an experience to scrape a website in real time.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入了解了`BeautifulSoup`的功能，并通过对一些示例进行操作，对其有了清晰的认识。最后，我们通过应用从前面章节中获得的知识，创建了一个实用的抓取机器人，这个经验让我们明白了如何实时抓取网站。
- en: In the next chapter, you will learn about the Flask microframework and we will
    build an application using it by following the best practices.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习关于 Flask 微型框架的内容，我们将遵循最佳实践来构建一个使用该框架的应用程序。
