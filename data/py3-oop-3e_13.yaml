- en: Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发
- en: Concurrency is the art of making a computer do (or appear to do) multiple things
    at once. Historically, this meant inviting the processor to switch between different
    tasks many times per second. In modern systems, it can also literally mean doing
    two or more things simultaneously on separate processor cores.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 并发是让计算机同时做（或看起来同时做）多件事情的艺术。从历史上看，这意味着邀请处理器每秒多次在多个任务之间切换。在现代系统中，这也可以字面意义上意味着在单独的处理器核心上同时做两件或多件事。
- en: 'Concurrency is not inherently an object-oriented topic, but Python''s concurrent
    systems provide object-oriented interfaces, as we''ve covered throughout the book.
    This chapter will introduce you to the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 并发本身并不是一个面向对象的主题，但Python的并发系统提供了面向对象的接口，正如我们在整本书中提到的。本章将介绍以下主题：
- en: Threads
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程
- en: Multiprocessing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多进程
- en: Futures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Futures
- en: AsyncIO
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AsyncIO
- en: Concurrency is complicated. The basic concepts are fairly simple, but the bugs
    that can occur are notoriously difficult to track down. However, for many projects,
    concurrency is the only way to get the performance we need. Imagine if a web server
    couldn't respond to a user's request until another user had completed! We won't
    be going into all the details of just how hard it is (another full book would
    be required), but we'll see how to implement basic concurrency in Python, and
    some common pitfalls to avoid.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 并发很复杂。基本概念相当简单，但可能出现的错误却难以追踪。然而，对于许多项目来说，并发是获得所需性能的唯一途径。想象一下，如果网络服务器不能在另一个用户完成之前响应用户的请求会怎样！我们不会深入探讨这有多么困难（需要另一本完整的书），但我们将看到如何在Python中实现基本的并发，以及一些常见的陷阱要避免。
- en: Threads
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程
- en: Most often, concurrency is created so that work can continue happening while
    the program is waiting for I/O to happen. For example, a server can start processing
    a new network request while it waits for data from a previous request to arrive.
    Or an interactive program might render an animation or perform a calculation while
    waiting for the user to press a key. Bear in mind that while a person can type
    more than 500 characters per minute, a computer can perform billions of instructions
    per second. Thus, a ton of processing can happen between individual key presses,
    even when typing quickly.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，并发是为了在程序等待I/O操作发生时继续执行工作。例如，服务器可以在等待前一个请求的数据到达时开始处理新的网络请求。或者，一个交互式程序可能在等待用户按下一个键时渲染动画或执行计算。记住，虽然一个人每分钟可以输入超过500个字符，但计算机每秒可以执行数十亿条指令。因此，在快速输入时，即使在单个按键之间，也可能发生大量的处理。
- en: 'It''s theoretically possible to manage all this switching between activities
    within your program, but it would be virtually impossible to get right. Instead,
    we can rely on Python and the operating system to take care of the tricky switching
    part, while we create objects that appear to be running independently, but simultaneously.
    These objects are called **threads**. Let''s take a look at a basic example:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上讲，你可以在程序内部管理所有这些活动之间的切换，但这几乎是不可能的。相反，我们可以依赖Python和操作系统来处理复杂的切换部分，同时我们创建看起来似乎是独立运行但实际上是同时运行的对象。这些对象被称为**线程**。让我们看看一个基本的例子：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This example runs two threads. Can you see them? Every program has (at least)
    one thread, called the main thread. The code that executes from startup is happening
    in this thread. The more visible second thread exists as the `InputReader` class.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子运行了两个线程。你能看到它们吗？每个程序都有（至少）一个线程，称为主线程。从启动执行的代码就在这个线程中。更明显的第二个线程是`InputReader`类。
- en: To construct a thread, we must extend the `Thread` class and implement the `run`
    method. Any code executed by the `run` method happens in a separate thread.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个线程，我们必须扩展`Thread`类并实现`run`方法。任何由`run`方法执行的代码都在一个单独的线程中执行。
- en: The new thread doesn't start running until we call the `start()` method on the
    object. In this case, the thread immediately pauses to wait for input from the
    keyboard. In the meantime, the original thread continues executing from the point
    `start` was called. It starts calculating squares inside a `while` loop. The condition
    in the `while` loop checks whether the `InputReader` thread has exited its `run`
    method yet; once it does, it outputs some summary information to the screen.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 新的线程在我们在对象上调用`start()`方法之前不会开始运行。在这种情况下，线程立即暂停以等待键盘输入。与此同时，原始线程从`start`被调用的地方继续执行。它开始在一个`while`循环中计算平方。`while`循环中的条件检查`InputReader`线程是否已经从其`run`方法退出；一旦它退出，它就会在屏幕上输出一些总结信息。
- en: 'If we run the example and type the string `hello world`, the output looks as
    follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行这个例子并输入字符串`hello world`，输出看起来如下：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will, of course, calculate more or less squares while typing the string
    as the numbers are related to both our relative typing speeds, and to the processor
    speeds of the computers we are running. When I updated this example between the
    first and third edition, my newer system was able to calculate more than twice
    as many squares.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在输入字符串时，你会计算更多或更少的平方，因为数字与我们的相对打字速度以及我们运行的计算机的处理器速度都有关。当我在第一版和第三版之间更新这个例子时，我的新系统能够计算比之前多两倍的平方。
- en: 'A thread only starts running in concurrent mode when we call the `start` method.
    If we want to take out the concurrent call to see how it compares, we can call
    `thread.run()` in the place that we originally called `thread.start()`. As shown
    here, the output is telling:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 线程只有在调用`start`方法时才会以并发模式开始运行。如果我们想取消并发调用以比较其效果，我们可以在原始调用`thread.start()`的地方调用`thread.run()`。正如这里所示，输出是说明性的：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this case, there is no second thread and the `while` loop never executes.
    We wasted a lot of CPU power sitting idle while we were typing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，没有第二个线程，`while` 循环从未执行。当我们输入时，我们浪费了很多CPU资源处于空闲状态。
- en: 'There are a lot of different patterns for using threads effectively. We won''t
    be covering all of them, but we will look at a common one so we can learn about
    the `join` method. Let''s check the current temperature in the capital city of
    each province and territory in Canada:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程有效有很多不同的模式。我们不会涵盖所有这些模式，但我们会查看一个常见的模式，这样我们就可以了解`join`方法。让我们检查加拿大每个省和地区的首府的当前温度：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code constructs 10 threads before starting them. Notice how we can override
    the constructor to pass them into the `Thread` object, remembering to call `super`
    to ensure the `Thread` is properly initialized.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在启动线程之前构建了10个线程。注意我们如何覆盖构造函数将它们传递给`Thread`对象，同时记得调用`super`以确保`Thread`被正确初始化。
- en: Data we construct in one thread is accessible from other running threads. The
    references to global variables inside the `run` method illustrate this. Less obviously,
    the data passed into the constructor is being assigned to `self` *in the main
    thread*, but is accessed inside the second thread. This can trip people up; just
    because a method is on a `Thread` instance does not mean it is magically executed
    inside that thread.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在一个线程中构建的数据可以从其他正在运行的线程中访问。`run` 方法中全局变量的引用说明了这一点。不那么明显的是，传递给构造函数的数据正在`主线程`中分配给`self`，但在第二个线程中被访问。这可能会让人困惑；仅仅因为一个方法在`Thread`实例上，并不意味着它会在那个线程中神奇地执行。
- en: After the 10 threads have been started, we loop over them again, calling the
    `join()` method on each. This method says *wait for the thread to complete before
    doing anything*. We call this ten times in sequence; this `for` loop won't exit
    until all ten threads have completed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动10个线程之后，我们再次遍历它们，对每个线程调用`join()`方法。这个方法表示*等待线程完成后再做任何事情*。我们依次调用十次；这个`for`循环不会退出，直到所有十个线程都完成。
- en: At this point, we can print the temperature that was stored on each thread object.
    Notice, once again, that we can access data that was constructed within the thread
    from the main thread. In threads, all state is shared by default.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们可以打印出存储在每个线程对象上的温度。请注意，再次强调，我们可以从主线程访问在线程中构建的数据。在线程中，所有状态默认是共享的。
- en: 'Executing the preceding code on my 100 megabit connection takes about three
    tenths of a second, and we get the following output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的100兆比特连接上执行前面的代码大约需要三分之一的秒，我们得到以下输出：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: I'm writing in September, but it's already below freezing up north! If I run
    this code in a single thread (by changing the `start()` call to `run()` and commenting
    out the `join()` loop), it takes closer to four seconds because each 0.3-second
    request has to complete before the next one begins. This order of magnitude speedup
    shows just how useful concurrent programming can be.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在是在九月写作，但北方已经低于冰点！如果我用单个线程（通过将`start()`调用改为`run()`并注释掉`join()`循环）运行这段代码，它需要接近四秒钟的时间，因为每个0.3秒的请求必须完成，下一个请求才能开始。这种数量级的速度提升仅仅展示了并发编程有多么有用。
- en: The many problems with threads
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程的许多问题
- en: Threads can be useful, especially in other programming languages, but modern
    Python programmers tend to avoid them for several reasons. As we'll see, there
    are other ways to code concurrent programming that are receiving more attention
    from the Python community. Let's discuss some of these pitfalls before moving
    on to them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 线程可能很有用，尤其是在其他编程语言中，但现代的 Python 程序员倾向于避免使用它们，有几个原因。正如我们将看到的，还有其他方法可以编写并发编程，这些方法正在得到
    Python 社区的更多关注。在我们继续之前，让我们讨论一些这些陷阱。
- en: Shared memory
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存
- en: The main problem with threads is also their primary advantage. Threads have
    access to all the program's memory and thus all the variables. This can too easily
    cause inconsistencies in the program state.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的主要问题也是它们的最大优势。线程可以访问程序的所有内存和所有变量。这很容易导致程序状态的不一致性。
- en: Have you ever encountered a room where a single light has two switches and two
    different people turn them on at the same time? Each person (thread) expects their
    action to turn the lamp (a variable) on, but the resulting value (the lamp) is
    off, which is inconsistent with those expectations. Now imagine if those two threads
    were transferring funds between bank accounts or managing the cruise control for
    a vehicle.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否遇到过这样一个房间，一个灯有两个开关，两个人同时打开它们？每个人（线程）都期望他们的动作会将灯（一个变量）打开，但结果是灯是关的，这与他们的期望不一致。现在想象如果这两个线程是在银行账户之间转账或管理车辆的巡航控制。
- en: The solution to this problem in threaded programming is to *synchronize* access
    to any code that reads or (especially) writes a shared variable. There are a few
    different ways to do this, but we won't go into them here so we can focus on more
    Pythonic constructs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在线程编程中，解决这个问题的方法是对任何读取或（尤其是）写入共享变量的代码进行同步。有几种不同的方法可以做到这一点，但我们不会在这里深入讨论，以便我们可以专注于更
    Pythonic 的结构。
- en: The synchronization solution works, but it is way too easy to forget to apply
    it. Worse, bugs due to inappropriate use of synchronization are really hard to
    track down because the order in which threads perform operations is inconsistent.
    We can't easily reproduce the error. Usually, it is safest to force communication
    between threads to happen using a lightweight data structure that already uses
    locks appropriately. Python offers the `queue.Queue` class to do this; its functionality
    is basically the same as `multiprocessing.Queue`, which we will discuss in the
    next section.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 同步解决方案是可行的，但很容易忘记应用它。更糟糕的是，由于不当使用同步而导致的错误很难追踪，因为线程执行操作的顺序不一致。我们无法轻易地重现错误。通常，最安全的方法是强制线程通过使用已经适当使用锁的轻量级数据结构进行通信。Python
    提供了 `queue.Queue` 类来完成这项任务；其功能基本上与 `multiprocessing.Queue` 相同，我们将在下一节中讨论。
- en: 'In some cases, these disadvantages might be outweighed by the one advantage
    of allowing shared memory: it''s fast. If multiple threads need access to a huge
    data structure, shared memory can provide that access quickly. However, this advantage
    is usually nullified by the fact that, in Python, it is impossible for two threads
    running on different CPU cores to be performing calculations at exactly the same
    time. This brings us to our second problem with threads.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这些缺点可能被允许共享内存的一个优点所抵消：它速度快。如果有多个线程需要访问一个巨大的数据结构，共享内存可以快速提供这种访问。然而，在 Python
    中，由于两个在不同的 CPU 核心上运行的线程不可能同时执行计算，这个优势通常被抵消。这把我们带到了线程的第二个问题。
- en: The global interpreter lock
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局解释器锁
- en: 'In order to efficiently manage memory, garbage collection, and calls to machine
    code in native libraries, Python has a utility called the **global interpreter
    lock**, or **GIL**. It''s impossible to turn off, and it means that threads are
    useless in Python for one thing that they excel at in other languages: parallel
    processing. The GIL''s primary effect, for our purposes, is to prevent any two
    threads from doing work at the exact same time, even if they have work to do.
    In this case, *doing work* means using the CPU, so it''s perfectly okay for multiple
    threads to access the disk or network; the GIL is released as soon as the thread
    starts to wait for something. This is why the weather example worked.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地管理内存、垃圾回收以及在本地库中对机器代码的调用，Python有一个名为**全局解释器锁**或**GIL**的实用工具。它无法关闭，这意味着在Python中，线程对于其他语言中它们擅长的某一方面（并行处理）是无用的。对于我们的目的而言，GIL的主要作用是防止任何两个线程在确切相同的时间进行工作，即使它们有工作要做。在这种情况下，“做工作”意味着使用CPU，所以多个线程访问磁盘或网络是完全正常的；一旦线程开始等待某事，GIL就会释放。这就是为什么天气示例可以工作。
- en: The GIL is highly disparaged, mostly by people who don't understand what it
    is or all the benefits it brings to Python. It would definitely be nice if our
    language didn't have this restriction, but the Python development team have determined
    that it brings more value than it costs. It makes the reference implementation
    easier to maintain and develop, and during the single-core processor days when
    Python was originally developed, it actually made the interpreter faster. The
    net result of the GIL, however, is that it limits the benefits that threads bring
    us, without alleviating the costs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: GIL（全局解释器锁）受到了高度批评，主要是由那些不理解它是什么或者它给Python带来所有好处的人。如果我们的语言没有这种限制，那当然会很棒，但Python开发团队已经确定，它带来的价值大于其成本。它使得参考实现更容易维护和开发，而且在Python最初开发的单核处理器时代，它实际上使解释器运行得更快。然而，GIL的净结果是限制了线程带来的好处，而没有减轻其成本。
- en: While the GIL is a problem in the reference implementation of Python that most
    people use, it has been solved in some of the non-standard implementations, such
    as IronPython and Jython. Unfortunately, at the time of publication, none of these
    support Python 3.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GIL是大多数人们使用的Python参考实现中的问题，但在一些非标准实现中，如IronPython和Jython，这个问题已经被解决了。不幸的是，在出版时，这些实现中没有一个支持Python
    3。
- en: Thread overhead
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程开销
- en: One final limitation of threads, as compared to the asynchronous system we will
    be discussing later, is the cost of maintaining each thread. Each thread takes
    up a certain amount of memory (both in the Python process and the operating system
    kernel) to record the state of that thread. Switching between the threads also
    uses a (small) amount of CPU time. This work happens seamlessly without any extra
    coding (we just have to call `start()` and the rest is taken care of), but the
    work still has to happen somewhere.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们稍后将要讨论的异步系统相比，线程的一个最终限制是维护每个线程的成本。每个线程都需要占用一定量的内存（在Python进程和操作系统内核中）来记录该线程的状态。在线程之间切换也会使用（少量）CPU时间。这项工作在没有额外编码的情况下无缝发生（我们只需调用`start()`，其余的都会处理），但这项工作仍然需要发生。
- en: This can be alleviated somewhat by structuring our workload so that threads
    can be reused to perform multiple jobs. Python provides a `ThreadPool` feature
    to handle this. It is shipped as part of the multiprocessing library and behaves
    identically to `ProcessPool`, which we will discuss shortly, so let's defer that
    discussion until the next section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过结构化我们的工作负载来在一定程度上缓解，使得线程可以被重用来执行多个任务。Python提供了一个`ThreadPool`功能来处理这个问题。它作为多进程库的一部分提供，其行为与我们将要讨论的`ProcessPool`相同，所以让我们将这个讨论推迟到下一节。
- en: Multiprocessing
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程
- en: The multiprocessing API was originally designed to mimic the thread API. However,
    it has evolved, and in recent versions of Python 3, it supports more features
    more robustly. The multiprocessing library is designed for when CPU-intensive
    jobs need to happen in parallel and multiple cores are available (almost all computers,
    even a little smartwatch, have multiple cores). Multiprocessing is not useful
    when the processes spend a majority of their time waiting on I/O (for example,
    network, disk, database, or keyboard), but it is the way to go for parallel computation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程 API 最初是为了模仿线程 API 而设计的。然而，它已经发展，在 Python 3 的最新版本中，它更稳健地支持更多功能。多进程库是为了当需要并行执行
    CPU 密集型任务且有多核可用时（几乎所有的计算机，甚至一个小巧的智能手表，都有多个核心）而设计的。当进程的大部分时间都在等待 I/O（例如，网络、磁盘、数据库或键盘）时，多进程并不有用，但对于并行计算来说，这是必经之路。
- en: 'The multiprocessing module spins up new operating system processes to do the
    work. This means there is an entirely separate copy of the Python interpreter
    running for each process. Let''s try to parallelize a compute-heavy operation
    using similar constructs to those provided by the `threading` API, as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程模块会启动新的操作系统进程来完成工作。这意味着每个进程都运行着一个完全独立的 Python 解释器副本。让我们尝试使用与 `threading`
    API 提供的类似构造来并行化一个计算密集型操作，如下所示：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This example just ties up the CPU for 200 million iterations. You may not consider
    this to be useful work, but it can warm up your laptop on a chilly day!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是让 CPU 进行 2 亿次迭代。你可能不会认为这是有用的工作，但它可以在寒冷的日子里给你的笔记本电脑加热！
- en: The API should be familiar; we implement a subclass of `Process` (instead of
    `Thread`) and implement a `run` method. This method prints out the process ID
    (a unique number the operating system assigns to each process on the machine)
    before doing some intense (if misguided) work.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: API 应该是熟悉的；我们实现了一个 `Process`（而不是 `Thread`）的子类，并实现了 `run` 方法。这个方法在执行一些激烈（如果方向错误）的工作之前，会打印出进程
    ID（操作系统分配给机器上每个进程的唯一数字）。
- en: Pay special attention to the `if __name__ == '__main__':` guard around the module
    level code that prevents it running if the module is being imported, rather than
    run as a program. This is good practice in general, but when using multiprocessing
    on some operating systems, it is essential. Behind the scenes, multiprocessing
    may have to reimport the module inside the new process in order to execute the
    `run()` method. If we allowed the entire module to execute at that point, it would
    start creating new processes recursively until the operating system ran out of
    resources, crashing your computer.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请特别注意模块级别代码周围的 `if __name__ == '__main__':` 保护，这可以防止模块被导入时运行，而应该作为程序运行。这通常是一种良好的做法，但使用某些操作系统上的多进程时，这是至关重要的。幕后，多进程可能需要在新的进程中重新导入模块以执行
    `run()` 方法。如果我们允许整个模块在那个时刻执行，它将开始递归地创建新进程，直到操作系统耗尽资源，导致你的电脑崩溃。
- en: 'We construct one process for each processor core on our machine, then start
    and join each of those processes. On my 2017-era 8-core ThinkCenter, the output
    looks as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为机器上的每个处理器核心构建一个进程，然后启动并加入这些进程。在我的 2017 年代的 8 核 ThinkCenter 上，输出如下：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The first four lines are the process ID that was printed inside each `MuchCPU`
    instance. The last line shows that the 200 million iterations can run in about
    13 seconds on my machine. During that 13 seconds, my process monitor indicated
    that all four of my cores were running at 100 percent.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 前四行是每个 `MuchCPU` 实例内部打印的进程 ID。最后一行显示在我的机器上，2 亿次迭代大约需要 13 秒。在这 13 秒内，我的进程监控显示我的四个核心都在以
    100% 的速度运行。
- en: 'If we subclass `threading.Thread` instead of `multiprocessing.Process` in `MuchCPU`,
    the output looks, as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在 `MuchCPU` 中使用 `threading.Thread` 而不是 `multiprocessing.Process` 作为子类，输出如下：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This time, the four threads are running inside the same process and take over
    three times as long to run. This is the cost of the GIL; in other languages, the
    threaded version would run at least as fast as the multiprocessing version.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，四个线程在同一个进程中运行，运行时间超过三倍。这是 GIL 的代价；在其他语言中，线程版本至少会与多进程版本一样快。
- en: We might expect it to be at least four times as long, but remember that many
    other programs are running on my laptop. In the multiprocessing version, these
    programs also need a share of the four CPUs. In the threading version, those programs
    can use the other seven CPUs instead.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能期望它至少需要四倍的时间，但请记住，我的笔记本电脑上还运行着许多其他程序。在多进程版本中，这些程序也需要四个CPU中的一份。在多线程版本中，那些程序可以使用其他七个CPU。
- en: Multiprocessing pools
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程池
- en: 'In general, there is no reason to have more processes than there are processors
    on the computer. There are a few reasons for this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，没有必要拥有比计算机上的处理器更多的进程。这有几个原因：
- en: Only `cpu_count()` processes can run simultaneously
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有`cpu_count()`个进程可以同时运行
- en: Each process consumes resources with a full copy of the Python interpreter
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个进程都消耗着Python解释器的完整副本的资源
- en: Communication between processes is expensive
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程间的通信代价高昂
- en: Creating processes takes a non-zero amount of time
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建进程需要一定的时间
- en: Given these constraints, it makes sense to create at most `cpu_count()` processes
    when the program starts and then have them execute tasks as needed. This has much
    less overhead than starting a new process for each task.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些限制，当程序启动时创建最多`cpu_count()`个进程，然后根据需要执行任务是有意义的。这比为每个任务启动一个新的进程要少得多开销。
- en: It is not difficult to implement a basic series of communicating processes that
    does this, but it can be tricky to debug, test, and get right. Of course, other
    Python developers have already done it for us in the form of multiprocessing pools.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这样一个基本的通信进程系列并不困难，但调试、测试和正确实现可能会很棘手。当然，其他Python开发者已经为我们以多进程池的形式实现了这一点。
- en: Pools abstract away the overhead of figuring out what code is executing in the
    main process and which code is running in the subprocess. The pool abstraction
    restricts the number of places in which code in different processes interacts,
    making it much easier to keep track of.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 池抽象化了确定主进程中执行什么代码以及子进程中运行什么代码的开销。池抽象限制了不同进程中的代码交互的地点，这使得跟踪变得更加容易。
- en: 'Unlike threads, multiprocessing cannot directly access variables set up by
    other threads. Multiprocessing provides a few different ways to implement interprocess
    communication. Pools seamlessly hide the process of passing data between processes.
    Using a pool looks much like a function call: you pass data into a function, it
    is executed in another process or processes, and when the work is done, a value
    is returned. It is important to understand that under the hood, a lot of work
    is being done to support this: objects in one process are being pickled and passed
    into an operating system process pipe. Then, another process retrieves data from
    the pipe and unpickles it. The requested work is done in the subprocess and a
    result is produced. The result is pickled and passed back through the pipe. Eventually,
    the original process unpickles and returns it.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程不同，多进程无法直接访问其他线程设置的变量。多进程提供了一些不同的方式来实现进程间通信。池无缝地隐藏了数据在进程间传递的过程。使用池看起来就像一个函数调用：你将数据传递给一个函数，它在另一个进程或多个进程中执行，当工作完成时，返回一个值。重要的是要理解，在底层，有很多工作正在进行以支持这一点：一个进程中的对象正在被序列化并通过操作系统进程管道传递。然后，另一个进程从管道中检索数据并反序列化它。请求的工作在子进程中完成，并产生一个结果。结果被序列化并通过管道返回。最终，原始进程反序列化并返回它。
- en: All this pickling and passing data into pipes takes time and memory. Therefore,
    it is ideal to keep the amount and size of data passed into and returned from
    the pool to a minimum, and it is only advantageous to use the pool if a lot of
    processing has to be done on the data in question.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些序列化和将数据传递到管道中的操作都需要时间和内存。因此，将传递到池中和从池中返回的数据的数量和大小保持在最低限度是理想的，并且只有在需要对相关数据进行大量处理时，使用池才有利。
- en: Pickling is an expensive operation for even medium-sized Python operations.
    It is frequently more expensive to pickle a large object for use in a separate
    process than it would be to do the work in the original process using threads.
    Make sure you profile your program to ensure the overhead of multiprocessing is
    actually worth the overhead of implementing and maintaining it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Pickling对于即使是中等规模的Python操作来说也是一个昂贵的操作。将大对象序列化以在单独的进程中使用，通常比在原始进程中使用线程来完成工作要昂贵得多。确保您对程序进行性能分析，以确保多进程的开销实际上值得实现和维护的开销。
- en: 'Armed with this knowledge, the code to make all this machinery work is surprisingly
    simple. Let''s look at the problem of calculating all the prime factors of a list
    of random numbers. This is a common and expensive part of a variety of cryptography
    algorithms (not to mention attacks on those algorithms!). It requires years of
    processing power to crack the extremely large numbers used to secure your bank
    accounts. The following implementation, while readable, is not at all efficient,
    but that''s okay because we want to see it using lots of CPU time:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，让所有这些机械运转的代码出人意料地简单。让我们看看计算一组随机数的所有质因数的问题。这是各种密码学算法（更不用说对这些算法的攻击！）中常见且昂贵的部分。要破解用于保护您的银行账户的极其大的数字，需要多年的处理能力。以下实现虽然可读，但效率并不高，但这没关系，因为我们想看到它使用大量的CPU时间：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let's focus on the parallel processing aspects, as the brute force recursive
    algorithm for calculating factors is pretty clear. We first construct a multiprocessing
    pool instance. By default, this pool creates a separate process for each of the
    CPU cores in the machine it is running on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于并行处理方面，因为计算因子的暴力递归算法已经很清晰了。我们首先构建一个多进程池实例。默认情况下，此池为运行在其上的机器中的每个CPU核心创建一个单独的进程。
- en: The `map` method accepts a function and an iterable. The pool pickles each of
    the values in the iterable and passes it into an available process, which executes
    the function on it. When that process is finished doing its work, it pickles the
    resulting list of factors and passes it back to the pool. Then, if the pool has
    more work available, it takes on the next job.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`map`方法接受一个函数和一个可迭代对象。池将可迭代中的每个值序列化，并将其传递给一个可用的进程，该进程在它上面执行函数。当该进程完成其工作后，它将结果列表的因数序列化，并将其返回给池。然后，如果池有更多工作可用，它将承担下一项工作。'
- en: Once all the pools are finished processing work (which could take some time),
    the results list is passed back to the original process, which has been waiting
    patiently for all this work to complete.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有池完成处理工作（这可能需要一些时间），结果列表就返回到原始进程，该进程一直在耐心地等待所有这些工作完成。
- en: It is often more useful to use the similar `map_async` method, which returns
    immediately even though the processes are still working. In that case, the results
    variable would not be a list of values, but a promise to return a list of values
    later by calling `results.get()`. This promise object also has methods such as `ready()` and
    `wait()`, which allow us to check whether all the results are in yet. I'll leave
    you to the Python documentation to discover more about their usage.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通常更有用使用类似的`map_async`方法，即使进程仍在工作，它也会立即返回。在这种情况下，结果变量将不会是一个值列表，而是一个承诺，稍后通过调用`results.get()`来返回一个值列表。这个承诺对象还具有`ready()`和`wait()`等方法，允许我们检查是否所有结果都已就绪。我将让您查阅Python文档以了解更多关于它们的使用方法。
- en: Alternatively, if we don't know all the values we want to get results for in
    advance, we can use the `apply_async` method to queue up a single job. If the
    pool has a process that isn't already working, it will start immediately; otherwise,
    it will hold onto the task until there is a free process available.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们事先不知道我们想要获取结果的值的全部，我们可以使用`apply_async`方法来排队一个单独的任务。如果池有一个尚未工作的进程，它将立即开始；否则，它将保留任务，直到有可用的进程。
- en: Pools can also be `closed`, which refuses to take any further tasks, but processes
    everything currently in the queue, or `terminated`, which goes one step further
    and refuses to start any jobs still in the queue, although any jobs currently
    running are still permitted to complete.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 池也可以被`closed`，这拒绝接受任何进一步的任务，但会处理队列中当前的所有任务，或者`terminated`，这更进一步，拒绝启动队列中仍然存在的任何任务，尽管当前正在运行的任务仍然允许完成。
- en: Queues
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 队列
- en: If we need more control over communication between processes, we can use a `Queue`.
    `Queue` data structures are useful for sending messages from one process into
    one or more other processes. Any picklable object can be sent into a `Queue`,
    but remember that pickling can be a costly operation, so keep such objects small.
    To illustrate queues, let's build a little search engine for text content that
    stores all relevant entries in memory.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要对进程之间的通信有更多的控制，我们可以使用一个`Queue`。`Queue`数据结构对于从一个进程向一个或多个其他进程发送消息非常有用。任何可序列化的对象都可以发送到`Queue`中，但请记住，序列化可能是一个昂贵的操作，因此保持这样的对象小巧。为了说明队列，让我们构建一个小型搜索引擎，用于存储所有相关条目在内存中。
- en: This is not the most sensible way to build a text-based search engine, but I
    have used this pattern to query numerical data that needed to use CPU-intensive
    processes to construct a chart that was then rendered to the user.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是构建基于文本的搜索引擎的最明智的方式，但我已经使用这种模式查询需要使用CPU密集型过程构建图表的数值数据，然后将其渲染给用户。
- en: 'This particular search engine scans all files in the current directory in parallel.
    A process is constructed for each core on the CPU. Each of these is instructed
    to load some of the files into memory. Let''s look at the function that does the
    loading and searching:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的搜索引擎并行扫描当前目录中的所有文件。为CPU上的每个核心构建一个进程。每个进程都被指示将一些文件加载到内存中。让我们看看执行加载和搜索的函数：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Remember, this function is run in a different process (in fact, it is run in
    `cpucount()` different processes) from the main thread. It passes a list of `path.path`
    objects, and two `multiprocessing.Queue` objects; one for incoming queries and
    one to send outgoing results. These queues automatically pickle the data in the
    queue and pass it into the subprocess over a pipe. These two queues are set up
    in the main process and passed through the pipes into the search function inside
    the child processes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '记住，这个函数是在不同的进程（实际上，它是在`cpucount()`不同的进程中运行的）中运行的，与主线程不同。它传递一个`path.path`对象的列表，以及两个`multiprocessing.Queue`对象；一个用于传入查询，一个用于发送输出结果。这些队列自动将数据序列化到队列中，并通过管道传递到子进程。这两个队列在主进程中设置，并通过管道传递到子进程中的搜索函数。 '
- en: The search code is pretty dumb, both in terms of efficiency and of capabilities;
    it loops over every line stored in memory and puts the matching ones in a list.
    The list is placed in a queue and passed back to the main process.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索代码在效率和功能方面都很愚蠢；它遍历存储在内存中的每一行，并将匹配的行放入列表中。这个列表被放入队列中，并返回给主进程。
- en: 'Let''s look at the `main` process, which sets up these queues:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`main`进程，它设置了这些队列：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For an easier description, let's assume `cpu_count` is four. Notice how the
    `import` statements are placed inside the `if` guard? This is a small optimization
    that prevents them from being imported in each subprocess (where they aren't needed)
    on some operating systems. We list all the paths in the current directory and
    then split the list into four approximately equal parts. We also construct a list
    of four `Queue` objects to send data into each subprocess. Finally, we construct
    a **single** results queue. This is passed into all four of the subprocesses.
    Each of them can put data into the queue and it will be aggregated in the main
    process.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易描述，让我们假设`cpu_count`是四。注意`import`语句是如何放在`if`保护中的？这是一个小的优化，可以防止在某些操作系统上在每个子进程中（它们不需要）导入它们。我们列出当前目录中的所有路径，然后将列表分成四个大致相等的部分。我们还构建了一个包含四个`Queue`对象的列表，用于将数据发送到每个子进程。最后，我们构建了一个**单个**的结果队列。这个队列被传递到所有四个子进程中。每个子进程都可以将数据放入队列中，它将在主进程中汇总。
- en: 'Now let''s look at the code that makes a search actually happen:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看使搜索真正发生的代码：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code performs a single search for `"def"` (because it's a common phrase
    in a directory full of Python files!).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码执行单个搜索，搜索`"def"`（因为它是充满Python文件的目录中的常见短语！）。
- en: This use of queues is actually a local version of what could become a distributed
    system. Imagine if the searches were being sent out to multiple computers and
    then recombined. Now imagine you had access to the millions of computers in Google's
    data centers and you might understand why they can return search results so quickly!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种队列的使用实际上是可能成为分布式系统的本地版本。想象一下，如果搜索被发送到多台计算机，然后重新组合。现在想象一下，如果你可以访问谷歌数据中心数百万台计算机，你可能会理解为什么他们可以如此快速地返回搜索结果！
- en: We won't discuss it here, but the multiprocessing module includes a manager
    class that can take a lot of the boilerplate out of the preceding code. There
    is even a version of `multiprocessing.Manager` that can manage subprocesses on
    remote systems to construct a rudimentary distributed application. Check the Python
    multiprocessing documentation if you are interested in pursuing this further.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里不会讨论它，但多进程模块包含一个管理类，可以消除前面代码中的许多样板代码。甚至有一个版本的`multiprocessing.Manager`可以管理远程系统上的子进程，以构建一个基本的分布式应用程序。如果你对此感兴趣，请查看Python多进程文档。
- en: The problems with multiprocessing
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程的问题
- en: As threads do, multiprocessing also has problems, some of which we have already
    discussed. There is no best way to do concurrency; this is especially true in
    Python. We always need to examine the parallel problem to figure out which of
    the many available solutions is the best one for that problem. Sometimes, there
    is no best solution.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 与线程一样，多进程也存在问题，其中一些我们已经讨论过。没有一种做并发的最佳方式；这在Python中尤其如此。我们总是需要检查并行问题，以确定众多可用解决方案中哪一个最适合该问题。有时，可能没有最佳解决方案。
- en: In the case of multiprocessing, the primary drawback is that sharing data between
    processes is costly. As we have discussed, all communication between processes,
    whether by queues, pipes, or a more implicit mechanism, requires pickling the
    objects. Excessive pickling quickly dominates processing time. Multiprocessing
    works best when relatively small objects are passed between processes and a tremendous
    amount of work needs to be done on each one. On the other hand, if no communication
    between processes is required, there may not be any point in using the module
    at all; we can spin up four separate Python processes (by running each in a separate
    terminal, for example) and use them independently.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在多进程的情况下，主要缺点是进程间共享数据成本高昂。正如我们讨论的，所有进程间的通信，无论是通过队列、管道还是更隐式的机制，都需要序列化对象。过度的序列化很快就会主导处理时间。多进程在需要将相对较小的对象在进程间传递，并且每个对象都需要完成大量工作时效果最好。另一方面，如果进程间不需要通信，可能根本不需要使用该模块；我们可以启动四个独立的Python进程（例如，通过在单独的终端中运行每个进程）并独立使用它们。
- en: The other major problem with multiprocessing is that, like threads, it can be
    hard to tell which process a variable or method is being accessed in. In multiprocessing,
    if you access a variable from another process it will usually overwrite the variable
    in the currently running process while the other process keeps the old value.
    This is really confusing to maintain, so don't do it.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程的另一个主要问题是，与线程一样，很难确定变量或方法是在哪个进程中访问的。在多进程中，如果你从一个进程访问变量，它通常会覆盖当前运行进程中的变量，而另一个进程则保留旧值。这真的很令人困惑，因此不要这样做。
- en: Futures
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Futures
- en: Let's start looking at a more asynchronous way of implementing concurrency.
    Futures wrap either multiprocessing or threading depending on what kind of concurrency
    we need (tending toward I/O versus tending toward CPU). They don't completely
    solve the problem of accidentally altering shared state, but they allow us to
    structure our code such that it is easier to track down when we do so.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探讨一种更异步的并发实现方式。根据我们需要哪种类型的并发（倾向于I/O还是倾向于CPU），Futures会包装多进程或线程。它们并不能完全解决意外改变共享状态的问题，但它们允许我们以这样的方式组织代码，使得在发生这种情况时更容易追踪。
- en: Futures provide distinct boundaries between the different threads or processes.
    Similar to the multiprocessing pool, they are useful for *call and answer* type
    interactions, in which processing can happen in another thread and then at some
    point in the future (they are aptly named, after all), you can ask it for the
    result. It's really just a wrapper around multiprocessing pools and thread pools,
    but it provides a cleaner API and encourages nicer code.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Futures在不同的线程或进程之间提供了明确的边界。类似于多进程池，它们对于*调用和响应*类型的交互很有用，在这种交互中，处理可以在另一个线程中进行，然后在某个时刻（毕竟，它们的名字很合适），你可以请求结果。它实际上只是多进程池和线程池的包装，但它提供了一个更干净的API，并鼓励编写更好的代码。
- en: A future is an object that wraps a function call. That function call is run
    in the *background*, in a thread or process. The `future` object has methods the
    main thread can use to check whether the future has completed and to get the results
    after it has completed.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 未来是一个封装函数调用的对象。该函数调用在*后台*运行，在一个线程或进程中。`future`对象有主线程可以使用的方法来检查未来是否完成，并在完成后获取结果。
- en: 'Let''s see another file search example. In the last section, we implemented
    a version of the `unix grep` command. This time, we''rr create a simple version
    of the `find` command. The example will search the entire filesystem for paths
    that contain a given string of characters, as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个文件搜索的例子。在上一个部分，我们实现了一个`unix grep`命令的版本。这次，我们将创建一个简单的`find`命令版本。该示例将搜索整个文件系统，查找包含给定字符序列的路径，如下所示：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code consists of a function named `find_files`, which is run in a separate
    thread (or process, if we used `ProcessPoolExecutor` instead). There isn't anything
    particularly special about this function, but note how it does not access any
    global variables. All interaction with the external environment is passed into
    the function or returned from it. This is not a technical requirement, but it
    is the best way to keep your brain inside your skull when programming with futures.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码由一个名为 `find_files` 的函数组成，它在单独的线程（或如果我们使用 `ProcessPoolExecutor` 代替，则是进程）中运行。这个函数没有什么特别之处，但请注意它没有访问任何全局变量。所有与外部环境的交互都传递到函数中或从函数返回。这不是一个技术要求，但这是在使用未来编程时保持你的大脑在头骨内的最佳方式。
- en: Accessing outside variables without proper synchronization results in something
    called a **race** **condition**. For example, imagine two concurrent writes trying
    to increment an integer counter. They start at the same time and both read the
    value as 5\. Then, they both increment the value and write back the result as
    6\. But if two processes are trying to increment a variable, the expected result
    would be that it gets incremented by two, so the result should be 7\. Modern wisdom
    is that the easiest way to avoid doing this is to keep as much state as possible
    private and share them through known-safe constructs, such as queues or futures.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有适当同步的情况下访问外部变量会导致称为 **竞争条件** 的情况。例如，想象有两个并发写入尝试增加一个整数计数器。它们同时开始，并且都读取值为 5。然后，它们都增加值并将结果写回为
    6。但如果两个进程都在尝试增加一个变量，预期的结果应该是它增加两次，所以结果应该是 7。现代的智慧是，避免这样做最简单的方法是尽可能多地保持状态私有，并通过已知安全的结构，如队列或未来，来共享。
- en: We set up a couple of variables before we get started; we'll be searching for
    all files that contain the characters `'.py'` for this example. We have a queue
    of futures, which we'll discuss shortly. The `basedir` variable points to the
    root of the filesystem: `'/'` on Unix machines and probably `C:\` on Windows.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们设置了一些变量；在这个例子中，我们将搜索包含字符 `'.py'` 的所有文件。我们有一个未来队列，我们稍后会讨论。`basedir` 变量指向文件系统的根目录：在
    Unix 机器上是 `'/'`，在 Windows 机器上可能是 `C:\`。
- en: First, let's take a short course on search theory. This algorithm implements
    breadth-first search in parallel. Rather than recursively searching every directory
    using a depth-first search, it adds all the subdirectories in the current folder
    to the queue, then all the subdirectories of each of those folders, and so on.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们简要地学习一下搜索理论。这个算法实现了并行广度优先搜索。而不是递归地使用深度优先搜索搜索每个目录，它将当前文件夹中的所有子目录添加到队列中，然后是每个这些文件夹的子目录，依此类推。
- en: The meat of the program is known as an event loop. We can construct a `ThreadPoolExecutor`
    as a context manager so that it is automatically cleaned up and closes its threads
    when it is done. It requires a `max_workers` argument to indicate the number of
    threads running at a time. If more than this many jobs are submitted, it queues
    up the rest until a worker thread becomes available. When using `ProcessPoolExecutor`,
    this is normally constrained to the number of CPUs on the machine, but with threads,
    it can be much higher, depending how many are waiting on I/O at a time. Each thread
    takes up a certain amount of memory, so it shouldn't be too high. It doesn't take
    all that many threads before the speed of the disk, rather than the number of
    parallel requests, is the bottleneck.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的核心部分被称为事件循环。我们可以将 `ThreadPoolExecutor` 作为上下文管理器来构建，这样它就会在完成后自动清理并关闭其线程。它需要一个
    `max_workers` 参数来指示同时运行的线程数。如果有超过这个数量的工作提交，它将剩余的工作排队，直到有工作线程可用。当使用 `ProcessPoolExecutor`
    时，这通常限制在机器上的 CPU 数量，但使用线程时，它可以高得多，这取决于一次有多少线程在等待 I/O。每个线程占用一定量的内存，所以它不应该太高。在磁盘速度而不是并行请求数量成为瓶颈之前，不需要太多线程。
- en: Once the executor has been constructed, we submit a job to it using the root
    directory. The `submit()` method immediately returns a `Future` object, which
    promises to give us a result eventually. The future is placed in the queue. The
    loop then repeatedly removes the first future from the queue and inspects it.
    If it is still running, it gets added back to the end of the queue. Otherwise,
    we check whether the function raised an exception with a call to `future.exception()`.
    If it did, we just ignore it (it's usually a permission error, although a real
    app would need to be more careful about what the exception was). If we didn't
    check this exception here, it would be raised when we called `result()` and could
    be handled through the normal `try...except` mechanism.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦构建了执行器，我们就会使用根目录向其提交一个任务。`submit()` 方法立即返回一个 `Future` 对象，它承诺最终会给我们一个结果。这个未来对象被放入队列中。然后循环会反复从队列中移除第一个未来对象并检查它。如果它仍在运行，它会被添加回队列的末尾。否则，我们会通过调用
    `future.exception()` 来检查函数是否抛出了异常。如果抛出了异常，我们只需忽略它（通常是一个权限错误，尽管真正的应用程序需要更小心地处理异常）。如果我们没有在这里检查这个异常，它会在我们调用
    `result()` 时抛出，并且可以通过正常的 `try...except` 机制来处理。
- en: Assuming no exception occurred, we can call `result()` to get the return value.
    Since the function returns a list of subdirectories that are not symbolic links
    (my lazy way of preventing an infinite loop), `result()` returns the same thing.
    These new subdirectories are submitted to the executor and the resulting futures
    are tossed onto the queue to have their contents searched in a later iteration.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 假设没有发生异常，我们可以调用 `result()` 来获取返回值。由于函数返回一个不包含符号链接的子目录列表（我防止无限循环的懒惰方式），`result()`
    返回相同的内容。这些新的子目录被提交给执行器，产生的未来对象被扔到队列中，以便在后续迭代中搜索其内容。
- en: And that's all that is required to develop a future-based I/O-bound application.
    Under the hood, it's using the same thread or process APIs we've already discussed,
    but it provides a more understandable interface and makes it easier to see the
    boundaries between concurrently running functions (just don't try to access global
    variables from inside the future!).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是开发基于未来的 I/O 密集型应用程序所需的所有内容。在底层，它使用的是我们之前讨论过的相同的线程或进程 API，但它提供了一个更易于理解的接口，并使得查看并发运行函数之间的边界更容易（只是不要尝试从未来内部访问全局变量！）。
- en: AsyncIO
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AsyncIO
- en: AsyncIO is the current state of the art in Python concurrent programming. It
    combines the concept of futures and an event loop with the coroutines we discussed
    in [Chapter 9](0abbcae0-eb3f-4237-adda-32765e1cce32.xhtml), *The Iterator Pattern*.
    The result is about as elegant and easy to understand as it is possible to get
    when writing concurrent code, though that isn't saying a lot!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO 是 Python 并发编程的当前最佳实践。它将我们讨论过的未来的概念和事件循环与 [第 9 章](0abbcae0-eb3f-4237-adda-32765e1cce32.xhtml)
    中讨论的协程结合在一起，*迭代器模式*。结果是尽可能优雅和易于理解，尽管这并不是说很多！
- en: AsyncIO can be used for a few different concurrent tasks, but it was specifically
    designed for network I/O. Most networking applications, especially on the server
    side, spend a lot of time waiting for data to come in from the network. This can
    be solved by handling each client in a separate thread, but threads use up memory
    and other resources. AsyncIO uses coroutines as a sort of lightweight thread.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO 可以用于几种不同的并发任务，但它专门设计用于网络 I/O。大多数网络应用程序，尤其是在服务器端，花费大量时间等待从网络传入的数据。这可以通过为每个客户端使用单独的线程来解决，但线程会消耗内存和其他资源。AsyncIO
    使用协程作为一种轻量级的线程。
- en: The library provides its own event loop, obviating the need for the several
    lines long the `while` loop in the previous example. However, event loops come
    with a cost. When we run code in an `async` task on the event loop, that code
    **must** return immediately, blocking neither on I/O nor on long-running calculations.
    This is a minor thing when writing our own code, but it means that any standard
    library or third-party functions that block on I/O have to have non-blocking versions
    created.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 该库提供自己的事件循环，消除了在前面示例中需要几行长的 `while` 循环的需求。然而，事件循环也有代价。当我们在一个事件循环上运行 `async`
    任务中的代码时，该代码**必须**立即返回，既不阻塞 I/O 也不阻塞长时间运行的计算。当我们自己编写代码时，这是一件小事，但这意味着任何在 I/O 上阻塞的标准库或第三方函数都必须有非阻塞版本。
- en: AsyncIO solves this by creating a set of coroutines that use `async` and `await`
    syntax to return control to the event loop immediately when code will block. These
    keywords replace the `yield`, `yield from`, and `send` syntax we used in the raw
    coroutines we saw earlier, as well as the need to manually advance to the first
    *send* location. The result is concurrent code that we can reason about as if
    it were sequential. The event loop takes care of checking whether the blocking
    call has completed and performing any subsequent tasks, much as we did manually
    in the previous section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO通过创建一组使用`async`和`await`语法来立即将控制权返回给事件循环的协程来解决此问题。这些关键字替换了我们之前在原始协程中使用的`yield`、`yield
    from`和`send`语法，以及手动前进到第一个*send*位置的需要。结果是并发代码，我们可以像处理顺序代码一样推理它。事件循环负责检查阻塞调用是否完成，并执行任何后续任务，就像我们在上一节中手动执行的那样。
- en: AsyncIO in action
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AsyncIO的实际应用
- en: 'A canonical example of a blocking function is the `time.sleep` call. Let''s
    use the asynchronous version of this call to illustrate the basics of an AsyncIO
    event loop, as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 阻塞函数的一个典型例子是`time.sleep`调用。让我们使用这个调用的异步版本来展示AsyncIO事件循环的基本原理，如下所示：
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is a fairly basic example, but it covers several features of AsyncIO programming.
    It is easiest to understand in the order that it executes, which is more or less
    bottom to top.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当基础的例子，但它涵盖了AsyncIO编程的几个特性。最容易理解的是它的执行顺序，这基本上是从下到上。
- en: 'Here''s how one execution of the script looks:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何执行脚本的一个示例：
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The second to last line gets the event loop and instructs it to run a task until
    it is finished. The task in question is named `five_sleepers`. Once that task
    has done its work, the loop will exit and our code will terminate. As asynchronous
    programmers, we don't need to know too much about what happens inside that `run_until_complete`
    call, but be aware that a lot is going on. It's a souped-up coroutine version
    of the futures loop we wrote in the previous chapter, which knows how to deal
    with iteration, exceptions, function returns, parallel calls, and more.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行获取事件循环并指示它运行一个任务，直到它完成。相关的任务是`five_sleepers`。一旦该任务完成其工作，循环将退出，我们的代码将终止。作为异步程序员，我们不需要了解太多关于`run_until_complete`调用内部发生的事情，但请注意，有很多事情在进行中。这是一个增强版的协程版本，我们之前在章节中编写的未来循环，它知道如何处理迭代、异常、函数返回、并行调用等等。
- en: 'A task, in this context, is an object that `asyncio` knows how to schedule
    on the event loop. This includes the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个上下文中，任务是一个`asyncio`知道如何在事件循环上安排的对象。这包括以下内容：
- en: Coroutines defined with the `async` and `await` syntax.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`async`和`await`语法定义的协程。
- en: Coroutines decorated with `@asyncio.coroutine` and using the `yield from` syntax
    (this is an older model, deprecated in favor of `async` and `await`).
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`@asyncio.coroutine`装饰器和`yield from`语法（这是一个较旧的模型，已被`async`和`await`所取代）装饰的协程。
- en: '`asyncio.Future` objects. These are almost identical to the `concurrent.futures`
    you saw in the previous section, but for use with `asyncio`.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asyncio.Future`对象。这些与我们在上一节中看到的`concurrent.futures`几乎相同，但用于`asyncio`。'
- en: Any awaitable object, that is, one with an `__await__` function.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何可等待的对象，即具有`__await__`函数的对象。
- en: In this example, all the tasks are coroutines; we'll see some of the others
    in later examples.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，所有任务都是协程；我们将在后面的例子中看到一些其他的例子。
- en: Look a little more closely at that `five_sleepers` future. The coroutine first
    constructs five instances of the `random_sleep` coroutine. These are each wrapped
    in a `asyncio.create_task` call, which adds the future to the loop's task queue
    so they can execute and start immediately when control is returned to the loop.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察一下那个`five_sleepers`未来。协程首先构建了五个`random_sleep`协程的实例。这些实例每个都被`asyncio.create_task`调用所包装，这会将未来添加到循环的任务队列中，以便它们可以在控制权返回到循环时立即执行。
- en: 'That control is returned whenever we call `await`. In this case, we call `await
    asyncio.sleep` to pause the execution of the coroutine for two seconds. During
    the break, the event loop executes the tasks that it has queued up: namely, the
    five `random_sleep` tasks.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们调用`await`时，控制权都会返回。在这种情况下，我们调用`await asyncio.sleep`来暂停协程的执行两秒钟。在暂停期间，事件循环执行它已经排队的任务：即五个`random_sleep`任务。
- en: When the sleep call in the `five_sleepers` task wakes up, it calls `asyncio.gather`.
    This function accepts tasks as varargs, and awaits each of them (among other things,
    to keep the loop running safely) before returning.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当`five_sleepers`任务中的睡眠调用唤醒时，它调用`asyncio.gather`。这个函数接受任务作为可变参数，并在返回之前等待每个任务（以及其他事情，以保持循环安全运行）。
- en: Each of the `random_sleep` coroutines prints a starting message, then sends
    control back to the event loop for a specific amount of time using its own `await`
    calls. When the sleep has completed, the event loop passes control back to the
    relevant `random_sleep` task, which prints its awakening message before returning.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`random_sleep`协程打印一条启动信息，然后使用自己的`await`调用将控制权返回给事件循环一段时间。当睡眠完成时，事件循环将控制权返回给相关的`random_sleep`任务，该任务在返回之前打印其唤醒信息。
- en: Note that any tasks that take less than two seconds to complete will output
    their own awakening messages before the original `five_sleepers` coroutine awakes
    to run until the `gather` task is called. Since the event queue is now empty (all
    six coroutines have run to completion and are not awaiting any tasks), the `run_until_complete`
    call is able to terminate and the program ends.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，任何少于两秒即可完成的任务都会在原始的`five_sleepers`协程唤醒并运行到调用`gather`任务之前输出它们自己的唤醒信息。由于事件队列现在为空（所有六个协程都已运行完成且不再等待任何任务），`run_until_complete`调用能够终止，程序结束。
- en: The `async` keyword acts as documentation notifying the python interpreter (and
    coder) that the coroutine contains the `await` calls. It also does some work to
    prepare the coroutine to run on the event loop. It behaves much like a decorator;
    in fact, back in Python 3.4, this was implemented as an `@asyncio.coroutine` decorator.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`async`关键字作为文档，通知 Python 解释器（和程序员）协程包含`await`调用。它还做一些工作来准备协程在事件循环上运行。它的工作方式很像装饰器；事实上，在
    Python 3.4 中，这被实现为一个`@asyncio.coroutine`装饰器。'
- en: Reading an AsyncIO Future
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取 AsyncIO 未来对象
- en: An AsyncIO coroutine executes each line in order until it encounters an `await`
    statement, at which point, it returns control to the event loop. The event loop
    then executes any other tasks that are ready to run, including the one that the
    original coroutine was waiting on. Whenever that child task completes, the event
    loop sends the result back into the coroutine so that it can pick up execution
    until it encounters another `await` statement or returns.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO 协程按顺序执行每一行，直到遇到`await`语句，此时，它将控制权返回给事件循环。事件循环随后执行任何其他准备就绪的任务，包括原始协程等待的任务。每当子任务完成时，事件循环将结果发送回协程，以便它可以继续执行，直到遇到另一个`await`语句或返回。
- en: This allows us to write code that executes synchronously until we explicitly
    need to wait for something. As a result, there is no nondeterministic behavior
    of threads, so we don't need to worry nearly so much about shared state.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许我们编写同步执行的代码，直到我们明确需要等待某事。因此，没有线程的非确定性行为，所以我们不必那么担心共享状态。
- en: It's still a good idea to avoid accessing shared state from inside a coroutine.
    It makes your code much easier to reason about. More importantly, even though
    an ideal world might have all asynchronous execution happening inside coroutines,
    the reality is that some futures are executed behind the scenes inside threads
    or processes. Stick to a *share nothing* philosophy to avoid a ton of difficult
    bugs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然建议避免在协程内部访问共享状态。这会使你的代码更容易推理。更重要的是，尽管理想的世界可能所有异步执行都在协程内部进行，但现实是有些未来对象在后台线程或进程中执行。坚持“无共享”哲学以避免大量难以调试的错误。
- en: In addition, AsyncIO allows us to collect logical sections of code together
    inside a single coroutine, even if we are waiting for other work elsewhere. As
    a specific instance, even though the `await asyncio.sleep` call in the `random_sleep`
    coroutine is allowing a ton of stuff to happen inside the event loop, the coroutine
    itself looks like it's doing everything in order. This ability to read related
    pieces of asynchronous code without worrying about the machinery that waits for
    tasks to complete is the primary benefit of the AsyncIO module.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AsyncIO 允许我们将代码的逻辑部分组合在一个单独的协程中，即使我们在等待其他地方的工作。作为一个具体的例子，即使在`random_sleep`协程中的`await
    asyncio.sleep`调用允许在事件循环中发生大量事情，但协程本身看起来像是有序地执行所有操作。这种无需担心等待任务完成的机制即可读取相关异步代码的能力是
    AsyncIO 模块的主要优势。
- en: AsyncIO for networking
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AsyncIO 网络编程
- en: AsyncIO was specifically designed for use with network sockets, so let's implement
    a DNS server. More accurately, let's implement one extremely basic feature of
    a DNS server.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO是专门为与网络套接字一起使用而设计的，所以让我们实现一个DNS服务器。更准确地说，让我们实现DNS服务器的一个非常基础的功能。
- en: 'The DNS''s basic purpose is to translate domain names, such as [https://www.python.org/](https://www.python.org/),
    into IP addresses, such as IPv4 addresses (for example `23.253.135.79`) or IPv6
    addresses (such as `2001:4802:7901:0:e60a:1375:0:6`). It has to be able to perform
    many types of queries and know how to contact other DNS servers if it doesn''t
    have the answer required. We won''t be implementing any of this, but the following
    example is able to respond directly to a standard DNS query to look up IPs for
    a few sites:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: DNS的基本目的是将域名，例如[https://www.python.org/](https://www.python.org/)，翻译成IP地址，例如IPv4地址（例如`23.253.135.79`）或IPv6地址（例如`2001:4802:7901:0:e60a:1375:0:6`）。它必须能够执行许多类型的查询，并且知道如何联系其他DNS服务器，如果它没有所需的答案。我们不会实现这些功能，但以下示例能够直接响应标准的DNS查询，查找几个网站的IP地址：
- en: '[PRE15]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This example sets up a dictionary that dumbly maps a few domains to IPv4 addresses.
    It is followed by two functions that extract information from a binary DNS query
    packet and construct the response. We won't be discussing these; if you want to
    know more about DNS read RFC (*request for comment*, the format for defining most
    IPs) `1034` and `1035`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例设置了一个字典，将几个域名愚蠢地映射到IPv4地址。随后是两个函数，它们从二进制DNS查询数据包中提取信息并构建响应。我们不会讨论这些；如果你想了解更多关于DNS的信息，请阅读RFC（*请求评论*，定义大多数IP的格式）`1034`和`1035`。
- en: 'You can test this service by running the following command in another terminal:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在另一个终端运行以下命令来测试这个服务：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Let's get on with the entree. AsyncIO networking revolves around the intimately
    linked concepts of transports and protocols. A protocol is a class that has specific
    methods that are called when relevant events happen. Since DNS runs on top of
    **UDP** (**User Datagram Protocol**), we build our protocol class as a subclass
    of `DatagramProtocol`. There are a variety of events this class can respond to.
    We are specifically interested in the initial connection occurring (solely so
    that we can store the transport for future use) and the `datagram_received` event.
    For DNS, each received datagram must be parsed and responded to, at which point,
    the interaction is over.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续深入主题。AsyncIO网络围绕紧密相连的概念——传输和协议。协议是一个类，当发生相关事件时，会调用其特定的方法。由于DNS运行在**UDP**（用户数据报协议）之上，我们构建我们的协议类作为`DatagramProtocol`的子类。这个类可以响应各种事件。我们特别关注初始连接的发生（仅此而已，这样我们就可以存储传输以供将来使用）以及`datagram_received`事件。对于DNS，每个接收到的数据报都必须被解析并响应，此时，交互就结束了。
- en: So, when a datagram is received, we process the packet, look up the IP, and
    construct a response using the functions we aren't talking about (they're black
    sheep in the family). Then, we instruct the underlying transport to send the resulting
    packet back to the requesting client using its `sendto` method.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当接收到数据报时，我们处理数据包，查找IP，并使用我们未讨论的函数（它们是这个家族中的黑羊）构建响应。然后，我们指示底层传输使用其`sendto`方法将生成的数据包发送回请求的客户机。
- en: The transport essentially represents a communication stream. In this case, it
    abstracts away all the fuss of sending and receiving data on a UDP socket on an
    event loop. There are similar transports for interacting with TCP sockets and
    subprocesses, for example.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 传输本质上代表了一种通信流。在这种情况下，它抽象掉了在事件循环上使用UDP套接字发送和接收数据的所有繁琐操作。例如，还有类似的传输用于与TCP套接字和子进程交互。
- en: The UDP transport is constructed by calling the loop's `create_datagram_endpoint`
    coroutine. This constructs the appropriate UDP socket and starts listening on
    it. We pass it the address that the socket needs to listen on and, importantly,
    the protocol class we created so that the transport knows what to call when it
    receives data.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: UDP传输是通过调用循环的`create_datagram_endpoint`协程来构建的。这会构建适当的UDP套接字并开始监听它。我们传递给它套接字需要监听的地址，以及，重要的是，我们创建的协议类，这样传输就知道在接收到数据时应该调用什么。
- en: 'Since the process of initializing a socket takes a non-trivial amount of time
    and would block the event loop, the `create_datagram_endpoint` function is a coroutine.
    In our example, we don''t need to do anything while we wait for this initialization,
    so we wrap the call in `loop.run_until_complete`. The event loop takes care of
    managing the future, and when it''s complete, it returns a tuple of two values:
    the newly initialized transport and the protocol object that was constructed from
    the class we passed in.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 由于初始化套接字的过程需要相当多的时间，并且会阻塞事件循环，因此`create_datagram_endpoint`函数是一个协程。在我们的示例中，在等待这个初始化的过程中我们不需要做任何事情，所以我们用`loop.run_until_complete`来包装这个调用。事件循环负责管理未来，当它完成时，它会返回一个包含两个值的元组：新初始化的传输和从我们传入的类中构建的协议对象。
- en: Behind the scenes, the transport has set up a task on the event loop that is
    listening for incoming UDP connections. All we have to do, then, is start the
    event loop running with the call to `loop.run_forever()` so that the task can
    process these packets. When the packets arrive, they are processed on the protocol
    and everything just works.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，传输已经在事件循环上设置了一个任务，该任务正在监听传入的UDP连接。然后我们只需要通过调用`loop.run_forever()`来启动事件循环的运行，以便任务可以处理这些数据包。当数据包到达时，它们在协议中被处理，一切正常工作。
- en: The only other major thing to pay attention to is that transports (and, indeed,
    event loops) are supposed to be closed when we are finished with them. In this
    case, the code runs just fine without the two calls to `close()`, but if we were
    constructing transports on the fly (or just doing proper error handling!), we'd
    need to be quite a bit more conscious of it.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要特别注意的另一件大事是，当我们完成传输（以及确实，事件循环）时，应该关闭它们。在这种情况下，代码运行得很好，不需要两个`close()`调用，但如果我们是在实时构建传输（或者只是做适当的错误处理！），我们就需要对此有更多的意识。
- en: You may have been dismayed to see how much boilerplate is required in setting
    up a protocol class and the underlying transport. AsyncIO provides an abstraction
    on top of these two key concepts, called streams. We'll see an example of streams
    in the TCP server in the next example.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对设置协议类和底层传输所需的样板代码感到沮丧。AsyncIO在这些两个关键概念之上提供了一个抽象，称为流。我们将在下一个示例中看到流的示例。
- en: Using executors to wrap blocking code
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用执行器包装阻塞代码
- en: 'AsyncIO provides its own version of the futures library to allow us to run
    code in a separate thread or process when there isn''t an appropriate non-blocking
    call to be made. This allows us to combine threads and processes with the asynchronous
    model. One of the more useful applications of this feature is to get the best
    of both worlds when an application has bursts of I/O-bound and CPU-bound activity.
    The I/O-bound portions can happen in the event loop, while the CPU-intensive work
    can be spun off to a different process. To illustrate this, let''s implement *sorting
    as a service* using AsyncIO:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: AsyncIO提供了一个自己的futures库版本，允许我们在没有适当的非阻塞调用可进行时在单独的线程或进程中运行代码。这允许我们将线程和进程与异步模型结合起来。这个特性的一个更有用的应用是在应用程序有I/O密集型和CPU密集型活动爆发时，能够获得两者的最佳效果。I/O密集型部分可以在事件循环中发生，而CPU密集型工作可以分配到不同的进程中。为了说明这一点，让我们使用AsyncIO来实现*排序作为一项服务*：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This is an example of good code implementing some really stupid ideas. The whole
    idea of sorting as a service is pretty ridiculous. Using our own sorting algorithm
    instead of calling Python's `sorted` is even worse. The algorithm we used is called
    gnome sort, or in some cases, *stupid sort*. It is a slow sort algorithm implemented
    in pure Python. We defined our own protocol instead of using one of the many perfectly
    suitable application protocols that exist in the wild. Even the idea of using
    multiprocessing for parallelism might be suspect here; we still end up passing
    all the data into and out of the subprocesses. Sometimes, it's important to take
    a step back from the program you are writing and ask yourself whether you are
    trying to meet the right goals.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实现了一些非常愚蠢想法的好代码的例子。将排序作为一项服务整个想法相当荒谬。使用我们自己的排序算法而不是调用Python的`sorted`甚至更糟糕。我们使用的算法被称为冒泡排序，或者在某些情况下，*愚蠢排序*。这是一个纯Python实现的慢速排序算法。我们定义了自己的协议而不是使用野外存在的许多完全合适的应用协议之一。甚至使用多进程来实现并行性的想法也可能值得怀疑；我们最终还是将所有数据传递到和从子进程中。有时，从你正在编写的程序中退一步，问问自己你是否在尝试达到正确的目标，这很重要。
- en: But ignoring the workload, let's look at some of the smart features of this
    design. First, we are passing bytes into and out of the subprocess. This is a
    lot smarter than decoding the JSON in the main process. It means the (relatively
    expensive) decoding can happen on a different CPU. Also, pickled JSON strings
    are generally smaller than pickled lists, so less data is passed between processes.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 但忽略工作负载，让我们看看这个设计的一些智能特性。首先，我们在子进程中传入和传出字节。这比在主进程中解码 JSON 智能得多。这意味着（相对昂贵的）解码可以在不同的
    CPU 上发生。此外，序列化的 JSON 字符串通常比序列化的列表小，因此进程间传递的数据更少。
- en: Second, the two methods are very linear; it looks like code is being executed
    one line after another. Of course, in AsyncIO, this is an illusion, but we don't
    have to worry about shared memory or concurrency primitives.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，这两个方法非常线性；看起来代码是一行一行执行的。当然，在 AsyncIO 中，这是一个错觉，但我们不必担心共享内存或并发原语。
- en: Streams
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流
- en: The sort service example should look familiar by now, as it has a similar boilerplate
    to other AsyncIO programs. However, there are a few differences. We called `start_server`
    instead of `create_server`. This method hooks into AsyncIO's streams instead of
    using the underlying transport/protocol code. It allows us to pass in a normal
    coroutine, which receives reader and writer parameters. These both represent streams
    of bytes that can be read from and written, like files or sockets. Second, because
    this is a TCP server instead of UDP, there is some socket cleanup required when
    the program finishes. This cleanup is a blocking call, so we have to run the `wait_closed`
    coroutine on the event loop.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的排序服务示例应该已经很熟悉了，因为它与其他 AsyncIO 程序有类似的模板。然而，也有一些不同之处。我们使用了 `start_server` 而不是
    `create_server`。这种方法通过 AsyncIO 的流而不是使用底层的传输/协议代码进行挂钩。它允许我们传入一个普通的协程，该协程接收读取器和写入器参数。这两个参数都代表可以读取和写入的字节流，就像文件或套接字一样。其次，因为这是一个
    TCP 服务器而不是 UDP，当程序结束时需要一些套接字清理。这个清理是一个阻塞调用，所以我们必须在事件循环上运行 `wait_closed` 协程。
- en: Streams are fairly simple to understand. Reading is a potentially blocking call
    so we have to call it with `await`. Writing doesn't block; it just puts the data
    in a queue, which AsyncIO sends out in the background.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 流相对简单易懂。读取是一个可能阻塞的调用，所以我们必须使用 `await` 来调用它。写入不会阻塞；它只是将数据放入队列，然后 AsyncIO 在后台发送出去。
- en: Our code inside the `sort_request` method makes two read requests. First, it
    reads 8 bytes from the wire and converts them to an integer using big endian notation.
    This integer represents the number of bytes of data the client intends to send.
    So, in the next call, to `readexactly`, it reads that many bytes. The difference
    between `read` and `readexactly` is that the former will read up to the requested
    number of bytes, while the latter will buffer reads until it receives all of them,
    or until the connection closes.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `sort_request` 方法内部的代码进行了两次读取请求。首先，它从线路上读取 8 个字节，并使用大端表示法将它们转换为整数。这个整数表示客户端打算发送的字节数。因此，在下一个调用
    `readexactly` 时，它读取这么多字节。`read` 和 `readexactly` 之间的区别在于，前者将读取请求的字节数，而后者将缓冲读取，直到接收到所有字节，或者直到连接关闭。
- en: Executors
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行器
- en: Now let's look at the executor code. We import the exact same `ProcessPoolExecutor`
    that we used in the previous section. Notice that we don't need a special AsyncIO
    version of it. The event loop has a handy `run_in_executor` coroutine that we
    can use to run futures on. By default, the loop runs code in `ThreadPoolExecutor`,
    but we can pass in a different executor if we wish. Or, as we did in this example,
    we can set a different default when we set up the event loop by calling `loop.set_default_executor()`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看执行器代码。我们导入与上一节中使用的完全相同的 `ProcessPoolExecutor`。注意，我们不需要一个特殊的 AsyncIO 版本。事件循环有一个方便的
    `run_in_executor` 协程，我们可以用它来运行未来。默认情况下，循环在 `ThreadPoolExecutor` 中运行代码，但如果我们愿意，我们可以传入不同的执行器。或者，就像在这个例子中那样，我们可以在设置事件循环时通过调用
    `loop.set_default_executor()` 来设置不同的默认值。
- en: As you probably recall, there is not a lot of boilerplate for using futures
    with an executor. However, when we use them with AsyncIO, there is none at all!
    The coroutine automatically wraps the function call in a future and submits it
    to the executor. Our code blocks until the future completes, while the event loop
    continues processing other connections, tasks, or futures. When the future is
    done, the coroutine wakes up and continues on to write the data back to the client.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所回忆的那样，使用执行器与 futures 一起使用时，没有太多的样板代码。然而，当我们与 AsyncIO 一起使用时，则完全没有！协程会自动将函数调用包装在
    future 中，并将其提交给执行器。我们的代码在 future 完成之前会阻塞，而事件循环会继续处理其他连接、任务或 futures。当 future 完成时，协程会唤醒并继续将数据写回客户端。
- en: 'You may be wondering if, instead of running multiple processes inside an event
    loop, it might be better to run multiple event loops in different processes. The
    answer is: *maybe*. However, depending on the exact problem space, we are probably
    better off running independent copies of a program with a single event loop than
    trying to coordinate everything with a master multiprocessing process.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道，是否在事件循环内部运行多个进程，而不是运行多个事件循环在不同进程中会更好。答案是：*可能吧*。然而，根据具体的问题空间，我们可能更倾向于运行具有单个事件循环的独立程序副本，而不是试图通过主多进程来协调一切。
- en: AsyncIO clients
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AsyncIO 客户端
- en: Because it is capable of handling many thousands of simultaneous connections,
    AsyncIO is very common for implementing servers. However, it is a generic networking
    library, and provides full support for client processes as well. This is pretty
    important, since many microservices run servers that act as clients to other servers.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它能够处理数以千计的并发连接，AsyncIO 非常常见于实现服务器。然而，它是一个通用的网络库，并为客户端进程提供全面支持。这非常重要，因为许多微服务运行的服务器充当其他服务器的客户端。
- en: 'Clients can be much simpler than servers, as they don''t have to be set up
    to wait for incoming connections. Like most networking libraries, you just open
    a connection, submit your requests, and process any responses. The main difference
    is that you need to use `await` any time you make a potentially blocking call.
    Here''s an example client for the sort service we implemented in the last section:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端可以比服务器简单得多，因为它们不需要设置来等待传入的连接。像大多数网络库一样，你只需打开一个连接，提交你的请求，并处理任何响应。主要区别在于，每次你进行可能阻塞的调用时，都需要使用
    `await`。以下是我们在上一个章节中实现的排序服务的一个示例客户端：
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We've hit most of the high points of AsyncIO in this section, and the chapter
    has covered many other concurrency primitives. Concurrency is a hard problem to
    solve, and no one solution fits all use cases. The most important part of designing
    a concurrent system is deciding which of the available tools is the correct one
    to use for the problem. We have seen the advantages and disadvantages of several
    concurrent systems, and now have some insight into which are the better choices
    for different types of requirements.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经涵盖了 AsyncIO 的多数要点，本章也涵盖了其他许多并发原语。并发是一个难以解决的问题，没有一种解决方案适合所有用例。设计并发系统最重要的部分是决定哪种可用的工具是解决该问题的正确选择。我们已经看到了几个并发系统的优缺点，现在对哪些是不同类型需求更好的选择有一些了解。
- en: Case study
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究
- en: To wrap up this chapter, and the book, let's build a basic image compression
    tool. It will take black and white images (with 1 bit per pixel, either on or
    off) and attempt to compress it using a very basic form of compression known as
    run-length encoding. You may find black and white images a bit far-fetched. If
    so, you haven't enjoyed enough hours at [http://xkcd.com](http://xkcd.com)!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结本章和本书，让我们构建一个基本的图像压缩工具。它将接受黑白图像（每个像素1位，开或关），并尝试使用一种称为运行长度编码的非常基础的压缩形式来压缩它。你可能觉得黑白图像有点牵强。如果是这样，你可能还没有在
    [http://xkcd.com](http://xkcd.com) 上享受足够的时间！
- en: I've included some sample black and white BMP images (which are easy to read
    data into and present plenty of opportunity to improve on file size) with the
    example code for this chapter.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经为本章的示例代码包含了一些黑白 BMP 图像（这些图像易于读取数据并提供了大量改进文件大小的机会）。
- en: Run-length encoding takes a sequence of bits and replaces any strings of repeated
    bits with the number of bits that are repeated. For example, the string 000011000
    might be replaced with 04 12 03 to indicate that four zeros are followed by two
    ones and then three more zeroes. To make things a little more interesting, we
    will break each row into 127-bit chunks.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 运行长度编码将位序列替换为任何重复位字符串的数量。例如，字符串000011000可能被替换为04 12 03，以表示四个零后面跟着两个一，然后是三个更多的零。为了使事情更有趣，我们将每行分解为127位块。
- en: I didn't pick 127 bits arbitrarily. 127 different values can be encoded into
    7 bits, which means that if a row contains all ones or all zeros, we can store
    it in a single byte, with the first bit indicating whether it is a row of 0s or
    a row of 1s, and the remaining seven bits indicating how many of that bit exists.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不是随意选择127位。127个不同的值可以编码到7位中，这意味着如果一个行包含全部为1或全部为0，我们可以将其存储在一个字节中，第一个位表示它是一个0行还是一个1行，其余七个位表示该位存在多少。
- en: 'Breaking up the image into blocks has another advantage: we can process individual
    blocks in parallel without them depending on each other. However, there''s a major
    disadvantage as well: if a run has just a few ones or zeros in it, then it will
    take up `more` space in the compressed file. When we break up long runs into blocks,
    we may end up creating more of these small runs and bloat the size of the file.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像分解成块有另一个优点：我们可以并行处理单个块，而无需它们相互依赖。然而，也存在一个主要的缺点：如果一个运行只有少数一或零，那么它在压缩文件中会占用`更多`的空间。当我们将长运行分解成块时，我们可能会创建更多的这些小运行，并使文件的大小膨胀。
- en: We have the freedom to design the layout of the bytes within the compressed
    file as we see fit. For this simple example, our compressed file will store two
    byte little-endian integers at the beginning of the file representing the width
    and height of the completed file. Then, it will write bytes representing the 127
    bit chunks of each row.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有权根据需要设计压缩文件中字节的布局。在这个简单的例子中，我们的压缩文件将在文件开头存储两个字节的小端整数，代表完成文件的宽度和高度。然后，它将写入代表每行127位块的字节。
- en: 'Now, before we start designing a concurrent system to build such compressed
    images, we should ask a fundamental question: is this application I/O-bound or
    CPU-bound?'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始设计一个并发系统来构建这样的压缩图像之前，我们应该问一个基本的问题：这个应用程序是I/O密集型还是CPU密集型？
- en: My answer, honestly, is *I don't know*. I'm not sure whether the app will spend
    more time loading data from disk and writing it back or doing the compression
    in memory. I suspect that it is a CPU-bound app in principle, but once we start
    passing image strings into subprocesses, we may lose any benefit of parallelism.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 实话实说，我的答案是*我不知道*。我不确定应用程序是否会花费更多的时间从磁盘加载数据并将其写回，还是在内存中进行压缩。我怀疑它本质上是一个CPU密集型应用程序，但一旦我们开始将图像字符串传递到子进程中，我们可能会失去任何并行化的好处。
- en: 'We''ll build this application using bottom-up design. That way, we''ll have
    some building blocks that we can combine into different concurrency patterns to
    see how they compare. Let''s start with the code that compresses a 127-bit chunk
    using run-length encoding:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用自下而上的设计来构建这个应用程序。这样，我们将有一些构建块可以组合成不同的并发模式，以比较它们。让我们从使用运行长度编码压缩127位块的代码开始：
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This code uses the `bitarray` class to manipulate individual zeros and ones.
    It is distributed as a third-party module, which you can install with the `pip
    install bitarray` command. The chunk that is passed into `compress_chunks` is
    an instance of this class (although the example would work just as well with a
    list of Booleans). The primary benefit of the `bitarray` in this case is that,
    when pickling them between processes, they take up an eighth of the space of a
    list of Booleans or a bytestring of 1s and 0s. Therefore, they pickle faster.
    They are also a little easier to work with than doing a ton of bitwise operations.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用`bitarray`类来操作单个0和1。它作为一个第三方模块分发，你可以使用`pip install bitarray`命令进行安装。传递给`compress_chunks`的块是这个类的一个实例（尽管示例也可以用布尔值列表工作）。在这种情况下，`bitarray`的主要好处是，在进程间序列化时，它们占用的空间是布尔值列表或1s和0s的字节字符串的八分之一。因此，它们序列化得更快。它们也比进行大量位操作要容易一些。
- en: The method compresses the data using run-length encoding and returns `bytearray`
    containing the packed data. Where a `bitarray` is like a list of ones and zeros,
    `bytearray` is like a list of byte objects (each byte, of course, containing eight
    ones or zeros).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法使用运行长度编码压缩数据，并返回包含打包数据的`bytearray`。就像`bitarray`是一个一和零的列表一样，`bytearray`就像是一个字节对象的列表（当然，每个字节当然包含八个一或零）。
- en: The algorithm that performs the compression is pretty simple (although I'd like
    to point out that it took me two days to implement and debug it–simple to understand
    does not necessarily imply easy to write!). It first sets the `last` variable
    to the type of bit in the current run (either `True` or `False`). It then loops
    over the bits, counting each one, until it finds one that is different. When it
    does, it constructs a new byte by making the leftmost bit of the byte (the 128
    position) either a zero or a one, depending on what the `last` variable contained.
    Then, it resets the counter and repeats the operation. Once the loop is done,
    it creates one last byte for the last run and returns the result.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 执行压缩的算法相当简单（虽然我想指出，实现和调试它花了我两天时间——易于理解并不一定意味着容易编写！）。它首先将`last`变量设置为当前运行中位的类型（要么是`True`要么是`False`）。然后，它遍历位，逐个计数，直到找到一个不同的位。当找到时，它通过将字节的最左边位（128位位置）设置为`last`变量包含的零或一，来构建一个新的字节。然后，它重置计数器并重复操作。一旦循环完成，它为最后一个运行创建一个最后的字节并返回结果。
- en: 'While we''re creating building blocks, let''s make a function that compresses
    a row of image data, as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建构建块时，让我们创建一个函数来压缩一行图像数据，如下所示：
- en: '[PRE20]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This function accepts a `bitarray` named `row`. It splits it into chunks that
    are each 127 bits wide using a function that we'll define very shortly. Then,
    it compresses each of those chunks using the previously defined `compress_chunk`,
    concatenating the results into `bytearray`, which it returns.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数接受一个名为`row`的`bitarray`。它使用我们将很快定义的函数将其分割成每个宽度为127位的块。然后，它使用先前定义的`compress_chunk`压缩这些块，将结果连接到`bytearray`中，并返回它。
- en: 'We define `split_bits` as a generator, as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`split_bits`定义为生成器，如下所示：
- en: '[PRE21]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, since we aren''t certain yet whether this will run more effectively in
    threads or processes, let''s wrap these functions in a method that runs everything
    in a provided executor:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于我们还不确定这将在线程或进程中运行得更有效，让我们将这些函数包装在一个方法中，该方法在提供的执行器中运行一切：
- en: '[PRE22]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This example barely needs explaining; it splits the incoming bits into rows
    based on the width of the image using the same `split_bits` function we have already
    defined (hooray for bottom-up design!).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子几乎不需要解释；它使用我们已定义的相同的`split_bits`函数将传入的位分割成基于图像宽度的行（为自下而上的设计欢呼！）。
- en: 'Note that this code will compress any sequence of bits, although it would bloat,
    rather than compress binary data that has frequent changes in bit values. Black
    and white images are definitely good candidates for the compression algorithm
    in question. Let''s now create a function that loads an image file using the third-party
    pillow module, converts it to bits, and compresses it. We can easily switch between
    executors using the venerable comment statement, as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此代码可以压缩任何位序列，尽管它会使具有频繁位值变化的二进制数据膨胀，而不是压缩。黑白图像无疑是所讨论压缩算法的良好候选者。现在，让我们创建一个函数，使用第三方pillow模块加载图像文件，将其转换为位，并压缩它。我们可以通过使用古老的注释语句轻松地在执行器之间切换，如下所示：
- en: '[PRE23]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `image.convert()` call changes the image to black and white (one bit) mode,
    while `getdata()` returns an iterator over those values. We pack the results into
    a `bitarray` so they transfer across the wire more quickly. When we output the
    compressed file, we first write the width and height of the image followed by
    the compressed data, which arrives as `bytearray`, which can be written directly
    to the binary file.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`image.convert()`调用将图像转换为黑白（一位）模式，而`getdata()`返回这些值的迭代器。我们将结果打包到`bitarray`中，以便它们可以更快地通过电线传输。当我们输出压缩文件时，我们首先写入图像的宽度和高度，然后是压缩数据，它作为`bytearray`到达，可以直接写入二进制文件。'
- en: Having written all this code, we are finally able to test whether thread pools
    or process pools give us better performance. I created a large (7,200 x 5,600
    pixels) black and white image and ran it through both pools. `ProcessPool` takes
    about 7.5 seconds to process the image on my system, while `ThreadPool` consistently
    takes about 9\. Thus, as we suspected, the cost of pickling bits and bytes back
    and forth between processes is eating almost all of the efficiency gains from
    running on multiple processors (though, looking at my CPU monitor, it does fully
    utilize all four cores on my machine).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 编写完所有这些代码后，我们终于能够测试线程池或进程池是否提供了更好的性能。我创建了一个大（7200 x 5600像素）的黑白图像，并通过这两个池运行它。`ProcessPool`在我的系统上处理图像大约需要7.5秒，而`ThreadPool`则始终需要大约9秒。因此，正如我们所怀疑的，在多个处理器上运行时，序列化和反序列化位和字节之间的成本几乎消耗了所有效率提升（尽管，查看我的CPU监视器，它确实完全利用了我机器上的所有四个核心）。
- en: So, it looks like compressing a single image is most effectively done in a separate
    process, but only barely, because we are passing so much data back and forth between
    the parent and subprocesses. Multiprocessing is more effective when the amount
    of data passed between processes is quite low.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，看起来压缩单个图像最有效地是在单独的进程中完成的，但只是略微，因为我们需要在父进程和子进程之间传递大量数据。当进程间传递的数据量相当低时，多进程更有效。
- en: 'So, let''s extend the app to compress all the bitmaps in a directory in parallel.
    The only thing we''ll have to pass into the subprocesses are filenames, so we
    should get a speed gain compared to using threads. Also, to be kind of crazy,
    we''ll use the existing code to compress individual images. This means we''ll
    be running `ProcessPoolExecutor` inside each subprocess to create even more subprocesses,
    as follows (I don''t recommend doing this in real life!):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们扩展这个应用程序，以并行压缩目录中的所有位图。我们唯一需要传递给子进程的是文件名，因此与使用线程相比，我们应该获得速度上的提升。此外，为了有点疯狂，我们将使用现有的代码来压缩单个图像。这意味着我们将在每个子进程中运行`ProcessPoolExecutor`以创建更多的子进程，如下所示（我不建议在实际生活中这样做！）：
- en: '[PRE24]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This code uses the `compress_image` function we defined previously, but runs
    it in a separate process for each image. It doesn't pass an executor into the
    function, so `compress_image` creates `ProcessPoolExecutor` once the new process
    has started running.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用我们之前定义的`compress_image`函数，但为每个图像在单独的进程中运行它。它没有将执行器传递到函数中，因此`compress_image`在新的进程开始运行后创建`ProcessPoolExecutor`。
- en: 'Now that we are running executors inside executors, there are four combinations
    of threads and process pools that we can be using to compress images. They each
    have quite different timing profiles, as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在执行器内部运行执行器，我们可以使用四种线程和进程池的组合来压缩图像。它们各自有不同的时间特性，如下所示：
- en: '|  | **Process pool per image** | **Thread pool per image** |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | **每图像进程池** | **每图像线程池** |'
- en: '| **Process pool per row** | 42 seconds | 53 seconds |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| **每行进程池** | 42秒 | 53秒 |'
- en: '| **Thread pool per row** | 34 seconds | 64 seconds |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| **每行线程池** | 34秒 | 64秒 |'
- en: As we might expect, using threads for each image and again using threads for
    each row is the slowest configuration, since the GIL prevents us from doing any
    work in parallel. Given that we were slightly faster when using separate processes
    for each row when we were using a single image, you may be surprised to see that
    it is faster to use a `ThreadPool` feature for rows if we are processing each
    image in a separate process. Take some time to understand why this might be.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所预期，为每个图像使用线程，然后再为每行使用线程是最慢的配置，因为全局解释器锁（GIL）阻止我们在并行中进行任何工作。鉴于我们在使用单个图像时使用单独的进程稍微快一点，你可能会惊讶地看到，如果我们为每个图像在单独的进程中处理，使用`ThreadPool`功能处理行会更快。花点时间理解为什么会这样。
- en: My machine contains only four processor cores. Each row in each image is being
    processed in a separate pool, which means that all those rows are competing for
    processing power. When there is only one image, we get a (very modest) speedup
    by running each row in parallel. However, when we increase the number of images
    being processed at once, the cost of passing all that row data into and out of
    a subprocess is actively stealing processing time from each of the other images.
    So, if we can process each image on a separate processor, where the only thing
    that has to get pickled into the subprocess pipe is a couple of filenames, we
    get a solid speedup.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我的机器只有四个处理器核心。每个图像的每一行都在一个单独的池中处理，这意味着所有这些行都在争夺处理能力。当只有一个图像时，通过并行运行每一行，我们可以获得（非常适度的）加速。然而，当我们同时处理多个图像时，将所有这些行数据传递到和从子进程中的成本会积极地从每个其他图像中窃取处理时间。所以，如果我们可以在单独的处理器上处理每个图像，唯一需要序列化到子进程管道中的是几个文件名，我们就可以获得稳定的加速。
- en: Thus, we see that different workloads require different concurrency paradigms.
    Even if we are just using futures, we have to make informed decisions about what
    kind of executor to use.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们看到不同的工作负载需要不同的并发范式。即使我们只是使用未来（futures），我们也必须就使用哪种执行器做出明智的决定。
- en: Also note that for typically-sized images, the program runs quickly enough that
    it really doesn't matter which concurrency structures we use. In fact, even if
    we didn't use any concurrency at all, we'd probably end up with about the same
    user experience.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，对于通常大小的图像，程序运行得足够快，以至于我们使用哪种并发结构实际上并不重要。事实上，即使我们根本不使用任何并发，我们可能也会得到几乎相同的使用体验。
- en: 'This problem could also have been solved using the threading and/or multiprocessing
    modules directly, though there would have been quite a bit more boilerplate code
    to write. You may be wondering whether or not AsyncIO would be useful here. The
    answer is: *probably not*. Most operating systems don''t have a good way to perform
    non-blocking reads from the filesystem, so the library ends up wrapping all the
    calls in futures anyway.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此问题也可以直接使用线程和/或进程池模块来解决，尽管需要编写相当多的模板代码。你可能想知道是否AsyncIO在这里会有用。答案是：*可能没有*。大多数操作系统都没有很好的方法从文件系统中执行非阻塞读取，因此库最终仍然会将所有调用包装在未来的包装中。
- en: 'For completeness, here''s the code that I used to decompress the **run-length
    encoding** (**RLE**) images to confirm that the algorithm was working correctly
    (indeed, it wasn''t until I fixed bugs in both compression and decompression,
    and I''m still not sure if it is perfect–I should have used test-driven development!):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，以下是我在解压缩**运行长度编码**（**RLE**）图像时使用的代码，以确认算法是否正确工作（实际上，直到我修复了压缩和解压缩中的错误，我仍然不确定它是否完美——我应该使用测试驱动开发！）：
- en: '[PRE25]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This code is fairly straightforward. Each run is encoded in a single byte. It
    uses some bitwise math to extract the color of the pixel and the length of the
    run. Then, it sets each pixel from that run in the image, incrementing the row
    and column of the next pixel to analyze at appropriate intervals.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码相当直接。每个运行被编码在一个单独的字节中。它使用一些位运算来提取像素的颜色和运行的长度。然后，它将图像中该运行中的每个像素设置好，并在适当的间隔增加下一个要分析的像素的行和列。
- en: Exercises
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: We've covered several different concurrency paradigms in this chapter and still
    don't have a clear idea of when each one is useful. As we saw in the case study,
    it is often a good idea to prototype a few different strategies before committing
    to one.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中介绍了几种不同的并发范式，但仍不清楚何时使用哪一个。正如我们在案例研究中看到的，在做出承诺之前原型化几个不同的策略通常是一个好主意。
- en: Concurrency in Python 3 is a huge topic and an entire book of this size could
    not cover everything there is to know about it. As your first exercise, I encourage
    you to search the web to discover what are considered to be the latest Python
    concurrency best practices.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3中的并发是一个巨大的主题，一本这么大的书也无法涵盖关于它的所有知识。作为你的第一个练习，我鼓励你上网搜索，了解被认为是最新的Python并发最佳实践。
- en: If you have used threads in a recent application, take a look at the code and
    see how you can make it more readable and less bug-prone by using futures. Compare
    thread and multiprocessing futures to see whether you can gain anything by using
    multiple CPUs.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最近在应用程序中使用了线程，请查看代码，看看如何通过使用未来（futures）使其更易于阅读且更少出错。比较线程和进程池中的未来（futures），看看是否可以通过使用多个CPU获得任何好处。
- en: Try implementing an AsyncIO service for some basic HTTP requests. If you can
    get it to the point that a web browser can render a simple GET request, you'll
    have a good understanding of AsyncIO network transports and protocols.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试实现一个用于基本HTTP请求的AsyncIO服务。如果您能将其做到网页浏览器可以渲染简单GET请求的程度，您就会对AsyncIO网络传输和协议有一个很好的理解。
- en: Make sure you understand the race conditions that happen in threads when you
    access shared data. Try to come up with a program that uses multiple threads to
    set shared values in such a way that the data deliberately becomes corrupt or
    invalid.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您理解在访问共享数据时线程中发生的竞态条件。尝试编写一个使用多个线程以这种方式设置共享值的程序，使得数据故意变得损坏或无效。
- en: Remember the link collector we covered for the case study in [Chapter 6](6a121a79-7716-4a8f-94ab-f96781e82d25.xhtml),
    *Python Data Structures*? Can you make it run faster by making requests in parallel?
    Is it better to use raw threads, futures, or AsyncIO for this?
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在[第6章](6a121a79-7716-4a8f-94ab-f96781e82d25.xhtml)“Python 数据结构”中讨论的链接收集器吗？您能否通过并行请求使其运行更快？对于这个任务，使用原始线程、未来对象还是AsyncIO更好？
- en: Try writing the run-length encoding example using threads or multiprocessing
    directly. Do you get any speed gains? Is the code easier or harder to reason about?
    Is there any way to speed up the decompression script by using concurrency or
    parallelism?
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试直接使用线程或多进程编写运行长度编码的示例。您是否获得了速度提升？代码是否更容易或更难理解？有没有办法通过并发或并行化来加快解压缩脚本的执行速度？
- en: Summary
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter ends our exploration of object-oriented programming with a topic
    that isn't very object-oriented. Concurrency is a difficult problem, and we've
    only scratched the surface. While the underlying OS abstractions of processes
    and threads do not provide an API that is remotely object-oriented, Python offers
    some really good object-oriented abstractions around them. The threading and multiprocessing
    packages both provide an object-oriented interface to the underlying mechanics.
    Futures are able to encapsulate a lot of the messy details into a single object.
    AsyncIO uses coroutine objects to make our code read as though it runs synchronously,
    while hiding ugly and complicated implementation details behind a very simple
    loop abstraction.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以一个不太面向对象的题目结束了我们对面向对象编程的探索。并发是一个难题，我们只是触及了表面。虽然底层操作系统的进程和线程抽象并没有提供一个接近面向对象的API，但Python围绕它们提供了一些真正优秀的面向对象抽象。线程和多进程包都提供了对底层机制的面向对象接口。未来对象能够将许多杂乱的细节封装成一个单一的对象。AsyncIO使用协程对象使我们的代码看起来像同步运行，同时在非常简单的循环抽象后面隐藏了丑陋和复杂的实现细节。
- en: Thank you for reading *Python 3 Object-Oriented Programming*, *Third Edition*.
    I hope you've enjoyed the ride and are eager to start implementing object-oriented
    software in all your future projects!
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您阅读《Python 3 面向对象编程》，第三版。我希望您享受了这次旅程，并渴望在您未来的所有项目中开始实现面向对象软件！
