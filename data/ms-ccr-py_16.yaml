- en: Designing Lock-Based and Mutex-Free Concurrent Data Structures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计基于锁和无互斥锁的并发数据结构
- en: 'In this chapter, we will analyze the detailed process of designing and implementing
    two common types of data structure in concurrent programming: lock-based and mutex-free.
    The principal differences between the two data structures, as well as their respective
    usages in concurrent programming, will be discussed. Throughout the chapter, an
    analysis of the trade-off between the accuracy and speed of concurrent programs
    is also supplied. Through this analysis, readers will be able to apply the same
    trade-off analysis for their own concurrent applications.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将分析设计和实现并发编程中两种常见类型的数据结构的详细过程：基于锁和无互斥锁。将讨论这两种数据结构之间的主要区别，以及它们在并发编程中的使用。在整个章节中，还提供了并发程序准确性和速度之间的权衡分析。通过这种分析，读者将能够为自己的并发应用程序应用相同的权衡分析。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Common problems with lock-based data structures, and how to address them
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于锁数据结构的常见问题，以及如何解决这些问题
- en: A detailed analysis of how to implement a lock-based data structure
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何实现基于锁的数据结构的详细分析
- en: The idea behind mutex-free data structures, along with their advantages and
    disadvantages, as compared to lock-based data structures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无互斥锁数据结构的理念，以及与基于锁数据结构相比的优缺点
- en: A detailed analysis of how to implement a mutex-free data structure
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何实现无互斥锁数据结构的详细分析
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following is a list of prerequisites for this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章的先决条件列表：
- en: Ensure that you have Python 3 installed on your computer
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您的计算机上已安装Python 3
- en: Download the GitHub repository at [https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)上下载GitHub存储库
- en: Throughout this chapter, we will be working with the subfolder named `Chapter16`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用名为`Chapter16`的子文件夹进行工作
- en: Check out the following video to see the Code in Action: [http://bit.ly/2QhT3MS](http://bit.ly/2QhT3MS)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码实际运行情况：[http://bit.ly/2QhT3MS](http://bit.ly/2QhT3MS)
- en: Lock-based concurrent data structures in Python
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中基于锁的并发数据结构
- en: In previous chapters that covered the usage of locks, you learned that locks
    don't lock anything; an insubstantial locking mechanism implemented on a data
    structure does not actually prevent external programs from accessing the data
    structure at the same time, by simply bypassing the lock imposed. One solution
    to this problem is to embed the lock into the data structure, so that it is impossible
    for the lock to be ignored by external entities.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了锁的使用，您了解到锁并不会锁住任何东西；在数据结构上实现的不牢固的锁定机制实际上并不能阻止外部程序同时访问数据结构，因为它们可以简单地绕过所施加的锁。解决这个问题的一个方法是将锁嵌入到数据结构中，这样外部实体就无法忽略锁。
- en: In the first section of this chapter, we will consider the theories behind the
    preceding specific use of locks and lock-based data structures. Specifically,
    we will analyze the process of designing a concurrent counter that can be safely
    executed by different threads, using locks (or mutex) as the synchronization mechanism.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一部分中，我们将考虑锁和基于锁的数据结构的特定使用背后的理论。具体来说，我们将分析设计一个可以由不同线程安全执行的并发计数器的过程，使用锁（或互斥锁）作为同步机制。
- en: LocklessCounter and race conditions
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LocklessCounter和竞争条件
- en: First, let's simulate the problem encountered with a naive, lockless implementation
    of a counter class in a concurrent program. If you have already downloaded the
    code for this book from the GitHub page, go ahead and navigate to the `Chapter16`
    folder.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们模拟在并发程序中使用一个天真的、无锁实现的计数器类遇到的问题。如果您已经从GitHub页面下载了本书的代码，请转到`Chapter16`文件夹。
- en: 'Let us take a look at the `Chapter16/example1.py` file—specifically, the implementation
    of the `LocklessCounter` class:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下`Chapter16/example1.py`文件，特别是`LocklessCounter`类的实现：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is a simple counter that has an attribute called `value`, which contains
    the current value of the counter, assigned with `0` when the counter instance
    is first initialized. The `increment()` method of the class takes in an argument, `x`,
    and increases the current value of the calling `LocklessCounter` object by `x`.
    Notice that we are creating a small delay inside the `increment()` function, between
    the process of computing the new value of the counter and the process of assigning
    that new value to the counter object. The class also has a method called `get_value()`,
    which returns the current value of the calling counter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的计数器，具有名为`value`的属性，其中包含计数器的当前值，在计数器实例首次初始化时赋值为`0`。该类的`increment()`方法接受一个参数`x`，并将调用`LocklessCounter`对象的当前值增加`x`。请注意，在`increment()`函数内部我们创建了一个小延迟，用于计算计数器的新值和将该新值分配给计数器对象的过程之间。该类还有一个名为`get_value()`的方法，返回调用计数器的当前值。
- en: 'It is quite obvious why this implementation of the `LocklessCounter` class
    can create a race condition in a concurrent program: while a thread is in the
    middle of incrementing a shared counter, another thread also might access the
    counter to execute the `increment()` method, and the change to the counter value
    made by the first thread might be overwritten by the one made by the second thread.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这种`LocklessCounter`类的实现在并发程序中可能会导致竞争条件：当一个线程正在增加共享计数器时，另一个线程也可能访问计数器来执行`increment()`方法，并且第一个线程对计数器值的更改可能会被第二个线程所覆盖。
- en: 'As a refresher, the following diagram shows how a race condition can occur
    in situations where multiple processes or threads access and mutate a shared resource
    at the same time:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为复习，以下图表显示了在多个进程或线程同时访问和改变共享资源的情况下竞争条件如何发生：
- en: '![](assets/c9c5bd97-d645-4f09-ac3e-f925f29357b6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c9c5bd97-d645-4f09-ac3e-f925f29357b6.png)'
- en: Diagram of a race condition
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争条件的图示
- en: 'To simulate this race condition, in our main program we are including a total
    of three threads, to increment a shared counter by 300 times:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这种竞争条件，在我们的主程序中，我们包括了共计三个线程，将共享计数器增加300次：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `concurrent.futures` module offers us an easy and high-level way to schedule
    a task through a pool of threads. Specifically, after initializing a shared counter
    object, we declare the variable `executor` as a pool of three threads (use a context
    manager), and that executor calls the `increment()` method on the shared counter
    300 times, each time incrementing the value of the counter by `1`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`concurrent.futures`模块为我们提供了一种简单且高级的方式，通过线程池调度任务。具体来说，在初始化共享计数器对象后，我们将变量`executor`声明为一个包含三个线程的线程池（使用上下文管理器），并且该执行器调用共享计数器的`increment()`方法300次，每次将计数器的值增加`1`。'
- en: 'These tasks are to be executed among the three threads in the pool, using the
    `map()` method of the `ThreadPoolExecutor` class. At the end of the program, we
    simply print out the final value of the counter object. The following code shows
    my own output after running the script:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务将在线程池中的三个线程之间执行，使用`ThreadPoolExecutor`类的`map()`方法。在程序结束时，我们只需打印出计数器对象的最终值。运行脚本后，以下代码显示了我的输出：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: While it is possible to obtain a different value for the counter when executing
    the script on your own system, it is extremely unlikely that the final value of
    the counter will actually be 300, which is the correct value. Additionally, if
    you were to run the script over and over again, it would be possible to obtain
    different values for the counter, illustrating the non-deterministic nature of
    the program. Again, as some threads were overwriting the changes made by other
    threads, some increments got lost during the execution, resulting in the fact
    that the counter was only successfully incremented `101` times, in this case.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在您自己的系统上执行脚本可能会获得计数器的不同值，但计数器的最终值实际上是300，这是正确的值，这种情况极不可能发生。此外，如果您一遍又一遍地运行脚本，可能会获得计数器的不同值，说明程序的非确定性。同样，由于一些线程覆盖了其他线程所做的更改，一些增量在执行过程中丢失了，导致计数器在这种情况下只成功增加了`101`次。
- en: Embedding locks in the data structure of the counter
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在计数器的数据结构中嵌入锁
- en: 'The goal of a good lock-based concurrent data structure is to have its locks
    internally implemented within its class attributes and methods, so that external
    functions and programs cannot bypass those locks and access a shared concurrent
    object simultaneously. For our counter data structure, we will be adding an additional
    attribute for the class, which will hold the `lock` object that corresponds to
    the value of the counter. Consider the following new implementation of the data
    structure in the `Chapter16/example2.py` file:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的基于锁的并发数据结构的目标是在其类属性和方法内部实现其锁，以便外部函数和程序无法绕过这些锁并同时访问共享的并发对象。对于我们的计数器数据结构，我们将为该类添加一个额外的属性，该属性将保存与计数器的值对应的`lock`对象。考虑在`Chapter16/example2.py`文件中的数据结构的以下新实现：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this implementation of our counter data structure, a `lock` object is also
    initialized as an attribute of a `LockedCounter` instance, when that instance
    is initialized. Additionally, any time the value of the counter is accessed by
    a thread, whether for reading (the `get_value()` method) or updating (the `increment()`
    method), that `lock` attribute has to be acquired, to ensure that no other thread
    is also accessing it. This is done by using a context manager with the `lock`
    attribute.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的计数器数据结构实现中，还初始化了一个`lock`对象作为`LockedCounter`实例的属性，当初始化该实例时。此外，每当线程访问计数器的值时，无论是读取（`get_value()`方法）还是更新（`increment()`方法），都必须获取该`lock`属性，以确保没有其他线程也在访问它。这是通过使用`lock`属性的上下文管理器来实现的。
- en: 'Theoretically, this implementation should solve the problem of the race condition
    for us. In our main program, we are implementing the same thread pool that was
    used in the previous example. A shared counter will be created, and it will be
    incremented 300 times (each time by one unit), across three different threads:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，这种实现应该为我们解决竞争条件的问题。在我们的主程序中，我们正在实现与上一个示例中使用的相同的线程池。将创建一个共享计数器，并且它将在三个不同的线程中被增加300次（每次增加一个单位）：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Run the script, and the output produced by the program should be similar to
    the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，程序产生的输出应与以下类似：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see, the problem of the race condition has been addressed successfully:
    the final value of the counter is `300`, which corresponds perfectly to the number
    of increments that were executed. Furthermore, no matter how many times the program
    is run again, the value of the counter will always remain `300`. What we currently
    have is a working, correct data structure for concurrent counters.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，竞争条件的问题已经成功解决：计数器的最终值为`300`，完全对应于执行的增量数量。此外，无论程序运行多少次，计数器的值始终保持为`300`。我们目前拥有的是一个可并发计数器的工作正确的数据结构。
- en: The concept of scalability
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展性的概念
- en: One aspect of programming that is essential to the application of concurrency
    is **scalability**. By scalability, we mean the changes in performance when the
    number of tasks to be processed by the program increases. Andre B. Bondi, founder
    and president of Software Performance and Scalability Consulting, LLC, defines
    the term scalability as <q>*"the capability of a system, network, or process to
    handle a growing amount of work, or its potential to be enlarged to accommodate
    that growth."*</q>
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 编程中一个重要的方面是**可扩展性**。可扩展性指的是当程序要处理的任务数量增加时，性能的变化。Software Performance and Scalability
    Consulting, LLC的创始人兼总裁Andre B. Bondi将可扩展性定义为<q>*“系统、网络或进程处理不断增长的工作量的能力，或者其扩大以适应这种增长的潜力。”*</q>
- en: In concurrent programming, scalability is an important concept that always needs
    to be taken into account; the amount of work that grows in concurrent programming
    is typically the number of tasks to be executed, as well as the number of processes
    and threads active to execute those tasks. For example, the designing, implementing,
    and testing phases of a concurrent application usually involve fairly small amounts
    of work, to facilitate efficient and fast development. This means that a typical
    concurrent application will handle significantly more work in real-life situations
    than it did during the development stage. This is why an analysis of scalability
    is crucial in well-designed concurrent applications.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发编程中，可伸缩性是一个重要的概念，总是需要考虑；在并发编程中增长的工作量通常是要执行的任务数量，以及执行这些任务的活动进程和线程的数量。例如，并发应用程序的设计、实现和测试阶段通常涉及相当少量的工作，以促进高效和快速的开发。这意味着典型的并发应用程序在实际情况下将处理比在开发阶段更多的工作。这就是为什么可伸缩性分析在设计良好的并发应用程序中至关重要。
- en: Since the execution of a process or thread is independent of the process execution
    of another, as long as the amount of work a single process/thread is responsible
    for remains the same, we would like changes in the number of processes/threads
    to not affect the performance of the general program. This characteristic is called
    **perfect scalability**, and is a desirable characteristic for a concurrent program;
    if the amount of work for a given perfectly scalable concurrent program increases,
    the program can simply create more active processes or threads, in order to absorb
    the increased amount of work. Its performance can then stay stable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于进程或线程的执行是独立于另一个进程的执行的，只要单个进程/线程负责的工作量保持不变，我们希望进程/线程数量的变化不会影响程序的性能。这种特性称为**完美的可伸缩性**，是并发程序的理想特性；如果给定的完全可伸缩的并发程序的工作量增加，程序可以简单地创建更多的活动进程或线程，以吸收增加的工作量。其性能可以保持稳定。
- en: However, perfect scalability is virtually impossible to achieve most of the
    time, due to the overhead in creating threads and processes. That being said,
    if the performance of a concurrent program does not considerably worsen as the
    number of active processes or threads increases, then we can accept the scalability.
    The term **considerably worsen** is highly dependent on the types of task that
    the concurrent program is responsible for executing, as well as how large a decrease
    in program performance is permitted.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于创建线程和进程的开销，完美的可伸缩性在大多数情况下几乎是不可能实现的。也就是说，如果并发程序的性能随着活动进程或线程数量的增加而没有明显恶化，那么我们可以接受可伸缩性。**明显恶化**这个术语在很大程度上取决于并发程序负责执行的任务类型，以及允许程序性能下降的程度有多大。
- en: In this kind of analysis, we will consider a two-dimensional graph, representing
    the scalability of a given concurrent program. The *x *axis denotes the number
    of active threads or processes (again, each is responsible for executing a fixed
    amount of work throughout the program); the *y *axis denotes the speed of the
    program, with different numbers of active threads or processes. The graph under
    consideration will have a generally increasing trend; the more processes/threads
    the program has, the more time it will (most likely) take for the program to execute.
    Perfect scalability, on the other hand, will translate to a horizontal line, as
    no additional time is needed when the number of threads/processes increases.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种分析中，我们将考虑一个二维图表，表示给定并发程序的可伸缩性。*x*轴表示活动线程或进程的数量（每个线程或进程负责在整个程序中执行固定数量的工作）；*y*轴表示程序的速度，具有不同数量的活动线程或进程。所考虑的图表将具有一般上升的趋势；程序拥有的进程/线程越多，程序执行所需的时间（很可能）就越长。另一方面，完美的可伸缩性将转化为水平线，因为增加线程/进程数量时不需要额外的时间。
- en: 'The following diagram is an example of such a graph, for scalability analysis:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是可伸缩性分析的示例：
- en: '![](assets/719e2141-ce98-4fb4-9b03-912088d34e31.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/719e2141-ce98-4fb4-9b03-912088d34e31.png)'
- en: Example of scalability analysis (Source: stackoverflow.com/questions/10660990/c-sharp-server-scalability-issue-on-linux)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩性分析示例（来源：stackoverflow.com/questions/10660990/c-sharp-server-scalability-issue-on-linux）
- en: In the preceding graph, the *x *axis indicates the number of executing threads/processes,
    and the *y *axis indicates the running time (in seconds, in this case). The different
    graphs indicate the scalability of specific setups (the operating system combined
    with multiple cores).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，*x*轴表示执行线程/进程的数量，*y*轴表示运行时间（在这种情况下为秒）。不同的图表表示特定设置的可伸缩性（操作系统与多个核心的组合）。
- en: The steeper the slope of a graph is, the worse the corresponding concurrent
    model scales with an increasing number of threads/processes. For example, a horizontal
    line (the dark blue and lowest graph in this case) signifies perfect scalability,
    while the yellow (upper most) graph indicates an undesirable scalability.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图表的斜率越陡，相应的并发模型随着线程/进程数量的增加而扩展得越差。例如，水平线（在这种情况下为深蓝色和最低的图表）表示完美的可伸缩性，而黄色（最上面的）图表表示不良的可伸缩性。
- en: Analysis of the scalability of the counter data structure
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对计数器数据结构的可伸缩性分析
- en: Now, let's consider the scalability of our current counter data structure—specifically,
    with changing numbers of active threads. We had three threads increment a shared
    counter for a total of 300 times; so, in our scalability analysis, we will have
    each of the active threads increment a shared counter 100 times, while changing
    the number of active threads in our program. Following the aforementioned specification
    of scalability, we will look at how the performance (speed) of the program that
    uses the counter data structure changes when the number of threads increases.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑我们当前计数器数据结构的可扩展性——具体来说，是随着活动线程数量的变化。我们有三个线程为共享计数器增加了总共300次；因此，在我们的可扩展性分析中，我们将使每个活动线程为共享计数器增加100次，同时改变程序中的活动线程数量。根据前述的可扩展性规范，我们将看看在线程数量增加时使用计数器数据结构的程序的性能（速度）如何变化。
- en: 'Consider the `Chapter16/example3.py` file, as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑`Chapter16/example3.py`文件，如下所示：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding script, we are still using the same implementation of the `LockedCounter`
    class that we used in the previous example. In our main program, we are testing
    this class against various numbers of active threads; specifically, we are iterating
    over a `for` loop, to have the number of active threads go from 1 to 10\. In each
    iteration, we initialize a shared counter and create a pool of threads to process
    an appropriate number of tasks—in this case, incrementing the shared counter 100
    times for each thread.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的脚本中，我们仍然使用了在上一个示例中使用的`LockedCounter`类的相同实现。在我们的主程序中，我们正在测试这个类针对各种数量的活动线程；具体来说，我们正在迭代一个`for`循环，使活动线程的数量从1增加到10。在每次迭代中，我们初始化一个共享计数器，并创建一个线程池来处理适当数量的任务——在这种情况下，为每个线程增加共享计数器100次。
- en: We are also keeping track of the number of active threads, as well as the time
    it took for the pool of threads to finish its tasks in each iteration. This is
    our data for the scalability analysis process. We are printing this data out and
    plotting a scalability graph similar to what we saw in the preceding sample graph.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还跟踪活动线程的数量，以及线程池完成任务所花费的时间。这是我们进行可扩展性分析的数据。我们将打印出这些数据，并绘制一个类似于前面示例图中的可扩展性图表。
- en: 'The following code shows my output from running the script:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了我运行脚本的输出：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Additionally, the scalability graph that I obtained is shown as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我得到的可扩展性图如下所示：
- en: '![](assets/e4a205f0-bac9-43e2-9c13-a4599f1d02a5.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e4a205f0-bac9-43e2-9c13-a4599f1d02a5.png)'
- en: Scalability of lock-based counter data structures
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 基于锁的计数器数据结构的可扩展性
- en: 'Even if your own output varies in the specific duration of each iteration,
    the scalability trend should be relatively the same; in other words, your scalability
    graph should have the same slope as the preceding graph. As you can see from the
    kinds of output that we have, even though the counter in each iteration had the
    correct value, the current scalability of our counter data structure is highly
    undesirable: as more threads are added to the program to execute more tasks, the
    performance of the program decreases, almost linearly. Recall that the desired
    perfect scalability requires the performance to remain stable across different
    numbers of threads/processes. Our counter data structure increases the execution
    time of the program that we have by an amount that is proportional to the increase
    in the number of active threads.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您自己的输出在每次迭代的具体持续时间上有所不同，可扩展性趋势应该是相对相同的；换句话说，您的可扩展性图应该与前面的图表具有相同的斜率。从我们所拥有的输出类型中可以看出，尽管每次迭代中计数器的值都是正确的，但我们当前的计数器数据结构的可扩展性非常不理想：随着程序添加更多线程来执行更多任务，程序的性能几乎是线性下降的。请记住，理想的完美可扩展性要求性能在不同数量的线程/进程之间保持稳定。我们的计数器数据结构通过与活动线程数量的增加成比例地增加程序的执行时间。
- en: 'Intuitively, this constraint in scalability results from our locking mechanism:
    since only one thread can access and increment the shared counter at any given
    time, the more increments the program has to execute, the longer it will take
    to finish all increment tasks. Of the biggest disadvantages to using locks as
    a synchronization mechanism, this is the second: locks can execute a concurrent
    program (again, the first disadvantage is the fact that locks don''t actually
    lock anything).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，这种可扩展性的限制是由我们的锁定机制造成的：由于在任何给定时间只有一个线程可以访问和增加共享计数器，程序需要执行的增量越多，完成所有增量任务所需的时间就越长。使用锁作为同步机制的最大缺点之一是：锁可以执行并发程序（再次强调，第一个缺点是锁实际上并没有锁定任何东西）。
- en: Approximate counters as a solution for scalability
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似计数器作为可扩展性的解决方案
- en: 'Given the complexity of designing and implementing a correct, yet fast, lock-based
    concurrent data structure, developing efficiently scalable locking mechanisms
    is a popular topic of research in computer science, and many approaches to solving
    the problem that we are facing have been proposed. In this section, we will discuss
    one of them: **approximate counters**.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到设计和实现正确但快速的基于锁的并发数据结构的复杂性，开发高效可扩展的锁定机制是计算机科学研究中的热门话题，提出了许多解决我们面临问题的方法。在本节中，我们将讨论其中之一：**近似计数器**。
- en: The idea behind approximate counters
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似计数器背后的思想
- en: 'Let''s think back to our current program and the reason why the locks are preventing
    us from achieving good performance in terms of speed: all of the active threads
    in our program interact with the same shared counter, which can only interact
    with one thread at a time. The solution to this problem is to isolate the interactions
    with a counter of separate threads. Specifically, the value of the counter that
    we are keeping track of will not be represented by only a single, shared counter
    object anymore; instead, we will use many **local counters**, one per thread/process,
    in addition to the shared **global counter** that we originally had.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们当前的程序以及锁阻止我们在速度方面获得良好性能的原因：我们程序中的所有活动线程都与相同的共享计数器交互，这只能一次与一个线程交互。解决这个问题的方法是隔离与单独线程计数器的交互。具体来说，我们跟踪的计数器的值将不再仅由单个共享计数器对象表示；相反，我们将使用许多**本地计数器**，每个线程/进程一个，以及我们最初拥有的共享**全局计数器**。
- en: The basic idea behind this approach is to distribute the work (incrementing
    the shared global counter) across other low-level counters. When an active thread
    executes and wants to increment the global counter, first it has to increment
    its corresponding local counter. Interacting with individual local counters, unlike
    doing it with a single, shared counter, is highly scalable, as only one thread
    accesses and updates each local counter; in other words, there is no contention
    between different threads in interacting with the individual local counters.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法背后的基本思想是将工作（递增共享全局计数器）分布到其他低级计数器中。当一个活动线程执行并想要递增全局计数器时，首先它必须递增其对应的本地计数器。与单个共享计数器进行交互不同，与各个本地计数器进行交互具有高度可扩展性，因为只有一个线程访问和更新每个本地计数器；换句话说，不同线程之间在与各个本地计数器交互时不会发生争用。
- en: As each thread interacts with its corresponding local counter, the local counters
    have to interact with the global counter. Specifically, each local counter will
    periodically acquire the lock for the global counter and increment it with respect
    to its current value; for example, if a local counter holding the value of six
    wants to increment the global counter, it will do it by six units, and set its
    own value back to zero. This is because all increments reported from the local
    counters are relative to the value of the global counter, meaning that, if a local
    counter holds the value of *x*, the global counter should increment its value
    by *x*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程与其对应的本地计数器交互时，本地计数器必须与全局计数器交互。具体来说，每个本地计数器将定期获取全局计数器的锁，并根据其当前值递增它；例如，如果一个值为六的本地计数器想要递增全局计数器，它将以六个单位递增，并将自己的值设为零。这是因为从本地计数器报告的所有递增都是相对于全局计数器的值的，这意味着如果一个本地计数器持有值*x*，全局计数器应该将其值递增*x*。
- en: 'You can think of this design as a simple network, with the global counter being
    at the center node, and each local counter being a rear node. Each rear node interacts
    with the center node by sending its value to the center node and consequently
    resetting its value back to zero. The following diagram further illustrates this
    design:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将这种设计看作是一个简单的网络，全局计数器位于中心节点，每个本地计数器都是一个后端节点。每个后端节点通过将其值发送到中心节点与中心节点交互，随后将其值重置为零。以下图示进一步说明了这种设计：
- en: '![](assets/abc0fe6d-7219-4f13-8299-0dad44854165.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/abc0fe6d-7219-4f13-8299-0dad44854165.png)'
- en: Diagram of four-thread approximate counters
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 四线程近似计数器的图示
- en: As discussed previously, if all of the active threads were to interact with
    the same lock-based counter, no additional speed could be gained from making the
    program concurrent, since the execution between separate threads cannot be overlapped.
    Now, with one separate counter object for each thread, the threads can update
    their corresponding local counters independently and simultaneously, creating
    overlaps that will result in better performance in speed for our program, making
    the program more scalable.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，如果所有活动线程都与相同的基于锁的计数器交互，那么无法从使程序并发化中获得额外的速度，因为不同线程之间的执行无法重叠。现在，对于每个线程有一个单独的计数器对象，线程可以独立和同时更新其对应的本地计数器，从而创建重叠，这将导致程序的速度性能更好，使程序更具可扩展性。
- en: The name of the technique, **approximate counters**, comes from the fact that
    the value of the global counter is simply an approximation of the correct value.
    Specifically, the value of the global counter is calculated solely via the values
    of the local counters, and it becomes more accurate each time the global counter
    is incremented by one of the local counters.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**近似计数器**这个技术的名称来源于全局计数器的值仅仅是正确值的近似。具体来说，全局计数器的值仅通过本地计数器的值计算，每次全局计数器被本地计数器之一递增时，它就变得更加准确。'
- en: There is, however, a specification in this design that deserves great consideration.
    How often should the local counters interact with the global counter and update
    its value? Surely it cannot be at the rate of every increment (incrementing the
    global counter every time a local counter is incremented), as that would be equivalent
    to using one shared lock, with even more over overhead (from the local counters).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种设计中有一个值得深思的规范。本地计数器应该多久与全局计数器交互并更新其值？当然不能是每次递增的速率（每次递增本地计数器时递增全局计数器），因为那将等同于使用一个共享锁，甚至有更多的开销（来自本地计数器）。
- en: A quantity called **threshold S** is used to denote the frequency in question;
    specifically, threshold S is defined as the upper boundary of the value of a local
    counter. So, if a local counter is incremented such that its value is greater
    than threshold S, it should update the global counter and reset its value to zero.
    The smaller threshold S is, the more frequently the local counters will update
    the global counter, and the less scalable our program will be, but the value of
    the global counter will be more up-to-date. Conversely, the larger threshold S
    is, the less frequently the value of the global counter will be updated, but the
    better the performance of our program will be.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值S是用来表示所讨论的频率的数量；具体来说，阈值S被定义为本地计数器值的上限。因此，如果本地计数器被递增，使其值大于阈值S，它应该更新全局计数器并将其值重置为零。阈值S越小，本地计数器更新全局计数器的频率就越高，我们的程序的可伸缩性就越低，但全局计数器的值将更加及时。相反，阈值S越大，全局计数器的值更新频率就越低，但程序的性能就会更好。
- en: There is, therefore, a trade-off between the accuracy of an approximate counter
    object and the scalability of a concurrent program using the data structure. Similar
    to other common trade-offs in computer science and programming, only through personal
    experimentation and testing can one determine the optimal threshold S for one's
    approximate counter data structure. In the next section, when we implement our
    own design for an approximate counter data structure, we will arbitrarily set
    the value of threshold S to 10.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，近似计数对象的准确性和使用该数据结构的并发程序的可伸缩性之间存在权衡。与计算机科学和编程中的其他常见权衡类似，只有通过个人实验和测试，才能确定适合自己的近似计数数据结构的最佳阈值S。在下一节中，当我们为近似计数数据结构实现我们自己的设计时，我们将任意将阈值S的值设置为10。
- en: Implementing approximate counters in Python
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中实现近似计数器
- en: 'With the concept of approximate counters in mind, let''s try to implement the
    data structure in Python, building on our previous design for the lock-based counter.
    Consider the following `Chapter16/example4.py` file—specifically, the `LockedCounter`
    class and the `ApproximateCounter` class:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑近似计数器的概念时，让我们尝试在Python中实现这个数据结构，建立在我们之前基于锁的计数器的设计之上。考虑以下`Chapter16/example4.py`文件，特别是`LockedCounter`类和`ApproximateCounter`类：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: While the `LockedCounter` class remains the same as in our previous example
    (this class will be used to implement our global counter objects), the `ApproximateCounter`
    class, which contains the implementation of the approximate counter logic that
    we discussed previously, is of interest. A newly initialized `ApproximateCounter`
    object will be given a starting value of `0`, and it will also have a lock, as
    it is also a lock-based data structure. The important attributes of an `ApproximateCounter`
    object are the global counter that it needs to report to and the threshold that
    specifies the rate at which it reports to its corresponding global counter. As
    mentioned previously, here, we are simply choosing `10` as an arbitrary value
    for the threshold.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`LockedCounter`类与之前的示例中保持不变（该类将用于实现我们的全局计数器对象），但`ApproximateCounter`类却很有意思，它包含了我们之前讨论的近似计数逻辑的实现。一个新初始化的`ApproximateCounter`对象将被赋予一个起始值为`0`，它也将有一个锁，因为它也是一个基于锁的数据结构。`ApproximateCounter`对象的重要属性是它需要报告给的全局计数器和指定它报告给相应全局计数器的速率的阈值。如前所述，这里我们只是随意选择`10`作为阈值的值。
- en: 'In the `increment()` method of the `ApproximateCounter` class, we can also
    see the same increment logic: the method takes in a parameter named `x` and increments
    the value of the counter by `x` while holding the lock of the calling approximate
    counter object. Additionally, the method also has to check whether the newly incremented
    value of the counter is past its threshold; if so, it will increment the value
    of its global counter by an amount that is equal to the current value of the local
    counter, and that value of the local counter will be set back to `0`. The `get_value()`
    method that is used to return the current value of the counter in this class is
    the same as what we saw previously.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ApproximateCounter`类的`increment()`方法中，我们还可以看到相同的递增逻辑：该方法接受一个名为`x`的参数，并在保持调用近似计数器对象的锁的情况下递增计数器的值。此外，该方法还必须检查计数器的新递增值是否超过了它的阈值；如果是，它将增加其全局计数器的值，增加的数量等于本地计数器的当前值，并将本地计数器的值设置回`0`。在这个类中用于返回计数器当前值的`get_value()`方法与我们之前看到的是一样的。
- en: 'Now, let''s test and compare the scalability of the new data structure in our
    main program. First, we will regenerate the data for the scalability of our old
    single-lock counter data structure:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在主程序中测试和比较新数据结构的可伸缩性。首先，我们将重新生成旧的单锁计数器数据结构的可伸缩性数据：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Just like in our previous example, we are using a `ThreadPoolExecutor` object
    to process tasks concurrently, in separate threads, while keeping track of the
    time it took for each iteration to finish; there is nothing surprising here. Next,
    we will generate the same data with a corresponding number of active threads in
    the iterations of the `for` loop, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在我们之前的示例中一样，我们使用`ThreadPoolExecutor`对象来并发处理任务，在单独的线程中跟踪每次迭代完成所花费的时间；这里没有什么令人惊讶的。接下来，我们将使用`for`循环的迭代中相应数量的活动线程生成相同的数据，如下所示：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's take some time to analyze the preceding code. First, we have an external
    `thread_increment()` function that takes in a counter and increments it by 1;
    this function will be used as refactored code later on, to individually increment
    our local counters.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一些时间来分析上述代码。首先，我们有一个外部的`thread_increment()`函数，它接受一个计数器并将其递增1；稍后，这个函数将被用作重构后的代码，以单独递增我们的本地计数器。
- en: Again, we will be iterating through a `for` loop to analyze the performance
    of this new data structure with a changing number of active threads. Inside each
    iteration, we first initialize a `LockedCounter` object as our global counter,
    together with a list of local counters, which are instances of the `ApproximateCounter`
    class. All of them are associated with the same global counter (which was passed
    in the initialization method), as they need to report to the same counter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将通过`for`循环来迭代分析这种新数据结构在不同数量的活动线程下的性能。在每次迭代中，我们首先初始化一个`LockedCounter`对象作为我们的全局计数器，以及一个本地计数器列表，这些本地计数器是`ApproximateCounter`类的实例。它们都与同一个全局计数器相关联（在初始化方法中传递），因为它们需要报告给同一个计数器。
- en: Next, similar to what we have been doing to schedule tasks for multiple threads,
    we are using a context manager to create a thread pool, inside of which we will
    be distributing the tasks (incrementing the local counters) via a nested `for`
    loop. The reason we are looping through another `for` loop is to simulate the
    number of tasks consistent with what we implemented in the previous example, and
    also to distribute those tasks across all of the local counters concurrently.
    We are also printing out the final value of the global counter in each iteration,
    to ensure that our new data structure is working correctly.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，类似于我们一直在为多个线程安排任务所做的，我们使用上下文管理器创建一个线程池，在其中通过嵌套的`for`循环分发任务（增加本地计数器）。我们循环另一个`for`循环是为了模拟与我们在上一个示例中实现的任务数量一致，并将这些任务同时分配到所有本地计数器上。我们还在每次迭代中打印出全局计数器的最终值，以确保我们的新数据结构正常工作。
- en: 'Finally, in our main program, we will be plotting the data points that are
    generated from the two `for` loops, to compare the scalability of the two data
    structures via their respective performances:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们的主程序中，我们将绘制从两个`for`循环生成的数据点，以比较两种数据结构的可伸缩性及其各自的性能：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Run the script, and the first output that you will receive will include the
    individual final values of the global counters in our second `for` loop, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，您将收到的第一个输出将包括我们第二个`for`循环中全局计数器的最终值，如下所示：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see, the final values that we obtained from the global counters
    are all correct, proving that our data structure is working as intended. Additionally,
    you will obtain a graph similar to the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们从全局计数器获得的最终值都是正确的，证明我们的数据结构按预期工作。此外，您将获得类似以下的图表：
- en: '![](assets/d0be6423-ae92-4f2a-96fa-b5ad1ab64ea7.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d0be6423-ae92-4f2a-96fa-b5ad1ab64ea7.png)'
- en: Scalability of single-lock counter and approximate counters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 单锁计数器和近似计数器的可伸缩性
- en: The blue line indicates the changes in speed of the single-lock counter data
    structure, while the red line indicates those of the approximate counter data
    structure. As you can see, even though the performance of the approximate counter
    does worsen somewhat as the number of threads increases (due to overheads such
    as creating individual local counters and distributing an increasing number of
    increment tasks), our new data structure is highly scalable, especially in comparison
    to our previous single-lock counter data structure.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝线表示单锁计数器数据结构速度的变化，而红线表示近似计数器数据结构的变化。正如您所看到的，即使随着线程数量的增加，近似计数器的性能略有下降（由于创建单独的本地计数器和分发增加的任务数量等开销），我们的新数据结构仍然具有很高的可伸缩性，特别是与以前的单锁计数器数据结构相比。
- en: A few considerations for approximate counter designs
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于近似计数器设计的一些考虑
- en: One thing that you may have noticed is that, even though only a single thread
    interacts with a single local counter, the data structure still has a `lock` attribute
    in its initialization. This is because it is, in fact, possible for multiple threads
    to share the same local counters. There are situations in which it is inefficient
    to create one local counter for every active thread, so the developer can have
    two or more share the same local counter instead, and individual counters can
    still report to the same global counter.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到的一件事是，即使只有一个线程与一个本地计数器交互，数据结构在初始化时仍然具有`lock`属性。这是因为实际上多个线程可以共享相同的本地计数器。有时创建每个活动线程的本地计数器是低效的，因此开发人员可以让两个或更多线程共享相同的本地计数器，而个别计数器仍然可以报告给相同的全局计数器。
- en: For example, suppose that there are 20 threads executing in a concurrent counter
    program; we can only have 10 local counters reporting to one global counter. From
    what we have seen, this setup will have a lower level of scalability than one
    with an individual local counter for each thread, but the advantage of this approach
    that it uses less memory space and avoids the overhead of creating more local
    counters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设有20个线程在并发计数器程序中执行；我们只能让10个本地计数器报告给一个全局计数器。从我们所见，这种设置的可伸缩性将低于为每个线程使用单独的本地计数器的设置，但这种方法的优势在于它使用更少的内存空间，并避免了创建更多本地计数器的开销。
- en: There is another possible variation to the way in which a program that utilizes
    approximate counters can be designed. Instead of having only one layer of local
    counters, we can also implement semi-global counters that local counters report
    to, which, in turn, report to the global counters that are one level higher than
    themselves. When using the approximate counter data structure, the developer not
    only has to find, as discussed previously, an appropriate threshold of reporting,
    but he or she also needs to optimize the number of threads associated with one
    single local counter, as well as the number of layers in our design.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 程序中使用近似计数器的方式还有另一种可能的变化。除了只有一层本地计数器之外，我们还可以实现半全局计数器，本地计数器报告给它，然后它再报告给比自己高一级的全局计数器。在使用近似计数器数据结构时，开发人员不仅需要像之前讨论的那样找到适当的报告阈值，还需要优化与一个单个本地计数器相关联的线程数量，以及我们设计中的层数。
- en: Mutex-free concurrent data structures in Python
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中无互斥锁的并发数据结构
- en: The previous subsection concluded our discussion of designing a lock-based concurrent
    data structure in Python, and the complexities involved therein. We will now move
    on to one approach to the theoretical design of mutex-free concurrent data structures.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 前一小节总结了我们在Python中设计基于锁的并发数据结构以及其中涉及的复杂性的讨论。我们现在将转向一种理论上设计无互斥锁并发数据结构的方法。
- en: The term **mutex-free** in concurrent data structures indicates the lack of
    a locking mechanism to protect the integrity of the data structure. This does
    not mean that the data structure simply disregards the protection of its data;
    instead, the data structure has to employ other synchronization mechanisms. In
    this section, we will analyze one such mechanism, known as **read-copy-update**,
    and discuss how to apply it to a Python data structure.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 并发数据结构中的“无互斥锁”一词表示缺乏保护数据结构完整性的锁定机制。这并不意味着数据结构简单地忽视了其数据的保护；相反，数据结构必须使用其他同步机制。在本节中，我们将分析一种这样的机制，称为“读-复制-更新”，并讨论如何将其应用到Python数据结构中。
- en: The impossibility of being lock-free in Python
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中无法实现无锁
- en: The opposite of a lock-based data structure is a lock-free one. Here we will
    be discussing its definition and the reason why the characteristic of being lock-free
    is actually impossible in Python, and why the closest we can get to it is being
    mutex-free.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 基于锁的数据结构的对立面是无锁数据结构。在这里，我们将讨论其定义以及为什么在Python中实际上无法实现无锁的特性，以及我们能够接近的最近的是无互斥锁。
- en: Unlike a lock-based data structure, a data structure that is lock-free not only
    does not employ any locking mechanism (like mutex-free data structures), but also
    requires that any given thread or process cannot be waiting to execute indefinitely.
    This means that, if a lock-free data structure is successfully implemented, applications
    utilizing that data structure will never encounter the problems of deadlock and
    starvation. For this reason, lock-free data structures are widely considered a
    more advanced technique in concurrent programming, and consequently, they are
    significantly more difficult to implement.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于锁的数据结构不同，无锁数据结构不仅不使用任何锁定机制（如无互斥锁数据结构），而且要求任何给定的线程或进程不能无限期地等待执行。这意味着，如果成功实现了无锁数据结构，使用该数据结构的应用程序将永远不会遇到死锁和饥饿问题。因此，无锁数据结构被广泛认为是并发编程中更高级的技术，因此它们要难得多地实现。
- en: The characteristic of being lock-free, however, is actually impossible to implement
    in Python (or in the CPython interpreter, to be more specific). As you have probably
    guessed, this is due to the existence of the GIL, which prevents more than one
    thread from executing in the CPU at any given time. To learn more about the GIL,
    navigate to [Chapter 15](0e30892f-4bb1-4196-93c5-5df1d57428b8.xhtml), *The Global
    Interpreter Lock*, and read the in-depth analysis on the GIL, if you have not
    already. All in all, having a purely lock-free data structure implemented in CPython
    is a logical impossibility.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，无锁的特性实际上是无法在Python（或者更具体地说，在CPython解释器中）中实现的。您可能已经猜到，这是由于GIL的存在，它阻止多个线程在任何给定时间在CPU中执行。要了解有关GIL的更多信息，请转到[第15章](0e30892f-4bb1-4196-93c5-5df1d57428b8.xhtml)，“全局解释器锁”，并阅读有关GIL的深入分析，如果您还没有阅读的话。总的来说，在CPython中实现纯粹的无锁数据结构是一个逻辑上的不可能。
- en: However, this does not mean that concurrent programs in Python cannot benefit
    from the design of lock-free data structures. As mentioned previously, mutex-free
    Python data structures (which can be considered a subset of lock-free data structures)
    are entirely possible to implement. In fact, mutex-free data structures still
    result in the successful avoidance of deadlock and starvation problems. However,
    they cannot fully take advantage of the purely lock-free execution that would
    result in better speed.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着Python中的并发程序不能从设计无锁数据结构中受益。如前所述，无互斥锁的Python数据结构（可以被视为无锁数据结构的子集）是完全可以实现的。事实上，无互斥锁的数据结构仍然可以成功避免死锁和饥饿问题。然而，它们无法充分利用纯粹的无锁执行，这将导致更快的速度。
- en: In the next subsections, we will take a look at a custom data structure in Python,
    analyze the problem that it raises if used concurrently, and, finally, try to
    apply a mutex-free logic to the underlying data structure.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将研究Python中的自定义数据结构，分析如果同时使用会引发的问题，并尝试将无互斥锁的逻辑应用到底层数据结构中。
- en: Introduction to the network data structure
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络数据结构介绍
- en: The data structure that we are implementing resembles a network of nodes, one
    of which is the primary node. Additionally, each node contains a key and a value
    for the node. You can think of this data structure as a Python dictionary (in
    other words, a set of keys and values respectively paired together), but one of
    these key and value pairs is called the primary node of the network.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在实现的数据结构类似于一个节点网络，其中一个节点是主节点。此外，每个节点都包含一个键和一个节点的值。您可以将这个数据结构看作是一个Python字典（换句话说，一组键和值分别配对在一起），但其中一个键和值对被称为网络的主节点。
- en: A good way to visualize this data structure is to analyze a situation in which
    the data structure is utilized. Suppose that you have been asked to implement
    the request handling logic of a popular website, which is also, unfortunately,
    a common target for **denial of service (DoS)** attacks. Since it is highly possible
    that the website will be taken down fairly frequently, despite the efforts of
    the cybersecurity team, an approach that you could take to guarantee that clients
    of the website will still be able to access it is to keep more than one working
    copy of the website, in addition to the main website, on the server.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的方式来可视化这种数据结构是分析使用该数据结构的情况。假设您被要求实现一个流行网站的请求处理逻辑，这个网站也不幸地是**拒绝服务（DoS）**攻击的常见目标。由于网站很可能会经常被关闭，尽管网络安全团队的努力，您可以采取的一种方法是在服务器上保留除主网站之外的多个工作副本，以确保网站的客户仍然能够访问它。
- en: These copies are equivalent to the main website in every way, and the main website
    can therefore be completely replaced by any of the copies at any time. Now, if
    and when the main website is taken down by a DoS attack, you, as the server administrator,
    can simply allow the main website to go down and switch the address of the new
    main website to one of the copies that you have ready. The clients of the website
    will therefore experience no difficulty or inconsistency when accessing the data
    from the website, since the copies are identical to the main website that was
    taken down. Servers that do not implement this mechanism, on the other hand, will
    most likely have to spend some time recovering from a DoS attack (isolating the
    attack, building back the interrupted or corrupted data, and so on).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这些副本在每个方面等同于主网站，因此主网站可以随时完全被任何副本替换。现在，如果主网站被DoS攻击关闭，作为服务器管理员，您可以简单地允许主网站关闭并将新主网站的地址切换到您准备好的任何一个副本。因此，网站的客户在访问网站数据时不会遇到任何困难或不一致，因为副本与被关闭的主网站相同。另一方面，不实现此机制的服务器很可能需要花费一些时间来从DoS攻击中恢复（隔离攻击，重建中断或损坏的数据等）。
- en: 'At this point, a connection between this method of web administration and the
    aforementioned network data structure can be made. In fact, the network data structure
    is, in essence, a high-level abstraction of the method; the data structure is
    a set of nodes or pairs of values (the website address and the data, in the preceding
    case), while keeping track of a primary node that can also be replaced by any
    other node (clients accessing the website are directed to a new website when the
    main website is attacked). We will call this processing **refreshing the primary**
    in our data structure, which is illustrated in the following diagram:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，可以建立这种网站管理方法与上述网络数据结构之间的联系。实际上，网络数据结构本质上是该方法的高级抽象；数据结构是一组节点或值对（在前面的情况下是网站地址和数据），同时跟踪一个主节点，也可以被任何其他节点替换（当主网站受到攻击时，访问网站的客户被引导到新网站）。我们将称这个处理为我们数据结构中的**刷新主要**，如下图所示：
- en: '![](assets/5091dce0-bb4e-424e-a79b-4e1ab81f7030.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5091dce0-bb4e-424e-a79b-4e1ab81f7030.png)'
- en: Diagram of network primary refreshing
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 网络主要刷新的图表
- en: 'In the preceding diagram, we have three separate notes of data in our network
    data structure (visualized as a dictionary, denoted by a pair of curly braces):
    key **A**, pointing to some data; key **B**, pointing to its own data; and, finally,
    key **C**, also pointing to its own data. Additionally, we have a pointer indicating
    the primary key of our dictionary network, pointing to key **A**. As the primary
    refresh process takes place, we will stop keeping track of key **A** (which is
    the primary key) and its own, and then have the primary pointer pointing to another
    node in the network (in this case, key **B**).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，我们的网络数据结构中有三个独立的数据节点（可视化为字典，用一对大括号表示）：键**A**，指向某些数据；键**B**，指向其自己的数据；最后，键**C**，也指向其自己的数据。此外，我们有一个指针指示我们字典网络的主键，指向键**A**。随着主要刷新过程的进行，我们将停止跟踪键**A**（即主键）及其自身，然后将主指针指向网络中的另一个节点（在本例中为键**B**）。
- en: Implementing a simple network data structure in Python and race conditions
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中实现一个简单的网络数据结构和竞争条件
- en: 'Let''s consider a starting implementation of this data structure in Python.
    Navigate to the `Chapter16/network.py` file, as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑Python中这种数据结构的起始实现。按照以下方式导航到`Chapter16/network.py`文件：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This file contains the `Network` class, which implements the logic that we discussed
    previously. Upon initialization, each instance of this class will have at least
    one node in its network (stored in the `data` attribute) that is its primary node;
    we are also using Python's dictionary data structure to implement this network
    design. Each object also has to keep track of the key of its primary data, stored
    in its `primary_key` attribute.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件包含了`Network`类，它实现了我们之前讨论过的逻辑。在初始化时，这个类的每个实例在其网络中至少有一个节点（存储在`data`属性中），这是它的主节点；我们还使用Python的字典数据结构来实现这个网络设计。每个对象还必须跟踪其主要数据的键，存储在其`primary_key`属性中。
- en: In this class, we also have an `add_node()` method that is used to add a new
    node of data to a network object; note that each node has to have a key and a
    value. Recall our web administration example—this corresponds to an internet address
    and the data that the website has. The class also has a `refresh_primary()` method
    that simulates refreshing the primary process (which deletes the reference to
    the previous primary data and pseudo-randomly selects a new primary node from
    the remaining nodes). Keep in mind that the precondition for this method is that
    the calling network object has to have at least two nodes left .
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类中，我们还有一个`add_node()`方法，用于向网络对象添加新的数据节点；请注意，每个节点都必须有一个键和一个值。回想一下我们的网络管理示例——这对应于一个互联网地址和网站所拥有的数据。该类还有一个`refresh_primary()`方法，用于模拟刷新主要过程（删除对先前主要数据的引用，并从剩余节点中伪随机选择一个新的主节点）。请记住，这个方法的前提是调用网络对象必须至少还有两个节点。
- en: Finally, we have an accessor method, called `get_primary_value()`, that returns
    the value that the primary key of the calling network object points to. Here,
    we add in a slight delay in the execution of the method, to simulate the race
    condition that will occur from using this naive data structure. (Additionally,
    we are overwriting the default `__str__()` method, for easy debugging.)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有一个叫做`get_primary_value()`的访问方法，它返回调用网络对象的主键指向的值。在这里，我们在方法的执行中添加了轻微的延迟，以模拟使用这种天真的数据结构会发生的竞争条件。（另外，我们正在重写默认的`__str__()`方法，以便进行简单的调试。）
- en: 'Now, let''s turn our attention to the `Chapter16/example5.py` file, where we
    import this data structure and use it in a concurrent program:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们把注意力转向`Chapter16/example5.py`文件，在这里我们导入这个数据结构并在一个并发程序中使用它：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'First of all, we implement a function called `print_network_primary_value()`,
    which accesses and obtains the primary data of a network object that is also a
    global variable, using the aforementioned `get_primary_value()` method. In our
    main program, we then initialize a network object with a starting node, with `A`
    as the node key and `1` as the node data (this node also automatically becomes
    the primary node). We then add two more nodes to this network: `B`, pointing to
    `1`, and `C`, pointing to `1`, respectively.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们实现了一个名为`print_network_primary_value()`的函数，它使用前面提到的`get_primary_value()`方法访问和获取网络对象的主要数据，这也是一个全局变量。在我们的主程序中，我们使用起始节点初始化了一个网络对象，`A`作为节点键，`1`作为节点数据（这个节点也自动成为主节点）。然后我们向这个网络添加了另外两个节点：`B`指向`1`，`C`也指向`1`。
- en: Now, two threads are initialized and started, the first of which calls the `print_network_primary_value()`
    function to print out the current primary data of the network. The second calls
    the `refresh_primary()` method from the network object. We are also printing out
    the current state of the network object at various points throughout the program.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，初始化并启动了两个线程，第一个调用`print_network_primary_value()`函数打印出网络的当前主要数据。第二个调用网络对象的`refresh_primary()`方法。我们还在程序的各个点打印出网络对象的当前状态。
- en: 'It is quite easy to spot the race condition that will likely occur here: since
    the first thread is trying to access the primary data while the second thread
    is trying to refresh the data of the network (in essence, deleting the current
    primary data at that time), the first thread will most likely cause an error in
    its execution. Specifically, the following is my output after running the script:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易发现这里可能会发生竞争条件：因为第一个线程正在尝试访问主要数据，而第二个线程正在尝试刷新网络的数据（实质上，在那个时候删除当前的主要数据），第一个线程很可能会在执行过程中引发错误。具体来说，运行脚本后，以下是我的输出：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Just like we discussed, we encountered a `KeyError` that resulted from the
    fact that, by the time the first thread obtained the primary key, that key and
    the primary data had already been deleted from the data structure by its execution
    in the second thread. The following diagram further illustrates this point:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们讨论过的那样，我们遇到了一个`KeyError`，这是因为第一个线程获取主键的时候，该键和主要数据已经被第二个线程的执行从数据结构中删除了。下面的图表进一步说明了这一点：
- en: '![](assets/f7229d9b-ab3e-4217-bd3b-0b9a75781c70.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f7229d9b-ab3e-4217-bd3b-0b9a75781c70.png)'
- en: Race condition with network data structure
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 网络数据结构的竞争条件
- en: As you saw in previous chapters, we are using the `time.sleep()` function in
    the source code of the data structure, to ensure that the race condition will
    occur. Most of the time, the execution will be fast enough that an error will
    not occur, yet the race condition will still be there, and this is a problem in
    our current data structure that we need to address.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在之前的章节中看到的，我们在数据结构的源代码中使用了`time.sleep()`函数，以确保竞争条件会发生。大多数情况下，执行速度会足够快，不会出现错误，但竞争条件仍然存在，这是我们当前数据结构中需要解决的问题。
- en: RCU as a solution
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RCU作为解决方案
- en: The root of the race condition that we are encountering is, as we know, the
    fact that the network object that we are working with is being shared between
    different threads, which are mutating and reading the data from the data structure
    simultaneously. Specifically, the second thread in our program was mutating the
    data (by calling the `refresh_primary()` method), while the first thread was reading
    from the same data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遇到的竞争条件的根源是，我们知道，我们正在使用的网络对象在不同的线程之间共享，这些线程同时对数据结构进行变异和读取数据。具体来说，我们程序中的第二个线程正在变异数据（通过调用`refresh_primary()`方法），而第一个线程正在从相同的数据中读取。
- en: Obviously, we can simply apply locking as the synchronization mechanism for
    this data structure. However, we know that the tasks of acquiring and releasing
    locks involve a slight cost that will become substantial as the data structure
    is widely used across a system. As popular websites and systems (namely, MongoDB)
    use this abstraction to design and structure their servers, a considerably high
    level of traffic will make the cost of using locks apparent, and cause the performance
    to decrease. Implementing a variation of an approximate data structure could help
    with this issue, but the complexity of the implementation might prove to be too
    difficult to follow through.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们可以简单地将锁定应用为该数据结构的同步机制。然而，我们知道获取和释放锁的任务涉及一些成本，随着数据结构在系统中被广泛使用，这些成本将变得相当可观。由于流行的网站和系统（即MongoDB）使用此抽象来设计和构造其服务器，因此高水平的流量将使使用锁的成本显而易见，并导致性能下降。实现近似数据结构的变体可能有助于解决此问题，但实现的复杂性可能会被证明难以跟进。
- en: Thus, we arrive at the goal of using a mutex-free approach as our synchronization
    mechanism—in this case, **read-copy-update** (**RCU**). To protect the integrity
    of your data structure, RCU is, in essence, a synchronization mechanism that creates
    and maintains another version of the data structure when a thread or process requests
    read or write access to it. By isolating the interaction between the data structure
    and threads/processes within a separate copy, RCU ensures that no conflicting
    data can occur. As a thread or a process has mutated the information in the copy
    of the data structure that it is assigned to, that update can then be reported
    to the original data structure.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的目标是使用无互斥量的方法作为我们的同步机制——在这种情况下是**读-复制-更新**（**RCU**）。为了保护数据结构的完整性，RCU本质上是一种同步机制，当线程或进程请求读取或写入访问时，它会创建并维护数据结构的另一个版本。通过在单独的副本中隔离数据结构和线程/进程之间的交互，RCU确保不会发生冲突的数据。当线程或进程改变了其分配的数据结构副本中的信息时，该更新可以报告给原始数据结构。
- en: In short, when a shared data structure has threads or processes requesting access
    to it (the read process), it needs to return a copy of itself, instead of letting
    the threads/processes access its own data (the copy process); finally, if there
    are any changes in the copies of the data structure, they will need to be updated
    back to the shared data structure (the update process).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，当共享数据结构有线程或进程请求访问它（读取过程）时，它需要返回自身的副本，而不是让线程/进程访问其自己的数据（复制过程）；最后，如果副本中的数据结构发生任何更改，它们将需要更新回共享数据结构（更新过程）。
- en: 'RCU is particularly useful for data structures that have to handle a single
    updater and multiple readers at the same time, which is the typical case of the
    server network that we discussed previously (multiple clients constantly accessing
    and requesting data, but only occasional, periodic attacks). But how would this
    apply to our current network data structure? Theoretically, the accessor method
    of our data structure (the `get_primary_value()` method), which is, again, the
    root of the race condition, needs to create a copy of the data structure before
    reading the data from a thread. This specification is implemented in the accessor
    method, in the `Chapter16/concurrent_network.py` file, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: RCU对于需要同时处理单个更新程序和多个读取程序的数据结构特别有用，这是我们之前讨论的服务器网络的典型情况（多个客户端不断访问和请求数据，但只有偶尔的定期攻击）。但是这如何应用到我们当前的网络数据结构呢？理论上，我们的数据结构的访问器方法（`get_primary_value()`方法）需要在从线程读取数据之前创建数据结构的副本。这个规范在访问器方法中实现，在`Chapter16/concurrent_network.py`文件中，如下：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here, we are using the built-in `deepcopy` method from the copy module, which
    returns a separate copy of our network in a different memory location. Then, we
    only read the data from this copy of the network object, and not the original
    object itself. This process is illustrated in the following diagram:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了copy模块中的内置`deepcopy`方法，它返回网络的不同内存位置的副本。然后，我们只从这个网络对象的副本中读取数据，而不是原始对象本身。这个过程在下面的图表中说明：
- en: '![](assets/9a43e409-4c9d-4035-bdd4-a834e1d80192.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9a43e409-4c9d-4035-bdd4-a834e1d80192.png)'
- en: RCU addressing the race condition
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: RCU解决竞争条件
- en: In the preceding diagram, we can see that no conflict will occur in terms of
    data, as the two threads now deal with different copies of the data structure.
    Let us see this implementation in action in the `Chapter16/example6.py` file,
    which contains the same instructions as the previous `example5.py` file (initializing
    a network object, calling two threads at the same time—one to access the primary
    data of the network, the other to refresh the same primary data), only now the
    program is using our new data structure from the `concurrent_network.py` file.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，我们可以看到在数据方面不会发生冲突，因为两个线程现在处理的是数据结构的不同副本。让我们在`Chapter16/example6.py`文件中看到这个实现的实际操作，该文件包含与之前的`example5.py`文件相同的指令（初始化网络对象，同时调用两个线程——一个用于访问网络的主要数据，另一个用于刷新相同的主要数据），只是现在程序正在使用我们从`concurrent_network.py`文件中获取的新数据结构。
- en: 'After running the script, your output should be the same as the following:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之后，您的输出应该与以下内容相同：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see, not only does the program obtain the correct value of the primary
    data in the first thread without evoking any errors, it also holds the correct
    network at the end of the program (without the previously deleted node, with the
    key `A`). The RCU method does, indeed, solve the problem of the race condition,
    without the use of any locking mechanisms.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，程序不仅在第一个线程中获取了主要数据的正确值而没有引发任何错误，而且在程序结束时也保持了正确的网络（没有之前删除的节点，带有键`A`）。
    RCU方法确实解决了竞争条件的问题，而没有使用任何锁定机制。
- en: One thing that you might have also noticed is that RCU could also be applied
    for our counter example in the previous section. It is true that both RCU and
    approximate counters are reasonable approaches to the counter problem, and the
    question of which one is the better solution for a specific concurrent problem
    can only be answered by empirical, hands-on analysis such as scalability analysis.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还注意到的一件事是，在前一节中，RCU也可以应用于我们的计数器示例。事实上，RCU和近似计数器都是解决计数器问题的合理方法，哪种方法对于特定的并发问题更好的问题只能通过可扩展性分析等经验性的实践分析来回答。
- en: Building on simple data structures
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于简单数据结构
- en: Throughout this chapter, we have worked with a number of simple, concurrent
    data structures, such as counters and networks. For this reason, we were able
    to truly get to the bottom of the problems that we encountered in the concurrent
    programs that utilize these data structures, and were able perform in-depth analyses
    of how to improve their structures and design.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了许多简单的并发数据结构，如计数器和网络。因此，我们真正深入地了解了在使用这些数据结构的并发程序中遇到的问题，并能够深入分析如何改进它们的结构和设计。
- en: As you work on more complex concurrent data structures in your work and projects,
    you will see that their designs and structures, and the problems that accompany
    them, are, in fact, fundamentally similar to those that we saw in the data structures
    we analyzed. By truly understanding the underlying architecture of the data structures,
    as well as the root of problems that can occur in the programs that use them,
    you can build on this knowledge and design data structures that are more complex
    in instruction but equivalent in logic.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在工作和项目中处理更复杂的并发数据结构时，您会发现它们的设计和结构以及伴随它们的问题实际上与我们分析的数据结构中看到的问题基本相似。通过真正理解数据结构的基本架构以及使用它们的程序可能出现的问题的根源，您可以在此基础上构建更复杂但逻辑上等效的数据结构。
- en: Summary
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we studied the theoretical differences between lock-based
    and mutex-free data structures: a lock-based data structure uses a locking mechanism
    to protect the integrity of its data, while a mutex-free one does not. We analyzed
    the problem of race conditions that can occur in poorly-designed data structures,
    and looked at how to address it in both situations.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了基于锁和无互斥锁数据结构之间的理论差异：基于锁的数据结构使用锁定机制来保护其数据的完整性，而无互斥锁的数据结构则不使用。我们分析了在设计不良的数据结构中可能出现的竞争条件问题，并探讨了如何在这两种情况下解决这个问题。
- en: In our example of the concurrent lock-based counter data structure, we considered
    the design of approximate counters, as well as the improved scalability that the
    design can offer. In our analysis of the concurrent network data structure, we
    studied the RCU technique, which isolates reading instructions from updating instructions,
    with the goal of maintaining the integrity of the concurrent data structure.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的并发基于锁的计数器数据结构示例中，我们考虑了近似计数器的设计，以及设计可以提供的改进可扩展性。在我们对并发网络数据结构的分析中，我们研究了RCU技术，该技术将读取指令与更新指令隔离开来，目的是保持并发数据结构的完整性。
- en: 'In the next chapter, we will look at another set of advanced concepts in Python
    concurrent programming: memory models and operations on atomic types. You will
    learn more about Python memory management, as well as the definition and uses
    of atomic types.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究Python并发编程中的另一组高级概念：内存模型和对原子类型的操作。您将更多地了解Python内存管理，以及原子类型的定义和用途。
- en: Questions
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the main approach to solving the problem that locks don't lock anything?
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决锁不锁任何东西的主要方法是什么？
- en: Describe the concept of scalability in the context of concurrent programming
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在并发编程的背景下描述可扩展性的概念
- en: How does a naive locking mechanism affect the scalability of a concurrent program?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天真的锁定机制如何影响并发程序的可扩展性？
- en: What are approximate counters, and how do they help with the problem of scalability
    in concurrent programming?
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近似计数器是什么，它如何帮助解决并发编程中的可扩展性问题？
- en: Are lock-free data structures possible in Python? Why or why not?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python中是否可能存在无锁数据结构？为什么？
- en: What is a mutex-free concurrent data structure, and how is it different from
    a concurrent lock-based one?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是无互斥锁并发数据结构，它与并发基于锁的数据结构有何不同？
- en: What is the RCU technique, and what problem does it solve for mutex-free concurrent
    data structures?
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RCU技术是什么，以及它如何解决无互斥锁并发数据结构的问题？
- en: Further reading
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information, you can refer to the following links:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，您可以参考以下链接：
- en: '*Operating systems: Three easy pieces*. Vol. 151\. Wisconsin: Arpaci-Dusseau
    Books, 2014, by Arpaci-Dusseau, Remzi H. and Andrea C. Arpaci-Dusseau'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统：三个简单部分。第151卷。威斯康星州：Arpaci-Dusseau Books，2014年，作者：Arpaci-Dusseau，Remzi H.和Andrea
    C. Arpaci-Dusseau
- en: '*The Secret Life of Concurrent Data Structures* ([addthis.com/blog/2013/04/25/the-secret-life-of-concurrent-data-structures/](https://www.addthis.com/blog/2013/04/25/the-secret-life-of-concurrent-data-structures/#.W7onwBNKiAw)),
    by Michael Spiegel'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发数据结构的秘密生活（[addthis.com/blog/2013/04/25/the-secret-life-of-concurrent-data-structures/](https://www.addthis.com/blog/2013/04/25/the-secret-life-of-concurrent-data-structures/#.W7onwBNKiAw)），作者：Michael
    Spiegel
- en: '*What is RCU, fundamentally? *Linux Weekly News (LWN. net) (2007), McKenney,
    Paul E. and Jonathan Walpole'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RCU在本质上是什么？Linux周刊新闻（LWN.net）（2007），作者：McKenney，Paul E.和Jonathan Walpole
- en: '*Wasp''s Nest: The Read-Copy-Update Pattern in Python* ([emptysqua.re/blog/wasps-nest-read-copy-update-python/](https://emptysqua.re/blog/wasps-nest-read-copy-update-python/)), Davis, A.
    Jesse Jiryu'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄蜂窝：Python中的读-复制-更新模式（[emptysqua.re/blog/wasps-nest-read-copy-update-python/](https://emptysqua.re/blog/wasps-nest-read-copy-update-python/)），作者：Davis，A.
    Jesse Jiryu
- en: '*Characteristics of scalability and their impact on performance*, proceedings
    of the second international **workshop on software and performance** (**WOSP**)
    ''00\. p. 195, André B'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性的特征及其对性能的影响，第二届国际软件和性能研讨会（WOSP）'00。第195页，André B
