- en: '*Chapter 9*: Concurrent Web Requests'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：并发网络请求'
- en: This chapter will focus on concurrently making web requests. Intuitively, making
    requests to a web page to collect information about it is independent of applying
    the same task to another web page. This means that concurrency, specifically threading
    in this case, can be a powerful tool that provides a significant speedup in this
    process. In this chapter, we will learn about the fundamentals of web requests
    and how to interact with websites using Python. We will also learn how concurrency
    can help us make multiple requests efficiently. Finally, we will look at several
    good practices regarding web requests.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将专注于并发地发起网络请求。直观地讲，向一个网页发送请求以收集其信息与将相同任务应用于另一个网页是独立的。这意味着并发，特别是这里的线程，可以是一个强大的工具，它能为这个过程提供显著的加速。在本章中，我们将学习网络请求的基本原理以及如何使用
    Python 与网站交互。我们还将学习并发如何帮助我们高效地发起多个请求。最后，我们将探讨关于网络请求的几个良好实践。
- en: Overall, this chapter serves as a practical exercise for us to become more comfortable
    with concurrency in Python, which will help you tackle future concurrent programming
    projects with more confidence.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，本章作为一个实际练习，旨在让我们更加熟悉 Python 中的并发，这将有助于你在未来的并发编程项目中更有信心地应对。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The basics of web requests
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络请求的基本原理
- en: The requests module
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求模块
- en: Concurrent web requests
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发网络请求
- en: The problem with timeouts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超时问题
- en: Good practices in making web requests
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发起网络请求的良好实践
- en: The basics of web requests
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络请求的基本原理
- en: The worldwide capacity to generate data is estimated to double in size every
    2 years. Even though there is an interdisciplinary field known as **data science**
    that is entirely dedicated to studying data, almost every programming task in
    software development also has something to do with collecting and analyzing data.
    A significant part of this is, of course, **data collection**. However, the data
    that we need for our applications is sometimes not stored nicely and cleanly in
    a database – sometimes, we need to collect the data we need from web pages.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 全球数据生成能力预计每两年翻一番。尽管有一个名为**数据科学**的跨学科领域完全致力于研究数据，但软件开发中的几乎所有编程任务都与收集和分析数据有关。其中很大一部分当然是**数据收集**。然而，我们应用程序所需的数据有时并没有以整洁的方式存储在数据库中——有时，我们需要从网页中收集所需的数据。
- en: For example, **web scraping** is a data extraction method that automatically
    makes requests to web pages and downloads specific information. Web scraping allows
    us to comb through numerous websites and collect any data we need systematically
    and consistently. The collected data can be analyzed later by our applications
    or simply saved on our computers in various formats. An example of this would
    be Google, which maintains and runs numerous web scrapers of its own to find and
    index web pages for its search engines.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**网络爬虫**是一种数据提取方法，它自动向网页发送请求并下载特定信息。网络爬虫使我们能够系统地、持续地从众多网站中收集所需数据。收集到的数据可以在以后由我们的应用程序进行分析，或者简单地以各种格式保存在我们的计算机上。例如，谷歌就维护并运行了大量的网络爬虫，以寻找和索引其搜索引擎的网页。
- en: The Python language itself provides several good options for applications of
    this kind. In this chapter, we will mainly work with the `requests` module to
    make client-side web requests from our Python programs. However, before we look
    into this module in more detail, we need to understand some web terminology to
    be able to effectively design our applications.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Python 语言本身为这类应用提供了几个不错的选择。在本章中，我们将主要使用 `requests` 模块来从我们的 Python 程序中发起客户端网络请求。然而，在我们详细了解这个模块之前，我们需要了解一些网络术语，以便能够有效地设计我们的应用程序。
- en: HTML
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTML
- en: '`.html` file extension. In an HTML document, text is surrounded and delimited
    by tags, written in angle brackets; that is, `<p>`, `<img>`, `<i>`, and so on.
    These tags typically consist of pairs – an opening tag and a closing tag – indicating
    the styling or the nature of the data included inside.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`.html` 文件扩展名。在 HTML 文档中，文本被角括号内的标签包围和分隔；即 `<p>`、`<img>`、`<i>` 等等。这些标签通常由一对组成——一个开标签和一个闭标签——表示包含在其中的数据的样式或性质。'
- en: It is also possible to include other forms of media in HTML code, such as images
    or videos. Numerous other tags are used in common HTML documents. Some specify
    a group of elements that share some common characteristics, such as `<id></id>`
    and `<class></class>`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在HTML代码中也可以包含其他形式的媒体，例如图片或视频。在常见的HTML文档中使用了大量的其他标签。其中一些指定了一组具有某些共同特征的元素，如`<id></id>`和`<class></class>`。
- en: 'The following is an example of HTML code:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个HTML代码的示例：
- en: '![Figure 9.1 – Sample HTML code ](img/Figure_9.1_B17499.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 – 示例HTML代码](img/Figure_9.1_B17499.jpg)'
- en: Figure 9.1 – Sample HTML code
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 示例HTML代码
- en: Fortunately, detailed knowledge of what each HTML tag accomplishes is not required
    for us to make effective web requests. As we will see later in this chapter, the
    more essential part of making web requests is the ability to interact with web
    pages efficiently.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们不需要详细了解每个HTML标签的功能，就能有效地进行网络请求。正如我们将在本章后面看到的那样，进行网络请求的更关键部分是能够有效地与网页交互。
- en: HTTP requests
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTTP请求
- en: In a typical communication process on the web, HTML text is the data that is
    to be saved and/or further processed. This kind of data needs to be collected
    from web pages, but how can we go about doing that? Most of the communication
    is done via the internet – more specifically, the **World Wide Web** (**WWW**)
    – and this utilizes the **Hypertext Transfer Protocol** (**HTTP**). In HTTP, request
    methods are used to convey the information of what data is being requested and
    should be sent back from a server.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络上的典型通信过程中，HTML文本是要保存和/或进一步处理的数据。这类数据需要从网页中收集，但我们如何进行操作呢？大部分的通信都是通过互联网进行的——更具体地说，是**万维网**（**WWW**）——并且它利用了**超文本传输协议**（**HTTP**）。在HTTP中，请求方法用于传达请求的数据信息，并应从服务器返回。
- en: 'For example, when you type `packtpub.com` in your browser, the browser sends
    a request method via HTTP to the Packt website''s main server, asking for data
    from the website. Now, if both your internet connection and Packt''s server are
    working well, then your browser will receive a response from the server, as shown
    in the following diagram. This response will be in the form of an HTML document,
    which will be interpreted by your browser, and your browser will display the corresponding
    HTML output on the screen:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你在浏览器中输入`packtpub.com`时，浏览器通过HTTP向Packt网站的主服务器发送一个请求方法，请求网站的数据。现在，如果你的互联网连接和Packt的服务器都运行良好，那么你的浏览器将收到服务器的响应，如下面的图所示。此响应将以HTML文档的形式呈现，并由你的浏览器解释，你的浏览器将在屏幕上显示相应的HTML输出：
- en: '![Figure 9.2 – Diagram of HTTP communication ](img/Figure_9.2_B17499.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2 – HTTP通信图](img/Figure_9.2_B17499.jpg)'
- en: Figure 9.2 – Diagram of HTTP communication
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – HTTP通信图
- en: 'Generally, request methods are defined as verbs that indicate the desired action
    to be performed while the HTTP client (web browsers) and the server communicate
    with each other: `GET`, `HEAD`, `POST`, `PUT`, `DELETE`, and so on. Of these methods,
    `GET` and `POST` are two of the most common request methods that are used in web
    scraping applications; their functionality is described here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，请求方法被定义为动词，表示HTTP客户端（网页浏览器）和服务器之间通信时希望执行的操作：`GET`、`HEAD`、`POST`、`PUT`、`DELETE`等。在这些方法中，`GET`和`POST`是两种在网页抓取应用中最常见的请求方法；它们的功能在此处描述：
- en: The `GET` method requests specific data from the server. This method only retrieves
    data and has no other effect on the server and its databases.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GET`方法从服务器请求特定的数据。此方法仅检索数据，对服务器及其数据库没有其他影响。'
- en: The `POST` method sends data in a specific form that is accepted by the server.
    This data could be, for example, a message to a bulletin board, mailing list,
    or newsgroup, information to be submitted to a web form, or an item to be added
    to a database.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`POST`方法以服务器接受的具体形式发送数据。这些数据可以是，例如，给公告板、邮件列表或新闻组的消息，要提交给网页表单的信息，或要添加到数据库的项目。'
- en: All general-purpose HTTP servers that we commonly see on the internet are required
    to implement at least the `GET` (and `HEAD`) method, while the `POST` method is
    considered optional.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在互联网上常见到的所有通用目的HTTP服务器都必须实现至少`GET`（和`HEAD`）方法，而`POST`方法被认为是可选的。
- en: HTTP status code
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTTP状态码
- en: It is not always the case that when a web request is made and sent to a web
    server, the server will process the request and return the requested data without
    fail. Sometimes, the server might be completely down or already busy interacting
    with other clients and therefore unresponsive to a new request; sometimes, the
    client itself makes bad requests to a server (for example, incorrectly formatted
    or malicious requests).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每次向网络服务器发送网络请求时，服务器都会成功处理请求并返回所需数据。有时，服务器可能完全关闭或已经忙于与其他客户端交互，因此对新请求无响应；有时，客户端本身向服务器发送了不良请求（例如，格式不正确或恶意请求）。
- en: As a way to categorize these problems as well as provide the most information
    possible during the communication resulting from a web request, HTTP requires
    servers to respond to each request from its clients with an **HTTP response status
    code**. A status code is typically a three-digit number that indicates the specific
    characteristics of the response that the server sends back to a client.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对这些问题进行分类以及提供尽可能多的信息的一种方式，HTTP 要求服务器对来自其客户端的每个请求以 **HTTP 响应状态码** 进行响应。状态码通常是一个三位数，表示服务器发送回客户端的响应的具体特征。
- en: 'In total, there are five large categories of HTTP response status codes, indicated
    by the first digit of the code. They are as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 总共有五个大类的 HTTP 响应状态码，由代码的第一位数字表示。它们如下所示：
- en: '**1xx (informational status code)**: The request was received, and the server
    is processing it. For example, **100** means that the request header has been
    received and that the server is waiting for the request body; **102** indicates
    that the request is currently being processed (this is used for large requests
    and to prevent clients from timing out).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1xx (信息状态码)**: 请求已被接收，服务器正在处理它。例如，**100** 表示请求头已接收，服务器正在等待请求体；**102** 表示请求正在处理中（这用于大请求，以防止客户端超时）。'
- en: '**2xx (successful status code)**: The request was successfully received, understood,
    and processed by the server. For example, **200** means the request was successfully
    fulfilled; **202** indicates that the request has been accepted for processing,
    but the processing itself is not complete.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2xx (成功状态码)**: 请求已被服务器成功接收、理解和处理。例如，**200** 表示请求已成功完成；**202** 表示请求已被接受处理，但处理本身尚未完成。'
- en: '**3xx (redirectional status code)**: Additional actions need to be taken so
    that the request can be successfully processed. For example, **300** means that
    there are multiple options regarding how the response from the server should be
    processed (for example, giving the client multiple video format options when a
    video file is to be downloaded); **301** indicates that the server has been moved
    permanently and all requests should be directed to another address (provided in
    the response from the server).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3xx (重定向状态码)**: 需要采取额外操作才能成功处理请求。例如，**300** 表示有多个选项关于如何处理来自服务器的响应（例如，在下载视频文件时给客户端提供多个视频格式选项）；**301**
    表示服务器已永久移动，所有请求应指向另一个地址（由服务器响应提供）。'
- en: '**4xx (error status code for the client)**: The request was incorrectly formatted
    by the client and could not be processed. For example, **400** means that the
    client sent in a bad request (for example, a syntax error or the size of the request
    is too large); **404** (arguably the most well-known status code) indicates that
    the request method is not supported by the server.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4xx (客户端错误状态码)**: 客户端格式错误，无法处理请求。例如，**400** 表示客户端发送了一个不良请求（例如，语法错误或请求大小过大）；**404**（可能是最著名的状态码）表示请求方法不受服务器支持。'
- en: '**5xx (error status code for the server)**: The request, although valid, could
    not be processed by the server. For example, **500** means that there is an internal
    server error in which an unexpected condition was encountered; **504** (Gateway
    Timeout) means that the server, which was acting as a gateway or a proxy, did
    not receive a response from the final server in time.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**5xx (服务器错误状态码)**: 请求虽然有效，但服务器无法处理。例如，**500** 表示服务器内部出现意外条件导致内部服务器错误；**504**（网关超时）表示充当网关或代理的服务器未及时从最终服务器收到响应。'
- en: A lot more can be said about these status codes, but it is already sufficient
    for us to keep the big five categories previously mentioned in mind when making
    web requests from Python. If you would like to find more specific information
    about these or other status codes, the **Internet Assigned Numbers Authority**
    (**IANA**) maintains the official registry of HTTP status codes. Now, let's start
    learning about making web requests in Python.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些状态码还有很多可以说的，但当我们从Python进行网络请求时，已经足够我们记住之前提到的五大类别。如果你想找到更多关于这些或其他状态码的详细信息，**互联网数字分配机构**（**IANA**）维护着HTTP状态码的官方注册表。现在，让我们开始学习如何在Python中制作网络请求。
- en: The requests module
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`requests`模块'
- en: The `requests` module allows its users to make and send HTTP request methods.
    In the applications that we will be considering, it is mainly used to make contact
    with the server of the web pages we want to extract data from and obtain the response
    for the server.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests`模块允许用户制作并发送HTTP请求方法。在我们将要考虑的应用中，它主要用于与我们要从中提取数据的网页的服务器建立联系，并获取服务器的响应。'
- en: Note
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: According to the official documentation of the module, the use of Python 3 is
    `requests`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模块的官方文档，Python 3的`requests`使用方式。
- en: 'To install the module on your computer, run one of the following commands:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要在你的计算机上安装该模块，运行以下命令之一：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These commands should install `requests` and any other required dependencies
    (`idna`, `certifi`, `urllib3`, and so on) for you if your system does not have
    those already. After this, run `import requests` in a Python interpreter to confirm
    that the module has been installed successfully. Next, we will use `requests`
    to build the sequential, non-concurrent version of our program.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的系统还没有这些，这些命令应该会为你安装`requests`和任何其他必需的依赖项（`idna`、`certifi`、`urllib3`等）。在此之后，在Python解释器中运行`import
    requests`以确认模块已成功安装。接下来，我们将使用`requests`构建我们程序的顺序、非并发版本。
- en: Making a request in Python
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中制作请求
- en: 'Let''s look at an example usage of the module, as shown in the following code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模块的一个示例用法，如下面的代码所示：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this example, we are using the `requests` module to download the HTML code
    of a web page; that is, `www.google.com`. The `requests.get()` method sends a
    `GET` request method to `url` and we store the response in the `res` variable.
    After checking the status and headers of the response by printing them out, we
    create a file called `google.html` and write the HTML code, which is stored in
    the response text, to the file.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`requests`模块来下载网页的HTML代码；即`www.google.com`。`requests.get()`方法向`url`发送一个`GET`请求方法，并将响应存储在`res`变量中。通过打印输出检查响应的状态和头部信息后，我们创建一个名为`google.html`的文件，并将存储在响应文本中的HTML代码写入该文件。
- en: 'After running the program (assuming that your internet is working and that
    the Google server is not down), you should get the following output:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行程序后（假设你的网络是正常的，并且Google服务器没有宕机），你应该得到以下输出：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The response had a `200` status code, which we know means that the request has
    been completed. The header of the response, which is stored in `res.headers`,
    also contains further specific information regarding the response. For example,
    we can see the date and time the request was made, that the content of the response
    is text and HTML, and that the total length of the content is `4958`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 响应有一个`200`状态码，我们知道这意味着请求已经完成。存储在`res.headers`中的响应头部还包含有关响应的进一步具体信息。例如，我们可以看到请求的日期和时间，响应的内容是文本和HTML，以及内容的总长度为`4958`。
- en: The data that was sent from the server was also written to the `google.html`
    file. When you open this file in a text editor, you will be able to see the HTML
    code of the web page that we have downloaded using `requests`. On the other hand,
    if you use a web browser to open the file, you will see how **most** of the information
    from the original web page is now being displayed through a downloaded offline
    file.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从服务器发送的数据也被写入到`google.html`文件中。当你用文本编辑器打开这个文件时，你将能够看到我们使用`requests`下载的网页的HTML代码。另一方面，如果你使用网页浏览器打开这个文件，你将看到原始网页的大部分信息现在是通过下载的离线文件来显示的。
- en: 'For example, the following is how Google Chrome interprets the HTML file on
    my system:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是我系统上Google Chrome解释HTML文件的方式：
- en: '![Figure 9.3 – Downloaded HTML opened offline ](img/Figure_9.3_B17499.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3 – 离线打开下载的HTML](img/Figure_9.3_B17499.jpg)'
- en: Figure 9.3 – Downloaded HTML opened offline
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 离线打开下载的HTML
- en: There is other information that is stored on the server that the web pages of
    that server refer to. This means that not all of the information that an online
    web page provides can be downloaded via a `GET` request, and this is why offline
    HTML code sometimes fails to contain all of the information available on the online
    web page that it was downloaded from. (For example, the downloaded HTML code in
    the preceding screenshot does not display the Google icon correctly.)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器上还存储了其他信息，这些信息由该服务器的网页引用。这意味着并非所有在线网页提供的信息都可以通过`GET`请求下载，这也是为什么离线HTML代码有时无法包含从其下载的在线网页上所有可用信息的原因。（例如，前面截图中的下载HTML代码无法正确显示Google图标。）
- en: Running a ping test
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行ping测试
- en: With the basic knowledge of HTTP requests and the `requests` module in Python
    in hand, we will, for the remaining portion of this chapter, tackle the central
    problem of running a **ping test**. A ping test is a procedure in which you test
    the communication between your system and specific web servers, simply by requesting
    each of the servers in question. By considering the HTTP response status code
    (potentially) returned by the server, the test is used to evaluate either the
    internet connection of your system or the availability of the servers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有HTTP请求的基本知识和Python中的`requests`模块，在本章剩余部分，我们将解决运行**ping测试**的核心问题。ping测试是一种测试你系统与特定网站服务器之间通信的流程，只需请求每个相关服务器即可。通过考虑服务器返回的HTTP响应状态码（可能是），测试用于评估你系统的互联网连接或服务器的可用性。
- en: Ping tests are quite common among web administrators, who usually have to manage
    a large number of websites simultaneously. It is a good tool to quickly identify
    pages that are unexpectedly unresponsive or down. Many tools provide you with
    powerful options regarding ping tests and, in this chapter, we will be designing
    a ping test application that can concurrently send multiple web requests at the
    same time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Ping测试在网站管理员中相当常见，他们通常需要同时管理大量网站。这是一个快速识别意外无响应或下线的页面的好工具。许多工具提供了关于ping测试的强大选项，在本章中，我们将设计一个可以同时并发发送多个网络请求的ping测试应用程序。
- en: To simulate different HTTP response status codes to be sent back to our program,
    we will be using [httpstat.us](http://httpstat.us), a website that can generate
    various status codes and is commonly used to test how applications that make web
    requests can handle varying responses. Specifically, to use a request that will
    return a `200` status code in a program, we can simply send the request [httpstat.us/200](http://httpstat.us/200);
    the same applies to other status codes. In our ping test program, we will have
    a list of [httpstat.us](http://httpstat.us) URLs with different status codes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟发送回我们程序的不同的HTTP响应状态码，我们将使用[httpstat.us](http://httpstat.us)，这是一个可以生成各种状态码的网站，通常用于测试制作网络请求的应用程序如何处理不同的响应。具体来说，为了在程序中使用返回`200`状态码的请求，我们可以简单地发送请求[httpstat.us/200](http://httpstat.us/200)；对其他状态码也是如此。在我们的ping测试程序中，我们将有一个包含不同状态码的[httpstat.us](http://httpstat.us)
    URL列表。
- en: 'Let''s take a look at the following code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下以下代码：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this program, the `ping()` function takes in a URL and attempts to make a
    `GET` request to the site. Then, it prints out the content of the response returned
    by the server. In our main program, we have a list of different status codes that
    we mentioned earlier, each of which we will go through and call the `ping()` function
    on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个程序中，`ping()`函数接收一个URL并尝试对该网站发起一个`GET`请求。然后，它打印出服务器返回的响应内容。在我们的主程序中，我们有一个之前提到的不同状态码的列表，我们将逐一遍历并调用`ping()`函数。
- en: 'The final output, after running the preceding example, should be as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的示例后，最终输出应该如下所示：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we can see that our ping test program was able to obtain the corresponding
    responses from the server. However, our current program is purely sequential,
    and we would like to implement a concurrent version of it. We will do this in
    the next section.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的ping测试程序能够从服务器获取相应的响应。然而，我们当前的程序完全是顺序执行的，我们希望实现一个并发版本。我们将在下一节中这样做。
- en: Concurrent web requests
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发网络请求
- en: In the context of concurrent programming, we can see that the process of making
    a request to a web server and obtaining the returned response is independent of
    the same procedure for a different web server. This is to say that we could apply
    concurrency and parallelism to our ping test application to speed up our execution.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发编程的背景下，我们可以看到向一个网络服务器发送请求并获取返回响应的过程与向不同网络服务器执行相同程序是独立的。这意味着我们可以将并发和并行性应用于我们的ping测试应用程序以加快我们的执行速度。
- en: 'In the concurrent ping test applications that we are designing, multiple HTTP
    requests will be made to the server simultaneously and the corresponding responses
    will be sent back to our program, as shown in the following diagram:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们设计的并发ping测试应用程序中，将同时向服务器发送多个HTTP请求，相应的响应将发送回我们的程序，如下所示：
- en: '![Figure 9.4 – Parallel HTTP requests ](img/Figure_9.4_B17499.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4 – 并行HTTP请求](img/Figure_9.4_B17499.jpg)'
- en: Figure 9.4 – Parallel HTTP requests
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 – 并行HTTP请求
- en: As we mentioned previously, concurrency and parallelism have significant applications
    in web development, and most servers nowadays can handle a large number of requests
    at the same time.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，并发和并行性在Web开发中有重要的应用，并且如今的大多数服务器都可以同时处理大量的请求。
- en: Now, let's see how we can make multiple web requests at the same time, with
    the help of `threading`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何借助`threading`模块同时发送多个网络请求。
- en: Spawning multiple threads
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动多个线程
- en: 'To apply concurrency, we can simply use the `threading` module that we have
    been discussing to create separate threads to handle different web requests. Let''s
    take a look at the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用并发，我们可以简单地使用我们一直在讨论的`threading`模块来创建单独的线程来处理不同的网络请求。让我们看一下以下代码：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this example, we are including the sequential logic from the previous example
    to process our URL list so that we can compare the speed improvement when we apply
    threading to our ping test program. We are also creating a thread to ping each
    of the URLs in our URL list using the `threading` module; these threads will be
    executed independently from each other. The time it takes to process the URLs
    both sequentially and concurrently is also tracked using methods from the `time`
    module.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们包含了之前示例中的顺序逻辑来处理我们的URL列表，以便我们可以比较在将线程应用于我们的ping测试程序时速度的提升。我们还在使用`threading`模块创建一个线程来ping我们URL列表中的每个URL；这些线程将独立执行。使用`time`模块的方法还跟踪了顺序和并发处理URL所需的时间。
- en: 'If you run the program, your output should be similar to the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行程序，你的输出应该类似于以下内容：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: While the specific time that the sequential logic and threading logic takes
    to process all the URLs might be different from system to system, there should
    still be a clear distinction between the two. Specifically, here, we can see that
    the threading logic was almost six times faster than the sequential logic (which
    corresponds to the fact that we had six threads processing six URLs in parallel).
    There is no doubt, then, that concurrency can provide a significant speedup for
    our ping test application and for the process of making web requests in general.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然顺序逻辑和线程逻辑处理所有URL所需的具体时间可能因系统而异，但两者之间应该仍然有明显的区别。具体来说，在这里，我们可以看到线程逻辑几乎比顺序逻辑快六倍（这对应于我们同时处理六个URL的六个线程）。因此，毫无疑问，并发可以为我们的ping测试应用程序以及一般网络请求过程提供显著的加速。
- en: Refactoring request logic
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重构请求逻辑
- en: 'The current version of our ping test application works as intended, but we
    can improve its readability by refactoring the logic where we make web requests
    in a thread class. Consider the `MyThread` class:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前的ping测试应用程序按预期工作，但我们可以通过重构线程类中我们进行网络请求的逻辑来提高其可读性。考虑以下`MyThread`类：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this example, `MyThread` inherits from the `threading.Thread` class and
    contains two additional attributes: `url` and `result`. The `url` attribute holds
    the URL that the thread instance should process; the response that''s returned
    from the web server to that thread will be written to the `result` attribute (in
    the `run()` function).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`MyThread`类继承自`threading.Thread`类，并包含两个额外的属性：`url`和`result`。`url`属性包含线程实例应处理的URL；从网络服务器返回给该线程的响应将被写入`result`属性（在`run()`函数中）。
- en: 'Outside of this class, we can simply loop through the URL list and create and
    manage the threads accordingly, while not having to worry about the request logic
    in the main program:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类之外，我们可以简单地遍历URL列表并相应地创建和管理线程，而无需担心主程序中的请求逻辑：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that we are now storing the responses in the `result` attribute of the
    `MyThread` class, instead of directly printing them out, as we did in the old
    `ping()` function from the previous examples. This means that, after making sure
    that all the threads have finished, we will need to loop through the threads one
    more time and print out those responses.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们现在将响应存储在`MyThread`类的`result`属性中，而不是像之前示例中的旧`ping()`函数那样直接打印出来。这意味着，在确保所有线程都完成后，我们还需要再次遍历线程并打印出这些响应。
- en: 'Refactoring the request logic should not greatly affect the performance of
    our current program; we are keeping track of the execution speed to see if this
    is the case. If you execute the program, you will obtain an output similar to
    the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重构请求逻辑不应大大影响我们当前程序的性能；我们正在跟踪执行速度以查看这是否属实。如果您执行程序，您将获得类似于以下输出的结果：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Just as we expected, we are still achieving a significant speedup from the sequential
    version of the program with this refactored request logic. Again, our main program
    is now more readable, and further adjustments to the request logic (as we will
    see in the next section) can simply be directed to the `MyThread` class, without
    affecting the rest of the program.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所预期的那样，通过这次重构的请求逻辑，我们仍然从程序的顺序版本中获得了显著的加速。再次强调，我们的主程序现在更加易于阅读，并且对请求逻辑的进一步调整（正如我们将在下一节中看到的）可以直接针对`MyThread`类进行，而不会影响程序的其余部分。
- en: 'Our program can now make concurrent web requests to specific sites and display
    the returned status code. However, there is a problem common in working with web
    requests that our program cannot handle yet: timeouts. We will learn how to address
    this in the next section.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的程序现在可以同时对特定网站发起并发网络请求并显示返回的状态码。然而，处理网络请求时常见的一个问题，我们程序目前还无法处理：超时。我们将在下一节中学习如何解决这个问题。
- en: The problem with timeouts
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超时的问题
- en: 'In this section, we will explore a potential improvement we can make to our
    ping test application: handling **timeouts**. Timeouts typically occur when the
    server takes an unusually long time to process a specific request, and the connection
    between the server and its client is terminated.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨我们可以对ping测试应用程序进行的一个潜在改进：处理**超时**。超时通常发生在服务器处理特定请求的时间异常长时，服务器与其客户端之间的连接被终止。
- en: In the context of a ping test application, we will be implementing a customized
    threshold for the timeout. Recall that a ping test is used to determine whether
    specific servers are still responsive, so we can specify in our program that,
    if a request takes more than our timeout threshold for the server to respond,
    we will categorize that specific server with a timeout.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在ping测试应用程序的上下文中，我们将实现一个针对超时的自定义阈值。回想一下，ping测试用于确定特定服务器是否仍然响应，因此我们可以在程序中指定，如果请求超过服务器响应的超时阈值，我们将将该特定服务器分类为超时。
- en: Support from httpstat.us and simulation in Python
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来自httpstat.us的支持和Python模拟
- en: In addition to different options for status codes, the [httpstat.us](http://httpstat.us)
    website also provides us with a way to simulate a delay in its response when we
    send in requests. Specifically, we can customize the delay time (in milliseconds)
    with a query argument in our `GET` request. For example, [httpstat.us/200?sleep=5000](http://httpstat.us/200?sleep=5000)
    will return a response after a 5-second delay.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不同的状态码选项之外，[httpstat.us](http://httpstat.us)网站还为我们提供了一个在发送请求时模拟其响应延迟的方法。具体来说，我们可以通过`GET`请求中的查询参数自定义延迟时间（以毫秒为单位）。例如，[httpstat.us/200?sleep=5000](http://httpstat.us/200?sleep=5000)将在5秒延迟后返回响应。
- en: 'Now, let''s see how a delay like this would affect the execution of our program.
    Consider the following program, which contains the current request logic of our
    ping test application but has a different URL list:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这种延迟会如何影响我们程序的执行。考虑以下程序，它包含我们ping测试应用程序当前的请求逻辑，但具有不同的URL列表：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, we have a URL that will take around 20 seconds to return a response. Considering
    that we will block the main program until all the threads finish their execution
    (with the `join()` method), our program will most likely appear to be hanging
    for 20 seconds before any response is printed out.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个大约需要20秒才能返回响应的URL。考虑到我们将使用`join()`方法阻塞主程序，直到所有线程完成它们的执行，我们的程序在打印出任何响应之前可能会看起来挂起20秒。
- en: 'Run the program to experience this for yourself. A 20-second delay will occur
    (which will make the execution take significantly longer to finish) and we will
    obtain the following output:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序亲自体验一下。将出现20秒的延迟（这将使执行完成的时间显著更长），我们将获得以下输出：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let's say that 20 seconds is too long of a response time, and we cannot afford
    to wait for a request that long. So, we would like to implement some logic that
    can handle long waiting times like this.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 假设20秒的响应时间太长，我们无法承受等待这么长时间的请求。因此，我们希望实现一些逻辑来处理这种长时间的等待。
- en: Timeout specifications
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超时指定
- en: Overall, an efficient ping test application should not be waiting for responses
    from its websites for a long time; it should have a set threshold for a timeout
    that, if a server fails to return a response under that threshold, the application
    will deem that server non-responsive. So, we need to implement a way to keep track
    of how much time has passed since a request has been sent to a server. We will
    do this by counting down from the timeout threshold. Once that threshold has been
    passed, all the responses (whether they've returned yet or not) will be printed
    out.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，一个高效的ping测试应用程序不应该长时间等待其网站的响应；它应该有一个设定的超时阈值，如果服务器在该阈值下未能返回响应，应用程序将认为该服务器无响应。因此，我们需要实现一种方法来跟踪自请求发送到服务器以来已经过去的时间。我们将通过从超时阈值开始倒计时来实现这一点。一旦超过该阈值，所有响应（无论它们是否已经返回）都将被打印出来。
- en: Additionally, we will also be keeping track of how many requests are still pending
    and have not had their responses returned. We will be using the `is_alive()` method
    from the `threading.Thread` class to indirectly determine whether a response has
    been returned for a specific request. If, at one point, the thread that's processing
    a specific request is alive, we can conclude that that specific request is still
    pending.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将跟踪有多少请求仍在等待，并且尚未收到它们的响应。我们将使用`threading.Thread`类中的`is_alive()`方法来间接确定是否为特定请求返回了响应。如果在某个时刻，处理特定请求的线程仍然存活，我们可以得出结论，该特定请求仍在等待。
- en: 'Let''s consider the following `process_requests()` function first:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先考虑以下`process_requests()`函数：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This function takes in a list of threads that we have been using to make web
    requests in the previous examples, as well as an optional argument specifying
    the timeout threshold. Inside this function, we have an inner function, `alive_count()`,
    which returns the count of the threads that are still alive at the time of the
    function call.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数接受一个线程列表，这是我们之前示例中用来进行Web请求的，以及一个可选的参数，指定超时阈值。在这个函数内部，我们有一个内部函数`alive_count()`，它在函数调用时返回仍然存活的线程数量。
- en: In the `process_requests()` function, so long as there are threads that are
    currently alive and processing requests, we will allow the threads to continue
    with their execution (this is done in the `while` loop with the double condition).
    The `UPDATE_INTERVAL` variable, as you can see, specifies how often we check for
    this condition. If either condition fails (if there are no alive threads left
    or if the threshold timeout is passed), then we will proceed with printing out
    the responses (even if some might have not been returned).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在`process_requests()`函数中，只要当前有线程正在存活并处理请求，我们将允许线程继续它们的执行（这是在`while`循环中通过双重条件完成的）。正如你所看到的，`UPDATE_INTERVAL`变量指定了我们检查此条件的时间间隔。如果任一条件失败（如果没有存活的线程或超时阈值已通过），那么我们将继续打印出响应（即使其中一些可能尚未返回）。
- en: 'Let''s turn our attention to the new `MyThread` class:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把注意力转向新的`MyThread`类：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This class is almost identical to the one we considered in the previous example,
    except that the initial value for the `result` attribute is a message indicating
    a timeout. In the case that we discussed earlier, where the timeout threshold
    specified in the `process_requests()` function is passed, this initial value will
    be used when the responses are printed out.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类与我们之前考虑的几乎相同，只是`result`属性的初始值是一个表示超时的消息。在我们之前讨论的情况中，即`process_requests()`函数中指定的超时阈值被传递时，这个初始值将在打印响应时使用。
- en: 'Finally, let''s consider our main program in `example6.py`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们考虑一下我们的主程序`example6.py`：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, in our URL list, we have a request that would take 4 seconds and another
    that would take 20 seconds, aside from the ones that would respond immediately.
    As the timeout threshold that we are using is 5 seconds, theoretically, we should
    be able to see that the 4-second-delay request will successfully obtain a response,
    while the 20-second-delay one will not.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的URL列表中，有一个请求需要4秒，另一个需要20秒，除了那些可以立即响应的请求。由于我们使用的超时阈值是5秒，理论上，我们应该能够看到4秒延迟的请求将成功获得响应，而20秒延迟的那个则不会。
- en: 'There is another point to be made about this program: `process_requests()`
    function, if the timeout threshold is passed while there is still at least one
    thread being processed, then the function will proceed to print out the `result`
    attribute of each thread:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个程序，还有另一点需要注意：如果`process_requests()`函数在仍有至少一个线程正在处理时传递了超时阈值，那么该函数将继续打印出每个线程的`result`属性：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This means that we do not block our program until all of the threads have finished
    their execution by using the `join()` function, which means the program can simply
    move forward if the timeout threshold is reached. However, this also means that
    the threads themselves do not terminate at this point. The 20-second-delay request,
    specifically, will still most likely be running after our program exits out of
    the `process_requests()` function.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不是通过使用`join()`函数来阻塞程序，直到所有线程都完成执行，这意味着如果达到超时阈值，程序可以简单地继续前进。然而，这也意味着线程本身在这个点并没有终止。具体来说，20秒延迟的请求，在程序退出`process_requests()`函数后，仍然很可能会继续运行。
- en: If the thread that's processing this request is not a daemon thread (as we know,
    daemon threads execute in the background and never terminate), it will block the
    main program from finishing until the thread itself finishes. By making this thread,
    and any other thread, a daemon thread, we allow the main program to finish as
    soon as it executes the last line of its instructions, even if there are threads
    still running.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理这个请求的线程不是一个守护线程（正如我们所知，守护线程在后台执行且永远不会终止），它将阻塞主程序完成，直到线程本身完成。通过将这个线程以及任何其他线程变成守护线程，我们允许主程序在执行完最后一条指令后立即完成，即使还有线程正在运行。
- en: 'Let''s see this program in action. Execute this code; your output should be
    similar to the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个程序的实际运行情况。执行这段代码；你的输出应该类似于以下内容：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, it took around 5 seconds for our program to finish this time.
    This is because it spent 5 seconds waiting for the threads that were still running
    and, as soon as the 5-second threshold was passed, the program printed out the
    results. Here, we can see that the result from the 20-second-delay request was
    simply the default value of the `result` attribute of the `MyThread` class, while
    the rest of the requests were able to obtain the correct response from the server
    (including the 4-second-delay request since it had enough time to obtain the response).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的程序这次完成大约花了5秒钟。这是因为它花了5秒钟等待仍在运行的线程，一旦超过5秒的阈值，程序就打印出了结果。在这里，我们可以看到20秒延迟请求的结果只是`MyThread`类的`result`属性的默认值，而其他请求都能够从服务器获得正确的响应（包括4秒延迟请求，因为它有足够的时间获得响应）。
- en: 'If you would like to see the effect of non-daemon threads, which we discussed
    earlier, simply comment out the corresponding line of code in our main program,
    as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想看到我们之前讨论的非守护线程的效果，只需在我们的主程序中注释掉相应的代码行，如下所示：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You will see that the main program will hang for around 20 seconds as the non-daemon
    thread processing the 20-second-delay request is still running, before being able
    to finish its execution (even though the output that's produced will be identical).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到主程序将挂起大约20秒，因为处理20秒延迟请求的非守护线程仍在运行，然后才能完成其执行（尽管产生的输出将是相同的）。
- en: Good practices in making web requests
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制作网络请求的良好实践
- en: There are a few aspects of making concurrent web requests that require careful
    consideration and implementation. In this section, we will be going over those
    aspects and some of the best practices that you should use when developing your
    applications.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在制作并发网络请求时，有几个方面需要仔细考虑和实施。在本节中，我们将讨论这些方面以及你在开发应用程序时应使用的最佳实践。
- en: Consider the terms of service and data-collecting policies
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑服务条款和数据收集政策
- en: Unauthorized data collection has been the topic of discussion in the technology
    world for the past few years, and it will continue to be for a long time – and
    for good reasons too. So, it is extremely important for developers who are making
    automated web requests in their applications to look for websites' policies on
    data collecting. You can find these policies in their terms of service or similar
    documents. When in doubt, it is generally a good rule of thumb to contact the
    website directly to ask for more details.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年中，未经授权的数据收集一直是科技界的讨论话题，并且这种情况还将持续很长时间——而且有很好的理由。因此，对于在应用程序中制作自动化网络请求的开发者来说，查找网站关于数据收集的政策至关重要。你可以在他们的服务条款或类似文件中找到这些政策。如果有疑问，通常直接联系网站以获取更多详细信息是一个很好的规则。
- en: Error handling
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误处理
- en: Errors are something that no one can easily avoid in the field of programming,
    and this is especially true when making web requests. Errors in these programs
    can include making bad requests (invalid requests or even bad internet connections),
    mishandling downloaded HTML code, or unsuccessfully parsing HTML code. So, it
    is important to make use of `try...except` blocks and other error-handling tools
    in Python to avoid crashing your application. Avoiding crashes is especially important
    if your code/applications are used in production and larger applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程领域，错误是任何人都难以轻易避免的，尤其是在进行网络请求时。这些程序中的错误可能包括发出不良请求（无效请求或甚至糟糕的互联网连接）、处理下载的HTML代码不当，或者解析HTML代码失败。因此，使用Python中的`try...except`块和其他错误处理工具来避免应用程序崩溃是非常重要的。如果你的代码/应用程序在生产环境中使用，或者用于更大的应用程序，避免崩溃尤为重要。
- en: Specifically, in concurrent web scraping, it might be possible for some threads
    to collect data successfully, while others fail. By implementing error-handling
    functionalities in multithreaded parts of your program, you can make sure that
    a failed thread will not be able to crash the entirety of your program and ensure
    that successful threads can still return their results.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，在并发网络爬取中，一些线程可能成功收集数据，而其他线程则失败。通过在程序的多线程部分实现错误处理功能，你可以确保失败的线程不会使整个程序崩溃，并确保成功的线程仍然可以返回其结果。
- en: However, it is important to note that `try...except` block in our program that
    will catch all errors that occur in the program's execution, and no further information
    regarding the errors can be obtained; this practice is also known as error swallowing.
    It's highly recommended that you have some specific error handling code in a program
    so that not only can appropriate actions be taken with regards to that specific
    error, but other errors that have not been taken into account might also reveal
    themselves.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，我们程序中的`try...except`块将捕获程序执行过程中发生的所有错误，并且无法获得有关错误的更多信息；这种做法也被称为错误吞没。强烈建议你在程序中添加一些特定的错误处理代码，这样不仅可以针对特定错误采取适当的行动，而且可能也会揭示出尚未考虑到的其他错误。
- en: Update your program regularly
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定期更新你的程序
- en: It is quite common for websites to change their request-handling logic, as well
    as their displayed data, regularly. If a program that makes requests to a website
    has considerably inflexible logic to interact with the server of the website (for
    example, structuring its requests in a specific format, only handling one kind
    of response, and so on), then if and when the website alters the way it handles
    its client requests, the program will most likely stop functioning correctly.
    This situation happens frequently with web scraping programs that look for data
    in specific HTML tags; when the HTML tags are changed, these programs will fail
    to find their data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 网站定期更改其请求处理逻辑以及显示的数据是很常见的。如果一个向网站发送请求的程序在与网站服务器交互时逻辑相当不灵活（例如，以特定格式结构化其请求，只处理一种类型的响应等），那么如果网站更改了处理客户端请求的方式，该程序很可能会停止正确运行。这种情况在寻找特定HTML标签中的数据的网络爬虫程序中经常发生；当HTML标签更改时，这些程序将无法找到它们的数据。
- en: This practice is implemented to prevent automated data collecting programs from
    functioning. The only way to keep using a website that has recently changed its
    request-handling logic is to analyze the updated protocols and alter our programs
    accordingly.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这种做法是为了防止自动化数据收集程序运行。要继续使用最近更改了请求处理逻辑的网站，唯一的方法是分析更新的协议并相应地修改我们的程序。
- en: Avoid making a large number of requests
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免大量请求
- en: Each time one of the programs that we have been discussing runs, it makes HTTP
    requests to a server that manages the site that you'd like to extract data from.
    This process happens significantly more frequently and over a shorter amount of
    time in a concurrent program, where multiple requests are being submitted to that
    server.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们讨论的程序运行时，它都会向管理您想要提取数据的网站的服务器发送HTTP请求。在并发程序中，这个过程发生得更加频繁，并且时间更短，因为多个请求正在提交到该服务器。
- en: As we mentioned previously, servers nowadays can handle multiple requests simultaneously
    with ease. However, to avoid having to overwork and overconsume resources, servers
    are also designed to stop answering requests that come in too frequently. The
    websites of big tech companies, such as Amazon or Twitter, look for large amounts
    of automated requests that are made from the same IP address and implement different
    response protocols; some requests might be delayed, some might be refused a response,
    or the IP address might even be banned from making further requests for a specific
    amount of time.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，现在的服务器可以轻松地同时处理多个请求。然而，为了避免过度工作并过度消耗资源，服务器也被设计为停止回答过于频繁到来的请求。像亚马逊或Twitter这样的大科技公司网站会寻找来自同一IP地址的大量自动化请求，并实施不同的响应协议；一些请求可能会延迟，一些请求可能会被拒绝响应，或者IP地址甚至可能被禁止在一段时间内进一步发送请求。
- en: 'Interestingly, making repeated, heavy-duty requests to servers is a form of
    hacking a website. In **Denial of Service** (**DoS**) and **Distributed Denial
    of Service** (**DDoS**) attacks, a very large number of requests are made at the
    same time to the server, flooding the bandwidth of the targeted server with traffic.
    As a result, normal, non-malicious requests from other clients are denied because
    the servers are busy processing the concurrent requests, as illustrated in the
    following diagram:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，向服务器发送重复的、大量请求是一种黑客攻击网站的方式。在**拒绝服务**（**DoS**）和**分布式拒绝服务**（**DDoS**）攻击中，同时向服务器发送大量请求，用流量淹没目标服务器的带宽。结果，来自其他客户端的正常、非恶意请求被拒绝，因为服务器正忙于处理并发请求，如下面的图所示：
- en: '![Figure 9.5 – Illustration of a DDoS attack ](img/Figure_9.5_B17499.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图9.5 – DDoS攻击的示意图](img/Figure_9.5_B17499.jpg)'
- en: Figure 9.5 – Illustration of a DDoS attack
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 – DDoS攻击的示意图
- en: So, it is important to space out the concurrent requests that your application
    makes to a server so that the application will not be considered an attacker and
    be potentially banned or treated as a malicious client. This could be as simple
    as limiting the maximum number of threads/requests that can be implemented at
    a time in your program or pausing the threading for a specific amount of time
    (for example, using the `time.sleep()` function) before sending a request to the
    server.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为避免应用程序被视为攻击者并可能被禁止或被视为恶意客户端，重要的是要分散应用程序对服务器发出的并发请求。这可以简单到限制程序中一次可以实施的最大线程/请求数量，或者在使用`time.sleep()`函数暂停一段时间（例如，在向服务器发送请求之前）。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the basics of HTML and web requests. The two
    most common web requests are `GET` and `POST` requests. There are five main categories
    of HTTP response status codes, each indicating a different concept regarding the
    communication between the server and its client. By considering the status codes
    that are received from different websites, we can write a ping test application
    that effectively checks the responsiveness of those websites.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了HTML和网络请求的基础知识。最常用的两种网络请求是`GET`和`POST`请求。HTTP响应状态码有五大类，每类都表示服务器与其客户端之间通信的不同概念。通过考虑从不同网站接收到的状态码，我们可以编写一个ping测试应用程序，有效地检查这些网站的响应性。
- en: Concurrency can be applied to the problem of making multiple web requests simultaneously
    via threading to provide a significant improvement in application speed. However,
    it is important to keep several considerations in mind when making concurrent
    web requests.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 并发可以通过多线程同时制作多个网络请求，从而显著提高应用程序的速度。然而，在制作并发网络请求时，需要考虑几个因素。
- en: All in all, the exercise we just went through in this chapter will prove useful
    in helping us approach the general problem of converting a sequential program
    into its concurrent version. The simple ping test that we have built could also
    be extended to have more complex behaviors and functionalities. In the next chapter,
    we will consider a similar procedure for the application of image processing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，本章中我们刚刚进行的练习将有助于我们解决将顺序程序转换为并发版本的一般问题。我们构建的简单ping测试也可以扩展以具有更复杂的行为和功能。在下一章中，我们将考虑一个类似的过程来应用图像处理。
- en: Questions
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is HTML?
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是HTML？
- en: What are HTTP requests?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是HTTP请求？
- en: What are HTTP response status codes?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是HTTP响应状态码？
- en: How does the `requests` module help with making web requests?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`requests`模块是如何帮助制作网络请求的？'
- en: What is a ping test and how is one typically designed?
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是ping测试以及通常是如何设计的？
- en: Why is concurrency applicable in making web requests?
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么并发适用于制作网络请求？
- en: What are the considerations that need to be made while developing applications
    that make concurrent web requests?
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开发制作并发网络请求的应用程序时，需要考虑哪些因素？
- en: Further reading
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Automate the Boring Stuff with Python: Practical Programming for Total Beginners*,
    Al. Sweigart, No Starch Press, 2015'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《用Python自动化无聊的事情：适合完全初学者的实用编程》*，艾尔·斯威加特，No Starch Press，2015'
- en: '*Web Scraping with Python*, Richard Lawson, Packt Publishing Ltd, 2015'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《使用Python进行网络爬取》*，理查德·劳森，Packt Publishing Ltd，2015'
- en: '*Instant Web Scraping with Java*, Ryan Mitchell, Packt Publishing Ltd, 2013'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《Java快速网络爬取》*，瑞安·米切尔，Packt Publishing Ltd，2013'
